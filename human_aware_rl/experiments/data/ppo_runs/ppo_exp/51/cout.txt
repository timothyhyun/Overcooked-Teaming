INFO - PPO - Running command 'ppo_run'
INFO - PPO - Started run with ID "51"
Creating env with params {'RUN_TYPE': 'ppo', 'SEEDS': [9456, 1887, 5578, 5987, 516], 'LOCAL_TESTING': False, 'EX_NAME': 'dispenser_side_specific_ppo_bc_train_random0_test2', 'SAVE_DIR': 'data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/', 'GPU_ID': 0, 'PPO_RUN_TOT_TIMESTEPS': 9000000.0, 'mdp_params': {'layout_name': 'random0', 'start_order_list': None, 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}}, 'env_params': {'horizon': 400}, 'mdp_generation_params': {'padded_mdp_shape': [11, 7], 'mdp_shape_fn': [[5, 11], [5, 7]], 'prop_empty_fn': [0.6, 1], 'prop_feats_fn': [0, 0.6]}, 'ENTROPY': 0.1, 'GAMMA': 0.99, 'sim_threads': 30, 'TOTAL_BATCH_SIZE': 12000, 'BATCH_SIZE': 400, 'MAX_GRAD_NORM': 0.1, 'LR': 0.0015, 'LR_ANNEALING': 2, 'VF_COEF': 0.1, 'STEPS_PER_UPDATE': 8, 'MINIBATCHES': 15, 'CLIPPING': 0.05, 'LAM': 0.98, 'SELF_PLAY_HORIZON': None, 'REW_SHAPING_HORIZON': 4000000.0, 'OTHER_AGENT_TYPE': 'bc_train', 'HM_PARAMS': [True, 0.3], 'NUM_HIDDEN_LAYERS': 3, 'SIZE_HIDDEN_LAYERS': 64, 'NUM_FILTERS': 25, 'NUM_CONV_LAYERS': 3, 'NETWORK_TYPE': 'conv_and_mlp', 'SAVE_BEST_THRESH': 50, 'TRAJECTORY_SELF_PLAY': True, 'VIZ_FREQUENCY': 50, 'grad_updates_per_agent': 90000.0}
Computing MediumLevelPlanner to be saved in /home/mzhao2/overcooked-teaming/overcooked_ai/overcooked_ai_py/data/planners/random0_am.pkl
It took 0.03898906707763672 seconds to create mlp
LOADING BC MODEL FROM: random0_bc_train_seed0
Loading a model without an environment, this model cannot be trained until it has a valid environment.
WARNING:tensorflow:From /home/mzhao2/anaconda3/envs/harl-gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING - tensorflow - From /home/mzhao2/anaconda3/envs/harl-gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/mzhao2/overcooked-teaming/stable-baselines/stable_baselines/common/policies.py:436: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING - tensorflow - From /home/mzhao2/overcooked-teaming/stable-baselines/stable_baselines/common/policies.py:436: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/mzhao2/anaconda3/envs/harl-gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING - tensorflow - From /home/mzhao2/anaconda3/envs/harl-gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /home/mzhao2/anaconda3/envs/harl-gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
WARNING - tensorflow - From /home/mzhao2/anaconda3/envs/harl-gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Mlp with different params or mdp found, computing from scratch
Computing MediumLevelPlanner to be saved in /home/mzhao2/overcooked-teaming/overcooked_ai/overcooked_ai_py/data/planners/random0_am.pkl
It took 0.03537130355834961 seconds to create mlp
NETWORK TYPE conv_and_mlp



Network conv_and_mlp 



WARNING:tensorflow:From /home/mzhao2/overcooked-teaming/baselines/baselines/common/input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING - tensorflow - From /home/mzhao2/overcooked-teaming/baselines/baselines/common/input.py:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
(30, 5, 5, 20)
WARNING:tensorflow:From ../../human_aware_rl/baselines_utils.py:127: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv2d instead.
WARNING - tensorflow - From ../../human_aware_rl/baselines_utils.py:127: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.conv2d instead.
WARNING:tensorflow:From ../../human_aware_rl/baselines_utils.py:143: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING - tensorflow - From ../../human_aware_rl/baselines_utils.py:143: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
Last layer conv network output shape (30, 64)
(800, 5, 5, 20)
Last layer conv network output shape (800, 64)
TOT NUM UPDATES 0



Network conv_and_mlp 



TOT NUM UPDATES 750
SP envs: 0/30
Other agent actions took 4.344166278839111 seconds
Total simulation time for 400 steps: 7.353402614593506 	 Other agent action time: 0 	 54.396586310419494 steps/s
Curr learning rate 0.0015 	 Curr reward per step 0.01825

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  20%|██        | 3/15 [00:00<00:00, 29.52it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 89.36it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.50it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.79it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.63it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.16it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.57it/s]
Logging to /tmp/openai-2021-08-16-19-10-15-747639
--------------------------------------
| approxkl           | 0.00068471185 |
| clipfrac           | 0.055708345   |
| eplenmean          | 400           |
| eprewmean          | 7.3           |
| explained_variance | 0.00443       |
| fps                | 1474          |
| nupdates           | 1             |
| policy_entropy     | 1.7910863     |
| policy_loss        | -0.0016403112 |
| serial_timesteps   | 400           |
| time_elapsed       | 8.14          |
| time_remaining     | 102           |
| total_timesteps    | 12000         |
| true_eprew         | 0             |
| value_loss         | 0.6019348     |
--------------------------------------
Current reward shaping 0.997
SP envs: 0/30
Other agent actions took 4.607993841171265 seconds
Total simulation time for 400 steps: 7.492652893066406 	 Other agent action time: 0 	 53.385630658288505 steps/s
Curr learning rate 0.001499 	 Curr reward per step 0.019192250000000008

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.28it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.88it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.59it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.63it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.83it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.35it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.74it/s]
--------------------------------------
| approxkl           | 0.0006061134  |
| clipfrac           | 0.06598958    |
| eplenmean          | 400           |
| eprewmean          | 7.49          |
| explained_variance | -0.000193     |
| fps                | 1462          |
| nupdates           | 2             |
| policy_entropy     | 1.7895528     |
| policy_loss        | -0.0022856356 |
| serial_timesteps   | 800           |
| time_elapsed       | 16.3          |
| time_remaining     | 102           |
| total_timesteps    | 24000         |
| true_eprew         | 0             |
| value_loss         | 0.61650604    |
--------------------------------------
Current reward shaping 0.994
SP envs: 0/30
Other agent actions took 4.478398323059082 seconds
Total simulation time for 400 steps: 7.480157136917114 	 Other agent action time: 0 	 53.474812450912864 steps/s
Curr learning rate 0.001498 	 Curr reward per step 0.025854000000000002

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.30it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.89it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.29it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.00it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.62it/s]
--------------------------------------
| approxkl           | 0.0005141694  |
| clipfrac           | 0.10200002    |
| eplenmean          | 400           |
| eprewmean          | 8.44          |
| explained_variance | 0.00276       |
| fps                | 1463          |
| nupdates           | 3             |
| policy_entropy     | 1.787917      |
| policy_loss        | -0.0022976832 |
| serial_timesteps   | 1200          |
| time_elapsed       | 24.5          |
| time_remaining     | 102           |
| total_timesteps    | 36000         |
| true_eprew         | 0.222         |
| value_loss         | 1.1798168     |
--------------------------------------
Current reward shaping 0.991
SP envs: 0/30
Other agent actions took 4.519073486328125 seconds
Total simulation time for 400 steps: 7.718563795089722 	 Other agent action time: 0 	 51.82311251407495 steps/s
Curr learning rate 0.001497 	 Curr reward per step 0.023784

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 184.69it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 183.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.00it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.31it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 197.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.63it/s]
--------------------------------------
| approxkl           | 0.0005268137  |
| clipfrac           | 0.108083345   |
| eplenmean          | 400           |
| eprewmean          | 8.95          |
| explained_variance | 0.00795       |
| fps                | 1431          |
| nupdates           | 4             |
| policy_entropy     | 1.7858334     |
| policy_loss        | -0.0033585327 |
| serial_timesteps   | 1600          |
| time_elapsed       | 32.9          |
| time_remaining     | 102           |
| total_timesteps    | 48000         |
| true_eprew         | 0.2           |
| value_loss         | 0.8259624     |
--------------------------------------
Current reward shaping 0.988
SP envs: 0/30
Other agent actions took 4.458422422409058 seconds
Total simulation time for 400 steps: 7.676737070083618 	 Other agent action time: 0 	 52.10547089841167 steps/s
Curr learning rate 0.001496 	 Curr reward per step 0.031923

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.09it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.36it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.39it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.63it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.28it/s]
-------------------------------------
| approxkl           | 0.0007772758 |
| clipfrac           | 0.16346875   |
| eplenmean          | 400          |
| eprewmean          | 10.4         |
| explained_variance | 0.0111       |
| fps                | 1431         |
| nupdates           | 5            |
| policy_entropy     | 1.7836536    |
| policy_loss        | -0.004154106 |
| serial_timesteps   | 2000         |
| time_elapsed       | 41.3         |
| time_remaining     | 103          |
| total_timesteps    | 60000        |
| true_eprew         | 0.8          |
| value_loss         | 2.0178292    |
-------------------------------------
Current reward shaping 0.985
SP envs: 0/30
Other agent actions took 4.514375448226929 seconds
Total simulation time for 400 steps: 7.737449407577515 	 Other agent action time: 0 	 51.69662235313204 steps/s
Curr learning rate 0.001495 	 Curr reward per step 0.030206666666666663

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.39it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.15it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.44it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.62it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.33it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.32it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.36it/s]
--------------------------------------
| approxkl           | 0.0008912209  |
| clipfrac           | 0.21164583    |
| eplenmean          | 400           |
| eprewmean          | 11.3          |
| explained_variance | 0.0335        |
| fps                | 1422          |
| nupdates           | 6             |
| policy_entropy     | 1.7801961     |
| policy_loss        | -0.0047323923 |
| serial_timesteps   | 2400          |
| time_elapsed       | 49.8          |
| time_remaining     | 103           |
| total_timesteps    | 72000         |
| true_eprew         | 0.6           |
| value_loss         | 1.0451789     |
--------------------------------------
Current reward shaping 0.982
SP envs: 0/30
Other agent actions took 4.453053951263428 seconds
Total simulation time for 400 steps: 7.6771080493927 	 Other agent action time: 0 	 52.10295301648674 steps/s
Curr learning rate 0.001494 	 Curr reward per step 0.03265150000000001

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.83it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.10it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.03it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.74it/s]
--------------------------------------
| approxkl           | 0.00096797704 |
| clipfrac           | 0.21894793    |
| eplenmean          | 400           |
| eprewmean          | 12.1          |
| explained_variance | 0.0477        |
| fps                | 1433          |
| nupdates           | 7             |
| policy_entropy     | 1.7780061     |
| policy_loss        | -0.0054161632 |
| serial_timesteps   | 2800          |
| time_elapsed       | 58.1          |
| time_remaining     | 103           |
| total_timesteps    | 84000         |
| true_eprew         | 0.6           |
| value_loss         | 1.1104957     |
--------------------------------------
Current reward shaping 0.979
SP envs: 0/30
Other agent actions took 4.4975714683532715 seconds
Total simulation time for 400 steps: 7.722558975219727 	 Other agent action time: 0 	 51.79630240229004 steps/s
Curr learning rate 0.001493 	 Curr reward per step 0.039276583333333344

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.73it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.80it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.59it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.34it/s]
-------------------------------------
| approxkl           | 0.0011502159 |
| clipfrac           | 0.24990621   |
| eplenmean          | 400          |
| eprewmean          | 13.5         |
| explained_variance | 0.0511       |
| fps                | 1423         |
| nupdates           | 8            |
| policy_entropy     | 1.7742165    |
| policy_loss        | -0.0062549   |
| serial_timesteps   | 3200         |
| time_elapsed       | 66.6         |
| time_remaining     | 103          |
| total_timesteps    | 96000        |
| true_eprew         | 0.4          |
| value_loss         | 1.7621131    |
-------------------------------------
Current reward shaping 0.976
SP envs: 0/30
Other agent actions took 4.521138429641724 seconds
Total simulation time for 400 steps: 7.712817668914795 	 Other agent action time: 0 	 51.861721250345674 steps/s
Curr learning rate 0.0014919999999999998 	 Curr reward per step 0.04830933333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.47it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.37it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.67it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.13it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.03it/s]
-------------------------------------
| approxkl           | 0.0012884474 |
| clipfrac           | 0.2825313    |
| eplenmean          | 400          |
| eprewmean          | 15.8         |
| explained_variance | 0.0442       |
| fps                | 1426         |
| nupdates           | 9            |
| policy_entropy     | 1.7690045    |
| policy_loss        | -0.006592787 |
| serial_timesteps   | 3600         |
| time_elapsed       | 75           |
| time_remaining     | 103          |
| total_timesteps    | 108000       |
| true_eprew         | 1            |
| value_loss         | 3.123132     |
-------------------------------------
Current reward shaping 0.973
SP envs: 0/30
Other agent actions took 4.497602224349976 seconds
Total simulation time for 400 steps: 7.771537780761719 	 Other agent action time: 0 	 51.46986494618758 steps/s
Curr learning rate 0.0014910000000000001 	 Curr reward per step 0.05048775

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 181.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.75it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.55it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.45it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.25it/s]
-------------------------------------
| approxkl           | 0.0015953127 |
| clipfrac           | 0.31125      |
| eplenmean          | 400          |
| eprewmean          | 18.1         |
| explained_variance | 0.0822       |
| fps                | 1415         |
| nupdates           | 10           |
| policy_entropy     | 1.7605137    |
| policy_loss        | -0.00587605  |
| serial_timesteps   | 4000         |
| time_elapsed       | 83.5         |
| time_remaining     | 103          |
| total_timesteps    | 120000       |
| true_eprew         | 1.6          |
| value_loss         | 2.762182     |
-------------------------------------
Current reward shaping 0.97
SP envs: 0/30
Other agent actions took 4.439223289489746 seconds
Total simulation time for 400 steps: 7.654154062271118 	 Other agent action time: 0 	 52.25920418452006 steps/s
Curr learning rate 0.00149 	 Curr reward per step 0.04868083333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.45it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.42it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 201.51it/s]
--------------------------------------
| approxkl           | 0.0016757168  |
| clipfrac           | 0.32152075    |
| eplenmean          | 400           |
| eprewmean          | 19.1          |
| explained_variance | 0.0756        |
| fps                | 1438          |
| nupdates           | 11            |
| policy_entropy     | 1.7560624     |
| policy_loss        | -0.0063105808 |
| serial_timesteps   | 4400          |
| time_elapsed       | 91.8          |
| time_remaining     | 103           |
| total_timesteps    | 132000        |
| true_eprew         | 1.8           |
| value_loss         | 2.4314418     |
--------------------------------------
Current reward shaping 0.967
SP envs: 0/30
Other agent actions took 4.4582414627075195 seconds
Total simulation time for 400 steps: 7.726147413253784 	 Other agent action time: 0 	 51.77224541610762 steps/s
Curr learning rate 0.0014889999999999999 	 Curr reward per step 0.06162833333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 182.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.00it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.27it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.31it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.39it/s]
--------------------------------------
| approxkl           | 0.0018554694  |
| clipfrac           | 0.3409062     |
| eplenmean          | 400           |
| eprewmean          | 21.4          |
| explained_variance | 0.0707        |
| fps                | 1430          |
| nupdates           | 12            |
| policy_entropy     | 1.7515912     |
| policy_loss        | -0.0064733815 |
| serial_timesteps   | 4800          |
| time_elapsed       | 100           |
| time_remaining     | 103           |
| total_timesteps    | 144000        |
| true_eprew         | 2.8           |
| value_loss         | 4.626966      |
--------------------------------------
Current reward shaping 0.964
SP envs: 0/30
Other agent actions took 4.525194883346558 seconds
Total simulation time for 400 steps: 7.765800952911377 	 Other agent action time: 0 	 51.5078872643576 steps/s
Curr learning rate 0.0014880000000000002 	 Curr reward per step 0.07171533333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.45it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.81it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.34it/s]
--------------------------------------
| approxkl           | 0.002123285   |
| clipfrac           | 0.36009368    |
| eplenmean          | 400           |
| eprewmean          | 24.3          |
| explained_variance | 0.0618        |
| fps                | 1415          |
| nupdates           | 13            |
| policy_entropy     | 1.7434903     |
| policy_loss        | -0.0074891015 |
| serial_timesteps   | 5200          |
| time_elapsed       | 109           |
| time_remaining     | 103           |
| total_timesteps    | 156000        |
| true_eprew         | 4             |
| value_loss         | 5.635514      |
--------------------------------------
Current reward shaping 0.961
SP envs: 0/30
Other agent actions took 4.515603542327881 seconds
Total simulation time for 400 steps: 7.788286209106445 	 Other agent action time: 0 	 51.35918085962229 steps/s
Curr learning rate 0.001487 	 Curr reward per step 0.06995225000000001

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.45it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.08it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.68it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.14it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.19it/s]
--------------------------------------
| approxkl           | 0.0020188894  |
| clipfrac           | 0.3587812     |
| eplenmean          | 400           |
| eprewmean          | 26.3          |
| explained_variance | 0.0818        |
| fps                | 1412          |
| nupdates           | 14            |
| policy_entropy     | 1.7406647     |
| policy_loss        | -0.0067577106 |
| serial_timesteps   | 5600          |
| time_elapsed       | 117           |
| time_remaining     | 103           |
| total_timesteps    | 168000        |
| true_eprew         | 4.8           |
| value_loss         | 5.4171853     |
--------------------------------------
Current reward shaping 0.958
SP envs: 0/30
Other agent actions took 4.573927879333496 seconds
Total simulation time for 400 steps: 7.918595552444458 	 Other agent action time: 0 	 50.51400811555789 steps/s
Curr learning rate 0.001486 	 Curr reward per step 0.06594350000000002

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.68it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.33it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.72it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.47it/s]
--------------------------------------
| approxkl           | 0.002269302   |
| clipfrac           | 0.37980214    |
| eplenmean          | 400           |
| eprewmean          | 27.6          |
| explained_variance | 0.111         |
| fps                | 1391          |
| nupdates           | 15            |
| policy_entropy     | 1.7342404     |
| policy_loss        | -0.0059529636 |
| serial_timesteps   | 6000          |
| time_elapsed       | 126           |
| time_remaining     | 103           |
| total_timesteps    | 180000        |
| true_eprew         | 5.6           |
| value_loss         | 5.4477005     |
--------------------------------------
Current reward shaping 0.955
SP envs: 0/30
Other agent actions took 4.665064811706543 seconds
Total simulation time for 400 steps: 7.986030101776123 	 Other agent action time: 0 	 50.08746459784049 steps/s
Curr learning rate 0.001485 	 Curr reward per step 0.09087666666666669

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.74it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.87it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.05it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.66it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.60it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.34it/s]
-------------------------------------
| approxkl           | 0.002484861  |
| clipfrac           | 0.3853958    |
| eplenmean          | 400          |
| eprewmean          | 30.2         |
| explained_variance | 0.0537       |
| fps                | 1378         |
| nupdates           | 16           |
| policy_entropy     | 1.725866     |
| policy_loss        | -0.006296494 |
| serial_timesteps   | 6400         |
| time_elapsed       | 134          |
| time_remaining     | 103          |
| total_timesteps    | 192000       |
| true_eprew         | 7.6          |
| value_loss         | 10.550464    |
-------------------------------------
Current reward shaping 0.952
SP envs: 0/30
Other agent actions took 4.510976791381836 seconds
Total simulation time for 400 steps: 7.762463331222534 	 Other agent action time: 0 	 51.53003407965893 steps/s
Curr learning rate 0.001484 	 Curr reward per step 0.09640333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 192.65it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 183.22it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.97it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.31it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.00it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.15it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.13it/s]
--------------------------------------
| approxkl           | 0.0025707444  |
| clipfrac           | 0.38528123    |
| eplenmean          | 400           |
| eprewmean          | 33.4          |
| explained_variance | 0.0838        |
| fps                | 1421          |
| nupdates           | 17            |
| policy_entropy     | 1.7218052     |
| policy_loss        | -0.0055672405 |
| serial_timesteps   | 6800          |
| time_elapsed       | 143           |
| time_remaining     | 103           |
| total_timesteps    | 204000        |
| true_eprew         | 10            |
| value_loss         | 10.628384     |
--------------------------------------
Current reward shaping 0.949
SP envs: 0/30
Other agent actions took 4.562632322311401 seconds
Total simulation time for 400 steps: 7.862883567810059 	 Other agent action time: 0 	 50.871922056376896 steps/s
Curr learning rate 0.001483 	 Curr reward per step 0.09604641666666663

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.11it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.16it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.39it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.01it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.74it/s]
--------------------------------------
| approxkl           | 0.002856022   |
| clipfrac           | 0.40510422    |
| eplenmean          | 400           |
| eprewmean          | 36.1          |
| explained_variance | 0.118         |
| fps                | 1404          |
| nupdates           | 18            |
| policy_entropy     | 1.7134857     |
| policy_loss        | -0.0066716326 |
| serial_timesteps   | 7200          |
| time_elapsed       | 151           |
| time_remaining     | 103           |
| total_timesteps    | 216000        |
| true_eprew         | 12            |
| value_loss         | 10.768278     |
--------------------------------------
Current reward shaping 0.946
SP envs: 0/30
Other agent actions took 4.552668809890747 seconds
Total simulation time for 400 steps: 7.825152397155762 	 Other agent action time: 0 	 51.117215320354596 steps/s
Curr learning rate 0.001482 	 Curr reward per step 0.12197483333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 181.89it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 187.97it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.10it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.71it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.35it/s]
--------------------------------------
| approxkl           | 0.0032498925  |
| clipfrac           | 0.43621877    |
| eplenmean          | 400           |
| eprewmean          | 41.4          |
| explained_variance | 0.0786        |
| fps                | 1408          |
| nupdates           | 19            |
| policy_entropy     | 1.6972027     |
| policy_loss        | -0.0063290084 |
| serial_timesteps   | 7600          |
| time_elapsed       | 160           |
| time_remaining     | 103           |
| total_timesteps    | 228000        |
| true_eprew         | 15.2          |
| value_loss         | 15.830447     |
--------------------------------------
Current reward shaping 0.943
SP envs: 0/30
Other agent actions took 4.571252107620239 seconds
Total simulation time for 400 steps: 7.818478584289551 	 Other agent action time: 0 	 51.16084871086811 steps/s
Curr learning rate 0.0014810000000000001 	 Curr reward per step 0.12020425

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.57it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.57it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.36it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.85it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.57it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.41it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.31it/s]
--------------------------------------
| approxkl           | 0.003362466   |
| clipfrac           | 0.4390105     |
| eplenmean          | 400           |
| eprewmean          | 44.3          |
| explained_variance | 0.114         |
| fps                | 1407          |
| nupdates           | 20            |
| policy_entropy     | 1.6920037     |
| policy_loss        | -0.0045525935 |
| serial_timesteps   | 8000          |
| time_elapsed       | 169           |
| time_remaining     | 103           |
| total_timesteps    | 240000        |
| true_eprew         | 16.6          |
| value_loss         | 15.38836      |
--------------------------------------
Current reward shaping 0.94
SP envs: 0/30
Other agent actions took 4.632322311401367 seconds
Total simulation time for 400 steps: 7.958803415298462 	 Other agent action time: 0 	 50.25881142272185 steps/s
Curr learning rate 0.00148 	 Curr reward per step 0.13061333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.87it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.86it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.70it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.16it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.63it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.83it/s]
--------------------------------------
| approxkl           | 0.0030005462  |
| clipfrac           | 0.417302      |
| eplenmean          | 400           |
| eprewmean          | 48.6          |
| explained_variance | 0.104         |
| fps                | 1386          |
| nupdates           | 21            |
| policy_entropy     | 1.6855935     |
| policy_loss        | -0.0037243275 |
| serial_timesteps   | 8400          |
| time_elapsed       | 177           |
| time_remaining     | 103           |
| total_timesteps    | 252000        |
| true_eprew         | 19.6          |
| value_loss         | 17.41708      |
--------------------------------------
Current reward shaping 0.937
SP envs: 0/30
Other agent actions took 4.571176767349243 seconds
Total simulation time for 400 steps: 7.850947141647339 	 Other agent action time: 0 	 50.949266729627894 steps/s
Curr learning rate 0.001479 	 Curr reward per step 0.12954266666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 192.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 194.50it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 194.34it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 195.19it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 198.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.52it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.52it/s]
--------------------------------------
| approxkl           | 0.003158904   |
| clipfrac           | 0.41969803    |
| eplenmean          | 400           |
| eprewmean          | 50            |
| explained_variance | 0.125         |
| fps                | 1413          |
| nupdates           | 22            |
| policy_entropy     | 1.6709206     |
| policy_loss        | -0.0048142993 |
| serial_timesteps   | 8800          |
| time_elapsed       | 186           |
| time_remaining     | 102           |
| total_timesteps    | 264000        |
| true_eprew         | 20.4          |
| value_loss         | 17.22976      |
--------------------------------------
Current reward shaping 0.9339999999999999
SP envs: 0/30
Other agent actions took 4.518950939178467 seconds
Total simulation time for 400 steps: 7.742482662200928 	 Other agent action time: 0 	 51.66301526935463 steps/s
Curr learning rate 0.0014780000000000001 	 Curr reward per step 0.131808

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.92it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.64it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 196.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.34it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.66it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.99it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.28it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.50it/s]
--------------------------------------
| approxkl           | 0.0030881914  |
| clipfrac           | 0.41382286    |
| eplenmean          | 400           |
| eprewmean          | 50.7          |
| explained_variance | 0.118         |
| fps                | 1427          |
| nupdates           | 23            |
| policy_entropy     | 1.6744964     |
| policy_loss        | -0.0042144675 |
| serial_timesteps   | 9200          |
| time_elapsed       | 194           |
| time_remaining     | 102           |
| total_timesteps    | 276000        |
| true_eprew         | 21.4          |
| value_loss         | 18.014757     |
--------------------------------------
Current reward shaping 0.931
SP envs: 0/30
Other agent actions took 4.520937919616699 seconds
Total simulation time for 400 steps: 7.86875581741333 	 Other agent action time: 0 	 50.833957652467944 steps/s
Curr learning rate 0.001477 	 Curr reward per step 0.13537358333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 180.69it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 196.47it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 195.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 167.80it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 168.30it/s]
--------------------------------------
| approxkl           | 0.0026325958  |
| clipfrac           | 0.38213533    |
| eplenmean          | 400           |
| eprewmean          | 52.2          |
| explained_variance | 0.181         |
| fps                | 1402          |
| nupdates           | 24            |
| policy_entropy     | 1.6774904     |
| policy_loss        | -0.0029948428 |
| serial_timesteps   | 9600          |
| time_elapsed       | 203           |
| time_remaining     | 102           |
| total_timesteps    | 288000        |
| true_eprew         | 22.2          |
| value_loss         | 18.404411     |
--------------------------------------
Current reward shaping 0.928
SP envs: 0/30
Other agent actions took 4.52728271484375 seconds
Total simulation time for 400 steps: 7.817433595657349 	 Other agent action time: 0 	 51.16768759279304 steps/s
Curr learning rate 0.0014759999999999999 	 Curr reward per step 0.1598

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.14it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.44it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.18it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.89it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.89it/s]
-------------------------------------
| approxkl           | 0.0029362317 |
| clipfrac           | 0.3969374    |
| eplenmean          | 400          |
| eprewmean          | 56.7         |
| explained_variance | 0.152        |
| fps                | 1411         |
| nupdates           | 25           |
| policy_entropy     | 1.6686925    |
| policy_loss        | -0.004047482 |
| serial_timesteps   | 10000        |
| time_elapsed       | 211          |
| time_remaining     | 102          |
| total_timesteps    | 300000       |
| true_eprew         | 25.6         |
| value_loss         | 24.30522     |
-------------------------------------
Current reward shaping 0.925
SP envs: 0/30
Other agent actions took 4.556436538696289 seconds
Total simulation time for 400 steps: 7.795036315917969 	 Other agent action time: 0 	 51.31470640915092 steps/s
Curr learning rate 0.0014750000000000002 	 Curr reward per step 0.14955000000000004

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.51it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.91it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.71it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.37it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 196.93it/s]
--------------------------------------
| approxkl           | 0.002775211   |
| clipfrac           | 0.39689583    |
| eplenmean          | 400           |
| eprewmean          | 59            |
| explained_variance | 0.206         |
| fps                | 1417          |
| nupdates           | 26            |
| policy_entropy     | 1.6728574     |
| policy_loss        | -0.0031569665 |
| serial_timesteps   | 10400         |
| time_elapsed       | 220           |
| time_remaining     | 102           |
| total_timesteps    | 312000        |
| true_eprew         | 27.2          |
| value_loss         | 22.816261     |
--------------------------------------
Current reward shaping 0.922
SP envs: 0/30
Other agent actions took 4.579308748245239 seconds
Total simulation time for 400 steps: 7.88402533531189 	 Other agent action time: 0 	 50.735504134979564 steps/s
Curr learning rate 0.001474 	 Curr reward per step 0.16043866666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.25it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.87it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.99it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.62it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.05it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.23it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.47it/s]
-------------------------------------
| approxkl           | 0.002494995  |
| clipfrac           | 0.37288544   |
| eplenmean          | 400          |
| eprewmean          | 60.6         |
| explained_variance | 0.236        |
| fps                | 1396         |
| nupdates           | 27           |
| policy_entropy     | 1.6604469    |
| policy_loss        | -0.002838343 |
| serial_timesteps   | 10800        |
| time_elapsed       | 228          |
| time_remaining     | 102          |
| total_timesteps    | 324000       |
| true_eprew         | 28           |
| value_loss         | 23.920458    |
-------------------------------------
Current reward shaping 0.919
SP envs: 0/30
Other agent actions took 4.5751917362213135 seconds
Total simulation time for 400 steps: 7.8509604930877686 	 Other agent action time: 0 	 50.94918008467531 steps/s
Curr learning rate 0.001473 	 Curr reward per step 0.1727826666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.57it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.82it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.68it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.03it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.30it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.50it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.31it/s]
--------------------------------------
| approxkl           | 0.0028239458  |
| clipfrac           | 0.3849896     |
| eplenmean          | 400           |
| eprewmean          | 64.1          |
| explained_variance | 0.232         |
| fps                | 1405          |
| nupdates           | 28            |
| policy_entropy     | 1.6515445     |
| policy_loss        | -0.0022805473 |
| serial_timesteps   | 11200         |
| time_elapsed       | 237           |
| time_remaining     | 102           |
| total_timesteps    | 336000        |
| true_eprew         | 30.2          |
| value_loss         | 25.346655     |
--------------------------------------
Current reward shaping 0.916
SP envs: 0/30
Other agent actions took 4.4671571254730225 seconds
Total simulation time for 400 steps: 7.688365459442139 	 Other agent action time: 0 	 52.02666315878065 steps/s
Curr learning rate 0.001472 	 Curr reward per step 0.17787233333333335

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 193.50it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 191.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 188.91it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 195.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 198.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 200.17it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 202.43it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 201.48it/s]
--------------------------------------
| approxkl           | 0.0032398     |
| clipfrac           | 0.4106771     |
| eplenmean          | 400           |
| eprewmean          | 66.8          |
| explained_variance | 0.255         |
| fps                | 1440          |
| nupdates           | 29            |
| policy_entropy     | 1.636235      |
| policy_loss        | -0.0020170927 |
| serial_timesteps   | 11600         |
| time_elapsed       | 245           |
| time_remaining     | 102           |
| total_timesteps    | 348000        |
| true_eprew         | 32            |
| value_loss         | 26.88195      |
--------------------------------------
Current reward shaping 0.913
SP envs: 0/30
Other agent actions took 4.4957075119018555 seconds
Total simulation time for 400 steps: 7.728182077407837 	 Other agent action time: 0 	 51.75861489720061 steps/s
Curr learning rate 0.001471 	 Curr reward per step 0.15769541666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.68it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.74it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.48it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.86it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.11it/s]
--------------------------------------
| approxkl           | 0.0029968324  |
| clipfrac           | 0.38808325    |
| eplenmean          | 400           |
| eprewmean          | 67.6          |
| explained_variance | 0.32          |
| fps                | 1423          |
| nupdates           | 30            |
| policy_entropy     | 1.6483059     |
| policy_loss        | -0.0020510834 |
| serial_timesteps   | 12000         |
| time_elapsed       | 254           |
| time_remaining     | 101           |
| total_timesteps    | 360000        |
| true_eprew         | 33            |
| value_loss         | 22.508366     |
--------------------------------------
Current reward shaping 0.91
SP envs: 0/30
Other agent actions took 4.547822952270508 seconds
Total simulation time for 400 steps: 7.782738208770752 	 Other agent action time: 0 	 51.39579274929488 steps/s
Curr learning rate 0.00147 	 Curr reward per step 0.17213416666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.25it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.64it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.82it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.30it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.53it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.45it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.87it/s]
--------------------------------------
| approxkl           | 0.0024549498  |
| clipfrac           | 0.3449896     |
| eplenmean          | 400           |
| eprewmean          | 67.4          |
| explained_variance | 0.326         |
| fps                | 1419          |
| nupdates           | 31            |
| policy_entropy     | 1.63848       |
| policy_loss        | -0.0009831013 |
| serial_timesteps   | 12400         |
| time_elapsed       | 262           |
| time_remaining     | 101           |
| total_timesteps    | 372000        |
| true_eprew         | 32.8          |
| value_loss         | 27.030176     |
--------------------------------------
Current reward shaping 0.907
SP envs: 0/30
Other agent actions took 4.5685203075408936 seconds
Total simulation time for 400 steps: 7.841089248657227 	 Other agent action time: 0 	 51.01332063890222 steps/s
Curr learning rate 0.001469 	 Curr reward per step 0.1685875

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.27it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.87it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.42it/s]
---------------------------------------
| approxkl           | 0.0029585816   |
| clipfrac           | 0.3751563      |
| eplenmean          | 400            |
| eprewmean          | 66.6           |
| explained_variance | 0.394          |
| fps                | 1408           |
| nupdates           | 32             |
| policy_entropy     | 1.6359599      |
| policy_loss        | -0.00038529912 |
| serial_timesteps   | 12800          |
| time_elapsed       | 270            |
| time_remaining     | 101            |
| total_timesteps    | 384000         |
| true_eprew         | 32.4           |
| value_loss         | 23.321882      |
---------------------------------------
Current reward shaping 0.904
SP envs: 0/30
Other agent actions took 4.618427753448486 seconds
Total simulation time for 400 steps: 7.881183385848999 	 Other agent action time: 0 	 50.753799323870204 steps/s
Curr learning rate 0.0014680000000000001 	 Curr reward per step 0.1829613333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.25it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 183.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.01it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.64it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.41it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.71it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.60it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 196.56it/s]
--------------------------------------
| approxkl           | 0.0023426437  |
| clipfrac           | 0.34077075    |
| eplenmean          | 400           |
| eprewmean          | 69.8          |
| explained_variance | 0.377         |
| fps                | 1404          |
| nupdates           | 33            |
| policy_entropy     | 1.6270896     |
| policy_loss        | -0.0012989218 |
| serial_timesteps   | 13200         |
| time_elapsed       | 279           |
| time_remaining     | 101           |
| total_timesteps    | 396000        |
| true_eprew         | 34.2          |
| value_loss         | 25.954294     |
--------------------------------------
Current reward shaping 0.901
SP envs: 0/30
Other agent actions took 4.472017526626587 seconds
Total simulation time for 400 steps: 7.7372355461120605 	 Other agent action time: 0 	 51.69805127633718 steps/s
Curr learning rate 0.001467 	 Curr reward per step 0.17909425

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 186.72it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.09it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.69it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.82it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.30it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 202.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 201.26it/s]
--------------------------------------
| approxkl           | 0.0026538265  |
| clipfrac           | 0.3658438     |
| eplenmean          | 400           |
| eprewmean          | 71.1          |
| explained_variance | 0.465         |
| fps                | 1431          |
| nupdates           | 34            |
| policy_entropy     | 1.6232319     |
| policy_loss        | -0.0012449978 |
| serial_timesteps   | 13600         |
| time_elapsed       | 287           |
| time_remaining     | 101           |
| total_timesteps    | 408000        |
| true_eprew         | 34.8          |
| value_loss         | 22.746775     |
--------------------------------------
Current reward shaping 0.898
SP envs: 0/30
Other agent actions took 4.541419982910156 seconds
Total simulation time for 400 steps: 7.820512771606445 	 Other agent action time: 0 	 51.14754130346293 steps/s
Curr learning rate 0.001466 	 Curr reward per step 0.2265423333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.29it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.60it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.57it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.59it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.65it/s]
---------------------------------------
| approxkl           | 0.0028824504   |
| clipfrac           | 0.37834376     |
| eplenmean          | 400            |
| eprewmean          | 77.1           |
| explained_variance | 0.368          |
| fps                | 1410           |
| nupdates           | 35             |
| policy_entropy     | 1.6059688      |
| policy_loss        | -0.00057255203 |
| serial_timesteps   | 14000          |
| time_elapsed       | 296            |
| time_remaining     | 101            |
| total_timesteps    | 420000         |
| true_eprew         | 38.6           |
| value_loss         | 35.85715       |
---------------------------------------
Current reward shaping 0.895
SP envs: 0/30
Other agent actions took 4.54735803604126 seconds
Total simulation time for 400 steps: 7.808633089065552 	 Other agent action time: 0 	 51.22535473719734 steps/s
Curr learning rate 0.0014650000000000002 	 Curr reward per step 0.17407833333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.42it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.41it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.34it/s]
--------------------------------------
| approxkl           | 0.0021380696  |
| clipfrac           | 0.3197916     |
| eplenmean          | 400           |
| eprewmean          | 75.7          |
| explained_variance | 0.442         |
| fps                | 1411          |
| nupdates           | 36            |
| policy_entropy     | 1.6272441     |
| policy_loss        | -0.0009371518 |
| serial_timesteps   | 14400         |
| time_elapsed       | 304           |
| time_remaining     | 101           |
| total_timesteps    | 432000        |
| true_eprew         | 37.8          |
| value_loss         | 23.318756     |
--------------------------------------
Current reward shaping 0.892
SP envs: 0/30
Other agent actions took 4.528831481933594 seconds
Total simulation time for 400 steps: 7.741628408432007 	 Other agent action time: 0 	 51.66871605001462 steps/s
Curr learning rate 0.001464 	 Curr reward per step 0.1793916666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.07it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.37it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.25it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.58it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.56it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.12it/s]
--------------------------------------
| approxkl           | 0.0024165665  |
| clipfrac           | 0.32372913    |
| eplenmean          | 400           |
| eprewmean          | 76.3          |
| explained_variance | 0.455         |
| fps                | 1420          |
| nupdates           | 37            |
| policy_entropy     | 1.619442      |
| policy_loss        | 0.00073267054 |
| serial_timesteps   | 14800         |
| time_elapsed       | 313           |
| time_remaining     | 100           |
| total_timesteps    | 444000        |
| true_eprew         | 38.4          |
| value_loss         | 24.444918     |
--------------------------------------
Current reward shaping 0.889
SP envs: 0/30
Other agent actions took 4.557481527328491 seconds
Total simulation time for 400 steps: 7.8660969734191895 	 Other agent action time: 0 	 50.85114019718604 steps/s
Curr learning rate 0.0014629999999999999 	 Curr reward per step 0.18997483333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.26it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.80it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.91it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.44it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.47it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.12it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.11it/s]
--------------------------------------
| approxkl           | 0.0022470085  |
| clipfrac           | 0.31489584    |
| eplenmean          | 400           |
| eprewmean          | 74.3          |
| explained_variance | 0.465         |
| fps                | 1402          |
| nupdates           | 38            |
| policy_entropy     | 1.6149769     |
| policy_loss        | 0.00028797568 |
| serial_timesteps   | 15200         |
| time_elapsed       | 321           |
| time_remaining     | 100           |
| total_timesteps    | 456000        |
| true_eprew         | 37.2          |
| value_loss         | 24.834558     |
--------------------------------------
Current reward shaping 0.886
SP envs: 0/30
Other agent actions took 4.527361631393433 seconds
Total simulation time for 400 steps: 7.881560802459717 	 Other agent action time: 0 	 50.75136892621142 steps/s
Curr learning rate 0.0014620000000000002 	 Curr reward per step 0.1866586666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 186.23it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.17it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.55it/s]
---------------------------------------
| approxkl           | 0.0024817984   |
| clipfrac           | 0.35236457     |
| eplenmean          | 400            |
| eprewmean          | 73.4           |
| explained_variance | 0.474          |
| fps                | 1405           |
| nupdates           | 39             |
| policy_entropy     | 1.622492       |
| policy_loss        | -0.00015998412 |
| serial_timesteps   | 15600          |
| time_elapsed       | 330            |
| time_remaining     | 100            |
| total_timesteps    | 468000         |
| true_eprew         | 36.4           |
| value_loss         | 25.993618      |
---------------------------------------
Current reward shaping 0.883
SP envs: 0/30
Other agent actions took 4.539438962936401 seconds
Total simulation time for 400 steps: 7.799522161483765 	 Other agent action time: 0 	 51.285193082124 steps/s
Curr learning rate 0.001461 	 Curr reward per step 0.1883036666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 184.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.29it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.99it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.17it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.03it/s]
-------------------------------------
| approxkl           | 0.0024463113 |
| clipfrac           | 0.3271875    |
| eplenmean          | 400          |
| eprewmean          | 74.2         |
| explained_variance | 0.488        |
| fps                | 1415         |
| nupdates           | 40           |
| policy_entropy     | 1.6165282    |
| policy_loss        | 0.0003680459 |
| serial_timesteps   | 16000        |
| time_elapsed       | 338          |
| time_remaining     | 100          |
| total_timesteps    | 480000       |
| true_eprew         | 37           |
| value_loss         | 24.446543    |
-------------------------------------
Current reward shaping 0.88
SP envs: 0/30
Other agent actions took 4.542421102523804 seconds
Total simulation time for 400 steps: 7.804060935974121 	 Other agent action time: 0 	 51.25536605642496 steps/s
Curr learning rate 0.00146 	 Curr reward per step 0.17552666666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.52it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.02it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.57it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.17it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.19it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.26it/s]
--------------------------------------
| approxkl           | 0.0028551102  |
| clipfrac           | 0.36285415    |
| eplenmean          | 400           |
| eprewmean          | 72.1          |
| explained_variance | 0.531         |
| fps                | 1410          |
| nupdates           | 41            |
| policy_entropy     | 1.6130512     |
| policy_loss        | 0.00072618946 |
| serial_timesteps   | 16400         |
| time_elapsed       | 347           |
| time_remaining     | 100           |
| total_timesteps    | 492000        |
| true_eprew         | 36            |
| value_loss         | 21.466679     |
--------------------------------------
Current reward shaping 0.877
SP envs: 0/30
Other agent actions took 4.591854095458984 seconds
Total simulation time for 400 steps: 7.925430536270142 	 Other agent action time: 0 	 50.470444245196504 steps/s
Curr learning rate 0.001459 	 Curr reward per step 0.2056945833333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 182.17it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 188.42it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.66it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.65it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 169.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.09it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.46it/s]
---------------------------------------
| approxkl           | 0.0020894234   |
| clipfrac           | 0.31457302     |
| eplenmean          | 400            |
| eprewmean          | 77.2           |
| explained_variance | 0.526          |
| fps                | 1390           |
| nupdates           | 42             |
| policy_entropy     | 1.6033939      |
| policy_loss        | -4.3590735e-05 |
| serial_timesteps   | 16800          |
| time_elapsed       | 356            |
| time_remaining     | 99.9           |
| total_timesteps    | 504000         |
| true_eprew         | 39.4           |
| value_loss         | 26.20568       |
---------------------------------------
Current reward shaping 0.874
SP envs: 0/30
Other agent actions took 4.5385942459106445 seconds
Total simulation time for 400 steps: 7.746233701705933 	 Other agent action time: 0 	 51.637997948849524 steps/s
Curr learning rate 0.001458 	 Curr reward per step 0.17739999999999997

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.73it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.44it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.99it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.64it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.42it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.74it/s]
-------------------------------------
| approxkl           | 0.0024135981 |
| clipfrac           | 0.31545836   |
| eplenmean          | 400          |
| eprewmean          | 73.7         |
| explained_variance | 0.539        |
| fps                | 1423         |
| nupdates           | 43           |
| policy_entropy     | 1.6149076    |
| policy_loss        | 0.0012983514 |
| serial_timesteps   | 17200        |
| time_elapsed       | 364          |
| time_remaining     | 99.8         |
| total_timesteps    | 516000       |
| true_eprew         | 37.4         |
| value_loss         | 21.046083    |
-------------------------------------
Current reward shaping 0.871
SP envs: 0/30
Other agent actions took 4.609643936157227 seconds
Total simulation time for 400 steps: 7.86653733253479 	 Other agent action time: 0 	 50.84829361270065 steps/s
Curr learning rate 0.001457 	 Curr reward per step 0.19798749999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.86it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.96it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.17it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.59it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.26it/s]
-------------------------------------
| approxkl           | 0.0022953975 |
| clipfrac           | 0.32825002   |
| eplenmean          | 400          |
| eprewmean          | 78.8         |
| explained_variance | 0.521        |
| fps                | 1399         |
| nupdates           | 44           |
| policy_entropy     | 1.5939238    |
| policy_loss        | 0.0010102696 |
| serial_timesteps   | 17600        |
| time_elapsed       | 373          |
| time_remaining     | 99.6         |
| total_timesteps    | 528000       |
| true_eprew         | 40.4         |
| value_loss         | 23.692675    |
-------------------------------------
Current reward shaping 0.868
SP envs: 0/30
Other agent actions took 4.621740102767944 seconds
Total simulation time for 400 steps: 7.842633962631226 	 Other agent action time: 0 	 51.003272868009624 steps/s
Curr learning rate 0.001456 	 Curr reward per step 0.18744500000000003

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.52it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.25it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.30it/s]
-------------------------------------
| approxkl           | 0.002873523  |
| clipfrac           | 0.35910416   |
| eplenmean          | 400          |
| eprewmean          | 75.1         |
| explained_variance | 0.579        |
| fps                | 1409         |
| nupdates           | 45           |
| policy_entropy     | 1.6047478    |
| policy_loss        | 0.0012541194 |
| serial_timesteps   | 18000        |
| time_elapsed       | 381          |
| time_remaining     | 99.5         |
| total_timesteps    | 540000       |
| true_eprew         | 38.2         |
| value_loss         | 21.150305    |
-------------------------------------
Current reward shaping 0.865
SP envs: 0/30
Other agent actions took 4.561237812042236 seconds
Total simulation time for 400 steps: 7.789628744125366 	 Other agent action time: 0 	 51.3503291542186 steps/s
Curr learning rate 0.0014550000000000001 	 Curr reward per step 0.20837624999999999

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.54it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.26it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.50it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.38it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.91it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.48it/s]
-------------------------------------
| approxkl           | 0.0030255339 |
| clipfrac           | 0.35501048   |
| eplenmean          | 400          |
| eprewmean          | 79.2         |
| explained_variance | 0.556        |
| fps                | 1411         |
| nupdates           | 46           |
| policy_entropy     | 1.5856265    |
| policy_loss        | 0.0032315315 |
| serial_timesteps   | 18400        |
| time_elapsed       | 390          |
| time_remaining     | 99.4         |
| total_timesteps    | 552000       |
| true_eprew         | 40.4         |
| value_loss         | 25.27291     |
-------------------------------------
Current reward shaping 0.862
SP envs: 0/30
Other agent actions took 4.491934299468994 seconds
Total simulation time for 400 steps: 7.78021502494812 	 Other agent action time: 0 	 51.412460801835905 steps/s
Curr learning rate 0.001454 	 Curr reward per step 0.2133108333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 180.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.09it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.08it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.58it/s]
--------------------------------------
| approxkl           | 0.002683654   |
| clipfrac           | 0.35497916    |
| eplenmean          | 400           |
| eprewmean          | 81.3          |
| explained_variance | 0.558         |
| fps                | 1415          |
| nupdates           | 47            |
| policy_entropy     | 1.581828      |
| policy_loss        | 0.00062954135 |
| serial_timesteps   | 18800         |
| time_elapsed       | 398           |
| time_remaining     | 99.2          |
| total_timesteps    | 564000        |
| true_eprew         | 42            |
| value_loss         | 26.000948     |
--------------------------------------
Current reward shaping 0.859
SP envs: 0/30
Other agent actions took 4.581757068634033 seconds
Total simulation time for 400 steps: 7.916398048400879 	 Other agent action time: 0 	 50.52803024233988 steps/s
Curr learning rate 0.001453 	 Curr reward per step 0.2134270833333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.60it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.87it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.92it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 173.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.92it/s]
-------------------------------------
| approxkl           | 0.0027840359 |
| clipfrac           | 0.35482293   |
| eplenmean          | 400          |
| eprewmean          | 84.2         |
| explained_variance | 0.56         |
| fps                | 1388         |
| nupdates           | 48           |
| policy_entropy     | 1.5800605    |
| policy_loss        | 0.0026463077 |
| serial_timesteps   | 19200        |
| time_elapsed       | 407          |
| time_remaining     | 99.1         |
| total_timesteps    | 576000       |
| true_eprew         | 44.2         |
| value_loss         | 25.22638     |
-------------------------------------
Current reward shaping 0.856
SP envs: 0/30
Other agent actions took 4.5133702754974365 seconds
Total simulation time for 400 steps: 7.6958229541778564 	 Other agent action time: 0 	 51.976247684187 steps/s
Curr learning rate 0.001452 	 Curr reward per step 0.21988599999999997

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.95it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.88it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.72it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.15it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.59it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.01it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.86it/s]
-------------------------------------
| approxkl           | 0.0027806112 |
| clipfrac           | 0.35426047   |
| eplenmean          | 400          |
| eprewmean          | 85.2         |
| explained_variance | 0.555        |
| fps                | 1430         |
| nupdates           | 49           |
| policy_entropy     | 1.5783155    |
| policy_loss        | 0.0024088917 |
| serial_timesteps   | 19600        |
| time_elapsed       | 415          |
| time_remaining     | 99           |
| total_timesteps    | 588000       |
| true_eprew         | 45           |
| value_loss         | 27.171349    |
-------------------------------------
Current reward shaping 0.853
SP envs: 0/30
Other agent actions took 4.479203701019287 seconds
Total simulation time for 400 steps: 7.704678297042847 	 Other agent action time: 0 	 51.91650898046257 steps/s
Curr learning rate 0.001451 	 Curr reward per step 0.19922474999999998

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 193.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 194.06it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 199.46it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 203.02it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 199.37it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.08it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 205.36it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 205.04it/s]
-------------------------------------
| approxkl           | 0.0025069972 |
| clipfrac           | 0.32868752   |
| eplenmean          | 400          |
| eprewmean          | 82.9         |
| explained_variance | 0.56         |
| fps                | 1440         |
| nupdates           | 50           |
| policy_entropy     | 1.5911127    |
| policy_loss        | 0.002671681  |
| serial_timesteps   | 20000        |
| time_elapsed       | 423          |
| time_remaining     | 98.8         |
| total_timesteps    | 600000       |
| true_eprew         | 43.6         |
| value_loss         | 24.417206    |
-------------------------------------
Current reward shaping 0.85
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X   X 
D   X ↓0X 
X X X S X 


Timestep: 3
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X   X 
D   X ↓0X 
X X X S X 


Timestep: 4
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ↓1X   X 
X X X S X 


Timestep: 5
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 6
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 7
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←1X ↓0X 
X X X S X 


Timestep: 8
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←1X →0X 
X X X S X 


Timestep: 9
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ←dX   X 
X X X S X 


Timestep: 10
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑dX   X 
D   X ↓0X 
X X X S X 


Timestep: 11
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dX   P 
O   X   X 
D   X ←0X 
X X X S X 


Timestep: 12
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↓dX   X 
D   X ↓0X 
X X X S X 


Timestep: 13
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↓dX   X 
D   X ↓0X 
X X X S X 


Timestep: 14
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↓dX   X 
D   X ↓0X 
X X X S X 


Timestep: 15
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↓dX   X 
D   X ←0X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ↓dX ←0X 
X X X S X 


Timestep: 17
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ↓dX   X 
X X X S X 


Timestep: 18
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑dX ←0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑dX ←0X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑dX ←0X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑dX   X 
D   X ↓0X 
X X X S X 


Timestep: 22
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dX   P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 23
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX   P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 24
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX   P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX   P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 26
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX   P 
O   X ↑0X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xd  P 
O   X →0X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xd  P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 29
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xd  P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 30
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXd  P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 31
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXd  P 
O   X   X 
D   X →0X 
X X X S X 


Timestep: 32
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ↓oX   X 
D   X ←0X 
X X X S X 


Timestep: 33
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O →oX   X 
D   X ↓0X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O →1Xo  X 
D   X ↓0X 
X X X S X 


Timestep: 35
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ←1Xo  X 
D   X →0X 
X X X S X 


Timestep: 36
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ←1Xo  X 
D   X ←0X 
X X X S X 


Timestep: 37
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ←oXo↑0X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ←oXo  X 
D   X ↓0X 
X X X S X 


Timestep: 39
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O   Xo  X 
D ↓oX →0X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O   Xo  X 
D ↓oX →0X 
X X X S X 


Timestep: 41
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O   Xo  X 
D ↓oX ↓0X 
X X X S X 


Timestep: 42
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O   Xo  X 
D →oX ←0X 
X X X S X 


Timestep: 43
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O   Xo  X 
D →1Xo→0X 
X X X S X 


Timestep: 44
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O   Xo  X 
D →1Xo↓0X 
X X X S X 


Timestep: 45
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ↑1Xo  X 
D   Xo→0X 
X X X S X 


Timestep: 46
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ↑1Xo↑0X 
D   Xo  X 
X X X S X 


Timestep: 47
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ↑1Xo←0X 
D   Xo  X 
X X X S X 


Timestep: 48
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ↑1Xo→0X 
D   Xo  X 
X X X S X 


Timestep: 49
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ←1Xo←0X 
D   Xo  X 
X X X S X 


Timestep: 50
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd↑0P 
O ←1Xo  X 
D   Xo  X 
X X X S X 


Timestep: 51
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd←0P 
O ←1Xo  X 
D   Xo  X 
X X X S X 


Timestep: 52
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1Xd←0P 
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 53
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1Xd↑0P 
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 54
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1Xd↑0P 
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 55
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1Xd→0P 
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 56
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xd→0P 
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 57
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXd←0P 
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 58
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXd  P 
O   Xo↓0X 
D   Xo  X 
X X X S X 


Timestep: 59
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXd  P 
O   Xo←0X 
D   Xo  X 
X X X S X 


Timestep: 60
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXd  P 
O   Xo→0X 
D   Xo  X 
X X X S X 


Timestep: 61
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXd  P 
O   Xo→0X 
D   Xo  X 
X X X S X 


Timestep: 62
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXd  P 
O   Xo←0X 
D   Xo  X 
X X X S X 


Timestep: 63
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXd  P 
O   Xo→0X 
D   Xo  X 
X X X S X 


Timestep: 64
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXd  P 
O   Xo→0X 
D   Xo  X 
X X X S X 


Timestep: 65
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXd  P 
O   Xo→0X 
D   Xo  X 
X X X S X 


Timestep: 66
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ↓oXo  X 
D   Xo↓0X 
X X X S X 


Timestep: 67
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O ↓oXo  X 
D   Xo←0X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O →oXo  X 
D   X ←oX 
X X X S X 


Timestep: 69
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O →oXo↑oX 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O →oXo←oX 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  P 
O →oXo←oX 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd↑oP 
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd→oP 
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd→oP 
O ←oXo  X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X P X 
O   Xd→0ø-
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø-
O →oXo↓0X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø-
O →oXo←0X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø-
O →oX ←oX 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø-
O →1Xo←oX 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd↑oø-
O ←1Xo  X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd→oø-
O ←1Xo  X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 3 
X X X P X 
O   Xd→0ø=
O ←1Xo  X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O ←1Xo↓0X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O ←oXo→0X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →oXo←0X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →oXo←0X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd↑0ø=
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd→0ø=
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd↑0ø=
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O ←oXo↓0X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd↑0ø=
O ←oXo  X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd←0ø=
O ←oXo  X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O ←oXo↓0X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →oXo←0X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →1Xo←oX 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd↑oø=
O ←1Xo  X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   Xd↑0ø=
O ←1Xo  X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd↑0ø=
O ←oXo  X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd←0ø=
O →oXo  X 
D   X   X 
X X X S X 


/home/mzhao2/overcooked-teaming/overcooked_ai/overcooked_ai_py/mdp/overcooked_env.py:162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  return np.array(trajectory), self.t, self.cumulative_sparse_rewards, self.cumulative_shaped_rewards
tot rew 20 tot rew shaped 35
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O   X   X 
D ↓1X   X 
X XoX S X 


Timestep: 14
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X XoX S X 


Timestep: 15
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ↓0X 
D   X   X 
X XoX S X 


Timestep: 16
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ←0X 
D   X   X 
X XoX S X 


Timestep: 17
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 18
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 19
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 20
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 21
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 22
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 23
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 24
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓1X   X 
D   X   X 
X XoX S X 


Timestep: 25
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 26
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 27
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 28
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 29
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 30
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 31
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 32
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 33
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 34
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↓1X   X 
D   X   X 
X XoX S X 


Timestep: 35
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X XoX S X 


Timestep: 36
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X XoX S X 


Timestep: 37
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 38
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 39
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 40
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 41
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X XoX S X 


Timestep: 42
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 43
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 44
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 45
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 46
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 47
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 48
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 49
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 50
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 51
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 52
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 53
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 54
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 55
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 56
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 57
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ↓1X ↓0X 
D   X   X 
X XoX S X 


Timestep: 58
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 59
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ↓1X ←0X 
D   X   X 
X XoX S X 


Timestep: 60
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←1X ←0X 
D   X   X 
X XoX S X 


Timestep: 61
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 62
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ↓1X ←0X 
D   X   X 
X XoX S X 


Timestep: 63
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ↓1X ←0X 
D   X   X 
X XoX S X 


Timestep: 64
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 65
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 66
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 67
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 68
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 69
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 70
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 71
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 72
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O →oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 73
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O →oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 74
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O →oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 75
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O →oX →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 76
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1Xo←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 77
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O →oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 78
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 79
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 80
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 81
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 82
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 83
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X XoX S X 


Timestep: 84
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ←0P 
O →oX   X 
D   X   X 
X XoX S X 


Timestep: 85
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O →1Xo↓0X 
D   X   X 
X XoX S X 


Timestep: 86
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O →1Xo↓0X 
D   X   X 
X XoX S X 


Timestep: 87
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O   Xo↓0X 
D ↓1X   X 
X XoX S X 


Timestep: 88
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O   Xo←0X 
D ←1X   X 
X XoX S X 


Timestep: 89
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O   Xo←0X 
D ←1X   X 
X XoX S X 


Timestep: 90
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O   Xo←0X 
D ←1X   X 
X XoX S X 


Timestep: 91
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O   X ←oX 
D →1X   X 
X XoX S X 


Timestep: 92
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ↑oP 
O ↑1X   X 
D   X   X 
X XoX S X 


Timestep: 93
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ↑oP 
O →1X   X 
D   X   X 
X XoX S X 


Timestep: 94
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X →oP 
O →1X   X 
D   X   X 
X XoX S X 


Timestep: 95
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X →oP 
O →1X   X 
D   X   X 
X XoX S X 


Timestep: 96
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X →oP 
O →1X   X 
D   X   X 
X XoX S X 


Timestep: 97
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X XoX P X 
O   X →0ø-
O →1X   X 
D   X   X 
X XoX S X 


Timestep: 98
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   ø-
O ←1X ↓0X 
D   X   X 
X XoX S X 


Timestep: 99
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   ø-
O →1X ↓0X 
D   X   X 
X XoX S X 


tot rew 0 tot rew shaped 15
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.574166536331177 seconds
Total simulation time for 400 steps: 7.8278796672821045 	 Other agent action time: 0 	 51.09940584189931 steps/s
Curr learning rate 0.00145 	 Curr reward per step 0.20551666666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 179.38it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.80it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.39it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.98it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.22it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.17it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.63it/s]
-------------------------------------
| approxkl           | 0.0027227127 |
| clipfrac           | 0.34832293   |
| eplenmean          | 400          |
| eprewmean          | 84.3         |
| explained_variance | 0.598        |
| fps                | 1412         |
| nupdates           | 51           |
| policy_entropy     | 1.5767019    |
| policy_loss        | 0.0020007605 |
| serial_timesteps   | 20400        |
| time_elapsed       | 434          |
| time_remaining     | 99.1         |
| total_timesteps    | 612000       |
| true_eprew         | 44.4         |
| value_loss         | 23.017395    |
-------------------------------------
Current reward shaping 0.847
SP envs: 0/30
Other agent actions took 4.537721633911133 seconds
Total simulation time for 400 steps: 7.792959690093994 	 Other agent action time: 0 	 51.32838047506639 steps/s
Curr learning rate 0.001449 	 Curr reward per step 0.20369141666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.42it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.81it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 159.10it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 171.52it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 161.60it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 171.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.03it/s]
------------------------------------
| approxkl           | 0.002540472 |
| clipfrac           | 0.3344167   |
| eplenmean          | 400         |
| eprewmean          | 81.1        |
| explained_variance | 0.609       |
| fps                | 1405        |
| nupdates           | 52          |
| policy_entropy     | 1.5820577   |
| policy_loss        | 0.002372424 |
| serial_timesteps   | 20800       |
| time_elapsed       | 442         |
| time_remaining     | 99          |
| total_timesteps    | 624000      |
| true_eprew         | 42.8        |
| value_loss         | 21.41965    |
------------------------------------
Current reward shaping 0.844
SP envs: 0/30
Other agent actions took 4.537885665893555 seconds
Total simulation time for 400 steps: 7.801656484603882 	 Other agent action time: 0 	 51.271162834377144 steps/s
Curr learning rate 0.001448 	 Curr reward per step 0.222448

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.00it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.65it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.38it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.11it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.41it/s]
-------------------------------------
| approxkl           | 0.0023054818 |
| clipfrac           | 0.3156875    |
| eplenmean          | 400          |
| eprewmean          | 84.3         |
| explained_variance | 0.584        |
| fps                | 1411         |
| nupdates           | 53           |
| policy_entropy     | 1.557001     |
| policy_loss        | 0.0022288917 |
| serial_timesteps   | 21200        |
| time_elapsed       | 451          |
| time_remaining     | 98.8         |
| total_timesteps    | 636000       |
| true_eprew         | 44.4         |
| value_loss         | 26.176327    |
-------------------------------------
Current reward shaping 0.841
SP envs: 0/30
Other agent actions took 4.528477907180786 seconds
Total simulation time for 400 steps: 7.748760938644409 	 Other agent action time: 0 	 51.62115635870645 steps/s
Curr learning rate 0.001447 	 Curr reward per step 0.22502425000000004

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 181.69it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 185.91it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 212.03it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 215.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 222.54it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 219.69it/s]
-------------------------------------
| approxkl           | 0.0025176136 |
| clipfrac           | 0.33308333   |
| eplenmean          | 400          |
| eprewmean          | 86.8         |
| explained_variance | 0.602        |
| fps                | 1432         |
| nupdates           | 54           |
| policy_entropy     | 1.5584408    |
| policy_loss        | 0.0024629652 |
| serial_timesteps   | 21600        |
| time_elapsed       | 459          |
| time_remaining     | 98.7         |
| total_timesteps    | 648000       |
| true_eprew         | 46.4         |
| value_loss         | 22.51266     |
-------------------------------------
Current reward shaping 0.838
SP envs: 0/30
Other agent actions took 4.5399205684661865 seconds
Total simulation time for 400 steps: 7.983683824539185 	 Other agent action time: 0 	 50.10218450416752 steps/s
Curr learning rate 0.001446 	 Curr reward per step 0.19690066666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.25it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.66it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.53it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 198.71it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 200.18it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 196.87it/s]
-------------------------------------
| approxkl           | 0.0029980957 |
| clipfrac           | 0.36888537   |
| eplenmean          | 400          |
| eprewmean          | 86.5         |
| explained_variance | 0.664        |
| fps                | 1386         |
| nupdates           | 55           |
| policy_entropy     | 1.5731053    |
| policy_loss        | 0.0030867318 |
| serial_timesteps   | 22000        |
| time_elapsed       | 468          |
| time_remaining     | 98.6         |
| total_timesteps    | 660000       |
| true_eprew         | 46.4         |
| value_loss         | 19.448753    |
-------------------------------------
Current reward shaping 0.835
SP envs: 0/30
Other agent actions took 4.66922926902771 seconds
Total simulation time for 400 steps: 8.087185859680176 	 Other agent action time: 0 	 49.46096292831074 steps/s
Curr learning rate 0.001445 	 Curr reward per step 0.18760875

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.79it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.54it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 200.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.52it/s]
-------------------------------------
| approxkl           | 0.0033574547 |
| clipfrac           | 0.3929271    |
| eplenmean          | 400          |
| eprewmean          | 82.1         |
| explained_variance | 0.611        |
| fps                | 1364         |
| nupdates           | 56           |
| policy_entropy     | 1.5746313    |
| policy_loss        | 0.0041316445 |
| serial_timesteps   | 22400        |
| time_elapsed       | 477          |
| time_remaining     | 98.5         |
| total_timesteps    | 672000       |
| true_eprew         | 43.8         |
| value_loss         | 19.76225     |
-------------------------------------
Current reward shaping 0.832
SP envs: 0/30
Other agent actions took 4.569774150848389 seconds
Total simulation time for 400 steps: 7.8880531787872314 	 Other agent action time: 0 	 50.70959727752482 steps/s
Curr learning rate 0.001444 	 Curr reward per step 0.24468266666666671

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.95it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.59it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.43it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.52it/s]
-------------------------------------
| approxkl           | 0.0040388126 |
| clipfrac           | 0.43896866   |
| eplenmean          | 400          |
| eprewmean          | 83.8         |
| explained_variance | 0.604        |
| fps                | 1396         |
| nupdates           | 57           |
| policy_entropy     | 1.5223587    |
| policy_loss        | 0.0050135264 |
| serial_timesteps   | 22800        |
| time_elapsed       | 485          |
| time_remaining     | 98.4         |
| total_timesteps    | 684000       |
| true_eprew         | 45           |
| value_loss         | 26.585487    |
-------------------------------------
Current reward shaping 0.829
SP envs: 0/30
Other agent actions took 4.648794174194336 seconds
Total simulation time for 400 steps: 7.9946675300598145 	 Other agent action time: 0 	 50.033350166971516 steps/s
Curr learning rate 0.001443 	 Curr reward per step 0.23464391666666662

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.26it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.61it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.83it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.63it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.21it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.00it/s]
-------------------------------------
| approxkl           | 0.0028525714 |
| clipfrac           | 0.37208334   |
| eplenmean          | 400          |
| eprewmean          | 88.9         |
| explained_variance | 0.597        |
| fps                | 1378         |
| nupdates           | 58           |
| policy_entropy     | 1.4997635    |
| policy_loss        | 0.0032404596 |
| serial_timesteps   | 23200        |
| time_elapsed       | 494          |
| time_remaining     | 98.3         |
| total_timesteps    | 696000       |
| true_eprew         | 48           |
| value_loss         | 26.648624    |
-------------------------------------
Current reward shaping 0.8260000000000001
SP envs: 0/30
Other agent actions took 4.623806476593018 seconds
Total simulation time for 400 steps: 7.868779897689819 	 Other agent action time: 0 	 50.83380208886454 steps/s
Curr learning rate 0.0014420000000000001 	 Curr reward per step 0.26380633333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.76it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.24it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.82it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.25it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.20it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.46it/s]
-------------------------------------
| approxkl           | 0.0027214547 |
| clipfrac           | 0.36178127   |
| eplenmean          | 400          |
| eprewmean          | 97.2         |
| explained_variance | 0.549        |
| fps                | 1396         |
| nupdates           | 59           |
| policy_entropy     | 1.4897026    |
| policy_loss        | 0.003096246  |
| serial_timesteps   | 23600        |
| time_elapsed       | 503          |
| time_remaining     | 98.1         |
| total_timesteps    | 708000       |
| true_eprew         | 52.8         |
| value_loss         | 31.763704    |
-------------------------------------
Current reward shaping 0.823
BEST REW 52.8 overwriting previous model with 0
WARNING:tensorflow:From ../../human_aware_rl/ppo/ppo.py:237: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.
WARNING - tensorflow - From ../../human_aware_rl/ppo/ppo.py:237: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.
WARNING:tensorflow:From /home/mzhao2/anaconda3/envs/harl-gpu/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
WARNING - tensorflow - From /home/mzhao2/anaconda3/envs/harl-gpu/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.627788305282593 seconds
Total simulation time for 400 steps: 8.08138370513916 	 Other agent action time: 0 	 49.49647419236259 steps/s
Curr learning rate 0.001441 	 Curr reward per step 0.21777916666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.01it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 185.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.90it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.50it/s]
-------------------------------------
| approxkl           | 0.0039041205 |
| clipfrac           | 0.42994797   |
| eplenmean          | 400          |
| eprewmean          | 94.4         |
| explained_variance | 0.624        |
| fps                | 1362         |
| nupdates           | 60           |
| policy_entropy     | 1.5274361    |
| policy_loss        | 0.0036936551 |
| serial_timesteps   | 24000        |
| time_elapsed       | 513          |
| time_remaining     | 98.3         |
| total_timesteps    | 720000       |
| true_eprew         | 51.2         |
| value_loss         | 23.997831    |
-------------------------------------
Current reward shaping 0.8200000000000001
SP envs: 0/30
Other agent actions took 4.801535129547119 seconds
Total simulation time for 400 steps: 8.091607093811035 	 Other agent action time: 0 	 49.433937580328745 steps/s
Curr learning rate 0.00144 	 Curr reward per step 0.24478500000000009

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.01it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.40it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.56it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 171.84it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.91it/s]
-------------------------------------
| approxkl           | 0.0030449873 |
| clipfrac           | 0.36819795   |
| eplenmean          | 400          |
| eprewmean          | 96.8         |
| explained_variance | 0.573        |
| fps                | 1357         |
| nupdates           | 61           |
| policy_entropy     | 1.5093485    |
| policy_loss        | 0.0043361215 |
| serial_timesteps   | 24400        |
| time_elapsed       | 522          |
| time_remaining     | 98.2         |
| total_timesteps    | 732000       |
| true_eprew         | 52.8         |
| value_loss         | 28.502186    |
-------------------------------------
Current reward shaping 0.817
SP envs: 0/30
Other agent actions took 4.818671226501465 seconds
Total simulation time for 400 steps: 8.20113205909729 	 Other agent action time: 0 	 48.773754296065874 steps/s
Curr learning rate 0.001439 	 Curr reward per step 0.20854650000000002

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.62it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.15it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.17it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.16it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.24it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.70it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.89it/s]
-------------------------------------
| approxkl           | 0.0026014284 |
| clipfrac           | 0.36318746   |
| eplenmean          | 400          |
| eprewmean          | 90.8         |
| explained_variance | 0.644        |
| fps                | 1344         |
| nupdates           | 62           |
| policy_entropy     | 1.5266795    |
| policy_loss        | 0.002013919  |
| serial_timesteps   | 24800        |
| time_elapsed       | 531          |
| time_remaining     | 98.1         |
| total_timesteps    | 744000       |
| true_eprew         | 49.6         |
| value_loss         | 20.922663    |
-------------------------------------
Current reward shaping 0.8140000000000001
SP envs: 0/30
Other agent actions took 4.7742908000946045 seconds
Total simulation time for 400 steps: 8.251246690750122 	 Other agent action time: 0 	 48.477522850990646 steps/s
Curr learning rate 0.001438 	 Curr reward per step 0.2561985

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.16it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.02it/s]
------------------------------------
| approxkl           | 0.002639968 |
| clipfrac           | 0.35976034  |
| eplenmean          | 400         |
| eprewmean          | 94.9        |
| explained_variance | 0.597       |
| fps                | 1338        |
| nupdates           | 63          |
| policy_entropy     | 1.4897475   |
| policy_loss        | 0.0025657   |
| serial_timesteps   | 25200       |
| time_elapsed       | 540         |
| time_remaining     | 98.1        |
| total_timesteps    | 756000      |
| true_eprew         | 52          |
| value_loss         | 28.446041   |
------------------------------------
Current reward shaping 0.8109999999999999
SP envs: 0/30
Other agent actions took 4.836125373840332 seconds
Total simulation time for 400 steps: 8.287192583084106 	 Other agent action time: 0 	 48.267250457831 steps/s
Curr learning rate 0.001437 	 Curr reward per step 0.21412183333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.55it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.02it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.72it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.22it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.12it/s]
-------------------------------------
| approxkl           | 0.0033462562 |
| clipfrac           | 0.40860426   |
| eplenmean          | 400          |
| eprewmean          | 92.9         |
| explained_variance | 0.592        |
| fps                | 1340         |
| nupdates           | 64           |
| policy_entropy     | 1.5044682    |
| policy_loss        | 0.0033294416 |
| serial_timesteps   | 25600        |
| time_elapsed       | 549          |
| time_remaining     | 98           |
| total_timesteps    | 768000       |
| true_eprew         | 51           |
| value_loss         | 24.161533    |
-------------------------------------
Current reward shaping 0.808
SP envs: 0/30
Other agent actions took 4.8706605434417725 seconds
Total simulation time for 400 steps: 8.112253665924072 	 Other agent action time: 0 	 49.30812280688658 steps/s
Curr learning rate 0.001436 	 Curr reward per step 0.19403133333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.48it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.83it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.69it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.70it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 161.38it/s]
-------------------------------------
| approxkl           | 0.0037434984 |
| clipfrac           | 0.4207605    |
| eplenmean          | 400          |
| eprewmean          | 87.3         |
| explained_variance | 0.522        |
| fps                | 1359         |
| nupdates           | 65           |
| policy_entropy     | 1.5047532    |
| policy_loss        | 0.0049459687 |
| serial_timesteps   | 26000        |
| time_elapsed       | 557          |
| time_remaining     | 97.9         |
| total_timesteps    | 780000       |
| true_eprew         | 47.2         |
| value_loss         | 24.273088    |
-------------------------------------
Current reward shaping 0.8049999999999999
SP envs: 0/30
Other agent actions took 4.806483507156372 seconds
Total simulation time for 400 steps: 8.164378643035889 	 Other agent action time: 0 	 48.99331810647892 steps/s
Curr learning rate 0.001435 	 Curr reward per step 0.2143399999999999

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 150.04it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.34it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 160.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.58it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.22it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.56it/s]
-------------------------------------
| approxkl           | 0.0036941387 |
| clipfrac           | 0.4140104    |
| eplenmean          | 400          |
| eprewmean          | 83.7         |
| explained_variance | 0.55         |
| fps                | 1346         |
| nupdates           | 66           |
| policy_entropy     | 1.4957753    |
| policy_loss        | 0.0040547405 |
| serial_timesteps   | 26400        |
| time_elapsed       | 566          |
| time_remaining     | 97.8         |
| total_timesteps    | 792000       |
| true_eprew         | 45.4         |
| value_loss         | 23.941465    |
-------------------------------------
Current reward shaping 0.802
SP envs: 0/30
Other agent actions took 4.861927270889282 seconds
Total simulation time for 400 steps: 8.360448360443115 	 Other agent action time: 0 	 47.84432398297828 steps/s
Curr learning rate 0.001434 	 Curr reward per step 0.26348299999999997

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 155.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.25it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.55it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.93it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.20it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.60it/s]
-------------------------------------
| approxkl           | 0.0033927097 |
| clipfrac           | 0.41870824   |
| eplenmean          | 400          |
| eprewmean          | 89.6         |
| explained_variance | 0.586        |
| fps                | 1320         |
| nupdates           | 67           |
| policy_entropy     | 1.4631317    |
| policy_loss        | 0.004107287  |
| serial_timesteps   | 26800        |
| time_elapsed       | 575          |
| time_remaining     | 97.8         |
| total_timesteps    | 804000       |
| true_eprew         | 49.4         |
| value_loss         | 29.140743    |
-------------------------------------
Current reward shaping 0.7989999999999999
SP envs: 0/30
Other agent actions took 4.821522235870361 seconds
Total simulation time for 400 steps: 8.12258529663086 	 Other agent action time: 0 	 49.24540468241247 steps/s
Curr learning rate 0.001433 	 Curr reward per step 0.2241384166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.09it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.87it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.47it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.50it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.54it/s]
-------------------------------------
| approxkl           | 0.0029846034 |
| clipfrac           | 0.376573     |
| eplenmean          | 400          |
| eprewmean          | 92.9         |
| explained_variance | 0.585        |
| fps                | 1359         |
| nupdates           | 68           |
| policy_entropy     | 1.4745933    |
| policy_loss        | 0.0042327824 |
| serial_timesteps   | 27200        |
| time_elapsed       | 584          |
| time_remaining     | 97.7         |
| total_timesteps    | 816000       |
| true_eprew         | 51.4         |
| value_loss         | 25.18563     |
-------------------------------------
Current reward shaping 0.796
SP envs: 0/30
Other agent actions took 4.796665668487549 seconds
Total simulation time for 400 steps: 8.225814580917358 	 Other agent action time: 0 	 48.627402923467216 steps/s
Curr learning rate 0.0014320000000000001 	 Curr reward per step 0.206598

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.31it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.27it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.86it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 195.18it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.13it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.21it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.94it/s]
-------------------------------------
| approxkl           | 0.0028144538 |
| clipfrac           | 0.3680834    |
| eplenmean          | 400          |
| eprewmean          | 89.9         |
| explained_variance | 0.618        |
| fps                | 1344         |
| nupdates           | 69           |
| policy_entropy     | 1.4785203    |
| policy_loss        | 0.0033198507 |
| serial_timesteps   | 27600        |
| time_elapsed       | 593          |
| time_remaining     | 97.6         |
| total_timesteps    | 828000       |
| true_eprew         | 49.6         |
| value_loss         | 22.261444    |
-------------------------------------
Current reward shaping 0.793
SP envs: 0/30
Other agent actions took 4.933810472488403 seconds
Total simulation time for 400 steps: 8.380122900009155 	 Other agent action time: 0 	 47.73199686600813 steps/s
Curr learning rate 0.001431 	 Curr reward per step 0.24550591666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 156.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.06it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 163.45it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 164.45it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.54it/s]
------------------------------------
| approxkl           | 0.003791517 |
| clipfrac           | 0.42098957  |
| eplenmean          | 400         |
| eprewmean          | 91.3        |
| explained_variance | 0.548       |
| fps                | 1312        |
| nupdates           | 70          |
| policy_entropy     | 1.4654049   |
| policy_loss        | 0.004273114 |
| serial_timesteps   | 28000       |
| time_elapsed       | 602         |
| time_remaining     | 97.5        |
| total_timesteps    | 840000      |
| true_eprew         | 50.4        |
| value_loss         | 26.030783   |
------------------------------------
Current reward shaping 0.79
SP envs: 0/30
Other agent actions took 4.806454181671143 seconds
Total simulation time for 400 steps: 8.076470375061035 	 Other agent action time: 0 	 49.52658542958837 steps/s
Curr learning rate 0.0014299999999999998 	 Curr reward per step 0.26621666666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.99it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.02it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.67it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.19it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.84it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 172.90it/s]
-------------------------------------
| approxkl           | 0.0042049782 |
| clipfrac           | 0.4363021    |
| eplenmean          | 400          |
| eprewmean          | 94.6         |
| explained_variance | 0.581        |
| fps                | 1362         |
| nupdates           | 71           |
| policy_entropy     | 1.4450786    |
| policy_loss        | 0.006132449  |
| serial_timesteps   | 28400        |
| time_elapsed       | 611          |
| time_remaining     | 97.4         |
| total_timesteps    | 852000       |
| true_eprew         | 52.6         |
| value_loss         | 30.688662    |
-------------------------------------
Current reward shaping 0.787
SP envs: 0/30
Other agent actions took 4.873039484024048 seconds
Total simulation time for 400 steps: 8.17554783821106 	 Other agent action time: 0 	 48.926384863222374 steps/s
Curr learning rate 0.0014290000000000001 	 Curr reward per step 0.24598266666666657

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.95it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.41it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.72it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.39it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 195.55it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.30it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.61it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.36it/s]
-------------------------------------
| approxkl           | 0.00375437   |
| clipfrac           | 0.4210417    |
| eplenmean          | 400          |
| eprewmean          | 96.4         |
| explained_variance | 0.642        |
| fps                | 1354         |
| nupdates           | 72           |
| policy_entropy     | 1.4642894    |
| policy_loss        | 0.0046211723 |
| serial_timesteps   | 28800        |
| time_elapsed       | 620          |
| time_remaining     | 97.3         |
| total_timesteps    | 864000       |
| true_eprew         | 54.2         |
| value_loss         | 23.879759    |
-------------------------------------
Current reward shaping 0.784
BEST REW 54.2 overwriting previous model with 52.8
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.772518873214722 seconds
Total simulation time for 400 steps: 8.112057209014893 	 Other agent action time: 0 	 49.30931694558093 steps/s
Curr learning rate 0.001428 	 Curr reward per step 0.2748213333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.26it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.76it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.52it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.64it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.69it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.80it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.82it/s]
-------------------------------------
| approxkl           | 0.0036446145 |
| clipfrac           | 0.4239582    |
| eplenmean          | 400          |
| eprewmean          | 105          |
| explained_variance | 0.552        |
| fps                | 1361         |
| nupdates           | 73           |
| policy_entropy     | 1.4392173    |
| policy_loss        | 0.003866885  |
| serial_timesteps   | 29200        |
| time_elapsed       | 630          |
| time_remaining     | 97.4         |
| total_timesteps    | 876000       |
| true_eprew         | 59.6         |
| value_loss         | 30.118822    |
-------------------------------------
Current reward shaping 0.781
BEST REW 59.6 overwriting previous model with 54.2
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.760305166244507 seconds
Total simulation time for 400 steps: 8.230662822723389 	 Other agent action time: 0 	 48.59875912978375 steps/s
Curr learning rate 0.001427 	 Curr reward per step 0.2795835833333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.03it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.31it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.35it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.47it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.10it/s]
-------------------------------------
| approxkl           | 0.0043456876 |
| clipfrac           | 0.4480834    |
| eplenmean          | 400          |
| eprewmean          | 109          |
| explained_variance | 0.582        |
| fps                | 1342         |
| nupdates           | 74           |
| policy_entropy     | 1.4025822    |
| policy_loss        | 0.0061413916 |
| serial_timesteps   | 29600        |
| time_elapsed       | 640          |
| time_remaining     | 97.5         |
| total_timesteps    | 888000       |
| true_eprew         | 61.8         |
| value_loss         | 28.731073    |
-------------------------------------
Current reward shaping 0.778
BEST REW 61.8 overwriting previous model with 59.6
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.777483940124512 seconds
Total simulation time for 400 steps: 8.132584571838379 	 Other agent action time: 0 	 49.184855867976495 steps/s
Curr learning rate 0.001426 	 Curr reward per step 0.23875233333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.75it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.64it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.65it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.81it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.49it/s]
------------------------------------
| approxkl           | 0.00433399  |
| clipfrac           | 0.45290622  |
| eplenmean          | 400         |
| eprewmean          | 106         |
| explained_variance | 0.569       |
| fps                | 1361        |
| nupdates           | 75          |
| policy_entropy     | 1.4359502   |
| policy_loss        | 0.006681424 |
| serial_timesteps   | 30000       |
| time_elapsed       | 651         |
| time_remaining     | 97.6        |
| total_timesteps    | 900000      |
| true_eprew         | 59.4        |
| value_loss         | 25.721872   |
------------------------------------
Current reward shaping 0.775
SP envs: 0/30
Other agent actions took 4.866052865982056 seconds
Total simulation time for 400 steps: 8.252686738967896 	 Other agent action time: 0 	 48.469063791221174 steps/s
Curr learning rate 0.001425 	 Curr reward per step 0.2741958333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.57it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.88it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.73it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 156.69it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.40it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.11it/s]
-------------------------------------
| approxkl           | 0.004008489  |
| clipfrac           | 0.42345837   |
| eplenmean          | 400          |
| eprewmean          | 105          |
| explained_variance | 0.636        |
| fps                | 1334         |
| nupdates           | 76           |
| policy_entropy     | 1.4228517    |
| policy_loss        | 0.0061438903 |
| serial_timesteps   | 30400        |
| time_elapsed       | 660          |
| time_remaining     | 97.5         |
| total_timesteps    | 912000       |
| true_eprew         | 59.8         |
| value_loss         | 27.969452    |
-------------------------------------
Current reward shaping 0.772
SP envs: 0/30
Other agent actions took 4.851618051528931 seconds
Total simulation time for 400 steps: 8.20771050453186 	 Other agent action time: 0 	 48.73466233721832 steps/s
Curr learning rate 0.001424 	 Curr reward per step 0.26008033333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.23it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.22it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.92it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.18it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.12it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.11it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.65it/s]
-------------------------------------
| approxkl           | 0.0046527893 |
| clipfrac           | 0.45483324   |
| eplenmean          | 400          |
| eprewmean          | 105          |
| explained_variance | 0.58         |
| fps                | 1347         |
| nupdates           | 77           |
| policy_entropy     | 1.4246236    |
| policy_loss        | 0.006897057  |
| serial_timesteps   | 30800        |
| time_elapsed       | 669          |
| time_remaining     | 97.4         |
| total_timesteps    | 924000       |
| true_eprew         | 59.6         |
| value_loss         | 26.988417    |
-------------------------------------
Current reward shaping 0.769
SP envs: 0/30
Other agent actions took 4.827082633972168 seconds
Total simulation time for 400 steps: 8.22761869430542 	 Other agent action time: 0 	 48.616740136104255 steps/s
Curr learning rate 0.001423 	 Curr reward per step 0.2702213333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.57it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 199.26it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.17it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.65it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.15it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 200.36it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.00it/s]
-------------------------------------
| approxkl           | 0.0048107835 |
| clipfrac           | 0.46116665   |
| eplenmean          | 400          |
| eprewmean          | 107          |
| explained_variance | 0.624        |
| fps                | 1350         |
| nupdates           | 78           |
| policy_entropy     | 1.4100149    |
| policy_loss        | 0.007429405  |
| serial_timesteps   | 31200        |
| time_elapsed       | 678          |
| time_remaining     | 97.3         |
| total_timesteps    | 936000       |
| true_eprew         | 61           |
| value_loss         | 28.928078    |
-------------------------------------
Current reward shaping 0.766
SP envs: 0/30
Other agent actions took 4.8356006145477295 seconds
Total simulation time for 400 steps: 8.193243026733398 	 Other agent action time: 0 	 48.82071710735985 steps/s
Curr learning rate 0.001422 	 Curr reward per step 0.2677366666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.59it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.21it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 168.15it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.43it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.76it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 167.42it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.83it/s]
------------------------------------
| approxkl           | 0.004247514 |
| clipfrac           | 0.43971875  |
| eplenmean          | 400         |
| eprewmean          | 105         |
| explained_variance | 0.601       |
| fps                | 1345        |
| nupdates           | 79          |
| policy_entropy     | 1.4300045   |
| policy_loss        | 0.005229232 |
| serial_timesteps   | 31600       |
| time_elapsed       | 687         |
| time_remaining     | 97.2        |
| total_timesteps    | 948000      |
| true_eprew         | 60.4        |
| value_loss         | 27.617651   |
------------------------------------
Current reward shaping 0.763
SP envs: 0/30
Other agent actions took 4.818778038024902 seconds
Total simulation time for 400 steps: 8.235197305679321 	 Other agent action time: 0 	 48.571999571175304 steps/s
Curr learning rate 0.001421 	 Curr reward per step 0.23392216666666663

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 142.20it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 141.74it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 151.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 159.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 160.84it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.12it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 170.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 170.94it/s]
------------------------------------
| approxkl           | 0.004128324 |
| clipfrac           | 0.4428646   |
| eplenmean          | 400         |
| eprewmean          | 104         |
| explained_variance | 0.609       |
| fps                | 1331        |
| nupdates           | 80          |
| policy_entropy     | 1.4462183   |
| policy_loss        | 0.005531681 |
| serial_timesteps   | 32000       |
| time_elapsed       | 696         |
| time_remaining     | 97.1        |
| total_timesteps    | 960000      |
| true_eprew         | 59.4        |
| value_loss         | 25.122005   |
------------------------------------
Current reward shaping 0.76
SP envs: 0/30
Other agent actions took 4.694507837295532 seconds
Total simulation time for 400 steps: 8.029992818832397 	 Other agent action time: 0 	 49.813245045736174 steps/s
Curr learning rate 0.00142 	 Curr reward per step 0.24380666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.86it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.10it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.42it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.54it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.54it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.86it/s]
-------------------------------------
| approxkl           | 0.0032960821 |
| clipfrac           | 0.39922908   |
| eplenmean          | 400          |
| eprewmean          | 99.4         |
| explained_variance | 0.543        |
| fps                | 1373         |
| nupdates           | 81           |
| policy_entropy     | 1.4368856    |
| policy_loss        | 0.0040320484 |
| serial_timesteps   | 32400        |
| time_elapsed       | 704          |
| time_remaining     | 96.9         |
| total_timesteps    | 972000       |
| true_eprew         | 56.6         |
| value_loss         | 29.353554    |
-------------------------------------
Current reward shaping 0.757
SP envs: 0/30
Other agent actions took 4.8058295249938965 seconds
Total simulation time for 400 steps: 8.137022495269775 	 Other agent action time: 0 	 49.158030499796276 steps/s
Curr learning rate 0.0014190000000000001 	 Curr reward per step 0.2306545

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.68it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.37it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 192.40it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.63it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.97it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.91it/s]
-------------------------------------
| approxkl           | 0.0035564944 |
| clipfrac           | 0.41900003   |
| eplenmean          | 400          |
| eprewmean          | 94.9         |
| explained_variance | 0.596        |
| fps                | 1362         |
| nupdates           | 82           |
| policy_entropy     | 1.4711277    |
| policy_loss        | 0.0049572783 |
| serial_timesteps   | 32800        |
| time_elapsed       | 713          |
| time_remaining     | 96.8         |
| total_timesteps    | 984000       |
| true_eprew         | 53.4         |
| value_loss         | 24.570518    |
-------------------------------------
Current reward shaping 0.754
SP envs: 0/30
Other agent actions took 4.825472831726074 seconds
Total simulation time for 400 steps: 8.113592863082886 	 Other agent action time: 0 	 49.29998420551925 steps/s
Curr learning rate 0.001418 	 Curr reward per step 0.2684141666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.43it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.74it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.10it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.53it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.55it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.49it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.35it/s]
-------------------------------------
| approxkl           | 0.0044279993 |
| clipfrac           | 0.4525729    |
| eplenmean          | 400          |
| eprewmean          | 98           |
| explained_variance | 0.55         |
| fps                | 1361         |
| nupdates           | 83           |
| policy_entropy     | 1.4321028    |
| policy_loss        | 0.0051646973 |
| serial_timesteps   | 33200        |
| time_elapsed       | 722          |
| time_remaining     | 96.7         |
| total_timesteps    | 996000       |
| true_eprew         | 55.2         |
| value_loss         | 30.29895     |
-------------------------------------
Current reward shaping 0.751
SP envs: 0/30
Other agent actions took 4.828110933303833 seconds
Total simulation time for 400 steps: 8.199134111404419 	 Other agent action time: 0 	 48.78563938155715 steps/s
Curr learning rate 0.0014169999999999999 	 Curr reward per step 0.26610849999999997

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.37it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.76it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.32it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.21it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.00it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.55it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.08it/s]
-------------------------------------
| approxkl           | 0.0046420842 |
| clipfrac           | 0.4558438    |
| eplenmean          | 400          |
| eprewmean          | 100          |
| explained_variance | 0.603        |
| fps                | 1345         |
| nupdates           | 84           |
| policy_entropy     | 1.4159559    |
| policy_loss        | 0.0071623    |
| serial_timesteps   | 33600        |
| time_elapsed       | 731          |
| time_remaining     | 96.6         |
| total_timesteps    | 1008000      |
| true_eprew         | 57           |
| value_loss         | 24.534489    |
-------------------------------------
Current reward shaping 0.748
SP envs: 0/30
Other agent actions took 4.752660512924194 seconds
Total simulation time for 400 steps: 7.985219955444336 	 Other agent action time: 0 	 50.09254625820036 steps/s
Curr learning rate 0.0014160000000000002 	 Curr reward per step 0.2784333333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.65it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.72it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.05it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 195.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.04it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.15it/s]
-------------------------------------
| approxkl           | 0.0034005204 |
| clipfrac           | 0.3989062    |
| eplenmean          | 400          |
| eprewmean          | 107          |
| explained_variance | 0.534        |
| fps                | 1386         |
| nupdates           | 85           |
| policy_entropy     | 1.399777     |
| policy_loss        | 0.0035130389 |
| serial_timesteps   | 34000        |
| time_elapsed       | 739          |
| time_remaining     | 96.4         |
| total_timesteps    | 1020000      |
| true_eprew         | 61.2         |
| value_loss         | 28.294046    |
-------------------------------------
Current reward shaping 0.745
SP envs: 0/30
Other agent actions took 4.797908544540405 seconds
Total simulation time for 400 steps: 8.114954948425293 	 Other agent action time: 0 	 49.29170926298488 steps/s
Curr learning rate 0.001415 	 Curr reward per step 0.21794833333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.04it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.87it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.53it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.24it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.14it/s]
------------------------------------
| approxkl           | 0.004937197 |
| clipfrac           | 0.47115627  |
| eplenmean          | 400         |
| eprewmean          | 102         |
| explained_variance | 0.58        |
| fps                | 1358        |
| nupdates           | 86          |
| policy_entropy     | 1.4406431   |
| policy_loss        | 0.006571288 |
| serial_timesteps   | 34400       |
| time_elapsed       | 748         |
| time_remaining     | 96.3        |
| total_timesteps    | 1032000     |
| true_eprew         | 58.2        |
| value_loss         | 25.718615   |
------------------------------------
Current reward shaping 0.742
SP envs: 0/30
Other agent actions took 4.982570171356201 seconds
Total simulation time for 400 steps: 8.398192405700684 	 Other agent action time: 0 	 47.629296957816834 steps/s
Curr learning rate 0.001414 	 Curr reward per step 0.24820266666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.91it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.92it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.34it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.52it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.00it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.38it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.46it/s]
-------------------------------------
| approxkl           | 0.0047152406 |
| clipfrac           | 0.47561458   |
| eplenmean          | 400          |
| eprewmean          | 99.2         |
| explained_variance | 0.628        |
| fps                | 1315         |
| nupdates           | 87           |
| policy_entropy     | 1.4034493    |
| policy_loss        | 0.006638453  |
| serial_timesteps   | 34800        |
| time_elapsed       | 757          |
| time_remaining     | 96.2         |
| total_timesteps    | 1044000      |
| true_eprew         | 56.8         |
| value_loss         | 27.430368    |
-------------------------------------
Current reward shaping 0.739
SP envs: 0/30
Other agent actions took 4.933281898498535 seconds
Total simulation time for 400 steps: 8.239473581314087 	 Other agent action time: 0 	 48.546790769150725 steps/s
Curr learning rate 0.0014130000000000002 	 Curr reward per step 0.25104649999999995

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.68it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.71it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.41it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.75it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.42it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 165.67it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 169.12it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.06it/s]
-------------------------------------
| approxkl           | 0.0044763177 |
| clipfrac           | 0.46038538   |
| eplenmean          | 400          |
| eprewmean          | 96.4         |
| explained_variance | 0.589        |
| fps                | 1334         |
| nupdates           | 88           |
| policy_entropy     | 1.3994604    |
| policy_loss        | 0.0045287    |
| serial_timesteps   | 35200        |
| time_elapsed       | 766          |
| time_remaining     | 96.1         |
| total_timesteps    | 1056000      |
| true_eprew         | 55.2         |
| value_loss         | 26.121012    |
-------------------------------------
Current reward shaping 0.736
SP envs: 0/30
Other agent actions took 4.77935528755188 seconds
Total simulation time for 400 steps: 8.12525224685669 	 Other agent action time: 0 	 49.22924087122868 steps/s
Curr learning rate 0.001412 	 Curr reward per step 0.27032799999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.37it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.03it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.53it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.66it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.40it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.40it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.06it/s]
-------------------------------------
| approxkl           | 0.004225384  |
| clipfrac           | 0.45917705   |
| eplenmean          | 400          |
| eprewmean          | 101          |
| explained_variance | 0.506        |
| fps                | 1363         |
| nupdates           | 89           |
| policy_entropy     | 1.3783616    |
| policy_loss        | 0.0050094738 |
| serial_timesteps   | 35600        |
| time_elapsed       | 775          |
| time_remaining     | 96           |
| total_timesteps    | 1068000      |
| true_eprew         | 58.6         |
| value_loss         | 30.127773    |
-------------------------------------
Current reward shaping 0.733
SP envs: 0/30
Other agent actions took 4.989345073699951 seconds
Total simulation time for 400 steps: 8.383511543273926 	 Other agent action time: 0 	 47.71270343403048 steps/s
Curr learning rate 0.001411 	 Curr reward per step 0.2322709166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.87it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.96it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.00it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.15it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.43it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.39it/s]
-------------------------------------
| approxkl           | 0.004006177  |
| clipfrac           | 0.44090614   |
| eplenmean          | 400          |
| eprewmean          | 101          |
| explained_variance | 0.548        |
| fps                | 1319         |
| nupdates           | 90           |
| policy_entropy     | 1.3841966    |
| policy_loss        | 0.0060274834 |
| serial_timesteps   | 36000        |
| time_elapsed       | 784          |
| time_remaining     | 95.9         |
| total_timesteps    | 1080000      |
| true_eprew         | 58           |
| value_loss         | 27.041157    |
-------------------------------------
Current reward shaping 0.73
SP envs: 0/30
Other agent actions took 4.859257698059082 seconds
Total simulation time for 400 steps: 8.183733224868774 	 Other agent action time: 0 	 48.877448593323855 steps/s
Curr learning rate 0.00141 	 Curr reward per step 0.2527966666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 183.95it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.16it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.07it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.38it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.23it/s]
-------------------------------------
| approxkl           | 0.0042044    |
| clipfrac           | 0.44370833   |
| eplenmean          | 400          |
| eprewmean          | 102          |
| explained_variance | 0.559        |
| fps                | 1352         |
| nupdates           | 91           |
| policy_entropy     | 1.3944784    |
| policy_loss        | 0.0050066644 |
| serial_timesteps   | 36400        |
| time_elapsed       | 793          |
| time_remaining     | 95.7         |
| total_timesteps    | 1092000      |
| true_eprew         | 58.6         |
| value_loss         | 28.07395     |
-------------------------------------
Current reward shaping 0.727
SP envs: 0/30
Other agent actions took 4.8364481925964355 seconds
Total simulation time for 400 steps: 8.102968692779541 	 Other agent action time: 0 	 49.36462365409794 steps/s
Curr learning rate 0.001409 	 Curr reward per step 0.2698054166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.99it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.96it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 192.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.89it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.85it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.17it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 210.28it/s]
------------------------------------
| approxkl           | 0.004287975 |
| clipfrac           | 0.45060417  |
| eplenmean          | 400         |
| eprewmean          | 101         |
| explained_variance | 0.577       |
| fps                | 1368        |
| nupdates           | 92          |
| policy_entropy     | 1.3687624   |
| policy_loss        | 0.005844261 |
| serial_timesteps   | 36800       |
| time_elapsed       | 802         |
| time_remaining     | 95.6        |
| total_timesteps    | 1104000     |
| true_eprew         | 57.8        |
| value_loss         | 28.622267   |
------------------------------------
Current reward shaping 0.724
SP envs: 0/30
Other agent actions took 4.855190753936768 seconds
Total simulation time for 400 steps: 8.154267311096191 	 Other agent action time: 0 	 49.05407006411068 steps/s
Curr learning rate 0.001408 	 Curr reward per step 0.2557266666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.40it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.04it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.29it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.12it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.22it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 167.96it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 160.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.59it/s]
------------------------------------
| approxkl           | 0.004977978 |
| clipfrac           | 0.46713525  |
| eplenmean          | 400         |
| eprewmean          | 102         |
| explained_variance | 0.546       |
| fps                | 1352        |
| nupdates           | 93          |
| policy_entropy     | 1.356649    |
| policy_loss        | 0.006725553 |
| serial_timesteps   | 37200       |
| time_elapsed       | 811         |
| time_remaining     | 95.5        |
| total_timesteps    | 1116000     |
| true_eprew         | 59          |
| value_loss         | 29.23101    |
------------------------------------
Current reward shaping 0.721
SP envs: 0/30
Other agent actions took 4.878007888793945 seconds
Total simulation time for 400 steps: 8.280074834823608 	 Other agent action time: 0 	 48.308742128478755 steps/s
Curr learning rate 0.001407 	 Curr reward per step 0.2579253333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.03it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.39it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.54it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.49it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.67it/s]
-------------------------------------
| approxkl           | 0.0039791223 |
| clipfrac           | 0.42570832   |
| eplenmean          | 400          |
| eprewmean          | 104          |
| explained_variance | 0.594        |
| fps                | 1333         |
| nupdates           | 94           |
| policy_entropy     | 1.3529645    |
| policy_loss        | 0.0048560575 |
| serial_timesteps   | 37600        |
| time_elapsed       | 820          |
| time_remaining     | 95.4         |
| total_timesteps    | 1128000      |
| true_eprew         | 59.6         |
| value_loss         | 27.761595    |
-------------------------------------
Current reward shaping 0.718
SP envs: 0/30
Other agent actions took 4.892110347747803 seconds
Total simulation time for 400 steps: 8.24914813041687 	 Other agent action time: 0 	 48.48985539792774 steps/s
Curr learning rate 0.0014060000000000001 	 Curr reward per step 0.2505546666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.95it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 160.96it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.84it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.59it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.58it/s]
-------------------------------------
| approxkl           | 0.004521479  |
| clipfrac           | 0.45355198   |
| eplenmean          | 400          |
| eprewmean          | 103          |
| explained_variance | 0.564        |
| fps                | 1336         |
| nupdates           | 95           |
| policy_entropy     | 1.3727542    |
| policy_loss        | 0.0062180846 |
| serial_timesteps   | 38000        |
| time_elapsed       | 829          |
| time_remaining     | 95.2         |
| total_timesteps    | 1140000      |
| true_eprew         | 59.6         |
| value_loss         | 27.916819    |
-------------------------------------
Current reward shaping 0.7150000000000001
SP envs: 0/30
Other agent actions took 4.827990293502808 seconds
Total simulation time for 400 steps: 8.110832929611206 	 Other agent action time: 0 	 49.31675987797397 steps/s
Curr learning rate 0.001405 	 Curr reward per step 0.27046916666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.86it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.77it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.26it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 195.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.80it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.11it/s]
-------------------------------------
| approxkl           | 0.0047439877 |
| clipfrac           | 0.46580204   |
| eplenmean          | 400          |
| eprewmean          | 105          |
| explained_variance | 0.562        |
| fps                | 1365         |
| nupdates           | 96           |
| policy_entropy     | 1.3601518    |
| policy_loss        | 0.0066629197 |
| serial_timesteps   | 38400        |
| time_elapsed       | 838          |
| time_remaining     | 95.1         |
| total_timesteps    | 1152000      |
| true_eprew         | 61           |
| value_loss         | 29.75269     |
-------------------------------------
Current reward shaping 0.712
SP envs: 0/30
Other agent actions took 4.874626159667969 seconds
Total simulation time for 400 steps: 8.17292833328247 	 Other agent action time: 0 	 48.942066256850325 steps/s
Curr learning rate 0.0014039999999999999 	 Curr reward per step 0.263278

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.71it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.87it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.02it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.66it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.31it/s]
------------------------------------
| approxkl           | 0.003973022 |
| clipfrac           | 0.43485412  |
| eplenmean          | 400         |
| eprewmean          | 105         |
| explained_variance | 0.55        |
| fps                | 1352        |
| nupdates           | 97          |
| policy_entropy     | 1.3478239   |
| policy_loss        | 0.004361076 |
| serial_timesteps   | 38800       |
| time_elapsed       | 847         |
| time_remaining     | 95          |
| total_timesteps    | 1164000     |
| true_eprew         | 60.6        |
| value_loss         | 27.815416   |
------------------------------------
Current reward shaping 0.7090000000000001
SP envs: 0/30
Other agent actions took 4.84818172454834 seconds
Total simulation time for 400 steps: 8.15259051322937 	 Other agent action time: 0 	 49.0641593430839 steps/s
Curr learning rate 0.0014030000000000002 	 Curr reward per step 0.28983333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.09it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.72it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.93it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.62it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.89it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.61it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.60it/s]
-------------------------------------
| approxkl           | 0.004395718  |
| clipfrac           | 0.45275006   |
| eplenmean          | 400          |
| eprewmean          | 108          |
| explained_variance | 0.543        |
| fps                | 1357         |
| nupdates           | 98           |
| policy_entropy     | 1.3343312    |
| policy_loss        | 0.0059195613 |
| serial_timesteps   | 39200        |
| time_elapsed       | 855          |
| time_remaining     | 94.8         |
| total_timesteps    | 1176000      |
| true_eprew         | 63.4         |
| value_loss         | 30.918064    |
-------------------------------------
Current reward shaping 0.706
BEST REW 63.4 overwriting previous model with 61.8
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.817047119140625 seconds
Total simulation time for 400 steps: 8.158136367797852 	 Other agent action time: 0 	 49.03080580742647 steps/s
Curr learning rate 0.001402 	 Curr reward per step 0.2604293333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.98it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.61it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.86it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.60it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.74it/s]
------------------------------------
| approxkl           | 0.005216799 |
| clipfrac           | 0.48700002  |
| eplenmean          | 400         |
| eprewmean          | 108         |
| explained_variance | 0.628       |
| fps                | 1357        |
| nupdates           | 99          |
| policy_entropy     | 1.36851     |
| policy_loss        | 0.006905586 |
| serial_timesteps   | 39600       |
| time_elapsed       | 866         |
| time_remaining     | 94.9        |
| total_timesteps    | 1188000     |
| true_eprew         | 63.8        |
| value_loss         | 25.485622   |
------------------------------------
Current reward shaping 0.7030000000000001
BEST REW 63.8 overwriting previous model with 63.4
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.909024000167847 seconds
Total simulation time for 400 steps: 8.151341199874878 	 Other agent action time: 0 	 49.07167914970115 steps/s
Curr learning rate 0.001401 	 Curr reward per step 0.2649023333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.66it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.10it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.75it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.98it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.49it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 206.64it/s]
-------------------------------------
| approxkl           | 0.0042903256 |
| clipfrac           | 0.44730216   |
| eplenmean          | 400          |
| eprewmean          | 109          |
| explained_variance | 0.499        |
| fps                | 1356         |
| nupdates           | 100          |
| policy_entropy     | 1.3507339    |
| policy_loss        | 0.00617647   |
| serial_timesteps   | 40000        |
| time_elapsed       | 876          |
| time_remaining     | 94.9         |
| total_timesteps    | 1200000      |
| true_eprew         | 64.2         |
| value_loss         | 28.84319     |
-------------------------------------
Current reward shaping 0.7
BEST REW 64.2 overwriting previous model with 63.8
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X   X 
D   X ↓0X 
X X X S X 


Timestep: 4
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X   X 
D   X →0X 
X X X S X 


Timestep: 5
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ↑0X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X   X 
D   X ↓0X 
X X X S X 


Timestep: 7
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oX ←0X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oX →0X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →1Xo→0X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →1Xo→0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1Xo  X 
D   X ↓0X 
X X X S X 


Timestep: 13
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1Xo  X 
D   X ↓0X 
X X X S X 


Timestep: 14
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1Xo  X 
D   X ↓0X 
X X X S X 


Timestep: 15
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1Xo  X 
D   X ←0X 
X X X S X 


Timestep: 16
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oXo  X 
D   X ↓0X 
X X X S X 


Timestep: 17
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oXo  X 
D   X ↓0X 
X X X S X 


Timestep: 18
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oXo↑0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oXo  X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oXo↓0X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oXo  X 
D   X ↓0X 
X X X S X 


Timestep: 25
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oXo  X 
D   X ↓0X 
X X X S X 


Timestep: 26
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oXo↑0X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oXo←0X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →1Xo←oX 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑oP 
O ←1Xo  X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   X ↑0P 
O ←1Xo  X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X →0P 
O ←oXo  X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O ←oXo↓0X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oXo→0X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oXo←0X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oXo→0X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oXo←0X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑oX   P 
O   X ←oX 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑oX ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑oX →oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑oX ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X ø=X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X →oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø2X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø3X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →1Xo↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø6X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø7X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←oX   P 
O   X ↓oX 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø9X 
O →oX ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø10X 
O →1Xo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø11X 
O →1Xo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø12X 
O   Xo→oP 
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø13X 
O   Xo→0ø-
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø14X 
O   Xo←0ø-
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø15X 
O   X ←oø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 62
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø16X 
O   X →oø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 63
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø17X 
O   X →oø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 64
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø18X 
O   X →oø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 65
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 3 
X X X ø19X 
O   X →0ø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 66
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X ↑0ø=
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O   X   X 
D →dX   X 
X X X S X 


Timestep: 68
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O   X   X 
D →dX   X 
X X X S X 


Timestep: 69
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O   X   X 
D →dX   X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O   X   X 
D →dX   X 
X X X S X 


Timestep: 71
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xd←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd←0ø=
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←dø=
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd←0ø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 82
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd←0ø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 83
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←dø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 84
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←dø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 85
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →dø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 86
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑dø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 87
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 5 
X X X P X 
O   X ↑sø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 88
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O   X ↓sX 
D ←1X   X 
X X X S X 


Timestep: 89
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O ↑1X   X 
D   X ↓sX 
X X X S X 


Timestep: 90
Joint action taken: ('interact', 'stay') 	 Reward: 20 + shape * 0 
X X X P X 
O   X   ø=
O ↑1X   X 
D   X ↓0X 
X X X S X 


Timestep: 91
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O ←1X   X 
D   X →0X 
X X X S X 


Timestep: 92
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 93
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O →oX ↑0X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O →oX ↑0X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O →1Xo  X 
D   X ↓0X 
X X X S X 


Timestep: 96
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O ←1Xo↑0X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O ←1Xo↑0X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O ←oXo←0X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O ←oX ←oX 
D   X   X 
X X X S X 


/home/mzhao2/overcooked-teaming/overcooked_ai/overcooked_ai_py/mdp/overcooked_env.py:162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  return np.array(trajectory), self.t, self.cumulative_sparse_rewards, self.cumulative_shaped_rewards
tot rew 100 tot rew shaped 94
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 8
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 9
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 10
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ↓1X   X 
X X X S X 


Timestep: 11
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D →1X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ↓1X   X 
X X X S X 


Timestep: 13
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ↓1X   X 
X X X S X 


Timestep: 14
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ↓1X   X 
X X X S X 


Timestep: 15
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 16
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ↓1X   X 
X X X S X 


Timestep: 17
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ←0X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →1X ←0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 34
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 35
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 37
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 38
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D →dX   X 
X X X S X 


Timestep: 39
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D →1Xd  X 
X X X S X 


Timestep: 40
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ←0X 
D   Xd  X 
X X X S X 


Timestep: 41
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   Xd  X 
X X X S X 


Timestep: 42
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   Xd  X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X   P 
O   X ←0X 
D   Xd  X 
X X X S X 


Timestep: 44
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X   P 
O   X ←0X 
D   Xd  X 
X X X S X 


Timestep: 45
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↓1X   X 
D   Xd  X 
X X X S X 


Timestep: 46
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↓1X   X 
D   Xd  X 
X X X S X 


Timestep: 47
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O   X   X 
D ↓1Xd  X 
X X X S X 


Timestep: 48
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O   X   X 
D →1Xd  X 
X X X S X 


Timestep: 49
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   Xd  X 
X X X S X 


Timestep: 50
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   Xd  X 
X X X S X 


Timestep: 51
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   Xd  X 
X X X S X 


Timestep: 52
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   Xd  X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   Xd  X 
X X X S X 


Timestep: 54
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 55
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 56
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 57
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 59
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 60
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 61
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 62
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 63
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 64
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 65
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 66
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 67
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 68
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 69
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 70
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 71
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 72
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 73
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   Xd  X 
X X X S X 


Timestep: 74
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   Xd  X 
X X X S X 


Timestep: 75
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   Xd  X 
X X X S X 


Timestep: 76
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   Xd  X 
X X X S X 


Timestep: 77
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   Xd  X 
X X X S X 


Timestep: 78
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   Xd  X 
X X X S X 


Timestep: 79
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oX ↓0X 
D   Xd  X 
X X X S X 


Timestep: 80
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   Xd  X 
X X X S X 


Timestep: 81
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   Xd  X 
X X X S X 


Timestep: 82
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   Xd  X 
X X X S X 


Timestep: 83
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ←0X 
D   Xd  X 
X X X S X 


Timestep: 84
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   P 
O   X ←0X 
D   Xd  X 
X X X S X 


Timestep: 85
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1X   P 
O   X ←0X 
D   Xd  X 
X X X S X 


Timestep: 86
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   P 
O   X ←0X 
D   Xd  X 
X X X S X 


Timestep: 87
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 88
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 89
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 90
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 91
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 92
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 93
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 94
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX →0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 95
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX →0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 96
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX →0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 97
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX →0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 98
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   Xd  X 
X X X S X 


tot rew 0 tot rew shaped 6
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.85258936882019 seconds
Total simulation time for 400 steps: 8.12194275856018 	 Other agent action time: 0 	 49.24930055415831 steps/s
Curr learning rate 0.0014000000000000002 	 Curr reward per step 0.2609916666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.89it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.20it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.25it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.44it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.65it/s]
------------------------------------
| approxkl           | 0.004639962 |
| clipfrac           | 0.454177    |
| eplenmean          | 400         |
| eprewmean          | 106         |
| explained_variance | 0.599       |
| fps                | 1362        |
| nupdates           | 101         |
| policy_entropy     | 1.3575816   |
| policy_loss        | 0.005420559 |
| serial_timesteps   | 40400       |
| time_elapsed       | 889         |
| time_remaining     | 95.2        |
| total_timesteps    | 1212000     |
| true_eprew         | 62.8        |
| value_loss         | 23.528137   |
------------------------------------
Current reward shaping 0.6970000000000001
SP envs: 0/30
Other agent actions took 4.806756019592285 seconds
Total simulation time for 400 steps: 8.12226939201355 	 Other agent action time: 0 	 49.24732001542713 steps/s
Curr learning rate 0.001399 	 Curr reward per step 0.2548404166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.67it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.43it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.22it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.48it/s]
-------------------------------------
| approxkl           | 0.0052932724 |
| clipfrac           | 0.4827708    |
| eplenmean          | 400          |
| eprewmean          | 104          |
| explained_variance | 0.519        |
| fps                | 1357         |
| nupdates           | 102          |
| policy_entropy     | 1.3383249    |
| policy_loss        | 0.008241704  |
| serial_timesteps   | 40800        |
| time_elapsed       | 898          |
| time_remaining     | 95.1         |
| total_timesteps    | 1224000      |
| true_eprew         | 61.2         |
| value_loss         | 27.73871     |
-------------------------------------
Current reward shaping 0.694
SP envs: 0/30
Other agent actions took 4.916241645812988 seconds
Total simulation time for 400 steps: 8.307979345321655 	 Other agent action time: 0 	 48.14648464734639 steps/s
Curr learning rate 0.001398 	 Curr reward per step 0.25057216666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 156.28it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.44it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.57it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.85it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.88it/s]
------------------------------------
| approxkl           | 0.004500968 |
| clipfrac           | 0.4571249   |
| eplenmean          | 400         |
| eprewmean          | 102         |
| explained_variance | 0.616       |
| fps                | 1328        |
| nupdates           | 103         |
| policy_entropy     | 1.3560259   |
| policy_loss        | 0.006303926 |
| serial_timesteps   | 41200       |
| time_elapsed       | 907         |
| time_remaining     | 95          |
| total_timesteps    | 1236000     |
| true_eprew         | 60.6        |
| value_loss         | 26.4706     |
------------------------------------
Current reward shaping 0.6910000000000001
SP envs: 0/30
Other agent actions took 4.896392107009888 seconds
Total simulation time for 400 steps: 8.243744134902954 	 Other agent action time: 0 	 48.521641799440545 steps/s
Curr learning rate 0.001397 	 Curr reward per step 0.27470275

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.65it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.71it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.25it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.27it/s]
-------------------------------------
| approxkl           | 0.005664468  |
| clipfrac           | 0.49272928   |
| eplenmean          | 400          |
| eprewmean          | 104          |
| explained_variance | 0.511        |
| fps                | 1345         |
| nupdates           | 104          |
| policy_entropy     | 1.3241694    |
| policy_loss        | 0.0089014815 |
| serial_timesteps   | 41600        |
| time_elapsed       | 916          |
| time_remaining     | 94.8         |
| total_timesteps    | 1248000      |
| true_eprew         | 61.8         |
| value_loss         | 30.597254    |
-------------------------------------
Current reward shaping 0.688
SP envs: 0/30
Other agent actions took 4.865936279296875 seconds
Total simulation time for 400 steps: 8.184947967529297 	 Other agent action time: 0 	 48.870194604394506 steps/s
Curr learning rate 0.001396 	 Curr reward per step 0.254576

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.66it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.84it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.97it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.18it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.23it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.21it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.62it/s]
-------------------------------------
| approxkl           | 0.0039121727 |
| clipfrac           | 0.4223646    |
| eplenmean          | 400          |
| eprewmean          | 104          |
| explained_variance | 0.582        |
| fps                | 1349         |
| nupdates           | 105          |
| policy_entropy     | 1.3225514    |
| policy_loss        | 0.004867227  |
| serial_timesteps   | 42000        |
| time_elapsed       | 925          |
| time_remaining     | 94.7         |
| total_timesteps    | 1260000      |
| true_eprew         | 61.4         |
| value_loss         | 27.298815    |
-------------------------------------
Current reward shaping 0.685
SP envs: 0/30
Other agent actions took 4.795229434967041 seconds
Total simulation time for 400 steps: 8.018061876296997 	 Other agent action time: 0 	 49.887367567277124 steps/s
Curr learning rate 0.001395 	 Curr reward per step 0.29235208333333335

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.60it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.22it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.68it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 169.83it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.26it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.09it/s]
-------------------------------------
| approxkl           | 0.004022636  |
| clipfrac           | 0.42225006   |
| eplenmean          | 400          |
| eprewmean          | 110          |
| explained_variance | 0.533        |
| fps                | 1373         |
| nupdates           | 106          |
| policy_entropy     | 1.2870545    |
| policy_loss        | 0.0044381972 |
| serial_timesteps   | 42400        |
| time_elapsed       | 934          |
| time_remaining     | 94.5         |
| total_timesteps    | 1272000      |
| true_eprew         | 65           |
| value_loss         | 30.64351     |
-------------------------------------
Current reward shaping 0.6819999999999999
BEST REW 65.0 overwriting previous model with 64.2
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.857121467590332 seconds
Total simulation time for 400 steps: 8.192753553390503 	 Other agent action time: 0 	 48.823633884905924 steps/s
Curr learning rate 0.001394 	 Curr reward per step 0.2805408333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.17it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.84it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.13it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.40it/s]
-------------------------------------
| approxkl           | 0.004468061  |
| clipfrac           | 0.43537506   |
| eplenmean          | 400          |
| eprewmean          | 111          |
| explained_variance | 0.587        |
| fps                | 1346         |
| nupdates           | 107          |
| policy_entropy     | 1.2859076    |
| policy_loss        | 0.0053676306 |
| serial_timesteps   | 42800        |
| time_elapsed       | 944          |
| time_remaining     | 94.6         |
| total_timesteps    | 1284000      |
| true_eprew         | 66.2         |
| value_loss         | 27.576578    |
-------------------------------------
Current reward shaping 0.679
BEST REW 66.2 overwriting previous model with 65.0
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.919041156768799 seconds
Total simulation time for 400 steps: 8.230537176132202 	 Other agent action time: 0 	 48.599501033779795 steps/s
Curr learning rate 0.0013930000000000001 	 Curr reward per step 0.26999291666666675

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.75it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.86it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.24it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.51it/s]
-------------------------------------
| approxkl           | 0.0043346407 |
| clipfrac           | 0.4442292    |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.627        |
| fps                | 1340         |
| nupdates           | 108          |
| policy_entropy     | 1.287989     |
| policy_loss        | 0.005839785  |
| serial_timesteps   | 43200        |
| time_elapsed       | 955          |
| time_remaining     | 94.6         |
| total_timesteps    | 1296000      |
| true_eprew         | 67.4         |
| value_loss         | 24.997581    |
-------------------------------------
Current reward shaping 0.6759999999999999
BEST REW 67.4 overwriting previous model with 66.2
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.922448396682739 seconds
Total simulation time for 400 steps: 8.284885168075562 	 Other agent action time: 0 	 48.280693321053384 steps/s
Curr learning rate 0.001392 	 Curr reward per step 0.27245099999999994

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 154.54it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.49it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 193.36it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.77it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.92it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.40it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.94it/s]
------------------------------------
| approxkl           | 0.005015426 |
| clipfrac           | 0.4628126   |
| eplenmean          | 400         |
| eprewmean          | 110         |
| explained_variance | 0.534       |
| fps                | 1338        |
| nupdates           | 109         |
| policy_entropy     | 1.2836356   |
| policy_loss        | 0.006925761 |
| serial_timesteps   | 43600       |
| time_elapsed       | 966         |
| time_remaining     | 94.7        |
| total_timesteps    | 1308000     |
| true_eprew         | 66          |
| value_loss         | 28.938038   |
------------------------------------
Current reward shaping 0.673
SP envs: 0/30
Other agent actions took 4.8933045864105225 seconds
Total simulation time for 400 steps: 8.327778100967407 	 Other agent action time: 0 	 48.03201948350827 steps/s
Curr learning rate 0.001391 	 Curr reward per step 0.2633213333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.32it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.52it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.58it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.64it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.97it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.35it/s]
-------------------------------------
| approxkl           | 0.0051422296 |
| clipfrac           | 0.46711463   |
| eplenmean          | 400          |
| eprewmean          | 108          |
| explained_variance | 0.565        |
| fps                | 1328         |
| nupdates           | 110          |
| policy_entropy     | 1.2901212    |
| policy_loss        | 0.007192615  |
| serial_timesteps   | 44000        |
| time_elapsed       | 975          |
| time_remaining     | 94.5         |
| total_timesteps    | 1320000      |
| true_eprew         | 65.2         |
| value_loss         | 27.108032    |
-------------------------------------
Current reward shaping 0.6699999999999999
SP envs: 0/30
Other agent actions took 4.864692449569702 seconds
Total simulation time for 400 steps: 8.187165260314941 	 Other agent action time: 0 	 48.85695931153256 steps/s
Curr learning rate 0.00139 	 Curr reward per step 0.2794891666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.96it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.74it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.03it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.84it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.36it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.52it/s]
-------------------------------------
| approxkl           | 0.004648359  |
| clipfrac           | 0.45136452   |
| eplenmean          | 400          |
| eprewmean          | 108          |
| explained_variance | 0.539        |
| fps                | 1348         |
| nupdates           | 111          |
| policy_entropy     | 1.2760459    |
| policy_loss        | 0.0057394146 |
| serial_timesteps   | 44400        |
| time_elapsed       | 984          |
| time_remaining     | 94.4         |
| total_timesteps    | 1332000      |
| true_eprew         | 65.6         |
| value_loss         | 27.503445    |
-------------------------------------
Current reward shaping 0.667
SP envs: 0/30
Other agent actions took 4.864375591278076 seconds
Total simulation time for 400 steps: 8.18977952003479 	 Other agent action time: 0 	 48.841363680362036 steps/s
Curr learning rate 0.001389 	 Curr reward per step 0.2967241666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.40it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.25it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.98it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.13it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.97it/s]
-------------------------------------
| approxkl           | 0.005088786  |
| clipfrac           | 0.4665728    |
| eplenmean          | 400          |
| eprewmean          | 111          |
| explained_variance | 0.56         |
| fps                | 1354         |
| nupdates           | 112          |
| policy_entropy     | 1.2530681    |
| policy_loss        | 0.0065215332 |
| serial_timesteps   | 44800        |
| time_elapsed       | 993          |
| time_remaining     | 94.2         |
| total_timesteps    | 1344000      |
| true_eprew         | 67.6         |
| value_loss         | 28.787703    |
-------------------------------------
Current reward shaping 0.6639999999999999
BEST REW 67.6 overwriting previous model with 67.4
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.915867567062378 seconds
Total simulation time for 400 steps: 8.328802585601807 	 Other agent action time: 0 	 48.02611130338102 steps/s
Curr learning rate 0.001388 	 Curr reward per step 0.279622

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 146.35it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 145.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.12it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.64it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.51it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.08it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.59it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.66it/s]
-------------------------------------
| approxkl           | 0.0037948566 |
| clipfrac           | 0.41842714   |
| eplenmean          | 400          |
| eprewmean          | 113          |
| explained_variance | 0.631        |
| fps                | 1327         |
| nupdates           | 113          |
| policy_entropy     | 1.255339     |
| policy_loss        | 0.0035311729 |
| serial_timesteps   | 45200        |
| time_elapsed       | 1e+03        |
| time_remaining     | 94.3         |
| total_timesteps    | 1356000      |
| true_eprew         | 69.2         |
| value_loss         | 23.824524    |
-------------------------------------
Current reward shaping 0.661
BEST REW 69.2 overwriting previous model with 67.6
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.930340766906738 seconds
Total simulation time for 400 steps: 8.277982234954834 	 Other agent action time: 0 	 48.32095414640407 steps/s
Curr learning rate 0.001387 	 Curr reward per step 0.2504861666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.17it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.15it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.06it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.03it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.94it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.48it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.28it/s]
-------------------------------------
| approxkl           | 0.0049085575 |
| clipfrac           | 0.45627084   |
| eplenmean          | 400          |
| eprewmean          | 110          |
| explained_variance | 0.563        |
| fps                | 1340         |
| nupdates           | 114          |
| policy_entropy     | 1.2861683    |
| policy_loss        | 0.006858197  |
| serial_timesteps   | 45600        |
| time_elapsed       | 1.01e+03     |
| time_remaining     | 94.4         |
| total_timesteps    | 1368000      |
| true_eprew         | 67.6         |
| value_loss         | 28.076433    |
-------------------------------------
Current reward shaping 0.6579999999999999
SP envs: 0/30
Other agent actions took 4.8272483348846436 seconds
Total simulation time for 400 steps: 8.182926416397095 	 Other agent action time: 0 	 48.88226774207242 steps/s
Curr learning rate 0.001386 	 Curr reward per step 0.2794906666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.35it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.52it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.91it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.55it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.77it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.44it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.08it/s]
------------------------------------
| approxkl           | 0.003976754 |
| clipfrac           | 0.41668758  |
| eplenmean          | 400         |
| eprewmean          | 110         |
| explained_variance | 0.549       |
| fps                | 1349        |
| nupdates           | 115         |
| policy_entropy     | 1.2419883   |
| policy_loss        | 0.004604569 |
| serial_timesteps   | 46000       |
| time_elapsed       | 1.02e+03    |
| time_remaining     | 94.2        |
| total_timesteps    | 1380000     |
| true_eprew         | 67.2        |
| value_loss         | 25.958204   |
------------------------------------
Current reward shaping 0.655
SP envs: 0/30
Other agent actions took 4.8866612911224365 seconds
Total simulation time for 400 steps: 8.214407444000244 	 Other agent action time: 0 	 48.69493055060931 steps/s
Curr learning rate 0.001385 	 Curr reward per step 0.27048041666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.92it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.22it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.57it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.57it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.62it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.72it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.03it/s]
------------------------------------
| approxkl           | 0.004504919 |
| clipfrac           | 0.43547913  |
| eplenmean          | 400         |
| eprewmean          | 106         |
| explained_variance | 0.529       |
| fps                | 1343        |
| nupdates           | 116         |
| policy_entropy     | 1.2363114   |
| policy_loss        | 0.006400345 |
| serial_timesteps   | 46400       |
| time_elapsed       | 1.03e+03    |
| time_remaining     | 94.1        |
| total_timesteps    | 1392000     |
| true_eprew         | 64.6        |
| value_loss         | 29.998009   |
------------------------------------
Current reward shaping 0.652
SP envs: 0/30
Other agent actions took 4.745873928070068 seconds
Total simulation time for 400 steps: 7.960845232009888 	 Other agent action time: 0 	 50.2459209220189 steps/s
Curr learning rate 0.001384 	 Curr reward per step 0.2847343333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.65it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 154.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 158.37it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 166.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 171.54it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 169.17it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 171.03it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.30it/s]
-------------------------------------
| approxkl           | 0.0037683186 |
| clipfrac           | 0.40439576   |
| eplenmean          | 400          |
| eprewmean          | 110          |
| explained_variance | 0.567        |
| fps                | 1376         |
| nupdates           | 117          |
| policy_entropy     | 1.225106     |
| policy_loss        | 0.00519999   |
| serial_timesteps   | 46800        |
| time_elapsed       | 1.04e+03     |
| time_remaining     | 93.9         |
| total_timesteps    | 1404000      |
| true_eprew         | 67           |
| value_loss         | 30.811504    |
-------------------------------------
Current reward shaping 0.649
SP envs: 0/30
Other agent actions took 4.8997111320495605 seconds
Total simulation time for 400 steps: 8.28070855140686 	 Other agent action time: 0 	 48.30504509569312 steps/s
Curr learning rate 0.0013830000000000001 	 Curr reward per step 0.24897249999999999

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.54it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.73it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.72it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.48it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 173.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 172.12it/s]
-------------------------------------
| approxkl           | 0.004564419  |
| clipfrac           | 0.43680206   |
| eplenmean          | 400          |
| eprewmean          | 106          |
| explained_variance | 0.447        |
| fps                | 1336         |
| nupdates           | 118          |
| policy_entropy     | 1.2410314    |
| policy_loss        | 0.0067657246 |
| serial_timesteps   | 47200        |
| time_elapsed       | 1.05e+03     |
| time_remaining     | 93.8         |
| total_timesteps    | 1416000      |
| true_eprew         | 64           |
| value_loss         | 30.895178    |
-------------------------------------
Current reward shaping 0.646
SP envs: 0/30
Other agent actions took 4.785292148590088 seconds
Total simulation time for 400 steps: 8.116697549819946 	 Other agent action time: 0 	 49.28112665832587 steps/s
Curr learning rate 0.001382 	 Curr reward per step 0.30514949999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.37it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.94it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.87it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.88it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.97it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.44it/s]
-------------------------------------
| approxkl           | 0.003933729  |
| clipfrac           | 0.41428116   |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.534        |
| fps                | 1356         |
| nupdates           | 119          |
| policy_entropy     | 1.2143668    |
| policy_loss        | 0.0045391256 |
| serial_timesteps   | 47600        |
| time_elapsed       | 1.06e+03     |
| time_remaining     | 93.6         |
| total_timesteps    | 1428000      |
| true_eprew         | 68.6         |
| value_loss         | 28.169695    |
-------------------------------------
Current reward shaping 0.643
SP envs: 0/30
Other agent actions took 4.868342399597168 seconds
Total simulation time for 400 steps: 8.247032642364502 	 Other agent action time: 0 	 48.50229377597277 steps/s
Curr learning rate 0.0013809999999999998 	 Curr reward per step 0.29026891666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.33it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.01it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.36it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 168.64it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.09it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.75it/s]
-------------------------------------
| approxkl           | 0.004215944  |
| clipfrac           | 0.42998967   |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.545        |
| fps                | 1337         |
| nupdates           | 120          |
| policy_entropy     | 1.2204679    |
| policy_loss        | 0.0053094244 |
| serial_timesteps   | 48000        |
| time_elapsed       | 1.07e+03     |
| time_remaining     | 93.5         |
| total_timesteps    | 1440000      |
| true_eprew         | 68.8         |
| value_loss         | 28.467182    |
-------------------------------------
Current reward shaping 0.64
SP envs: 0/30
Other agent actions took 4.8679139614105225 seconds
Total simulation time for 400 steps: 8.253759860992432 	 Other agent action time: 0 	 48.462762030479524 steps/s
Curr learning rate 0.0013800000000000002 	 Curr reward per step 0.3111466666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 154.80it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.52it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.83it/s]
------------------------------------
| approxkl           | 0.00377717  |
| clipfrac           | 0.41405204  |
| eplenmean          | 400         |
| eprewmean          | 120         |
| explained_variance | 0.553       |
| fps                | 1338        |
| nupdates           | 121         |
| policy_entropy     | 1.2116666   |
| policy_loss        | 0.004588941 |
| serial_timesteps   | 48400       |
| time_elapsed       | 1.08e+03    |
| time_remaining     | 93.3        |
| total_timesteps    | 1452000     |
| true_eprew         | 74          |
| value_loss         | 30.465023   |
------------------------------------
Current reward shaping 0.637
BEST REW 74.0 overwriting previous model with 69.2
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.78992223739624 seconds
Total simulation time for 400 steps: 8.14546799659729 	 Other agent action time: 0 	 49.107061763313915 steps/s
Curr learning rate 0.001379 	 Curr reward per step 0.3181955

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.93it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.18it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.00it/s]
-------------------------------------
| approxkl           | 0.0047268765 |
| clipfrac           | 0.44234377   |
| eplenmean          | 400          |
| eprewmean          | 123          |
| explained_variance | 0.569        |
| fps                | 1352         |
| nupdates           | 122          |
| policy_entropy     | 1.1805413    |
| policy_loss        | 0.00584311   |
| serial_timesteps   | 48800        |
| time_elapsed       | 1.09e+03     |
| time_remaining     | 93.4         |
| total_timesteps    | 1464000      |
| true_eprew         | 76           |
| value_loss         | 29.275087    |
-------------------------------------
Current reward shaping 0.634
BEST REW 76.0 overwriting previous model with 74.0
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.826634407043457 seconds
Total simulation time for 400 steps: 8.202536344528198 	 Other agent action time: 0 	 48.76540416268129 steps/s
Curr learning rate 0.001378 	 Curr reward per step 0.28465799999999997

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 179.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 188.66it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.40it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.95it/s]
-------------------------------------
| approxkl           | 0.0041080597 |
| clipfrac           | 0.42559373   |
| eplenmean          | 400          |
| eprewmean          | 123          |
| explained_variance | 0.583        |
| fps                | 1353         |
| nupdates           | 123          |
| policy_entropy     | 1.2086926    |
| policy_loss        | 0.0042578964 |
| serial_timesteps   | 49200        |
| time_elapsed       | 1.1e+03      |
| time_remaining     | 93.4         |
| total_timesteps    | 1476000      |
| true_eprew         | 76.2         |
| value_loss         | 27.590773    |
-------------------------------------
Current reward shaping 0.631
BEST REW 76.2 overwriting previous model with 76.0
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.841624736785889 seconds
Total simulation time for 400 steps: 8.13997197151184 	 Other agent action time: 0 	 49.140218344720886 steps/s
Curr learning rate 0.001377 	 Curr reward per step 0.2920916666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.64it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.27it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.63it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.27it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.48it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.34it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.84it/s]
------------------------------------
| approxkl           | 0.003753808 |
| clipfrac           | 0.4110104   |
| eplenmean          | 400         |
| eprewmean          | 119         |
| explained_variance | 0.556       |
| fps                | 1357        |
| nupdates           | 124         |
| policy_entropy     | 1.2098157   |
| policy_loss        | 0.005145912 |
| serial_timesteps   | 49600       |
| time_elapsed       | 1.11e+03    |
| time_remaining     | 93.4        |
| total_timesteps    | 1488000     |
| true_eprew         | 74.4        |
| value_loss         | 28.622135   |
------------------------------------
Current reward shaping 0.628
SP envs: 0/30
Other agent actions took 5.042845726013184 seconds
Total simulation time for 400 steps: 8.340895652770996 	 Other agent action time: 0 	 47.956480533012396 steps/s
Curr learning rate 0.001376 	 Curr reward per step 0.290363

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.37it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.50it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.46it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.96it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.09it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.23it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.00it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.82it/s]
-------------------------------------
| approxkl           | 0.0044368436 |
| clipfrac           | 0.43073955   |
| eplenmean          | 400          |
| eprewmean          | 116          |
| explained_variance | 0.509        |
| fps                | 1326         |
| nupdates           | 125          |
| policy_entropy     | 1.1879355    |
| policy_loss        | 0.005428818  |
| serial_timesteps   | 50000        |
| time_elapsed       | 1.12e+03     |
| time_remaining     | 93.3         |
| total_timesteps    | 1500000      |
| true_eprew         | 72.2         |
| value_loss         | 30.11615     |
-------------------------------------
Current reward shaping 0.625
SP envs: 0/30
Other agent actions took 4.9072089195251465 seconds
Total simulation time for 400 steps: 8.316555500030518 	 Other agent action time: 0 	 48.09683528217087 steps/s
Curr learning rate 0.001375 	 Curr reward per step 0.28921875

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.02it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.74it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 162.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.00it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.48it/s]
-------------------------------------
| approxkl           | 0.005230626  |
| clipfrac           | 0.4573335    |
| eplenmean          | 400          |
| eprewmean          | 116          |
| explained_variance | 0.576        |
| fps                | 1329         |
| nupdates           | 126          |
| policy_entropy     | 1.2099394    |
| policy_loss        | 0.0066597783 |
| serial_timesteps   | 50400        |
| time_elapsed       | 1.13e+03     |
| time_remaining     | 93.1         |
| total_timesteps    | 1512000      |
| true_eprew         | 71.8         |
| value_loss         | 28.57363     |
-------------------------------------
Current reward shaping 0.622
SP envs: 0/30
Other agent actions took 4.894012212753296 seconds
Total simulation time for 400 steps: 8.255629062652588 	 Other agent action time: 0 	 48.45178931422064 steps/s
Curr learning rate 0.001374 	 Curr reward per step 0.26722333333333326

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.93it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.07it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.47it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.53it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.52it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.53it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.26it/s]
-------------------------------------
| approxkl           | 0.0056186225 |
| clipfrac           | 0.47560415   |
| eplenmean          | 400          |
| eprewmean          | 114          |
| explained_variance | 0.542        |
| fps                | 1341         |
| nupdates           | 127          |
| policy_entropy     | 1.2183737    |
| policy_loss        | 0.008070737  |
| serial_timesteps   | 50800        |
| time_elapsed       | 1.14e+03     |
| time_remaining     | 93           |
| total_timesteps    | 1524000      |
| true_eprew         | 71           |
| value_loss         | 26.795153    |
-------------------------------------
Current reward shaping 0.619
SP envs: 0/30
Other agent actions took 4.890836000442505 seconds
Total simulation time for 400 steps: 8.186962842941284 	 Other agent action time: 0 	 48.85816726832661 steps/s
Curr learning rate 0.001373 	 Curr reward per step 0.30497925000000004

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.18it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.82it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.21it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.21it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.54it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.55it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.93it/s]
-------------------------------------
| approxkl           | 0.0037380601 |
| clipfrac           | 0.4060937    |
| eplenmean          | 400          |
| eprewmean          | 115          |
| explained_variance | 0.569        |
| fps                | 1349         |
| nupdates           | 128          |
| policy_entropy     | 1.1994367    |
| policy_loss        | 0.003761582  |
| serial_timesteps   | 51200        |
| time_elapsed       | 1.15e+03     |
| time_remaining     | 92.8         |
| total_timesteps    | 1536000      |
| true_eprew         | 71.6         |
| value_loss         | 30.234076    |
-------------------------------------
Current reward shaping 0.616
SP envs: 0/30
Other agent actions took 4.878906965255737 seconds
Total simulation time for 400 steps: 8.184641361236572 	 Other agent action time: 0 	 48.87202533936883 steps/s
Curr learning rate 0.001372 	 Curr reward per step 0.27515466666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.67it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.91it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.14it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.78it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.87it/s]
-------------------------------------
| approxkl           | 0.004650341  |
| clipfrac           | 0.43921873   |
| eplenmean          | 400          |
| eprewmean          | 114          |
| explained_variance | 0.555        |
| fps                | 1345         |
| nupdates           | 129          |
| policy_entropy     | 1.23409      |
| policy_loss        | 0.0060481937 |
| serial_timesteps   | 51600        |
| time_elapsed       | 1.16e+03     |
| time_remaining     | 92.7         |
| total_timesteps    | 1548000      |
| true_eprew         | 70.8         |
| value_loss         | 29.993828    |
-------------------------------------
Current reward shaping 0.613
SP envs: 0/30
Other agent actions took 4.894637107849121 seconds
Total simulation time for 400 steps: 8.21590518951416 	 Other agent action time: 0 	 48.68605354775931 steps/s
Curr learning rate 0.001371 	 Curr reward per step 0.28461866666666663

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.49it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.16it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.57it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.97it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.16it/s]
-------------------------------------
| approxkl           | 0.005412431  |
| clipfrac           | 0.4492083    |
| eplenmean          | 400          |
| eprewmean          | 114          |
| explained_variance | 0.573        |
| fps                | 1348         |
| nupdates           | 130          |
| policy_entropy     | 1.214323     |
| policy_loss        | 0.0069736387 |
| serial_timesteps   | 52000        |
| time_elapsed       | 1.16e+03     |
| time_remaining     | 92.5         |
| total_timesteps    | 1560000      |
| true_eprew         | 71.6         |
| value_loss         | 27.608046    |
-------------------------------------
Current reward shaping 0.61
SP envs: 0/30
Other agent actions took 4.934025526046753 seconds
Total simulation time for 400 steps: 8.192452192306519 	 Other agent action time: 0 	 48.825429872589005 steps/s
Curr learning rate 0.0013700000000000001 	 Curr reward per step 0.27024333333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.35it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.08it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 206.10it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.56it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 196.55it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.07it/s]
-------------------------------------
| approxkl           | 0.0035697562 |
| clipfrac           | 0.4103541    |
| eplenmean          | 400          |
| eprewmean          | 111          |
| explained_variance | 0.578        |
| fps                | 1356         |
| nupdates           | 131          |
| policy_entropy     | 1.2448605    |
| policy_loss        | 0.004596446  |
| serial_timesteps   | 52400        |
| time_elapsed       | 1.17e+03     |
| time_remaining     | 92.4         |
| total_timesteps    | 1572000      |
| true_eprew         | 69.4         |
| value_loss         | 26.558283    |
-------------------------------------
Current reward shaping 0.607
SP envs: 0/30
Other agent actions took 4.965842247009277 seconds
Total simulation time for 400 steps: 8.28041124343872 	 Other agent action time: 0 	 48.306779487184805 steps/s
Curr learning rate 0.001369 	 Curr reward per step 0.3168955

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.24it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.39it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.48it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.73it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.54it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.77it/s]
-------------------------------------
| approxkl           | 0.0032736226 |
| clipfrac           | 0.38651043   |
| eplenmean          | 400          |
| eprewmean          | 116          |
| explained_variance | 0.569        |
| fps                | 1334         |
| nupdates           | 132          |
| policy_entropy     | 1.2083968    |
| policy_loss        | 0.0032939995 |
| serial_timesteps   | 52800        |
| time_elapsed       | 1.18e+03     |
| time_remaining     | 92.2         |
| total_timesteps    | 1584000      |
| true_eprew         | 73           |
| value_loss         | 26.817425    |
-------------------------------------
Current reward shaping 0.604
SP envs: 0/30
Other agent actions took 4.878016710281372 seconds
Total simulation time for 400 steps: 8.396965026855469 	 Other agent action time: 0 	 47.63625890077021 steps/s
Curr learning rate 0.001368 	 Curr reward per step 0.30063266666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.32it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 183.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 199.40it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 200.16it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 200.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 201.13it/s]
-------------------------------------
| approxkl           | 0.004068128  |
| clipfrac           | 0.42014572   |
| eplenmean          | 400          |
| eprewmean          | 118          |
| explained_variance | 0.552        |
| fps                | 1325         |
| nupdates           | 133          |
| policy_entropy     | 1.2211596    |
| policy_loss        | 0.0060383677 |
| serial_timesteps   | 53200        |
| time_elapsed       | 1.19e+03     |
| time_remaining     | 92.1         |
| total_timesteps    | 1596000      |
| true_eprew         | 74.4         |
| value_loss         | 30.465343    |
-------------------------------------
Current reward shaping 0.601
SP envs: 0/30
Other agent actions took 4.801870584487915 seconds
Total simulation time for 400 steps: 8.098057746887207 	 Other agent action time: 0 	 49.39456009112247 steps/s
Curr learning rate 0.0013670000000000002 	 Curr reward per step 0.306185

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.89it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.79it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 199.88it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.65it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 196.48it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.69it/s]
-------------------------------------
| approxkl           | 0.0049643973 |
| clipfrac           | 0.44383344   |
| eplenmean          | 400          |
| eprewmean          | 121          |
| explained_variance | 0.525        |
| fps                | 1370         |
| nupdates           | 134          |
| policy_entropy     | 1.1797596    |
| policy_loss        | 0.0066250945 |
| serial_timesteps   | 53600        |
| time_elapsed       | 1.2e+03      |
| time_remaining     | 91.9         |
| total_timesteps    | 1608000      |
| true_eprew         | 77           |
| value_loss         | 31.615469    |
-------------------------------------
Current reward shaping 0.598
BEST REW 77.0 overwriting previous model with 76.2
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.896692752838135 seconds
Total simulation time for 400 steps: 8.19861388206482 	 Other agent action time: 0 	 48.7887349927571 steps/s
Curr learning rate 0.001366 	 Curr reward per step 0.28746283333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.75it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.57it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.40it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.41it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.14it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.50it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.81it/s]
-------------------------------------
| approxkl           | 0.004051601  |
| clipfrac           | 0.42213538   |
| eplenmean          | 400          |
| eprewmean          | 120          |
| explained_variance | 0.585        |
| fps                | 1343         |
| nupdates           | 135          |
| policy_entropy     | 1.1962745    |
| policy_loss        | 0.0054696444 |
| serial_timesteps   | 54000        |
| time_elapsed       | 1.21e+03     |
| time_remaining     | 92           |
| total_timesteps    | 1620000      |
| true_eprew         | 76           |
| value_loss         | 28.617155    |
-------------------------------------
Current reward shaping 0.595
SP envs: 0/30
Other agent actions took 4.908090114593506 seconds
Total simulation time for 400 steps: 8.336202383041382 	 Other agent action time: 0 	 47.9834799612991 steps/s
Curr learning rate 0.0013650000000000001 	 Curr reward per step 0.3163225

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.01it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.82it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.70it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.27it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.94it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 164.79it/s]
-------------------------------------
| approxkl           | 0.0044566095 |
| clipfrac           | 0.43262485   |
| eplenmean          | 400          |
| eprewmean          | 120          |
| explained_variance | 0.492        |
| fps                | 1327         |
| nupdates           | 136          |
| policy_entropy     | 1.2031454    |
| policy_loss        | 0.006287044  |
| serial_timesteps   | 54400        |
| time_elapsed       | 1.22e+03     |
| time_remaining     | 91.8         |
| total_timesteps    | 1632000      |
| true_eprew         | 76.2         |
| value_loss         | 33.145443    |
-------------------------------------
Current reward shaping 0.5920000000000001
SP envs: 0/30
Other agent actions took 4.837225914001465 seconds
Total simulation time for 400 steps: 8.190024375915527 	 Other agent action time: 0 	 48.839903477733635 steps/s
Curr learning rate 0.001364 	 Curr reward per step 0.30058399999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 153.45it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.41it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.72it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 168.55it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.43it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.10it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.74it/s]
-------------------------------------
| approxkl           | 0.0046886285 |
| clipfrac           | 0.44103128   |
| eplenmean          | 400          |
| eprewmean          | 122          |
| explained_variance | 0.599        |
| fps                | 1345         |
| nupdates           | 137          |
| policy_entropy     | 1.2125806    |
| policy_loss        | 0.006294622  |
| serial_timesteps   | 54800        |
| time_elapsed       | 1.23e+03     |
| time_remaining     | 91.7         |
| total_timesteps    | 1644000      |
| true_eprew         | 77.4         |
| value_loss         | 26.675516    |
-------------------------------------
Current reward shaping 0.589
BEST REW 77.4 overwriting previous model with 77.0
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.969818115234375 seconds
Total simulation time for 400 steps: 8.296092748641968 	 Other agent action time: 0 	 48.21546866932969 steps/s
Curr learning rate 0.001363 	 Curr reward per step 0.28469258333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.50it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.04it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.92it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.23it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.92it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.78it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.28it/s]
------------------------------------
| approxkl           | 0.00521376  |
| clipfrac           | 0.45310408  |
| eplenmean          | 400         |
| eprewmean          | 119         |
| explained_variance | 0.618       |
| fps                | 1330        |
| nupdates           | 138         |
| policy_entropy     | 1.1858132   |
| policy_loss        | 0.006473931 |
| serial_timesteps   | 55200       |
| time_elapsed       | 1.24e+03    |
| time_remaining     | 91.7        |
| total_timesteps    | 1656000     |
| true_eprew         | 75.6        |
| value_loss         | 26.897287   |
------------------------------------
Current reward shaping 0.5860000000000001
SP envs: 0/30
Other agent actions took 4.939283847808838 seconds
Total simulation time for 400 steps: 8.321044445037842 	 Other agent action time: 0 	 48.070888533534436 steps/s
Curr learning rate 0.001362 	 Curr reward per step 0.2965543333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.37it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.61it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.95it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.48it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.69it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.09it/s]
------------------------------------
| approxkl           | 0.004903863 |
| clipfrac           | 0.4448437   |
| eplenmean          | 400         |
| eprewmean          | 119         |
| explained_variance | 0.542       |
| fps                | 1332        |
| nupdates           | 139         |
| policy_entropy     | 1.188588    |
| policy_loss        | 0.007463637 |
| serial_timesteps   | 55600       |
| time_elapsed       | 1.25e+03    |
| time_remaining     | 91.5        |
| total_timesteps    | 1668000     |
| true_eprew         | 76.4        |
| value_loss         | 28.20328    |
------------------------------------
Current reward shaping 0.583
SP envs: 0/30
Other agent actions took 5.037555694580078 seconds
Total simulation time for 400 steps: 8.500028848648071 	 Other agent action time: 0 	 47.05866381425517 steps/s
Curr learning rate 0.001361 	 Curr reward per step 0.2993759166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.02it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.48it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.11it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.93it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.86it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.64it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.22it/s]
------------------------------------
| approxkl           | 0.005025911 |
| clipfrac           | 0.44539586  |
| eplenmean          | 400         |
| eprewmean          | 118         |
| explained_variance | 0.555       |
| fps                | 1303        |
| nupdates           | 140         |
| policy_entropy     | 1.1802738   |
| policy_loss        | 0.007701837 |
| serial_timesteps   | 56000       |
| time_elapsed       | 1.26e+03    |
| time_remaining     | 91.4        |
| total_timesteps    | 1680000     |
| true_eprew         | 75.4        |
| value_loss         | 33.257286   |
------------------------------------
Current reward shaping 0.5800000000000001
SP envs: 0/30
Other agent actions took 4.989043712615967 seconds
Total simulation time for 400 steps: 8.32121229171753 	 Other agent action time: 0 	 48.06991889849243 steps/s
Curr learning rate 0.00136 	 Curr reward per step 0.29292666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.96it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.99it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.31it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.23it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.30it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.64it/s]
------------------------------------
| approxkl           | 0.004300157 |
| clipfrac           | 0.4094583   |
| eplenmean          | 400         |
| eprewmean          | 119         |
| explained_variance | 0.549       |
| fps                | 1327        |
| nupdates           | 141         |
| policy_entropy     | 1.1560569   |
| policy_loss        | 0.005171529 |
| serial_timesteps   | 56400       |
| time_elapsed       | 1.27e+03    |
| time_remaining     | 91.3        |
| total_timesteps    | 1692000     |
| true_eprew         | 76.6        |
| value_loss         | 33.29468    |
------------------------------------
Current reward shaping 0.577
SP envs: 0/30
Other agent actions took 4.9103028774261475 seconds
Total simulation time for 400 steps: 8.25081467628479 	 Other agent action time: 0 	 48.48006114471518 steps/s
Curr learning rate 0.001359 	 Curr reward per step 0.282834

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.01it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.23it/s]
-------------------------------------
| approxkl           | 0.0062659425 |
| clipfrac           | 0.46947923   |
| eplenmean          | 400          |
| eprewmean          | 118          |
| explained_variance | 0.542        |
| fps                | 1339         |
| nupdates           | 142          |
| policy_entropy     | 1.1651714    |
| policy_loss        | 0.0075248894 |
| serial_timesteps   | 56800        |
| time_elapsed       | 1.28e+03     |
| time_remaining     | 91.1         |
| total_timesteps    | 1704000      |
| true_eprew         | 75.8         |
| value_loss         | 27.637394    |
-------------------------------------
Current reward shaping 0.5740000000000001
SP envs: 0/30
Other agent actions took 4.881673336029053 seconds
Total simulation time for 400 steps: 8.20485782623291 	 Other agent action time: 0 	 48.75160648379592 steps/s
Curr learning rate 0.001358 	 Curr reward per step 0.316356

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.41it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.42it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.81it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.75it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.63it/s]
-------------------------------------
| approxkl           | 0.0048470674 |
| clipfrac           | 0.42675003   |
| eplenmean          | 400          |
| eprewmean          | 122          |
| explained_variance | 0.547        |
| fps                | 1347         |
| nupdates           | 143          |
| policy_entropy     | 1.1188769    |
| policy_loss        | 0.006217725  |
| serial_timesteps   | 57200        |
| time_elapsed       | 1.29e+03     |
| time_remaining     | 91           |
| total_timesteps    | 1716000      |
| true_eprew         | 78.4         |
| value_loss         | 29.517038    |
-------------------------------------
Current reward shaping 0.571
BEST REW 78.4 overwriting previous model with 77.4
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.811756134033203 seconds
Total simulation time for 400 steps: 8.160821914672852 	 Other agent action time: 0 	 49.01467084838783 steps/s
Curr learning rate 0.0013570000000000001 	 Curr reward per step 0.3216768333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.05it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.27it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.34it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.84it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.97it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.05it/s]
-------------------------------------
| approxkl           | 0.0052573606 |
| clipfrac           | 0.44255218   |
| eplenmean          | 400          |
| eprewmean          | 122          |
| explained_variance | 0.567        |
| fps                | 1356         |
| nupdates           | 144          |
| policy_entropy     | 1.1127212    |
| policy_loss        | 0.0076128156 |
| serial_timesteps   | 57600        |
| time_elapsed       | 1.3e+03      |
| time_remaining     | 91           |
| total_timesteps    | 1728000      |
| true_eprew         | 78.8         |
| value_loss         | 29.11181     |
-------------------------------------
Current reward shaping 0.5680000000000001
BEST REW 78.8 overwriting previous model with 78.4
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.970446825027466 seconds
Total simulation time for 400 steps: 8.36013412475586 	 Other agent action time: 0 	 47.84612232661772 steps/s
Curr learning rate 0.001356 	 Curr reward per step 0.2933186666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.01it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.94it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.17it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 164.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.29it/s]
------------------------------------
| approxkl           | 0.004886983 |
| clipfrac           | 0.4401979   |
| eplenmean          | 400         |
| eprewmean          | 122         |
| explained_variance | 0.545       |
| fps                | 1319        |
| nupdates           | 145         |
| policy_entropy     | 1.1482208   |
| policy_loss        | 0.007618455 |
| serial_timesteps   | 58000       |
| time_elapsed       | 1.31e+03    |
| time_remaining     | 91          |
| total_timesteps    | 1740000     |
| true_eprew         | 78.8        |
| value_loss         | 31.519697   |
------------------------------------
Current reward shaping 0.565
SP envs: 0/30
Other agent actions took 4.9858245849609375 seconds
Total simulation time for 400 steps: 8.310359716415405 	 Other agent action time: 0 	 48.13269384836403 steps/s
Curr learning rate 0.0013549999999999999 	 Curr reward per step 0.3208154166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.10it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.79it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.97it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.59it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.13it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.47it/s]
-------------------------------------
| approxkl           | 0.004240911  |
| clipfrac           | 0.4082082    |
| eplenmean          | 400          |
| eprewmean          | 126          |
| explained_variance | 0.556        |
| fps                | 1330         |
| nupdates           | 146          |
| policy_entropy     | 1.0907937    |
| policy_loss        | 0.0056652683 |
| serial_timesteps   | 58400        |
| time_elapsed       | 1.32e+03     |
| time_remaining     | 90.9         |
| total_timesteps    | 1752000      |
| true_eprew         | 81.4         |
| value_loss         | 29.796165    |
-------------------------------------
Current reward shaping 0.562
BEST REW 81.4 overwriting previous model with 78.8
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.919342041015625 seconds
Total simulation time for 400 steps: 8.279702425003052 	 Other agent action time: 0 	 48.310914990384155 steps/s
Curr learning rate 0.0013540000000000002 	 Curr reward per step 0.268237

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 183.05it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.22it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 202.83it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 221.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.23it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.24it/s]
------------------------------------
| approxkl           | 0.004364987 |
| clipfrac           | 0.414427    |
| eplenmean          | 400         |
| eprewmean          | 119         |
| explained_variance | 0.517       |
| fps                | 1343        |
| nupdates           | 147         |
| policy_entropy     | 1.1532441   |
| policy_loss        | 0.004789789 |
| serial_timesteps   | 58800       |
| time_elapsed       | 1.33e+03    |
| time_remaining     | 90.9        |
| total_timesteps    | 1764000     |
| true_eprew         | 76.8        |
| value_loss         | 32.311268   |
------------------------------------
Current reward shaping 0.5589999999999999
SP envs: 0/30
Other agent actions took 4.846001386642456 seconds
Total simulation time for 400 steps: 8.187376260757446 	 Other agent action time: 0 	 48.85570019753733 steps/s
Curr learning rate 0.001353 	 Curr reward per step 0.31725549999999997

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.86it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 153.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 167.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 168.41it/s]
-------------------------------------
| approxkl           | 0.0045517823 |
| clipfrac           | 0.41600007   |
| eplenmean          | 400          |
| eprewmean          | 121          |
| explained_variance | 0.45         |
| fps                | 1342         |
| nupdates           | 148          |
| policy_entropy     | 1.0857619    |
| policy_loss        | 0.0055862674 |
| serial_timesteps   | 59200        |
| time_elapsed       | 1.34e+03     |
| time_remaining     | 90.7         |
| total_timesteps    | 1776000      |
| true_eprew         | 78.6         |
| value_loss         | 32.629467    |
-------------------------------------
Current reward shaping 0.556
SP envs: 0/30
Other agent actions took 4.827179908752441 seconds
Total simulation time for 400 steps: 8.202158689498901 	 Other agent action time: 0 	 48.767649486239996 steps/s
Curr learning rate 0.001352 	 Curr reward per step 0.2953606666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.34it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 201.41it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.53it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.62it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 203.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 196.71it/s]
-------------------------------------
| approxkl           | 0.003930304  |
| clipfrac           | 0.3882292    |
| eplenmean          | 400          |
| eprewmean          | 119          |
| explained_variance | 0.558        |
| fps                | 1353         |
| nupdates           | 149          |
| policy_entropy     | 1.1022223    |
| policy_loss        | 0.0044259424 |
| serial_timesteps   | 59600        |
| time_elapsed       | 1.35e+03     |
| time_remaining     | 90.6         |
| total_timesteps    | 1788000      |
| true_eprew         | 77.2         |
| value_loss         | 33.243332    |
-------------------------------------
Current reward shaping 0.5529999999999999
SP envs: 0/30
Other agent actions took 4.849517583847046 seconds
Total simulation time for 400 steps: 8.156795978546143 	 Other agent action time: 0 	 49.03886293736815 steps/s
Curr learning rate 0.001351 	 Curr reward per step 0.30188258333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.82it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.54it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.83it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.67it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.69it/s]
-------------------------------------
| approxkl           | 0.0043719085 |
| clipfrac           | 0.39929155   |
| eplenmean          | 400          |
| eprewmean          | 121          |
| explained_variance | 0.588        |
| fps                | 1356         |
| nupdates           | 150          |
| policy_entropy     | 1.0628963    |
| policy_loss        | 0.0044775857 |
| serial_timesteps   | 60000        |
| time_elapsed       | 1.36e+03     |
| time_remaining     | 90.4         |
| total_timesteps    | 1800000      |
| true_eprew         | 78.6         |
| value_loss         | 29.722807    |
-------------------------------------
Current reward shaping 0.55
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø2X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø3X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø5X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø6X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø7X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø9X 
O ←oX ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø10X 
O →oX ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø11X 
O →oX ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →oXo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø13X 
O →1Xo←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø14X 
O ←1Xo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø15X 
O ←1Xo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø16X 
O ←1Xo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø17X 
O ←1Xo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø18X 
O ←oXo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø19X 
O →oXo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oXo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oXo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oXo↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑oP 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑oP 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑oP 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑oP 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo→oP 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   Xo→0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑0ø-
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 63
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑0ø-
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 64
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑0ø-
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 65
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   X ↓0X 
D ↓oX   X 
X X X S X 


Timestep: 66
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   X ↓0X 
D →oX   X 
X X X S X 


Timestep: 67
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   X ←0X 
D →oX   X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   X ←0X 
D →oX   X 
X X X S X 


Timestep: 69
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑0ø-
O   X   X 
D →1Xo  X 
X X X S X 


Timestep: 70
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø-
O ↑1X   X 
D   Xo  X 
X X X S X 


Timestep: 71
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←oø-
O ↑1X   X 
D   Xo  X 
X X X S X 


Timestep: 72
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →oø-
O ←1X   X 
D   Xo  X 
X X X S X 


Timestep: 73
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X →0ø=
O ←1X   X 
D   Xo  X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O ←1X   X 
D   Xo  X 
X X X S X 


Timestep: 75
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O ←1X   X 
D   Xo  X 
X X X S X 


Timestep: 76
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O ←oX   X 
D   Xo  X 
X X X S X 


Timestep: 77
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O →oX   X 
D   Xo  X 
X X X S X 


Timestep: 78
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O →1Xo  X 
D   Xo  X 
X X X S X 


Timestep: 79
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑1X ↑0ø=
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 80
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑1X ←0ø=
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 81
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←1X ↑0ø=
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 82
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←oX ←0ø=
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 83
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX ←0ø=
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 84
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX ←0ø=
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 85
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX ←0ø=
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 86
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX ←0ø=
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 87
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo←0ø=
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 88
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø=
O ↓1Xo  X 
D   Xo  X 
X X X S X 


Timestep: 89
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←oø=
O ↓1Xo  X 
D   Xo  X 
X X X S X 


Timestep: 90
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑oø=
O   Xo  X 
D ↓1Xo  X 
X X X S X 


Timestep: 91
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑oø=
O   Xo  X 
D ←1Xo  X 
X X X S X 


Timestep: 92
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X ↑oø=
O   Xo  X 
D ←dXo  X 
X X X S X 


Timestep: 93
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑oø=
O   Xo  X 
D ←dXo  X 
X X X S X 


Timestep: 94
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑oø=
O   Xo  X 
D ←dXo  X 
X X X S X 


Timestep: 95
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →oø=
O ↑dXo  X 
D   Xo  X 
X X X S X 


Timestep: 96
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X →0ø1
O ↑dXo  X 
D   Xo  X 
X X X S X 


Timestep: 97
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX ←0ø2
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 98
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX ↑0ø3
O   Xo  X 
D   Xo  X 
X X X S X 


Timestep: 99
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX ↑0ø4
O   Xo  X 
D   Xo  X 
X X X S X 


tot rew 120 tot rew shaped 99
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O →1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O →1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O →1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O →1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oX   X 
D   X ↓0X 
X X X S X 


Timestep: 18
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →1Xo↑0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   Xo↑0X 
D ↓1X   X 
X X X S X 


Timestep: 20
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O   Xo  X 
D ←1X   X 
X X X S X 


Timestep: 21
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D →1X   X 
X X X S X 


Timestep: 22
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   Xo↓0X 
D ↓1X   X 
X X X S X 


Timestep: 23
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   Xo←0X 
D ↓1X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←oX 
D ↓1X   X 
X X X S X 


Timestep: 25
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←oX 
D →1X   X 
X X X S X 


Timestep: 26
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ←oX 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑oP 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →oP 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X P X 
O   X →0ø-
O →1X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0ø-
O →1X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   ø-
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   ø-
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ↓1X ↓0X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D ↓1X   X 
X X X S X 


Timestep: 37
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ←0X 
D ↓1X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 39
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 40
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 41
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X   X 
D ←1X ↓0X 
X X X S X 


Timestep: 42
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X   X 
D ←1X ↓0X 
X X X S X 


Timestep: 43
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X   X 
D ↓1X ↓0X 
X X X S X 


Timestep: 44
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X   X 
D ←1X ←0X 
X X X S X 


Timestep: 45
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ↑1X   X 
D   X ←0X 
X X X S X 


Timestep: 46
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ↑1X   X 
D   X ←0X 
X X X S X 


Timestep: 47
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O →1X   X 
D   X ←0X 
X X X S X 


Timestep: 48
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X   X 
D ↓1X ←0X 
X X X S X 


Timestep: 49
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↑0X 
D ↓1X   X 
X X X S X 


Timestep: 50
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0ø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 51
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 52
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O   X   X 
D →1X   X 
X X X S X 


Timestep: 53
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O   X   X 
D →1X   X 
X X X S X 


Timestep: 54
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O   X   X 
D →1X   X 
X X X S X 


Timestep: 55
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D →1X   X 
X X X S X 


Timestep: 56
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ←0X 
D →1X   X 
X X X S X 


Timestep: 57
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 59
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 60
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ←0X 
D ←1X   X 
X X X S X 


Timestep: 61
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X   X 
D →1X ↓0X 
X X X S X 


Timestep: 62
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X   X 
D ←1X ↓0X 
X X X S X 


Timestep: 63
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ↑1X   X 
D   X ↓0X 
X X X S X 


Timestep: 64
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←1X   X 
D   X ↓0X 
X X X S X 


Timestep: 65
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O →oX ←0X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0ø-
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 72
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0ø-
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1X →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1X →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   ø-
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O →oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1Xo←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X ←oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX →oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX →oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X XoX P X 
O ←oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX →0ø=
O   X   X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 18
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.865773677825928 seconds
Total simulation time for 400 steps: 8.172864198684692 	 Other agent action time: 0 	 48.9424503180139 steps/s
Curr learning rate 0.00135 	 Curr reward per step 0.2750875

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 191.20it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 214.25it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 212.62it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 212.31it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.19it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.76it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 169.21it/s]
------------------------------------
| approxkl           | 0.005116997 |
| clipfrac           | 0.4140312   |
| eplenmean          | 400         |
| eprewmean          | 118         |
| explained_variance | 0.477       |
| fps                | 1359        |
| nupdates           | 151         |
| policy_entropy     | 1.0712816   |
| policy_loss        | 0.005811481 |
| serial_timesteps   | 60400       |
| time_elapsed       | 1.37e+03    |
| time_remaining     | 90.4        |
| total_timesteps    | 1812000     |
| true_eprew         | 76.6        |
| value_loss         | 35.385197   |
------------------------------------
Current reward shaping 0.5469999999999999
SP envs: 0/30
Other agent actions took 4.956588268280029 seconds
Total simulation time for 400 steps: 8.290907621383667 	 Other agent action time: 0 	 48.24562258640196 steps/s
Curr learning rate 0.001349 	 Curr reward per step 0.28293291666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.87it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.17it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.38it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.07it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.47it/s]
------------------------------------
| approxkl           | 0.00634195  |
| clipfrac           | 0.4495521   |
| eplenmean          | 400         |
| eprewmean          | 115         |
| explained_variance | 0.471       |
| fps                | 1337        |
| nupdates           | 152         |
| policy_entropy     | 1.043967    |
| policy_loss        | 0.008786423 |
| serial_timesteps   | 60800       |
| time_elapsed       | 1.38e+03    |
| time_remaining     | 90.3        |
| total_timesteps    | 1824000     |
| true_eprew         | 74.8        |
| value_loss         | 33.606125   |
------------------------------------
Current reward shaping 0.544
SP envs: 0/30
Other agent actions took 4.977020502090454 seconds
Total simulation time for 400 steps: 8.222586154937744 	 Other agent action time: 0 	 48.646495453233534 steps/s
Curr learning rate 0.001348 	 Curr reward per step 0.25427199999999994

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 179.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 185.18it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 199.77it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.48it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.57it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 201.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.89it/s]
-------------------------------------
| approxkl           | 0.0051818555 |
| clipfrac           | 0.42644787   |
| eplenmean          | 400          |
| eprewmean          | 109          |
| explained_variance | 0.49         |
| fps                | 1353         |
| nupdates           | 153          |
| policy_entropy     | 1.0553302    |
| policy_loss        | 0.0066231093 |
| serial_timesteps   | 61200        |
| time_elapsed       | 1.39e+03     |
| time_remaining     | 90.1         |
| total_timesteps    | 1836000      |
| true_eprew         | 70.4         |
| value_loss         | 33.807808    |
-------------------------------------
Current reward shaping 0.5409999999999999
SP envs: 0/30
Other agent actions took 4.7973620891571045 seconds
Total simulation time for 400 steps: 8.22091794013977 	 Other agent action time: 0 	 48.65636695471008 steps/s
Curr learning rate 0.001347 	 Curr reward per step 0.27494408333333337

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.32it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 159.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 162.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 155.28it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.17it/s]
------------------------------------
| approxkl           | 0.004658848 |
| clipfrac           | 0.41491672  |
| eplenmean          | 400         |
| eprewmean          | 108         |
| explained_variance | 0.6         |
| fps                | 1337        |
| nupdates           | 154         |
| policy_entropy     | 1.0662997   |
| policy_loss        | 0.005000686 |
| serial_timesteps   | 61600       |
| time_elapsed       | 1.39e+03    |
| time_remaining     | 89.9        |
| total_timesteps    | 1848000     |
| true_eprew         | 70.4        |
| value_loss         | 28.287998   |
------------------------------------
Current reward shaping 0.538
SP envs: 0/30
Other agent actions took 4.784256458282471 seconds
Total simulation time for 400 steps: 8.24263858795166 	 Other agent action time: 0 	 48.52814978260525 steps/s
Curr learning rate 0.001346 	 Curr reward per step 0.2902921666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.84it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.64it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.76it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.69it/s]
-------------------------------------
| approxkl           | 0.0055444445 |
| clipfrac           | 0.40773958   |
| eplenmean          | 400          |
| eprewmean          | 110          |
| explained_variance | 0.543        |
| fps                | 1341         |
| nupdates           | 155          |
| policy_entropy     | 1.0406162    |
| policy_loss        | 0.0056573153 |
| serial_timesteps   | 62000        |
| time_elapsed       | 1.4e+03      |
| time_remaining     | 89.8         |
| total_timesteps    | 1860000      |
| true_eprew         | 71.6         |
| value_loss         | 30.48451     |
-------------------------------------
Current reward shaping 0.5349999999999999
SP envs: 0/30
Other agent actions took 4.8855602741241455 seconds
Total simulation time for 400 steps: 8.188640832901001 	 Other agent action time: 0 	 48.8481554097289 steps/s
Curr learning rate 0.001345 	 Curr reward per step 0.27384791666666664

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.17it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.39it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.73it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.64it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.83it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.50it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.32it/s]
-------------------------------------
| approxkl           | 0.0042883907 |
| clipfrac           | 0.40534365   |
| eplenmean          | 400          |
| eprewmean          | 110          |
| explained_variance | 0.51         |
| fps                | 1349         |
| nupdates           | 156          |
| policy_entropy     | 1.0560834    |
| policy_loss        | 0.0055718743 |
| serial_timesteps   | 62400        |
| time_elapsed       | 1.41e+03     |
| time_remaining     | 89.6         |
| total_timesteps    | 1872000      |
| true_eprew         | 72.2         |
| value_loss         | 29.610027    |
-------------------------------------
Current reward shaping 0.532
SP envs: 0/30
Other agent actions took 4.913859128952026 seconds
Total simulation time for 400 steps: 8.178126573562622 	 Other agent action time: 0 	 48.91095734481262 steps/s
Curr learning rate 0.0013440000000000001 	 Curr reward per step 0.29457266666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.48it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.77it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 197.84it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 199.68it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 195.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.55it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 198.60it/s]
-------------------------------------
| approxkl           | 0.0040959823 |
| clipfrac           | 0.3873542    |
| eplenmean          | 400          |
| eprewmean          | 113          |
| explained_variance | 0.54         |
| fps                | 1357         |
| nupdates           | 157          |
| policy_entropy     | 1.0484105    |
| policy_loss        | 0.0047078873 |
| serial_timesteps   | 62800        |
| time_elapsed       | 1.42e+03     |
| time_remaining     | 89.5         |
| total_timesteps    | 1884000      |
| true_eprew         | 74.4         |
| value_loss         | 30.982061    |
-------------------------------------
Current reward shaping 0.529
SP envs: 0/30
Other agent actions took 4.895627737045288 seconds
Total simulation time for 400 steps: 8.128392219543457 	 Other agent action time: 0 	 49.210223768270204 steps/s
Curr learning rate 0.001343 	 Curr reward per step 0.2745943333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.69it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.15it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.49it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.54it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.19it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.42it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.57it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.93it/s]
-------------------------------------
| approxkl           | 0.0046391063 |
| clipfrac           | 0.40651038   |
| eplenmean          | 400          |
| eprewmean          | 114          |
| explained_variance | 0.464        |
| fps                | 1358         |
| nupdates           | 158          |
| policy_entropy     | 1.0426081    |
| policy_loss        | 0.006481601  |
| serial_timesteps   | 63200        |
| time_elapsed       | 1.43e+03     |
| time_remaining     | 89.3         |
| total_timesteps    | 1896000      |
| true_eprew         | 75.6         |
| value_loss         | 34.546005    |
-------------------------------------
Current reward shaping 0.526
SP envs: 0/30
Other agent actions took 4.821325778961182 seconds
Total simulation time for 400 steps: 8.167568683624268 	 Other agent action time: 0 	 48.97418258654967 steps/s
Curr learning rate 0.0013419999999999999 	 Curr reward per step 0.3055098333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.13it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.04it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 195.58it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 198.52it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.02it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 200.56it/s]
-------------------------------------
| approxkl           | 0.0051885336 |
| clipfrac           | 0.42138538   |
| eplenmean          | 400          |
| eprewmean          | 114          |
| explained_variance | 0.545        |
| fps                | 1359         |
| nupdates           | 159          |
| policy_entropy     | 1.0431687    |
| policy_loss        | 0.0052068825 |
| serial_timesteps   | 63600        |
| time_elapsed       | 1.44e+03     |
| time_remaining     | 89.1         |
| total_timesteps    | 1908000      |
| true_eprew         | 75.8         |
| value_loss         | 29.325977    |
-------------------------------------
Current reward shaping 0.523
SP envs: 0/30
Other agent actions took 4.985077619552612 seconds
Total simulation time for 400 steps: 8.273191452026367 	 Other agent action time: 0 	 48.348935512912284 steps/s
Curr learning rate 0.0013410000000000002 	 Curr reward per step 0.2953393333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.48it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.84it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.03it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.66it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.36it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 173.63it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 167.17it/s]
-------------------------------------
| approxkl           | 0.0046279146 |
| clipfrac           | 0.41416678   |
| eplenmean          | 400          |
| eprewmean          | 117          |
| explained_variance | 0.518        |
| fps                | 1332         |
| nupdates           | 160          |
| policy_entropy     | 1.0356833    |
| policy_loss        | 0.0052276063 |
| serial_timesteps   | 64000        |
| time_elapsed       | 1.45e+03     |
| time_remaining     | 89           |
| total_timesteps    | 1920000      |
| true_eprew         | 77.8         |
| value_loss         | 31.044813    |
-------------------------------------
Current reward shaping 0.52
SP envs: 0/30
Other agent actions took 4.894055604934692 seconds
Total simulation time for 400 steps: 8.233726739883423 	 Other agent action time: 0 	 48.58067466126079 steps/s
Curr learning rate 0.00134 	 Curr reward per step 0.29367

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.67it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.15it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 165.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 169.63it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.65it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.24it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.50it/s]
-------------------------------------
| approxkl           | 0.0055081914 |
| clipfrac           | 0.43085402   |
| eplenmean          | 400          |
| eprewmean          | 118          |
| explained_variance | 0.608        |
| fps                | 1338         |
| nupdates           | 161          |
| policy_entropy     | 1.0539043    |
| policy_loss        | 0.006655557  |
| serial_timesteps   | 64400        |
| time_elapsed       | 1.46e+03     |
| time_remaining     | 88.8         |
| total_timesteps    | 1932000      |
| true_eprew         | 78.8         |
| value_loss         | 27.215693    |
-------------------------------------
Current reward shaping 0.517
SP envs: 0/30
Other agent actions took 4.913585424423218 seconds
Total simulation time for 400 steps: 8.33378291130066 	 Other agent action time: 0 	 47.99741057060625 steps/s
Curr learning rate 0.001339 	 Curr reward per step 0.254788

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 188.75it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 199.49it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 203.18it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 206.24it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 214.75it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 213.69it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.91it/s]
-------------------------------------
| approxkl           | 0.0053859823 |
| clipfrac           | 0.4397292    |
| eplenmean          | 400          |
| eprewmean          | 114          |
| explained_variance | 0.584        |
| fps                | 1336         |
| nupdates           | 162          |
| policy_entropy     | 1.0861077    |
| policy_loss        | 0.006657229  |
| serial_timesteps   | 64800        |
| time_elapsed       | 1.47e+03     |
| time_remaining     | 88.7         |
| total_timesteps    | 1944000      |
| true_eprew         | 75.6         |
| value_loss         | 28.323229    |
-------------------------------------
Current reward shaping 0.514
SP envs: 0/30
Other agent actions took 4.8944714069366455 seconds
Total simulation time for 400 steps: 8.212260961532593 	 Other agent action time: 0 	 48.70765820444057 steps/s
Curr learning rate 0.001338 	 Curr reward per step 0.2924496666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.26it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.90it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 198.41it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 203.45it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.22it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.49it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.06it/s]
-------------------------------------
| approxkl           | 0.00413161   |
| clipfrac           | 0.3934062    |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.538        |
| fps                | 1348         |
| nupdates           | 163          |
| policy_entropy     | 1.0220053    |
| policy_loss        | 0.0048589697 |
| serial_timesteps   | 65200        |
| time_elapsed       | 1.47e+03     |
| time_remaining     | 88.5         |
| total_timesteps    | 1956000      |
| true_eprew         | 74           |
| value_loss         | 32.009094    |
-------------------------------------
Current reward shaping 0.511
SP envs: 0/30
Other agent actions took 4.875093221664429 seconds
Total simulation time for 400 steps: 8.196110010147095 	 Other agent action time: 0 	 48.8036397150337 steps/s
Curr learning rate 0.001337 	 Curr reward per step 0.27604908333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.97it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.35it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.15it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.14it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.54it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.09it/s]
-------------------------------------
| approxkl           | 0.0041946396 |
| clipfrac           | 0.4001457    |
| eplenmean          | 400          |
| eprewmean          | 110          |
| explained_variance | 0.51         |
| fps                | 1351         |
| nupdates           | 164          |
| policy_entropy     | 1.033447     |
| policy_loss        | 0.006150072  |
| serial_timesteps   | 65600        |
| time_elapsed       | 1.48e+03     |
| time_remaining     | 88.3         |
| total_timesteps    | 1968000      |
| true_eprew         | 73.4         |
| value_loss         | 31.761763    |
-------------------------------------
Current reward shaping 0.508
SP envs: 0/30
Other agent actions took 4.863643646240234 seconds
Total simulation time for 400 steps: 8.215789318084717 	 Other agent action time: 0 	 48.68674019178098 steps/s
Curr learning rate 0.001336 	 Curr reward per step 0.29208599999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.66it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 151.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.47it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.02it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 163.51it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.98it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 165.13it/s]
------------------------------------
| approxkl           | 0.006095774 |
| clipfrac           | 0.44264585  |
| eplenmean          | 400         |
| eprewmean          | 113         |
| explained_variance | 0.542       |
| fps                | 1340        |
| nupdates           | 165         |
| policy_entropy     | 1.0198091   |
| policy_loss        | 0.007978006 |
| serial_timesteps   | 66000       |
| time_elapsed       | 1.49e+03    |
| time_remaining     | 88.2        |
| total_timesteps    | 1980000     |
| true_eprew         | 75.4        |
| value_loss         | 29.004187   |
------------------------------------
Current reward shaping 0.505
SP envs: 0/30
Other agent actions took 4.859920024871826 seconds
Total simulation time for 400 steps: 8.166677713394165 	 Other agent action time: 0 	 48.97952558406464 steps/s
Curr learning rate 0.001335 	 Curr reward per step 0.2757316666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.84it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.23it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.88it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.85it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.54it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.01it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.39it/s]
-------------------------------------
| approxkl           | 0.0031291845 |
| clipfrac           | 0.34873968   |
| eplenmean          | 400          |
| eprewmean          | 114          |
| explained_variance | 0.524        |
| fps                | 1352         |
| nupdates           | 166          |
| policy_entropy     | 1.0193286    |
| policy_loss        | 0.0037604019 |
| serial_timesteps   | 66400        |
| time_elapsed       | 1.5e+03      |
| time_remaining     | 88           |
| total_timesteps    | 1992000      |
| true_eprew         | 77           |
| value_loss         | 30.146143    |
-------------------------------------
Current reward shaping 0.502
SP envs: 0/30
Other agent actions took 4.874631643295288 seconds
Total simulation time for 400 steps: 8.163440227508545 	 Other agent action time: 0 	 48.998950056878 steps/s
Curr learning rate 0.0013340000000000001 	 Curr reward per step 0.29867150000000003

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.77it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.88it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.78it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.52it/s]
------------------------------------
| approxkl           | 0.003921069 |
| clipfrac           | 0.36470836  |
| eplenmean          | 400         |
| eprewmean          | 115         |
| explained_variance | 0.562       |
| fps                | 1353        |
| nupdates           | 167         |
| policy_entropy     | 0.9918713   |
| policy_loss        | 0.004156489 |
| serial_timesteps   | 66800       |
| time_elapsed       | 1.51e+03    |
| time_remaining     | 87.9        |
| total_timesteps    | 2004000     |
| true_eprew         | 77.4        |
| value_loss         | 29.223019   |
------------------------------------
Current reward shaping 0.499
SP envs: 0/30
Other agent actions took 4.904345273971558 seconds
Total simulation time for 400 steps: 8.34303593635559 	 Other agent action time: 0 	 47.944178000835535 steps/s
Curr learning rate 0.001333 	 Curr reward per step 0.27257116666666664

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.94it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.84it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.92it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 162.04it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 161.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.60it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.69it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.23it/s]
-------------------------------------
| approxkl           | 0.0047512567 |
| clipfrac           | 0.3955313    |
| eplenmean          | 400          |
| eprewmean          | 113          |
| explained_variance | 0.558        |
| fps                | 1323         |
| nupdates           | 168          |
| policy_entropy     | 1.0121862    |
| policy_loss        | 0.0052905804 |
| serial_timesteps   | 67200        |
| time_elapsed       | 1.52e+03     |
| time_remaining     | 87.7         |
| total_timesteps    | 2016000      |
| true_eprew         | 76.6         |
| value_loss         | 28.605814    |
-------------------------------------
Current reward shaping 0.496
SP envs: 0/30
Other agent actions took 4.993262529373169 seconds
Total simulation time for 400 steps: 8.301730155944824 	 Other agent action time: 0 	 48.18272727324944 steps/s
Curr learning rate 0.001332 	 Curr reward per step 0.29744933333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 153.98it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 157.58it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.22it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.94it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.59it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.53it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.38it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.14it/s]
-------------------------------------
| approxkl           | 0.0067781275 |
| clipfrac           | 0.45106256   |
| eplenmean          | 400          |
| eprewmean          | 116          |
| explained_variance | 0.624        |
| fps                | 1329         |
| nupdates           | 169          |
| policy_entropy     | 0.9865597    |
| policy_loss        | 0.009058797  |
| serial_timesteps   | 67600        |
| time_elapsed       | 1.53e+03     |
| time_remaining     | 87.6         |
| total_timesteps    | 2028000      |
| true_eprew         | 78.8         |
| value_loss         | 26.385956    |
-------------------------------------
Current reward shaping 0.493
SP envs: 0/30
Other agent actions took 4.883164882659912 seconds
Total simulation time for 400 steps: 8.255032062530518 	 Other agent action time: 0 	 48.455293325339674 steps/s
Curr learning rate 0.001331 	 Curr reward per step 0.2982769166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 160.39it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.87it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.23it/s]
-------------------------------------
| approxkl           | 0.004560805  |
| clipfrac           | 0.3854166    |
| eplenmean          | 400          |
| eprewmean          | 116          |
| explained_variance | 0.584        |
| fps                | 1336         |
| nupdates           | 170          |
| policy_entropy     | 0.9909233    |
| policy_loss        | 0.0039411024 |
| serial_timesteps   | 68000        |
| time_elapsed       | 1.54e+03     |
| time_remaining     | 87.4         |
| total_timesteps    | 2040000      |
| true_eprew         | 79           |
| value_loss         | 31.196026    |
-------------------------------------
Current reward shaping 0.49
SP envs: 0/30
Other agent actions took 4.914297819137573 seconds
Total simulation time for 400 steps: 8.274545192718506 	 Other agent action time: 0 	 48.34102548040887 steps/s
Curr learning rate 0.00133 	 Curr reward per step 0.2823575

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 154.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.61it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 164.82it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 169.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.95it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.10it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.76it/s]
-------------------------------------
| approxkl           | 0.00481802   |
| clipfrac           | 0.40137494   |
| eplenmean          | 400          |
| eprewmean          | 117          |
| explained_variance | 0.481        |
| fps                | 1329         |
| nupdates           | 171          |
| policy_entropy     | 1.0081518    |
| policy_loss        | 0.0059778583 |
| serial_timesteps   | 68400        |
| time_elapsed       | 1.55e+03     |
| time_remaining     | 87.3         |
| total_timesteps    | 2052000      |
| true_eprew         | 79.4         |
| value_loss         | 31.671091    |
-------------------------------------
Current reward shaping 0.487
SP envs: 0/30
Other agent actions took 4.9897990226745605 seconds
Total simulation time for 400 steps: 8.402081489562988 	 Other agent action time: 0 	 47.60725071482316 steps/s
Curr learning rate 0.0013289999999999999 	 Curr reward per step 0.29249216666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 154.57it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.60it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.05it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 166.55it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 166.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 167.27it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.55it/s]
-------------------------------------
| approxkl           | 0.0045266217 |
| clipfrac           | 0.39658323   |
| eplenmean          | 400          |
| eprewmean          | 117          |
| explained_variance | 0.563        |
| fps                | 1311         |
| nupdates           | 172          |
| policy_entropy     | 0.9880151    |
| policy_loss        | 0.0048039937 |
| serial_timesteps   | 68800        |
| time_elapsed       | 1.56e+03     |
| time_remaining     | 87.1         |
| total_timesteps    | 2064000      |
| true_eprew         | 79.8         |
| value_loss         | 30.408945    |
-------------------------------------
Current reward shaping 0.484
SP envs: 0/30
Other agent actions took 4.939968109130859 seconds
Total simulation time for 400 steps: 8.221037149429321 	 Other agent action time: 0 	 48.6556614122303 steps/s
Curr learning rate 0.001328 	 Curr reward per step 0.31219033333333335

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.84it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.07it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.78it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 198.99it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.93it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.03it/s]
-------------------------------------
| approxkl           | 0.0055243615 |
| clipfrac           | 0.41683337   |
| eplenmean          | 400          |
| eprewmean          | 118          |
| explained_variance | 0.57         |
| fps                | 1344         |
| nupdates           | 173          |
| policy_entropy     | 0.9734558    |
| policy_loss        | 0.006567967  |
| serial_timesteps   | 69200        |
| time_elapsed       | 1.56e+03     |
| time_remaining     | 87           |
| total_timesteps    | 2076000      |
| true_eprew         | 80.4         |
| value_loss         | 29.885397    |
-------------------------------------
Current reward shaping 0.481
SP envs: 0/30
Other agent actions took 4.769674062728882 seconds
Total simulation time for 400 steps: 8.095146417617798 	 Other agent action time: 0 	 49.4123242946494 steps/s
Curr learning rate 0.001327 	 Curr reward per step 0.28207783333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 185.99it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.85it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.34it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.94it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 197.26it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.28it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.63it/s]
-------------------------------------
| approxkl           | 0.0050772442 |
| clipfrac           | 0.4092292    |
| eplenmean          | 400          |
| eprewmean          | 119          |
| explained_variance | 0.58         |
| fps                | 1370         |
| nupdates           | 174          |
| policy_entropy     | 1.0104158    |
| policy_loss        | 0.0054388666 |
| serial_timesteps   | 69600        |
| time_elapsed       | 1.57e+03     |
| time_remaining     | 86.8         |
| total_timesteps    | 2088000      |
| true_eprew         | 81.6         |
| value_loss         | 28.68936     |
-------------------------------------
Current reward shaping 0.478
BEST REW 81.6 overwriting previous model with 81.4
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 5.002915620803833 seconds
Total simulation time for 400 steps: 8.30626368522644 	 Other agent action time: 0 	 48.1564293114655 steps/s
Curr learning rate 0.001326 	 Curr reward per step 0.2952686666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.25it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 166.78it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 163.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 172.93it/s]
-------------------------------------
| approxkl           | 0.005057889  |
| clipfrac           | 0.41623956   |
| eplenmean          | 400          |
| eprewmean          | 118          |
| explained_variance | 0.636        |
| fps                | 1327         |
| nupdates           | 175          |
| policy_entropy     | 0.9949097    |
| policy_loss        | 0.0061541637 |
| serial_timesteps   | 70000        |
| time_elapsed       | 1.58e+03     |
| time_remaining     | 86.8         |
| total_timesteps    | 2100000      |
| true_eprew         | 81           |
| value_loss         | 26.657677    |
-------------------------------------
Current reward shaping 0.475
SP envs: 0/30
Other agent actions took 4.849473714828491 seconds
Total simulation time for 400 steps: 8.220913410186768 	 Other agent action time: 0 	 48.65639376572786 steps/s
Curr learning rate 0.001325 	 Curr reward per step 0.30249791666666664

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.95it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.77it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.59it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 201.39it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.45it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.22it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.75it/s]
------------------------------------
| approxkl           | 0.004219004 |
| clipfrac           | 0.3814583   |
| eplenmean          | 400         |
| eprewmean          | 119         |
| explained_variance | 0.528       |
| fps                | 1347        |
| nupdates           | 176         |
| policy_entropy     | 0.9908536   |
| policy_loss        | 0.005000877 |
| serial_timesteps   | 70400       |
| time_elapsed       | 1.59e+03    |
| time_remaining     | 86.6        |
| total_timesteps    | 2112000     |
| true_eprew         | 81.4        |
| value_loss         | 33.49546    |
------------------------------------
Current reward shaping 0.472
SP envs: 0/30
Other agent actions took 4.962197303771973 seconds
Total simulation time for 400 steps: 8.274656295776367 	 Other agent action time: 0 	 48.340376409854265 steps/s
Curr learning rate 0.001324 	 Curr reward per step 0.27443399999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.58it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.90it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.95it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.67it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.73it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.78it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.65it/s]
------------------------------------
| approxkl           | 0.00592166  |
| clipfrac           | 0.43412513  |
| eplenmean          | 400         |
| eprewmean          | 116         |
| explained_variance | 0.58        |
| fps                | 1338        |
| nupdates           | 177         |
| policy_entropy     | 1.0214695   |
| policy_loss        | 0.007746818 |
| serial_timesteps   | 70800       |
| time_elapsed       | 1.6e+03     |
| time_remaining     | 86.5        |
| total_timesteps    | 2124000     |
| true_eprew         | 79.8        |
| value_loss         | 30.034472   |
------------------------------------
Current reward shaping 0.469
SP envs: 0/30
Other agent actions took 4.863873720169067 seconds
Total simulation time for 400 steps: 8.231053113937378 	 Other agent action time: 0 	 48.59645472615076 steps/s
Curr learning rate 0.001323 	 Curr reward per step 0.29452600000000007

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.33it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 197.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 198.78it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 195.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.36it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.27it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.39it/s]
------------------------------------
| approxkl           | 0.005929744 |
| clipfrac           | 0.4413541   |
| eplenmean          | 400         |
| eprewmean          | 115         |
| explained_variance | 0.609       |
| fps                | 1346        |
| nupdates           | 178         |
| policy_entropy     | 0.9795387   |
| policy_loss        | 0.006919375 |
| serial_timesteps   | 71200       |
| time_elapsed       | 1.61e+03    |
| time_remaining     | 86.3        |
| total_timesteps    | 2136000     |
| true_eprew         | 79          |
| value_loss         | 26.089338   |
------------------------------------
Current reward shaping 0.46599999999999997
SP envs: 0/30
Other agent actions took 4.870881795883179 seconds
Total simulation time for 400 steps: 8.27385687828064 	 Other agent action time: 0 	 48.34504704209031 steps/s
Curr learning rate 0.0013219999999999998 	 Curr reward per step 0.2809025

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.43it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.17it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.64it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.88it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.24it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.63it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.67it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.08it/s]
-------------------------------------
| approxkl           | 0.0038377636 |
| clipfrac           | 0.36328128   |
| eplenmean          | 400          |
| eprewmean          | 115          |
| explained_variance | 0.563        |
| fps                | 1340         |
| nupdates           | 179          |
| policy_entropy     | 0.9584275    |
| policy_loss        | 0.005517651  |
| serial_timesteps   | 71600        |
| time_elapsed       | 1.62e+03     |
| time_remaining     | 86.2         |
| total_timesteps    | 2148000      |
| true_eprew         | 79.2         |
| value_loss         | 29.16691     |
-------------------------------------
Current reward shaping 0.46299999999999997
SP envs: 0/30
Other agent actions took 4.9375104904174805 seconds
Total simulation time for 400 steps: 8.300514221191406 	 Other agent action time: 0 	 48.18978551699733 steps/s
Curr learning rate 0.0013210000000000001 	 Curr reward per step 0.3089504166666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.41it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.43it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.38it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.86it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.32it/s]
------------------------------------
| approxkl           | 0.005154648 |
| clipfrac           | 0.40736464  |
| eplenmean          | 400         |
| eprewmean          | 116         |
| explained_variance | 0.56        |
| fps                | 1331        |
| nupdates           | 180         |
| policy_entropy     | 0.9462645   |
| policy_loss        | 0.005361414 |
| serial_timesteps   | 72000       |
| time_elapsed       | 1.63e+03    |
| time_remaining     | 86          |
| total_timesteps    | 2160000     |
| true_eprew         | 80.4        |
| value_loss         | 28.712673   |
------------------------------------
Current reward shaping 0.45999999999999996
SP envs: 0/30
Other agent actions took 4.930325984954834 seconds
Total simulation time for 400 steps: 8.149893045425415 	 Other agent action time: 0 	 49.08039869609362 steps/s
Curr learning rate 0.00132 	 Curr reward per step 0.2624916666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.71it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.21it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.13it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.56it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 161.48it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 170.72it/s]
------------------------------------
| approxkl           | 0.00475608  |
| clipfrac           | 0.39424992  |
| eplenmean          | 400         |
| eprewmean          | 114         |
| explained_variance | 0.566       |
| fps                | 1347        |
| nupdates           | 181         |
| policy_entropy     | 0.9991982   |
| policy_loss        | 0.005351029 |
| serial_timesteps   | 72400       |
| time_elapsed       | 1.64e+03    |
| time_remaining     | 85.8        |
| total_timesteps    | 2172000     |
| true_eprew         | 79.6        |
| value_loss         | 25.9884     |
------------------------------------
Current reward shaping 0.45699999999999996
SP envs: 0/30
Other agent actions took 4.843165397644043 seconds
Total simulation time for 400 steps: 8.258426427841187 	 Other agent action time: 0 	 48.43537730765532 steps/s
Curr learning rate 0.0013189999999999999 	 Curr reward per step 0.29468625

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 153.69it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.87it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.48it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.03it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.73it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.99it/s]
------------------------------------
| approxkl           | 0.004802947 |
| clipfrac           | 0.40239584  |
| eplenmean          | 400         |
| eprewmean          | 117         |
| explained_variance | 0.576       |
| fps                | 1335        |
| nupdates           | 182         |
| policy_entropy     | 0.96682626  |
| policy_loss        | 0.005573349 |
| serial_timesteps   | 72800       |
| time_elapsed       | 1.65e+03    |
| time_remaining     | 85.7        |
| total_timesteps    | 2184000     |
| true_eprew         | 81.2        |
| value_loss         | 28.631762   |
------------------------------------
Current reward shaping 0.45399999999999996
SP envs: 0/30
Other agent actions took 4.859978199005127 seconds
Total simulation time for 400 steps: 8.179045677185059 	 Other agent action time: 0 	 48.90546107546205 steps/s
Curr learning rate 0.0013180000000000002 	 Curr reward per step 0.30106283333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.27it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 200.40it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 202.14it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 203.20it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 201.87it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 201.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 202.52it/s]
------------------------------------
| approxkl           | 0.004953646 |
| clipfrac           | 0.41368744  |
| eplenmean          | 400         |
| eprewmean          | 114         |
| explained_variance | 0.522       |
| fps                | 1360        |
| nupdates           | 183         |
| policy_entropy     | 1.0110048   |
| policy_loss        | 0.00543307  |
| serial_timesteps   | 73200       |
| time_elapsed       | 1.66e+03    |
| time_remaining     | 85.5        |
| total_timesteps    | 2196000     |
| true_eprew         | 79.2        |
| value_loss         | 32.023815   |
------------------------------------
Current reward shaping 0.45099999999999996
SP envs: 0/30
Other agent actions took 4.956106185913086 seconds
Total simulation time for 400 steps: 8.205523014068604 	 Other agent action time: 0 	 48.74765439255835 steps/s
Curr learning rate 0.001317 	 Curr reward per step 0.2970675833333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.42it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.32it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.58it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.33it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.68it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.63it/s]
------------------------------------
| approxkl           | 0.004583465 |
| clipfrac           | 0.39989576  |
| eplenmean          | 400         |
| eprewmean          | 119         |
| explained_variance | 0.546       |
| fps                | 1346        |
| nupdates           | 184         |
| policy_entropy     | 0.98072946  |
| policy_loss        | 0.004939692 |
| serial_timesteps   | 73600       |
| time_elapsed       | 1.67e+03    |
| time_remaining     | 85.4        |
| total_timesteps    | 2208000     |
| true_eprew         | 82.6        |
| value_loss         | 28.01254    |
------------------------------------
Current reward shaping 0.44799999999999995
BEST REW 82.6 overwriting previous model with 81.6
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.905635356903076 seconds
Total simulation time for 400 steps: 8.307894468307495 	 Other agent action time: 0 	 48.14697653248946 steps/s
Curr learning rate 0.0013160000000000001 	 Curr reward per step 0.30175199999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.29it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.88it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.67it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.18it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.74it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.88it/s]
-------------------------------------
| approxkl           | 0.0052160546 |
| clipfrac           | 0.40156248   |
| eplenmean          | 400          |
| eprewmean          | 120          |
| explained_variance | 0.558        |
| fps                | 1329         |
| nupdates           | 185          |
| policy_entropy     | 0.9700971    |
| policy_loss        | 0.006620928  |
| serial_timesteps   | 74000        |
| time_elapsed       | 1.68e+03     |
| time_remaining     | 85.4         |
| total_timesteps    | 2220000      |
| true_eprew         | 84           |
| value_loss         | 29.057302    |
-------------------------------------
Current reward shaping 0.44499999999999995
BEST REW 84.0 overwriting previous model with 82.6
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.852313756942749 seconds
Total simulation time for 400 steps: 8.194715976715088 	 Other agent action time: 0 	 48.81194188262068 steps/s
Curr learning rate 0.001315 	 Curr reward per step 0.27380625

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.16it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.58it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.75it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.03it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.29it/s]
-------------------------------------
| approxkl           | 0.0063667367 |
| clipfrac           | 0.4490415    |
| eplenmean          | 400          |
| eprewmean          | 118          |
| explained_variance | 0.529        |
| fps                | 1346         |
| nupdates           | 186          |
| policy_entropy     | 0.99228656   |
| policy_loss        | 0.006732696  |
| serial_timesteps   | 74400        |
| time_elapsed       | 1.69e+03     |
| time_remaining     | 85.4         |
| total_timesteps    | 2232000      |
| true_eprew         | 82.4         |
| value_loss         | 29.62057     |
-------------------------------------
Current reward shaping 0.44199999999999995
SP envs: 0/30
Other agent actions took 4.791401386260986 seconds
Total simulation time for 400 steps: 8.14896535873413 	 Other agent action time: 0 	 49.08598605972433 steps/s
Curr learning rate 0.001314 	 Curr reward per step 0.3002876666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 155.40it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 157.40it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.24it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.45it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 173.72it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 170.43it/s]
-------------------------------------
| approxkl           | 0.0055320943 |
| clipfrac           | 0.41496876   |
| eplenmean          | 400          |
| eprewmean          | 117          |
| explained_variance | 0.532        |
| fps                | 1348         |
| nupdates           | 187          |
| policy_entropy     | 0.9508717    |
| policy_loss        | 0.006543762  |
| serial_timesteps   | 74800        |
| time_elapsed       | 1.7e+03      |
| time_remaining     | 85.2         |
| total_timesteps    | 2244000      |
| true_eprew         | 82.2         |
| value_loss         | 28.238213    |
-------------------------------------
Current reward shaping 0.43899999999999995
SP envs: 0/30
Other agent actions took 4.848638296127319 seconds
Total simulation time for 400 steps: 8.430896520614624 	 Other agent action time: 0 	 47.44453914503027 steps/s
Curr learning rate 0.001313 	 Curr reward per step 0.2935520833333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 143.79it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 143.32it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.46it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.83it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.71it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.24it/s]
-------------------------------------
| approxkl           | 0.0070955763 |
| clipfrac           | 0.45502082   |
| eplenmean          | 400          |
| eprewmean          | 116          |
| explained_variance | 0.563        |
| fps                | 1308         |
| nupdates           | 188          |
| policy_entropy     | 0.96414113   |
| policy_loss        | 0.008887791  |
| serial_timesteps   | 75200        |
| time_elapsed       | 1.71e+03     |
| time_remaining     | 85           |
| total_timesteps    | 2256000      |
| true_eprew         | 81.4         |
| value_loss         | 27.374666    |
-------------------------------------
Current reward shaping 0.43600000000000005
SP envs: 0/30
Other agent actions took 4.9555089473724365 seconds
Total simulation time for 400 steps: 8.273964643478394 	 Other agent action time: 0 	 48.34441736650196 steps/s
Curr learning rate 0.0013120000000000002 	 Curr reward per step 0.29020166666666664

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.39it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.61it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.47it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.60it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.48it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.69it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.99it/s]
------------------------------------
| approxkl           | 0.005794586 |
| clipfrac           | 0.4174062   |
| eplenmean          | 400         |
| eprewmean          | 118         |
| explained_variance | 0.552       |
| fps                | 1336        |
| nupdates           | 189         |
| policy_entropy     | 0.9773537   |
| policy_loss        | 0.00701934  |
| serial_timesteps   | 75600       |
| time_elapsed       | 1.72e+03    |
| time_remaining     | 84.9        |
| total_timesteps    | 2268000     |
| true_eprew         | 82.8        |
| value_loss         | 28.958864   |
------------------------------------
Current reward shaping 0.43300000000000005
SP envs: 0/30
Other agent actions took 4.986668825149536 seconds
Total simulation time for 400 steps: 8.239114761352539 	 Other agent action time: 0 	 48.54890502026891 steps/s
Curr learning rate 0.001311 	 Curr reward per step 0.28375625000000004

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.87it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.63it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 201.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 201.41it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 198.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.00it/s]
-------------------------------------
| approxkl           | 0.0041521243 |
| clipfrac           | 0.37321863   |
| eplenmean          | 400          |
| eprewmean          | 117          |
| explained_variance | 0.545        |
| fps                | 1348         |
| nupdates           | 190          |
| policy_entropy     | 0.9856624    |
| policy_loss        | 0.0037714322 |
| serial_timesteps   | 76000        |
| time_elapsed       | 1.72e+03     |
| time_remaining     | 84.7         |
| total_timesteps    | 2280000      |
| true_eprew         | 82.6         |
| value_loss         | 29.938995    |
-------------------------------------
Current reward shaping 0.43000000000000005
SP envs: 0/30
Other agent actions took 4.9085352420806885 seconds
Total simulation time for 400 steps: 8.24614691734314 	 Other agent action time: 0 	 48.507503444878914 steps/s
Curr learning rate 0.00131 	 Curr reward per step 0.27876083333333335

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.92it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.50it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.29it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 167.90it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.90it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.59it/s]
-------------------------------------
| approxkl           | 0.0048558437 |
| clipfrac           | 0.39634383   |
| eplenmean          | 400          |
| eprewmean          | 113          |
| explained_variance | 0.583        |
| fps                | 1336         |
| nupdates           | 191          |
| policy_entropy     | 0.9891249    |
| policy_loss        | 0.00559677   |
| serial_timesteps   | 76400        |
| time_elapsed       | 1.73e+03     |
| time_remaining     | 84.6         |
| total_timesteps    | 2292000      |
| true_eprew         | 79.6         |
| value_loss         | 26.560413    |
-------------------------------------
Current reward shaping 0.42700000000000005
SP envs: 0/30
Other agent actions took 4.958468437194824 seconds
Total simulation time for 400 steps: 8.33191204071045 	 Other agent action time: 0 	 48.00818804202026 steps/s
Curr learning rate 0.001309 	 Curr reward per step 0.2912895833333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.30it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 156.82it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.91it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.64it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.65it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.60it/s]
-------------------------------------
| approxkl           | 0.0053724814 |
| clipfrac           | 0.39911467   |
| eplenmean          | 400          |
| eprewmean          | 113          |
| explained_variance | 0.544        |
| fps                | 1325         |
| nupdates           | 192          |
| policy_entropy     | 0.9447266    |
| policy_loss        | 0.0066119176 |
| serial_timesteps   | 76800        |
| time_elapsed       | 1.74e+03     |
| time_remaining     | 84.4         |
| total_timesteps    | 2304000      |
| true_eprew         | 80           |
| value_loss         | 31.514347    |
-------------------------------------
Current reward shaping 0.42400000000000004
SP envs: 0/30
Other agent actions took 4.947338819503784 seconds
Total simulation time for 400 steps: 8.354372024536133 	 Other agent action time: 0 	 47.879122311674834 steps/s
Curr learning rate 0.0013080000000000001 	 Curr reward per step 0.2244006666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.03it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 158.37it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.47it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.76it/s]
-------------------------------------
| approxkl           | 0.005735575  |
| clipfrac           | 0.42256248   |
| eplenmean          | 400          |
| eprewmean          | 106          |
| explained_variance | 0.545        |
| fps                | 1324         |
| nupdates           | 193          |
| policy_entropy     | 1.0275276    |
| policy_loss        | 0.0066956603 |
| serial_timesteps   | 77200        |
| time_elapsed       | 1.75e+03     |
| time_remaining     | 84.3         |
| total_timesteps    | 2316000      |
| true_eprew         | 74.8         |
| value_loss         | 31.690544    |
-------------------------------------
Current reward shaping 0.42100000000000004
SP envs: 0/30
Other agent actions took 4.857619762420654 seconds
Total simulation time for 400 steps: 8.153162956237793 	 Other agent action time: 0 	 49.06071449166479 steps/s
Curr learning rate 0.001307 	 Curr reward per step 0.27290233333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 150.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 156.62it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.20it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 168.81it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 159.63it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.47it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.44it/s]
-------------------------------------
| approxkl           | 0.0043299436 |
| clipfrac           | 0.37419796   |
| eplenmean          | 400          |
| eprewmean          | 106          |
| explained_variance | 0.548        |
| fps                | 1347         |
| nupdates           | 194          |
| policy_entropy     | 0.9379768    |
| policy_loss        | 0.005125902  |
| serial_timesteps   | 77600        |
| time_elapsed       | 1.76e+03     |
| time_remaining     | 84.1         |
| total_timesteps    | 2328000      |
| true_eprew         | 74.6         |
| value_loss         | 29.165098    |
-------------------------------------
Current reward shaping 0.41800000000000004
SP envs: 0/30
Other agent actions took 4.916372776031494 seconds
Total simulation time for 400 steps: 8.281346559524536 	 Other agent action time: 0 	 48.30132359814749 steps/s
Curr learning rate 0.001306 	 Curr reward per step 0.27522116666666663

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.57it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.29it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.48it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.17it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.34it/s]
-------------------------------------
| approxkl           | 0.0053574992 |
| clipfrac           | 0.40369767   |
| eplenmean          | 400          |
| eprewmean          | 103          |
| explained_variance | 0.48         |
| fps                | 1336         |
| nupdates           | 195          |
| policy_entropy     | 0.9441981    |
| policy_loss        | 0.0038900748 |
| serial_timesteps   | 78000        |
| time_elapsed       | 1.77e+03     |
| time_remaining     | 84           |
| total_timesteps    | 2340000      |
| true_eprew         | 72.8         |
| value_loss         | 31.35925     |
-------------------------------------
Current reward shaping 0.41500000000000004
SP envs: 0/30
Other agent actions took 4.862122535705566 seconds
Total simulation time for 400 steps: 8.158612489700317 	 Other agent action time: 0 	 49.027944458076945 steps/s
Curr learning rate 0.0013050000000000002 	 Curr reward per step 0.28887125

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.49it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.47it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.26it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.05it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.29it/s]
-------------------------------------
| approxkl           | 0.004489759  |
| clipfrac           | 0.38100004   |
| eplenmean          | 400          |
| eprewmean          | 111          |
| explained_variance | 0.573        |
| fps                | 1354         |
| nupdates           | 196          |
| policy_entropy     | 0.9421197    |
| policy_loss        | 0.0047419006 |
| serial_timesteps   | 78400        |
| time_elapsed       | 1.78e+03     |
| time_remaining     | 83.8         |
| total_timesteps    | 2352000      |
| true_eprew         | 78.8         |
| value_loss         | 28.668188    |
-------------------------------------
Current reward shaping 0.41200000000000003
SP envs: 0/30
Other agent actions took 4.809612274169922 seconds
Total simulation time for 400 steps: 8.149799346923828 	 Other agent action time: 0 	 49.08096297499416 steps/s
Curr learning rate 0.001304 	 Curr reward per step 0.28650733333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.13it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.78it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 167.88it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.74it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.70it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 163.69it/s]
-------------------------------------
| approxkl           | 0.0041925297 |
| clipfrac           | 0.3674479    |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.54         |
| fps                | 1350         |
| nupdates           | 197          |
| policy_entropy     | 0.9507297    |
| policy_loss        | 0.004501582  |
| serial_timesteps   | 78800        |
| time_elapsed       | 1.79e+03     |
| time_remaining     | 83.6         |
| total_timesteps    | 2364000      |
| true_eprew         | 80           |
| value_loss         | 26.9267      |
-------------------------------------
Current reward shaping 0.40900000000000003
SP envs: 0/30
Other agent actions took 4.93181300163269 seconds
Total simulation time for 400 steps: 8.277574062347412 	 Other agent action time: 0 	 48.32333688435344 steps/s
Curr learning rate 0.0013030000000000001 	 Curr reward per step 0.2993869166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.36it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.62it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 188.96it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.94it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.16it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 169.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.45it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.53it/s]
-------------------------------------
| approxkl           | 0.0049660704 |
| clipfrac           | 0.38148955   |
| eplenmean          | 400          |
| eprewmean          | 115          |
| explained_variance | 0.477        |
| fps                | 1335         |
| nupdates           | 198          |
| policy_entropy     | 0.91942954   |
| policy_loss        | 0.0048616347 |
| serial_timesteps   | 79200        |
| time_elapsed       | 1.8e+03      |
| time_remaining     | 83.5         |
| total_timesteps    | 2376000      |
| true_eprew         | 82.8         |
| value_loss         | 29.598145    |
-------------------------------------
Current reward shaping 0.406
SP envs: 0/30
Other agent actions took 4.877482891082764 seconds
Total simulation time for 400 steps: 8.119608163833618 	 Other agent action time: 0 	 49.26346098592308 steps/s
Curr learning rate 0.001302 	 Curr reward per step 0.2904556666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.50it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.62it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.93it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.15it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.75it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.83it/s]
-------------------------------------
| approxkl           | 0.0052710767 |
| clipfrac           | 0.4057813    |
| eplenmean          | 400          |
| eprewmean          | 116          |
| explained_variance | 0.61         |
| fps                | 1360         |
| nupdates           | 199          |
| policy_entropy     | 0.93620044   |
| policy_loss        | 0.006047155  |
| serial_timesteps   | 79600        |
| time_elapsed       | 1.81e+03     |
| time_remaining     | 83.3         |
| total_timesteps    | 2388000      |
| true_eprew         | 83.8         |
| value_loss         | 25.412611    |
-------------------------------------
Current reward shaping 0.403
SP envs: 0/30
Other agent actions took 4.784737825393677 seconds
Total simulation time for 400 steps: 8.110192775726318 	 Other agent action time: 0 	 49.320652549368965 steps/s
Curr learning rate 0.001301 	 Curr reward per step 0.26511341666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.42it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.97it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.75it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.28it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.84it/s]
-------------------------------------
| approxkl           | 0.0058772136 |
| clipfrac           | 0.40971866   |
| eplenmean          | 400          |
| eprewmean          | 114          |
| explained_variance | 0.534        |
| fps                | 1366         |
| nupdates           | 200          |
| policy_entropy     | 0.9425178    |
| policy_loss        | 0.006743207  |
| serial_timesteps   | 80000        |
| time_elapsed       | 1.81e+03     |
| time_remaining     | 83.2         |
| total_timesteps    | 2400000      |
| true_eprew         | 82.6         |
| value_loss         | 29.816103    |
-------------------------------------
Current reward shaping 0.4
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X →0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X →0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX   P 
O   Xo↓0X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX   P 
O   Xo←0X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←1X ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX   P 
O   Xo↓0X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo→0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo→0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1Xo→0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oXo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø1X 
O →1Xo↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø2X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø3X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø5X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø6X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø7X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø9X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø10X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø11X 
O →oX →0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø13X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø14X 
O ←1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø15X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø16X 
O ←1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø17X 
O ←oX ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X ø18X 
O →oX →oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø19X 
O →1Xo→0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo←0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo←0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←oø-
O ↓1Xo  X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑oø-
O ↓1Xo  X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →oø-
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 65
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X →0ø=
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 66
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 69
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O   Xo  X 
D ←1X   X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø=
O   Xo  X 
D ←1X   X 
X X X S X 


Timestep: 71
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O   Xo  X 
D ←1X   X 
X X X S X 


Timestep: 72
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O   Xo  X 
D ←1X   X 
X X X S X 


Timestep: 73
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X ←0ø=
O   Xo  X 
D ←dX   X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O ↑dXo  X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O ↑dXo  X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O ↑dXo  X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX ←0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dX ←0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dX ←0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xd←0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1X ←dø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑dø=
O ↓1Xo  X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 5 
X X X P X 
O   X ↑sø=
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 84
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O   Xo↓sX 
D ←1X   X 
X X X S X 


Timestep: 85
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O   Xo  X 
D ←1X ↓sX 
X X X S X 


Timestep: 86
Joint action taken: ('interact', 'interact') 	 Reward: 20 + shape * 3 
X X X P X 
O   X   ø=
O   Xo  X 
D ←dX ↓0X 
X X X S X 


Timestep: 87
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O   Xo  X 
D ←dX ↓0X 
X X X S X 


Timestep: 88
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø=
O ↑dXo  X 
D   X ↓0X 
X X X S X 


Timestep: 89
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dX   ø=
O   Xo↑0X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX ↑0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX ←0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xd←0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xd←0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←dø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXd←0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←dø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ↑dø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ↑dø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ↑dø=
O   Xo  X 
D   X   X 
X X X S X 


tot rew 60 tot rew shaped 60
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O →1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↓1X ↓0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ↓1X   X 
X X X S X 


Timestep: 13
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ←0X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ←0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ←0X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ←0X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 3 
X X X P X 
O ↑1X →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0ø-
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0ø-
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 68
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 69
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 70
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 71
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 72
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X   X 
D →oX ↓0X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 74
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↑0X 
D ←oX   X 
X X X S X 


Timestep: 75
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0ø-
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 76
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 77
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 78
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 79
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D ↓oX   X 
X X X S X 


Timestep: 81
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 82
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 83
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 84
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ↑oX ←0X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 90
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 91
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 92
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 93
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O →oX ↑0X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O →1Xo↑0X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←1Xo←0X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   ø-
O ←1X ←oX 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   ø-
O   X ←oX 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑oø-
O   X   X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 15
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.958435535430908 seconds
Total simulation time for 400 steps: 8.290043115615845 	 Other agent action time: 0 	 48.25065375673684 steps/s
Curr learning rate 0.0013 	 Curr reward per step 0.28063333333333335

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.67it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.93it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.94it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.63it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.46it/s]
-------------------------------------
| approxkl           | 0.0049545458 |
| clipfrac           | 0.38953117   |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.564        |
| fps                | 1333         |
| nupdates           | 201          |
| policy_entropy     | 0.91998863   |
| policy_loss        | 0.006063884  |
| serial_timesteps   | 80400        |
| time_elapsed       | 1.83e+03     |
| time_remaining     | 83.1         |
| total_timesteps    | 2412000      |
| true_eprew         | 80.8         |
| value_loss         | 28.668907    |
-------------------------------------
Current reward shaping 0.397
SP envs: 0/30
Other agent actions took 4.881263971328735 seconds
Total simulation time for 400 steps: 8.225248336791992 	 Other agent action time: 0 	 48.63075054047643 steps/s
Curr learning rate 0.001299 	 Curr reward per step 0.28320900000000004

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.04it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 147.58it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.36it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.41it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 170.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.99it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.30it/s]
-------------------------------------
| approxkl           | 0.0051942235 |
| clipfrac           | 0.38713545   |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.569        |
| fps                | 1337         |
| nupdates           | 202          |
| policy_entropy     | 0.90562993   |
| policy_loss        | 0.006087403  |
| serial_timesteps   | 80800        |
| time_elapsed       | 1.83e+03     |
| time_remaining     | 82.9         |
| total_timesteps    | 2424000      |
| true_eprew         | 80.8         |
| value_loss         | 25.613207    |
-------------------------------------
Current reward shaping 0.394
SP envs: 0/30
Other agent actions took 4.915298700332642 seconds
Total simulation time for 400 steps: 8.178375244140625 	 Other agent action time: 0 	 48.9094701648202 steps/s
Curr learning rate 0.0012980000000000001 	 Curr reward per step 0.301952

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.07it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 157.80it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.25it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.85it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.54it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.66it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.37it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.13it/s]
-------------------------------------
| approxkl           | 0.0040663304 |
| clipfrac           | 0.3572083    |
| eplenmean          | 400          |
| eprewmean          | 115          |
| explained_variance | 0.512        |
| fps                | 1352         |
| nupdates           | 203          |
| policy_entropy     | 0.91590667   |
| policy_loss        | 0.004031277  |
| serial_timesteps   | 81200        |
| time_elapsed       | 1.84e+03     |
| time_remaining     | 82.8         |
| total_timesteps    | 2436000      |
| true_eprew         | 83.4         |
| value_loss         | 29.258419    |
-------------------------------------
Current reward shaping 0.391
SP envs: 0/30
Other agent actions took 5.000669002532959 seconds
Total simulation time for 400 steps: 8.252525091171265 	 Other agent action time: 0 	 48.470013187591384 steps/s
Curr learning rate 0.001297 	 Curr reward per step 0.27073350000000007

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.42it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.27it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 195.13it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.75it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 171.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.57it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.89it/s]
------------------------------------
| approxkl           | 0.004147339 |
| clipfrac           | 0.3602604   |
| eplenmean          | 400         |
| eprewmean          | 114         |
| explained_variance | 0.51        |
| fps                | 1338        |
| nupdates           | 204         |
| policy_entropy     | 0.9015555   |
| policy_loss        | 0.005389595 |
| serial_timesteps   | 81600       |
| time_elapsed       | 1.85e+03    |
| time_remaining     | 82.6        |
| total_timesteps    | 2448000     |
| true_eprew         | 82.8        |
| value_loss         | 29.021654   |
------------------------------------
Current reward shaping 0.388
SP envs: 0/30
Other agent actions took 4.8497397899627686 seconds
Total simulation time for 400 steps: 8.299263715744019 	 Other agent action time: 0 	 48.19704659356526 steps/s
Curr learning rate 0.001296 	 Curr reward per step 0.2661303333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.37it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.34it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.46it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.92it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.24it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.39it/s]
------------------------------------
| approxkl           | 0.005010316 |
| clipfrac           | 0.39173967  |
| eplenmean          | 400         |
| eprewmean          | 113         |
| explained_variance | 0.546       |
| fps                | 1333        |
| nupdates           | 205         |
| policy_entropy     | 0.92858094  |
| policy_loss        | 0.005445957 |
| serial_timesteps   | 82000       |
| time_elapsed       | 1.86e+03    |
| time_remaining     | 82.5        |
| total_timesteps    | 2460000     |
| true_eprew         | 82.2        |
| value_loss         | 29.597567   |
------------------------------------
Current reward shaping 0.385
SP envs: 0/30
Other agent actions took 4.8408122062683105 seconds
Total simulation time for 400 steps: 8.098328351974487 	 Other agent action time: 0 	 49.39290957527973 steps/s
Curr learning rate 0.0012950000000000001 	 Curr reward per step 0.29697124999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.88it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 161.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.35it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.19it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.61it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.01it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.19it/s]
-------------------------------------
| approxkl           | 0.004583626  |
| clipfrac           | 0.36712503   |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.511        |
| fps                | 1357         |
| nupdates           | 206          |
| policy_entropy     | 0.8861059    |
| policy_loss        | 0.0054941988 |
| serial_timesteps   | 82400        |
| time_elapsed       | 1.87e+03     |
| time_remaining     | 82.3         |
| total_timesteps    | 2472000      |
| true_eprew         | 81.2         |
| value_loss         | 29.801481    |
-------------------------------------
Current reward shaping 0.382
SP envs: 0/30
Other agent actions took 4.8778862953186035 seconds
Total simulation time for 400 steps: 8.210150003433228 	 Other agent action time: 0 	 48.72018170590459 steps/s
Curr learning rate 0.001294 	 Curr reward per step 0.28703666666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.15it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.62it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.71it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.07it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.99it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.24it/s]
------------------------------------
| approxkl           | 0.004563323 |
| clipfrac           | 0.3658437   |
| eplenmean          | 400         |
| eprewmean          | 114         |
| explained_variance | 0.532       |
| fps                | 1346        |
| nupdates           | 207         |
| policy_entropy     | 0.90350586  |
| policy_loss        | 0.005919355 |
| serial_timesteps   | 82800       |
| time_elapsed       | 1.88e+03    |
| time_remaining     | 82.1        |
| total_timesteps    | 2484000     |
| true_eprew         | 83.2        |
| value_loss         | 30.372065   |
------------------------------------
Current reward shaping 0.379
SP envs: 0/30
Other agent actions took 4.931386709213257 seconds
Total simulation time for 400 steps: 8.213552236557007 	 Other agent action time: 0 	 48.700000740200295 steps/s
Curr learning rate 0.0012929999999999999 	 Curr reward per step 0.29627374999999995

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 153.41it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.60it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.99it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.36it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.60it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.57it/s]
-------------------------------------
| approxkl           | 0.0035442922 |
| clipfrac           | 0.32986456   |
| eplenmean          | 400          |
| eprewmean          | 115          |
| explained_variance | 0.594        |
| fps                | 1340         |
| nupdates           | 208          |
| policy_entropy     | 0.9011851    |
| policy_loss        | 0.0031936504 |
| serial_timesteps   | 83200        |
| time_elapsed       | 1.89e+03     |
| time_remaining     | 82           |
| total_timesteps    | 2496000      |
| true_eprew         | 84.6         |
| value_loss         | 23.073706    |
-------------------------------------
Current reward shaping 0.376
BEST REW 84.6 overwriting previous model with 84.0
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.9064788818359375 seconds
Total simulation time for 400 steps: 8.24271559715271 	 Other agent action time: 0 	 48.52769639876601 steps/s
Curr learning rate 0.0012920000000000002 	 Curr reward per step 0.281898

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.43it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.03it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.60it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.83it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.59it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.11it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.30it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.59it/s]
-------------------------------------
| approxkl           | 0.00296609   |
| clipfrac           | 0.3189583    |
| eplenmean          | 400          |
| eprewmean          | 115          |
| explained_variance | 0.556        |
| fps                | 1337         |
| nupdates           | 209          |
| policy_entropy     | 0.92224556   |
| policy_loss        | 0.0023858824 |
| serial_timesteps   | 83600        |
| time_elapsed       | 1.9e+03      |
| time_remaining     | 82           |
| total_timesteps    | 2508000      |
| true_eprew         | 84.2         |
| value_loss         | 28.885542    |
-------------------------------------
Current reward shaping 0.373
SP envs: 0/30
Other agent actions took 4.851292610168457 seconds
Total simulation time for 400 steps: 8.192811965942383 	 Other agent action time: 0 	 48.82328578549157 steps/s
Curr learning rate 0.001291 	 Curr reward per step 0.26738125

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.20it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.70it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.77it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.50it/s]
-------------------------------------
| approxkl           | 0.005634753  |
| clipfrac           | 0.3928854    |
| eplenmean          | 400          |
| eprewmean          | 115          |
| explained_variance | 0.534        |
| fps                | 1346         |
| nupdates           | 210          |
| policy_entropy     | 0.916089     |
| policy_loss        | 0.0047968305 |
| serial_timesteps   | 84000        |
| time_elapsed       | 1.91e+03     |
| time_remaining     | 81.8         |
| total_timesteps    | 2520000      |
| true_eprew         | 84.6         |
| value_loss         | 28.222063    |
-------------------------------------
Current reward shaping 0.37
SP envs: 0/30
Other agent actions took 5.014101266860962 seconds
Total simulation time for 400 steps: 8.333287715911865 	 Other agent action time: 0 	 48.00026275778602 steps/s
Curr learning rate 0.00129 	 Curr reward per step 0.31121499999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.00it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.94it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.65it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.51it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.63it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.31it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.28it/s]
-------------------------------------
| approxkl           | 0.0055054203 |
| clipfrac           | 0.39178133   |
| eplenmean          | 400          |
| eprewmean          | 114          |
| explained_variance | 0.553        |
| fps                | 1327         |
| nupdates           | 211          |
| policy_entropy     | 0.87791663   |
| policy_loss        | 0.0050815525 |
| serial_timesteps   | 84400        |
| time_elapsed       | 1.92e+03     |
| time_remaining     | 81.7         |
| total_timesteps    | 2532000      |
| true_eprew         | 84           |
| value_loss         | 27.207888    |
-------------------------------------
Current reward shaping 0.367
SP envs: 0/30
Other agent actions took 4.847873210906982 seconds
Total simulation time for 400 steps: 8.210378646850586 	 Other agent action time: 0 	 48.71882494157998 steps/s
Curr learning rate 0.001289 	 Curr reward per step 0.27830825000000003

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.39it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.08it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 193.11it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.17it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.66it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.74it/s]
-------------------------------------
| approxkl           | 0.005660002  |
| clipfrac           | 0.4118021    |
| eplenmean          | 400          |
| eprewmean          | 113          |
| explained_variance | 0.534        |
| fps                | 1352         |
| nupdates           | 212          |
| policy_entropy     | 0.9366247    |
| policy_loss        | 0.0060302215 |
| serial_timesteps   | 84800        |
| time_elapsed       | 1.93e+03     |
| time_remaining     | 81.5         |
| total_timesteps    | 2544000      |
| true_eprew         | 83.4         |
| value_loss         | 26.490662    |
-------------------------------------
Current reward shaping 0.364
SP envs: 0/30
Other agent actions took 4.867063522338867 seconds
Total simulation time for 400 steps: 8.179005861282349 	 Other agent action time: 0 	 48.905699150249276 steps/s
Curr learning rate 0.001288 	 Curr reward per step 0.28101199999999993

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.20it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.52it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.00it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.93it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.59it/s]
-------------------------------------
| approxkl           | 0.0062960917 |
| clipfrac           | 0.39314583   |
| eplenmean          | 400          |
| eprewmean          | 115          |
| explained_variance | 0.52         |
| fps                | 1352         |
| nupdates           | 213          |
| policy_entropy     | 0.88369805   |
| policy_loss        | 0.006556267  |
| serial_timesteps   | 85200        |
| time_elapsed       | 1.94e+03     |
| time_remaining     | 81.3         |
| total_timesteps    | 2556000      |
| true_eprew         | 85           |
| value_loss         | 28.929958    |
-------------------------------------
Current reward shaping 0.361
BEST REW 85.0 overwriting previous model with 84.6
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.935206890106201 seconds
Total simulation time for 400 steps: 8.275654077529907 	 Other agent action time: 0 	 48.33454809162236 steps/s
Curr learning rate 0.001287 	 Curr reward per step 0.2731446666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.10it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.60it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.96it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 171.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 169.02it/s]
------------------------------------
| approxkl           | 0.004628321 |
| clipfrac           | 0.36519787  |
| eplenmean          | 400         |
| eprewmean          | 113         |
| explained_variance | 0.506       |
| fps                | 1334        |
| nupdates           | 214         |
| policy_entropy     | 0.904672    |
| policy_loss        | 0.005030004 |
| serial_timesteps   | 85600       |
| time_elapsed       | 1.95e+03    |
| time_remaining     | 81.3        |
| total_timesteps    | 2568000     |
| true_eprew         | 83.6        |
| value_loss         | 30.890144   |
------------------------------------
Current reward shaping 0.358
SP envs: 0/30
Other agent actions took 4.713839292526245 seconds
Total simulation time for 400 steps: 8.060373544692993 	 Other agent action time: 0 	 49.62549164528024 steps/s
Curr learning rate 0.001286 	 Curr reward per step 0.26200966666666664

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.40it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.26it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.98it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 169.97it/s]
-------------------------------------
| approxkl           | 0.0044353697 |
| clipfrac           | 0.37167704   |
| eplenmean          | 400          |
| eprewmean          | 108          |
| explained_variance | 0.557        |
| fps                | 1368         |
| nupdates           | 215          |
| policy_entropy     | 0.9346134    |
| policy_loss        | 0.0049683084 |
| serial_timesteps   | 86000        |
| time_elapsed       | 1.96e+03     |
| time_remaining     | 81.2         |
| total_timesteps    | 2580000      |
| true_eprew         | 80           |
| value_loss         | 28.96542     |
-------------------------------------
Current reward shaping 0.355
SP envs: 0/30
Other agent actions took 4.822885274887085 seconds
Total simulation time for 400 steps: 8.233031988143921 	 Other agent action time: 0 	 48.58477418477481 steps/s
Curr learning rate 0.0012850000000000001 	 Curr reward per step 0.2695504166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.02it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.02it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.03it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.49it/s]
-------------------------------------
| approxkl           | 0.0054901317 |
| clipfrac           | 0.40630212   |
| eplenmean          | 400          |
| eprewmean          | 107          |
| explained_variance | 0.555        |
| fps                | 1341         |
| nupdates           | 216          |
| policy_entropy     | 0.93005216   |
| policy_loss        | 0.0062418585 |
| serial_timesteps   | 86400        |
| time_elapsed       | 1.97e+03     |
| time_remaining     | 81           |
| total_timesteps    | 2592000      |
| true_eprew         | 79.2         |
| value_loss         | 28.802805    |
-------------------------------------
Current reward shaping 0.352
SP envs: 0/30
Other agent actions took 4.924408435821533 seconds
Total simulation time for 400 steps: 8.170037508010864 	 Other agent action time: 0 	 48.95938355335493 steps/s
Curr learning rate 0.001284 	 Curr reward per step 0.2925466666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.64it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.26it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.47it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.86it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.45it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.45it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 166.20it/s]
-------------------------------------
| approxkl           | 0.0035981052 |
| clipfrac           | 0.35139582   |
| eplenmean          | 400          |
| eprewmean          | 109          |
| explained_variance | 0.539        |
| fps                | 1348         |
| nupdates           | 217          |
| policy_entropy     | 0.90213454   |
| policy_loss        | 0.0032844387 |
| serial_timesteps   | 86800        |
| time_elapsed       | 1.97e+03     |
| time_remaining     | 80.8         |
| total_timesteps    | 2604000      |
| true_eprew         | 81.2         |
| value_loss         | 29.667118    |
-------------------------------------
Current reward shaping 0.349
SP envs: 0/30
Other agent actions took 5.055089712142944 seconds
Total simulation time for 400 steps: 8.414121389389038 	 Other agent action time: 0 	 47.53912874426032 steps/s
Curr learning rate 0.001283 	 Curr reward per step 0.28824075

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.09it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 188.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.58it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.30it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 173.80it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.37it/s]
-------------------------------------
| approxkl           | 0.004138413  |
| clipfrac           | 0.36160415   |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.544        |
| fps                | 1317         |
| nupdates           | 218          |
| policy_entropy     | 0.8942785    |
| policy_loss        | 0.0031773385 |
| serial_timesteps   | 87200        |
| time_elapsed       | 1.98e+03     |
| time_remaining     | 80.7         |
| total_timesteps    | 2616000      |
| true_eprew         | 83.8         |
| value_loss         | 26.010439    |
-------------------------------------
Current reward shaping 0.346
SP envs: 0/30
Other agent actions took 4.871170997619629 seconds
Total simulation time for 400 steps: 8.16395092010498 	 Other agent action time: 0 	 48.995884947683685 steps/s
Curr learning rate 0.0012820000000000002 	 Curr reward per step 0.28075133333333324

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.32it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.70it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.94it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.99it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.93it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.30it/s]
------------------------------------
| approxkl           | 0.005032696 |
| clipfrac           | 0.39554173  |
| eplenmean          | 400         |
| eprewmean          | 114         |
| explained_variance | 0.525       |
| fps                | 1352        |
| nupdates           | 219         |
| policy_entropy     | 0.9179465   |
| policy_loss        | 0.006512822 |
| serial_timesteps   | 87600       |
| time_elapsed       | 1.99e+03    |
| time_remaining     | 80.5        |
| total_timesteps    | 2628000     |
| true_eprew         | 85.6        |
| value_loss         | 27.354525   |
------------------------------------
Current reward shaping 0.34299999999999997
BEST REW 85.6 overwriting previous model with 85.0
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.884319543838501 seconds
Total simulation time for 400 steps: 8.161250114440918 	 Other agent action time: 0 	 49.01209917488257 steps/s
Curr learning rate 0.001281 	 Curr reward per step 0.24939825000000007

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.28it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.05it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.39it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.84it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.00it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.75it/s]
-------------------------------------
| approxkl           | 0.0054153567 |
| clipfrac           | 0.39897922   |
| eplenmean          | 400          |
| eprewmean          | 109          |
| explained_variance | 0.582        |
| fps                | 1356         |
| nupdates           | 220          |
| policy_entropy     | 0.92331713   |
| policy_loss        | 0.0066761044 |
| serial_timesteps   | 88000        |
| time_elapsed       | 2e+03        |
| time_remaining     | 80.5         |
| total_timesteps    | 2640000      |
| true_eprew         | 81.8         |
| value_loss         | 27.52383     |
-------------------------------------
Current reward shaping 0.33999999999999997
SP envs: 0/30
Other agent actions took 5.0156965255737305 seconds
Total simulation time for 400 steps: 8.394404649734497 	 Other agent action time: 0 	 47.65078843472853 steps/s
Curr learning rate 0.0012799999999999999 	 Curr reward per step 0.23862666666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 144.45it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 144.01it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 147.80it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 147.37it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.43it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.86it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.92it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.90it/s]
-------------------------------------
| approxkl           | 0.006931802  |
| clipfrac           | 0.4220729    |
| eplenmean          | 400          |
| eprewmean          | 103          |
| explained_variance | 0.523        |
| fps                | 1315         |
| nupdates           | 221          |
| policy_entropy     | 0.94223243   |
| policy_loss        | 0.0075280517 |
| serial_timesteps   | 88400        |
| time_elapsed       | 2.01e+03     |
| time_remaining     | 80.3         |
| total_timesteps    | 2652000      |
| true_eprew         | 77.2         |
| value_loss         | 28.089514    |
-------------------------------------
Current reward shaping 0.33699999999999997
SP envs: 0/30
Other agent actions took 4.762279748916626 seconds
Total simulation time for 400 steps: 8.088326454162598 	 Other agent action time: 0 	 49.45398807365681 steps/s
Curr learning rate 0.0012790000000000002 	 Curr reward per step 0.24306658333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.40it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.85it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.78it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.16it/s]
------------------------------------
| approxkl           | 0.006624016 |
| clipfrac           | 0.42096874  |
| eplenmean          | 400         |
| eprewmean          | 99.7        |
| explained_variance | 0.515       |
| fps                | 1364        |
| nupdates           | 222         |
| policy_entropy     | 0.9205298   |
| policy_loss        | 0.006524718 |
| serial_timesteps   | 88800       |
| time_elapsed       | 2.02e+03    |
| time_remaining     | 80.2        |
| total_timesteps    | 2664000     |
| true_eprew         | 74.6        |
| value_loss         | 25.305609   |
------------------------------------
Current reward shaping 0.33399999999999996
SP envs: 0/30
Other agent actions took 4.868169069290161 seconds
Total simulation time for 400 steps: 8.251337051391602 	 Other agent action time: 0 	 48.47699197217248 steps/s
Curr learning rate 0.001278 	 Curr reward per step 0.26154283333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.33it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 189.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 196.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.71it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.21it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.50it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.77it/s]
-------------------------------------
| approxkl           | 0.0056612287 |
| clipfrac           | 0.3992812    |
| eplenmean          | 400          |
| eprewmean          | 99.4         |
| explained_variance | 0.559        |
| fps                | 1344         |
| nupdates           | 223          |
| policy_entropy     | 0.89809966   |
| policy_loss        | 0.0048119393 |
| serial_timesteps   | 89200        |
| time_elapsed       | 2.03e+03     |
| time_remaining     | 80           |
| total_timesteps    | 2676000      |
| true_eprew         | 74.8         |
| value_loss         | 25.831259    |
-------------------------------------
Current reward shaping 0.33099999999999996
SP envs: 0/30
Other agent actions took 4.875577449798584 seconds
Total simulation time for 400 steps: 8.32264494895935 	 Other agent action time: 0 	 48.06164415917026 steps/s
Curr learning rate 0.001277 	 Curr reward per step 0.2602855

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.22it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.20it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.87it/s]
-------------------------------------
| approxkl           | 0.0049495683 |
| clipfrac           | 0.37998956   |
| eplenmean          | 400          |
| eprewmean          | 102          |
| explained_variance | 0.492        |
| fps                | 1329         |
| nupdates           | 224          |
| policy_entropy     | 0.8806952    |
| policy_loss        | 0.0036875156 |
| serial_timesteps   | 89600        |
| time_elapsed       | 2.04e+03     |
| time_remaining     | 79.9         |
| total_timesteps    | 2688000      |
| true_eprew         | 77.2         |
| value_loss         | 28.324047    |
-------------------------------------
Current reward shaping 0.32799999999999996
SP envs: 0/30
Other agent actions took 4.799225807189941 seconds
Total simulation time for 400 steps: 8.141594171524048 	 Other agent action time: 0 	 49.130427232425276 steps/s
Curr learning rate 0.001276 	 Curr reward per step 0.29043733333333327

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.79it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.11it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.93it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.31it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.28it/s]
-------------------------------------
| approxkl           | 0.0033723798 |
| clipfrac           | 0.32377085   |
| eplenmean          | 400          |
| eprewmean          | 109          |
| explained_variance | 0.529        |
| fps                | 1355         |
| nupdates           | 225          |
| policy_entropy     | 0.8659974    |
| policy_loss        | 0.0025179512 |
| serial_timesteps   | 90000        |
| time_elapsed       | 2.05e+03     |
| time_remaining     | 79.7         |
| total_timesteps    | 2700000      |
| true_eprew         | 82.6         |
| value_loss         | 26.862846    |
-------------------------------------
Current reward shaping 0.32499999999999996
SP envs: 0/30
Other agent actions took 4.803398370742798 seconds
Total simulation time for 400 steps: 8.117603778839111 	 Other agent action time: 0 	 49.275625036382785 steps/s
Curr learning rate 0.001275 	 Curr reward per step 0.2543791666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.80it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.14it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.88it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.04it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 153.89it/s]
-------------------------------------
| approxkl           | 0.0055979835 |
| clipfrac           | 0.38887495   |
| eplenmean          | 400          |
| eprewmean          | 107          |
| explained_variance | 0.59         |
| fps                | 1357         |
| nupdates           | 226          |
| policy_entropy     | 0.88017774   |
| policy_loss        | 0.005583977  |
| serial_timesteps   | 90400        |
| time_elapsed       | 2.06e+03     |
| time_remaining     | 79.5         |
| total_timesteps    | 2712000      |
| true_eprew         | 81.4         |
| value_loss         | 24.52401     |
-------------------------------------
Current reward shaping 0.32199999999999995
SP envs: 0/30
Other agent actions took 4.870537281036377 seconds
Total simulation time for 400 steps: 8.142422199249268 	 Other agent action time: 0 	 49.125431009568636 steps/s
Curr learning rate 0.001274 	 Curr reward per step 0.2565556666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.79it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.77it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.12it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.89it/s]
------------------------------------
| approxkl           | 0.005517592 |
| clipfrac           | 0.37719792  |
| eplenmean          | 400         |
| eprewmean          | 107         |
| explained_variance | 0.535       |
| fps                | 1354        |
| nupdates           | 227         |
| policy_entropy     | 0.85401124  |
| policy_loss        | 0.00411482  |
| serial_timesteps   | 90800       |
| time_elapsed       | 2.07e+03    |
| time_remaining     | 79.4        |
| total_timesteps    | 2724000     |
| true_eprew         | 81.4        |
| value_loss         | 27.314672   |
------------------------------------
Current reward shaping 0.31899999999999995
SP envs: 0/30
Other agent actions took 4.835763454437256 seconds
Total simulation time for 400 steps: 8.219830751419067 	 Other agent action time: 0 	 48.66280244650344 steps/s
Curr learning rate 0.001273 	 Curr reward per step 0.26813541666666657

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.81it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.09it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 188.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.86it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.14it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.96it/s]
-------------------------------------
| approxkl           | 0.0042862147 |
| clipfrac           | 0.35033336   |
| eplenmean          | 400          |
| eprewmean          | 105          |
| explained_variance | 0.498        |
| fps                | 1345         |
| nupdates           | 228          |
| policy_entropy     | 0.8661807    |
| policy_loss        | 0.004415704  |
| serial_timesteps   | 91200        |
| time_elapsed       | 2.08e+03     |
| time_remaining     | 79.2         |
| total_timesteps    | 2736000      |
| true_eprew         | 80           |
| value_loss         | 27.666416    |
-------------------------------------
Current reward shaping 0.31599999999999995
SP envs: 0/30
Other agent actions took 4.808280944824219 seconds
Total simulation time for 400 steps: 8.216222286224365 	 Other agent action time: 0 	 48.6841745592321 steps/s
Curr learning rate 0.0012720000000000001 	 Curr reward per step 0.25677799999999995

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.68it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.65it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.66it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.05it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.82it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.29it/s]
-------------------------------------
| approxkl           | 0.0058733886 |
| clipfrac           | 0.3967708    |
| eplenmean          | 400          |
| eprewmean          | 105          |
| explained_variance | 0.506        |
| fps                | 1344         |
| nupdates           | 229          |
| policy_entropy     | 0.8951909    |
| policy_loss        | 0.006010626  |
| serial_timesteps   | 91600        |
| time_elapsed       | 2.08e+03     |
| time_remaining     | 79.1         |
| total_timesteps    | 2748000      |
| true_eprew         | 79.6         |
| value_loss         | 29.012356    |
-------------------------------------
Current reward shaping 0.31299999999999994
SP envs: 0/30
Other agent actions took 4.99087381362915 seconds
Total simulation time for 400 steps: 8.306212902069092 	 Other agent action time: 0 	 48.15672373391239 steps/s
Curr learning rate 0.001271 	 Curr reward per step 0.24188774999999998

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.65it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.56it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.77it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.76it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.30it/s]
-------------------------------------
| approxkl           | 0.0040150997 |
| clipfrac           | 0.34990627   |
| eplenmean          | 400          |
| eprewmean          | 104          |
| explained_variance | 0.509        |
| fps                | 1332         |
| nupdates           | 230          |
| policy_entropy     | 0.9121181    |
| policy_loss        | 0.004634869  |
| serial_timesteps   | 92000        |
| time_elapsed       | 2.09e+03     |
| time_remaining     | 78.9         |
| total_timesteps    | 2760000      |
| true_eprew         | 79           |
| value_loss         | 31.312534    |
-------------------------------------
Current reward shaping 0.31000000000000005
SP envs: 0/30
Other agent actions took 4.822396993637085 seconds
Total simulation time for 400 steps: 8.225385189056396 	 Other agent action time: 0 	 48.62994143206652 steps/s
Curr learning rate 0.00127 	 Curr reward per step 0.27423499999999995

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 142.80it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 142.29it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 145.07it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 144.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 161.82it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 157.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 147.73it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 147.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 154.61it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 157.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 158.06it/s]
-------------------------------------
| approxkl           | 0.0049638394 |
| clipfrac           | 0.36230198   |
| eplenmean          | 400          |
| eprewmean          | 104          |
| explained_variance | 0.45         |
| fps                | 1327         |
| nupdates           | 231          |
| policy_entropy     | 0.8531336    |
| policy_loss        | 0.0034801795 |
| serial_timesteps   | 92400        |
| time_elapsed       | 2.1e+03      |
| time_remaining     | 78.7         |
| total_timesteps    | 2772000      |
| true_eprew         | 79.6         |
| value_loss         | 31.202755    |
-------------------------------------
Current reward shaping 0.30700000000000005
SP envs: 0/30
Other agent actions took 4.8677990436553955 seconds
Total simulation time for 400 steps: 8.235307216644287 	 Other agent action time: 0 	 48.571351314200456 steps/s
Curr learning rate 0.001269 	 Curr reward per step 0.26125025

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 153.67it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.17it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.12it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.21it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.06it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.47it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.69it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.19it/s]
-------------------------------------
| approxkl           | 0.004499673  |
| clipfrac           | 0.35928115   |
| eplenmean          | 400          |
| eprewmean          | 102          |
| explained_variance | 0.572        |
| fps                | 1339         |
| nupdates           | 232          |
| policy_entropy     | 0.87674737   |
| policy_loss        | 0.0049224184 |
| serial_timesteps   | 92800        |
| time_elapsed       | 2.11e+03     |
| time_remaining     | 78.6         |
| total_timesteps    | 2784000      |
| true_eprew         | 78.6         |
| value_loss         | 23.953888    |
-------------------------------------
Current reward shaping 0.30400000000000005
SP envs: 0/30
Other agent actions took 4.874783754348755 seconds
Total simulation time for 400 steps: 8.254379987716675 	 Other agent action time: 0 	 48.45912116903258 steps/s
Curr learning rate 0.001268 	 Curr reward per step 0.23019600000000004

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.72it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.17it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.85it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.68it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.71it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.63it/s]
-------------------------------------
| approxkl           | 0.004769639  |
| clipfrac           | 0.3811874    |
| eplenmean          | 400          |
| eprewmean          | 102          |
| explained_variance | 0.533        |
| fps                | 1338         |
| nupdates           | 233          |
| policy_entropy     | 0.9181901    |
| policy_loss        | 0.0049648224 |
| serial_timesteps   | 93200        |
| time_elapsed       | 2.12e+03     |
| time_remaining     | 78.4         |
| total_timesteps    | 2796000      |
| true_eprew         | 78.6         |
| value_loss         | 29.818365    |
-------------------------------------
Current reward shaping 0.30100000000000005
SP envs: 0/30
Other agent actions took 4.961201906204224 seconds
Total simulation time for 400 steps: 8.342397928237915 	 Other agent action time: 0 	 47.94784466538726 steps/s
Curr learning rate 0.001267 	 Curr reward per step 0.25019725000000004

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.79it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.12it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.70it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.75it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.78it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.27it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.46it/s]
-------------------------------------
| approxkl           | 0.003723258  |
| clipfrac           | 0.3650521    |
| eplenmean          | 400          |
| eprewmean          | 101          |
| explained_variance | 0.587        |
| fps                | 1327         |
| nupdates           | 234          |
| policy_entropy     | 0.9392375    |
| policy_loss        | 0.0035849777 |
| serial_timesteps   | 93600        |
| time_elapsed       | 2.13e+03     |
| time_remaining     | 78.3         |
| total_timesteps    | 2808000      |
| true_eprew         | 78.2         |
| value_loss         | 26.983717    |
-------------------------------------
Current reward shaping 0.29800000000000004
SP envs: 0/30
Other agent actions took 4.942775726318359 seconds
Total simulation time for 400 steps: 8.36607313156128 	 Other agent action time: 0 	 47.81215675619511 steps/s
Curr learning rate 0.001266 	 Curr reward per step 0.24672216666666671

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.57it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.40it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.79it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.90it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.68it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.29it/s]
------------------------------------
| approxkl           | 0.005178225 |
| clipfrac           | 0.3746771   |
| eplenmean          | 400         |
| eprewmean          | 98.1        |
| explained_variance | 0.507       |
| fps                | 1322        |
| nupdates           | 235         |
| policy_entropy     | 0.91009784  |
| policy_loss        | 0.004407932 |
| serial_timesteps   | 94000       |
| time_elapsed       | 2.14e+03    |
| time_remaining     | 78.1        |
| total_timesteps    | 2820000     |
| true_eprew         | 75.8        |
| value_loss         | 26.450806   |
------------------------------------
Current reward shaping 0.29500000000000004
SP envs: 0/30
Other agent actions took 4.878192663192749 seconds
Total simulation time for 400 steps: 8.164795398712158 	 Other agent action time: 0 	 48.9908173403944 steps/s
Curr learning rate 0.001265 	 Curr reward per step 0.26716124999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.93it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 185.23it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.91it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.86it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.19it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.74it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.55it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.62it/s]
------------------------------------
| approxkl           | 0.005545121 |
| clipfrac           | 0.3775624   |
| eplenmean          | 400         |
| eprewmean          | 99.7        |
| explained_variance | 0.565       |
| fps                | 1358        |
| nupdates           | 236         |
| policy_entropy     | 0.8574149   |
| policy_loss        | 0.005574356 |
| serial_timesteps   | 94400       |
| time_elapsed       | 2.15e+03    |
| time_remaining     | 78          |
| total_timesteps    | 2832000     |
| true_eprew         | 77.4        |
| value_loss         | 25.634012   |
------------------------------------
Current reward shaping 0.29200000000000004
SP envs: 0/30
Other agent actions took 4.888685464859009 seconds
Total simulation time for 400 steps: 8.279017925262451 	 Other agent action time: 0 	 48.31490928162469 steps/s
Curr learning rate 0.001264 	 Curr reward per step 0.24732899999999994

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.20it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.37it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.35it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.99it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.95it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]
------------------------------------
| approxkl           | 0.005904669 |
| clipfrac           | 0.41086456  |
| eplenmean          | 400         |
| eprewmean          | 101         |
| explained_variance | 0.563       |
| fps                | 1334        |
| nupdates           | 237         |
| policy_entropy     | 0.9178692   |
| policy_loss        | 0.005820507 |
| serial_timesteps   | 94800       |
| time_elapsed       | 2.16e+03    |
| time_remaining     | 77.8        |
| total_timesteps    | 2844000     |
| true_eprew         | 78.2        |
| value_loss         | 26.60081    |
------------------------------------
Current reward shaping 0.28900000000000003
SP envs: 0/30
Other agent actions took 4.862224102020264 seconds
Total simulation time for 400 steps: 8.205472946166992 	 Other agent action time: 0 	 48.74795183949163 steps/s
Curr learning rate 0.001263 	 Curr reward per step 0.2837151666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.23it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 159.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.33it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.40it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.90it/s]
-------------------------------------
| approxkl           | 0.0061372435 |
| clipfrac           | 0.39175004   |
| eplenmean          | 400          |
| eprewmean          | 106          |
| explained_variance | 0.596        |
| fps                | 1344         |
| nupdates           | 238          |
| policy_entropy     | 0.8402178    |
| policy_loss        | 0.004243386  |
| serial_timesteps   | 95200        |
| time_elapsed       | 2.17e+03     |
| time_remaining     | 77.7         |
| total_timesteps    | 2856000      |
| true_eprew         | 83           |
| value_loss         | 21.242735    |
-------------------------------------
Current reward shaping 0.28600000000000003
SP envs: 0/30
Other agent actions took 4.940065860748291 seconds
Total simulation time for 400 steps: 8.260551929473877 	 Other agent action time: 0 	 48.42291452376069 steps/s
Curr learning rate 0.001262 	 Curr reward per step 0.256245

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.20it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.68it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.45it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.52it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.68it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.44it/s]
-------------------------------------
| approxkl           | 0.0054548387 |
| clipfrac           | 0.3803646    |
| eplenmean          | 400          |
| eprewmean          | 105          |
| explained_variance | 0.574        |
| fps                | 1334         |
| nupdates           | 239          |
| policy_entropy     | 0.8591598    |
| policy_loss        | 0.0051263785 |
| serial_timesteps   | 95600        |
| time_elapsed       | 2.17e+03     |
| time_remaining     | 77.5         |
| total_timesteps    | 2868000      |
| true_eprew         | 83           |
| value_loss         | 25.92572     |
-------------------------------------
Current reward shaping 0.28300000000000003
SP envs: 0/30
Other agent actions took 4.957146883010864 seconds
Total simulation time for 400 steps: 8.322888851165771 	 Other agent action time: 0 	 48.06023571298477 steps/s
Curr learning rate 0.001261 	 Curr reward per step 0.26928075

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.36it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.92it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.86it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.66it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.92it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.78it/s]
------------------------------------
| approxkl           | 0.005095831 |
| clipfrac           | 0.37595823  |
| eplenmean          | 400         |
| eprewmean          | 108         |
| explained_variance | 0.473       |
| fps                | 1327        |
| nupdates           | 240         |
| policy_entropy     | 0.87853783  |
| policy_loss        | 0.004617848 |
| serial_timesteps   | 96000       |
| time_elapsed       | 2.18e+03    |
| time_remaining     | 77.3        |
| total_timesteps    | 2880000     |
| true_eprew         | 85.2        |
| value_loss         | 28.064457   |
------------------------------------
Current reward shaping 0.28
SP envs: 0/30
Other agent actions took 4.757401704788208 seconds
Total simulation time for 400 steps: 7.987890005111694 	 Other agent action time: 0 	 50.07580221360432 steps/s
Curr learning rate 0.0012599999999999998 	 Curr reward per step 0.28231

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.07it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.16it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.34it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.82it/s]
-------------------------------------
| approxkl           | 0.0038817297 |
| clipfrac           | 0.3287187    |
| eplenmean          | 400          |
| eprewmean          | 108          |
| explained_variance | 0.55         |
| fps                | 1379         |
| nupdates           | 241          |
| policy_entropy     | 0.83545876   |
| policy_loss        | 0.0035483718 |
| serial_timesteps   | 96400        |
| time_elapsed       | 2.19e+03     |
| time_remaining     | 77.2         |
| total_timesteps    | 2892000      |
| true_eprew         | 85.2         |
| value_loss         | 26.820736    |
-------------------------------------
Current reward shaping 0.277
SP envs: 0/30
Other agent actions took 4.987642526626587 seconds
Total simulation time for 400 steps: 8.344196319580078 	 Other agent action time: 0 	 47.93751065772264 steps/s
Curr learning rate 0.0012590000000000001 	 Curr reward per step 0.2575560833333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.12it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.95it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.68it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.29it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.30it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.45it/s]
-------------------------------------
| approxkl           | 0.004470656  |
| clipfrac           | 0.35455206   |
| eplenmean          | 400          |
| eprewmean          | 107          |
| explained_variance | 0.575        |
| fps                | 1326         |
| nupdates           | 242          |
| policy_entropy     | 0.86709434   |
| policy_loss        | 0.0040830555 |
| serial_timesteps   | 96800        |
| time_elapsed       | 2.2e+03      |
| time_remaining     | 77           |
| total_timesteps    | 2904000      |
| true_eprew         | 84.4         |
| value_loss         | 25.95453     |
-------------------------------------
Current reward shaping 0.274
SP envs: 0/30
Other agent actions took 4.770598649978638 seconds
Total simulation time for 400 steps: 8.134123802185059 	 Other agent action time: 0 	 49.175548556631085 steps/s
Curr learning rate 0.001258 	 Curr reward per step 0.25265350000000003

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.83it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.25it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.50it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 197.18it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 196.04it/s]
-------------------------------------
| approxkl           | 0.0059172064 |
| clipfrac           | 0.4044271    |
| eplenmean          | 400          |
| eprewmean          | 106          |
| explained_variance | 0.533        |
| fps                | 1362         |
| nupdates           | 243          |
| policy_entropy     | 0.88518924   |
| policy_loss        | 0.0062803533 |
| serial_timesteps   | 97200        |
| time_elapsed       | 2.21e+03     |
| time_remaining     | 76.9         |
| total_timesteps    | 2916000      |
| true_eprew         | 83.8         |
| value_loss         | 25.559237    |
-------------------------------------
Current reward shaping 0.271
SP envs: 0/30
Other agent actions took 4.83965802192688 seconds
Total simulation time for 400 steps: 8.208234071731567 	 Other agent action time: 0 	 48.73155376715738 steps/s
Curr learning rate 0.0012569999999999999 	 Curr reward per step 0.2754646666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.52it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.99it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 203.02it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 202.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.93it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 204.04it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 205.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 209.48it/s]
------------------------------------
| approxkl           | 0.005101855 |
| clipfrac           | 0.3698126   |
| eplenmean          | 400         |
| eprewmean          | 106         |
| explained_variance | 0.552       |
| fps                | 1356        |
| nupdates           | 244         |
| policy_entropy     | 0.8467492   |
| policy_loss        | 0.004861993 |
| serial_timesteps   | 97600       |
| time_elapsed       | 2.22e+03    |
| time_remaining     | 76.7        |
| total_timesteps    | 2928000     |
| true_eprew         | 84.2        |
| value_loss         | 23.603313   |
------------------------------------
Current reward shaping 0.268
SP envs: 0/30
Other agent actions took 4.932077646255493 seconds
Total simulation time for 400 steps: 8.301907777786255 	 Other agent action time: 0 	 48.181696389147554 steps/s
Curr learning rate 0.0012560000000000002 	 Curr reward per step 0.288826

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.17it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 161.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.06it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.69it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.97it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 171.68it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.31it/s]
-------------------------------------
| approxkl           | 0.004710075  |
| clipfrac           | 0.36183324   |
| eplenmean          | 400          |
| eprewmean          | 109          |
| explained_variance | 0.557        |
| fps                | 1328         |
| nupdates           | 245          |
| policy_entropy     | 0.82388556   |
| policy_loss        | 0.0038362555 |
| serial_timesteps   | 98000        |
| time_elapsed       | 2.23e+03     |
| time_remaining     | 76.5         |
| total_timesteps    | 2940000      |
| true_eprew         | 87           |
| value_loss         | 26.203716    |
-------------------------------------
Current reward shaping 0.265
BEST REW 87.0 overwriting previous model with 85.6
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.942333221435547 seconds
Total simulation time for 400 steps: 8.334683656692505 	 Other agent action time: 0 	 47.992223397562526 steps/s
Curr learning rate 0.001255 	 Curr reward per step 0.2780779166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.35it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.18it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.17it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.68it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.65it/s]
-------------------------------------
| approxkl           | 0.00377193   |
| clipfrac           | 0.32387495   |
| eplenmean          | 400          |
| eprewmean          | 112          |
| explained_variance | 0.542        |
| fps                | 1328         |
| nupdates           | 246          |
| policy_entropy     | 0.8258196    |
| policy_loss        | 0.0024504715 |
| serial_timesteps   | 98400        |
| time_elapsed       | 2.24e+03     |
| time_remaining     | 76.5         |
| total_timesteps    | 2952000      |
| true_eprew         | 89.6         |
| value_loss         | 26.020844    |
-------------------------------------
Current reward shaping 0.262
BEST REW 89.6 overwriting previous model with 87.0
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.887577533721924 seconds
Total simulation time for 400 steps: 8.25829815864563 	 Other agent action time: 0 	 48.43612961361042 steps/s
Curr learning rate 0.001254 	 Curr reward per step 0.27278566666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.52it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.17it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.09it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.12it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.57it/s]
-------------------------------------
| approxkl           | 0.0047240923 |
| clipfrac           | 0.3682709    |
| eplenmean          | 400          |
| eprewmean          | 111          |
| explained_variance | 0.54         |
| fps                | 1342         |
| nupdates           | 247          |
| policy_entropy     | 0.83969724   |
| policy_loss        | 0.0043010474 |
| serial_timesteps   | 98800        |
| time_elapsed       | 2.25e+03     |
| time_remaining     | 76.5         |
| total_timesteps    | 2964000      |
| true_eprew         | 88.6         |
| value_loss         | 26.518679    |
-------------------------------------
Current reward shaping 0.259
SP envs: 0/30
Other agent actions took 4.938457012176514 seconds
Total simulation time for 400 steps: 8.2384512424469 	 Other agent action time: 0 	 48.552815113972336 steps/s
Curr learning rate 0.0012530000000000002 	 Curr reward per step 0.27359141666666664

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 145.94it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 145.48it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 154.85it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 160.70it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.49it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.36it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.65it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 166.62it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.29it/s]
------------------------------------
| approxkl           | 0.004637413 |
| clipfrac           | 0.34960413  |
| eplenmean          | 400         |
| eprewmean          | 111         |
| explained_variance | 0.615       |
| fps                | 1333        |
| nupdates           | 248         |
| policy_entropy     | 0.83070034  |
| policy_loss        | 0.00405433  |
| serial_timesteps   | 99200       |
| time_elapsed       | 2.26e+03    |
| time_remaining     | 76.3        |
| total_timesteps    | 2976000     |
| true_eprew         | 88.6        |
| value_loss         | 24.049097   |
------------------------------------
Current reward shaping 0.256
SP envs: 0/30
Other agent actions took 4.8542938232421875 seconds
Total simulation time for 400 steps: 8.07575273513794 	 Other agent action time: 0 	 49.53098653696803 steps/s
Curr learning rate 0.001252 	 Curr reward per step 0.2729706666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.09it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.42it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.63it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.83it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 205.79it/s]
-------------------------------------
| approxkl           | 0.003945526  |
| clipfrac           | 0.34058332   |
| eplenmean          | 400          |
| eprewmean          | 110          |
| explained_variance | 0.59         |
| fps                | 1368         |
| nupdates           | 249          |
| policy_entropy     | 0.8418415    |
| policy_loss        | 0.0027966374 |
| serial_timesteps   | 99600        |
| time_elapsed       | 2.27e+03     |
| time_remaining     | 76.2         |
| total_timesteps    | 2988000      |
| true_eprew         | 88           |
| value_loss         | 23.380196    |
-------------------------------------
Current reward shaping 0.253
SP envs: 0/30
Other agent actions took 4.720323801040649 seconds
Total simulation time for 400 steps: 7.9875168800354 	 Other agent action time: 0 	 50.07814143088574 steps/s
Curr learning rate 0.001251 	 Curr reward per step 0.25920741666666663

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.90it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.17it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.05it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.59it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.27it/s]
-------------------------------------
| approxkl           | 0.004772857  |
| clipfrac           | 0.35150003   |
| eplenmean          | 400          |
| eprewmean          | 107          |
| explained_variance | 0.573        |
| fps                | 1379         |
| nupdates           | 250          |
| policy_entropy     | 0.80939823   |
| policy_loss        | 0.0045939097 |
| serial_timesteps   | 100000       |
| time_elapsed       | 2.28e+03     |
| time_remaining     | 76           |
| total_timesteps    | 3000000      |
| true_eprew         | 86.4         |
| value_loss         | 24.482616    |
-------------------------------------
Current reward shaping 0.25
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø2X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø3X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø6X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø7X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø9X 
O ←oX →oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X ø10X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø11X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø13X 
O →oX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø14X 
O →1Xo←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø15X 
O ←1X ←oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø16X 
O ←1X →oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø17X 
O ←1X →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø18X 
O ←oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X ø19X 
O →oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo  ø=
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø=
O ↓1X ←0X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø=
O   X ←0X 
D ↓1X   X 
X X X S X 


Timestep: 56
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑0ø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 57
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←oø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 59
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →oø=
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →oø=
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →oø=
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →oø=
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →oø=
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X →0ø1
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø2
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø3
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø4
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 68
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ↑0ø5
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑oX ↑0ø6
O   X   X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX ↑0ø7
O   X   X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo←0ø8
O   X   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø9
O ↓1X ↓0X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑0ø10
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø11
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 75
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø12
O   X ↓0X 
D ↓1X   X 
X X X S X 


Timestep: 76
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø13
O   X   X 
D ←1X ↓0X 
X X X S X 


Timestep: 77
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   Xo  ø14
O   X   X 
D ←dX ←0X 
X X X S X 


Timestep: 78
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø15
O   X   X 
D ←dX ↓0X 
X X X S X 


Timestep: 79
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø16
O   X   X 
D ←dX ↓0X 
X X X S X 


Timestep: 80
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø17
O   X   X 
D →dX ↓0X 
X X X S X 


Timestep: 81
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø18
O   X   X 
D →1Xd↓0X 
X X X S X 


Timestep: 82
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø19
O   X   X 
D →1Xd↓0X 
X X X S X 


Timestep: 83
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →dX ←0X 
X X X S X 


Timestep: 84
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →dX ←0X 
X X X S X 


Timestep: 85
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D ←dX ←0X 
X X X S X 


Timestep: 86
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X ↑0X 
D →dX   X 
X X X S X 


Timestep: 87
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →1Xd↓0X 
X X X S X 


Timestep: 88
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →1Xd←0X 
X X X S X 


Timestep: 89
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →1X ←dX 
X X X S X 


Timestep: 90
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O ↑1X ↑dX 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑dø20
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo→dø20
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 5 
X X X ø20X 
O ↑1Xo→sP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑1Xo  P 
O   X ↓sX 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←1Xo  P 
O   X   X 
D   X ↓sX 
X X X S X 


Timestep: 96
Joint action taken: ('interact', 'stay') 	 Reward: 20 + shape * 0 
X X X ø20X 
O ←1Xo  P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 97
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←oXo  P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 98
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←oXo  P 
O   X   X 
D   X →0X 
X X X S X 


Timestep: 99
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oXo  P 
O   X ↑0X 
D   X   X 
X X X S X 


tot rew 100 tot rew shaped 82
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O   X   X 
D →1X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ↓0X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX →0X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX →0X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX →0X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX →0X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 30
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 31
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 32
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 33
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ↓oX   X 
X X X S X 


Timestep: 34
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 42
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   Xo↓0X 
D ←1X   X 
X X X S X 


Timestep: 43
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   Xo↓0X 
D ←dX   X 
X X X S X 


Timestep: 44
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   Xo←0X 
D ←dX   X 
X X X S X 


Timestep: 45
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   Xo←0X 
D ←dX   X 
X X X S X 


Timestep: 46
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   Xo←0X 
D ←dX   X 
X X X S X 


Timestep: 47
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   Xo←0X 
D ←dX   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←oX 
D ←dX   X 
X X X S X 


Timestep: 49
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑oP 
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →oP 
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 3 
X X X P X 
O ↑dX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX ←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O ↓dX   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O   X   X 
D ↓dX   X 
X X X S X 


Timestep: 55
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0ø-
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dX   ø-
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O ↑1X   ø-
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X XdX P X 
O →1X   ø-
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O ←1X   ø-
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O ←1X   ø-
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O ←1X   ø-
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O ←1X ↑0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ↑0ø-
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ↑0ø-
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ↑0ø-
O →1X   X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ←0ø-
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ←0ø-
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 75
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 76
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 77
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 78
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 79
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 80
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ←0X 
D →oX   X 
X X X S X 


Timestep: 81
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 82
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 83
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ↑0ø-
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 84
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ↑0ø-
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 85
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ↑0ø-
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ↑0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ←0ø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ↓0X 
D ↓oX   X 
X X X S X 


Timestep: 92
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 93
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O ↑oX ↓0X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O →oX ←0X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X   ø-
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XdX P X 
O   X ↑0ø-
O ←oX   X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 15
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.828641176223755 seconds
Total simulation time for 400 steps: 8.148956775665283 	 Other agent action time: 0 	 49.08603776062414 steps/s
Curr learning rate 0.0012500000000000002 	 Curr reward per step 0.2561458333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.93it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.47it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.75it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.98it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.94it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.65it/s]
-------------------------------------
| approxkl           | 0.0057657654 |
| clipfrac           | 0.38396874   |
| eplenmean          | 400          |
| eprewmean          | 105          |
| explained_variance | 0.481        |
| fps                | 1355         |
| nupdates           | 251          |
| policy_entropy     | 0.8512866    |
| policy_loss        | 0.00627288   |
| serial_timesteps   | 100400       |
| time_elapsed       | 2.29e+03     |
| time_remaining     | 75.9         |
| total_timesteps    | 3012000      |
| true_eprew         | 84.6         |
| value_loss         | 28.632814    |
-------------------------------------
Current reward shaping 0.247
SP envs: 0/30
Other agent actions took 4.855376720428467 seconds
Total simulation time for 400 steps: 8.191234350204468 	 Other agent action time: 0 	 48.83268905497928 steps/s
Curr learning rate 0.0012490000000000001 	 Curr reward per step 0.2526504166666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.64it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.82it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.42it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.04it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.84it/s]
-------------------------------------
| approxkl           | 0.005556881  |
| clipfrac           | 0.3762501    |
| eplenmean          | 400          |
| eprewmean          | 103          |
| explained_variance | 0.604        |
| fps                | 1350         |
| nupdates           | 252          |
| policy_entropy     | 0.8240022    |
| policy_loss        | 0.0056925486 |
| serial_timesteps   | 100800       |
| time_elapsed       | 2.3e+03      |
| time_remaining     | 75.7         |
| total_timesteps    | 3024000      |
| true_eprew         | 83.6         |
| value_loss         | 24.045256    |
-------------------------------------
Current reward shaping 0.244
SP envs: 0/30
Other agent actions took 4.934061288833618 seconds
Total simulation time for 400 steps: 8.282448053359985 	 Other agent action time: 0 	 48.2948999405713 steps/s
Curr learning rate 0.001248 	 Curr reward per step 0.25050666666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.61it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.45it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.86it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.00it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.27it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.27it/s]
------------------------------------
| approxkl           | 0.005201305 |
| clipfrac           | 0.37811458  |
| eplenmean          | 400         |
| eprewmean          | 101         |
| explained_variance | 0.605       |
| fps                | 1335        |
| nupdates           | 253         |
| policy_entropy     | 0.8706958   |
| policy_loss        | 0.004619119 |
| serial_timesteps   | 101200      |
| time_elapsed       | 2.31e+03    |
| time_remaining     | 75.6        |
| total_timesteps    | 3036000     |
| true_eprew         | 81.4        |
| value_loss         | 25.338535   |
------------------------------------
Current reward shaping 0.241
SP envs: 0/30
Other agent actions took 4.843241930007935 seconds
Total simulation time for 400 steps: 8.14659595489502 	 Other agent action time: 0 	 49.1002625163524 steps/s
Curr learning rate 0.001247 	 Curr reward per step 0.2686420833333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.96it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.83it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.00it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.29it/s]
-------------------------------------
| approxkl           | 0.004164325  |
| clipfrac           | 0.3437188    |
| eplenmean          | 400          |
| eprewmean          | 103          |
| explained_variance | 0.552        |
| fps                | 1357         |
| nupdates           | 254          |
| policy_entropy     | 0.82748824   |
| policy_loss        | 0.0025178478 |
| serial_timesteps   | 101600       |
| time_elapsed       | 2.32e+03     |
| time_remaining     | 75.4         |
| total_timesteps    | 3048000      |
| true_eprew         | 83.2         |
| value_loss         | 25.102282    |
-------------------------------------
Current reward shaping 0.238
SP envs: 0/30
Other agent actions took 5.058865308761597 seconds
Total simulation time for 400 steps: 8.435479164123535 	 Other agent action time: 0 	 47.41876450850802 steps/s
Curr learning rate 0.0012460000000000001 	 Curr reward per step 0.24119183333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 151.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 150.20it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 161.42it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 161.63it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 163.07it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 162.54it/s]
-------------------------------------
| approxkl           | 0.0069346214 |
| clipfrac           | 0.41223955   |
| eplenmean          | 400          |
| eprewmean          | 101          |
| explained_variance | 0.413        |
| fps                | 1301         |
| nupdates           | 255          |
| policy_entropy     | 0.86243564   |
| policy_loss        | 0.007130015  |
| serial_timesteps   | 102000       |
| time_elapsed       | 2.33e+03     |
| time_remaining     | 75.3         |
| total_timesteps    | 3060000      |
| true_eprew         | 81.6         |
| value_loss         | 32.150333    |
-------------------------------------
Current reward shaping 0.235
SP envs: 0/30
Other agent actions took 4.934100866317749 seconds
Total simulation time for 400 steps: 8.25152063369751 	 Other agent action time: 0 	 48.475913441515544 steps/s
Curr learning rate 0.001245 	 Curr reward per step 0.2456291666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.52it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.90it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.84it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.70it/s]
-------------------------------------
| approxkl           | 0.0050029946 |
| clipfrac           | 0.3717395    |
| eplenmean          | 400          |
| eprewmean          | 100          |
| explained_variance | 0.542        |
| fps                | 1343         |
| nupdates           | 256          |
| policy_entropy     | 0.8585739    |
| policy_loss        | 0.0051447344 |
| serial_timesteps   | 102400       |
| time_elapsed       | 2.34e+03     |
| time_remaining     | 75.1         |
| total_timesteps    | 3072000      |
| true_eprew         | 81.2         |
| value_loss         | 27.037022    |
-------------------------------------
Current reward shaping 0.23199999999999998
SP envs: 0/30
Other agent actions took 4.924151659011841 seconds
Total simulation time for 400 steps: 8.176457643508911 	 Other agent action time: 0 	 48.92094075941923 steps/s
Curr learning rate 0.001244 	 Curr reward per step 0.26749799999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.38it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.23it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 197.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 200.72it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.67it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 201.59it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.13it/s]
-------------------------------------
| approxkl           | 0.0028572185 |
| clipfrac           | 0.31206244   |
| eplenmean          | 400          |
| eprewmean          | 102          |
| explained_variance | 0.574        |
| fps                | 1357         |
| nupdates           | 257          |
| policy_entropy     | 0.8625975    |
| policy_loss        | 0.002614904  |
| serial_timesteps   | 102800       |
| time_elapsed       | 2.34e+03     |
| time_remaining     | 75           |
| total_timesteps    | 3084000      |
| true_eprew         | 83           |
| value_loss         | 26.448507    |
-------------------------------------
Current reward shaping 0.22899999999999998
SP envs: 0/30
Other agent actions took 4.830923080444336 seconds
Total simulation time for 400 steps: 8.121126413345337 	 Other agent action time: 0 	 49.25425115199357 steps/s
Curr learning rate 0.0012430000000000002 	 Curr reward per step 0.23613725

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.49it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.87it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.40it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 171.14it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.23it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.43it/s]
-------------------------------------
| approxkl           | 0.0051928614 |
| clipfrac           | 0.38636473   |
| eplenmean          | 400          |
| eprewmean          | 98.6         |
| explained_variance | 0.536        |
| fps                | 1358         |
| nupdates           | 258          |
| policy_entropy     | 0.88934165   |
| policy_loss        | 0.005292843  |
| serial_timesteps   | 103200       |
| time_elapsed       | 2.35e+03     |
| time_remaining     | 74.8         |
| total_timesteps    | 3096000      |
| true_eprew         | 80.4         |
| value_loss         | 26.49113     |
-------------------------------------
Current reward shaping 0.22599999999999998
SP envs: 0/30
Other agent actions took 4.859685897827148 seconds
Total simulation time for 400 steps: 8.170201539993286 	 Other agent action time: 0 	 48.95840060272597 steps/s
Curr learning rate 0.001242 	 Curr reward per step 0.24774233333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.15it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 166.67it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.22it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.94it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.40it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.25it/s]
-------------------------------------
| approxkl           | 0.00452474   |
| clipfrac           | 0.36987498   |
| eplenmean          | 400          |
| eprewmean          | 98.8         |
| explained_variance | 0.561        |
| fps                | 1350         |
| nupdates           | 259          |
| policy_entropy     | 0.8885206    |
| policy_loss        | 0.0034534815 |
| serial_timesteps   | 103600       |
| time_elapsed       | 2.36e+03     |
| time_remaining     | 74.6         |
| total_timesteps    | 3108000      |
| true_eprew         | 80.8         |
| value_loss         | 25.571388    |
-------------------------------------
Current reward shaping 0.22299999999999998
SP envs: 0/30
Other agent actions took 4.8307716846466064 seconds
Total simulation time for 400 steps: 8.116740226745605 	 Other agent action time: 0 	 49.280867543592606 steps/s
Curr learning rate 0.001241 	 Curr reward per step 0.24687408333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.67it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.14it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 196.39it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.08it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.31it/s]
-------------------------------------
| approxkl           | 0.0062284977 |
| clipfrac           | 0.3910417    |
| eplenmean          | 400          |
| eprewmean          | 97.4         |
| explained_variance | 0.528        |
| fps                | 1363         |
| nupdates           | 260          |
| policy_entropy     | 0.8776524    |
| policy_loss        | 0.0042518973 |
| serial_timesteps   | 104000       |
| time_elapsed       | 2.37e+03     |
| time_remaining     | 74.5         |
| total_timesteps    | 3120000      |
| true_eprew         | 80           |
| value_loss         | 25.463533    |
-------------------------------------
Current reward shaping 0.21999999999999997
SP envs: 0/30
Other agent actions took 4.889976263046265 seconds
Total simulation time for 400 steps: 8.136276483535767 	 Other agent action time: 0 	 49.16253777872759 steps/s
Curr learning rate 0.00124 	 Curr reward per step 0.260485

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.01it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.47it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.87it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.70it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.80it/s]
-------------------------------------
| approxkl           | 0.00349054   |
| clipfrac           | 0.32321876   |
| eplenmean          | 400          |
| eprewmean          | 98.7         |
| explained_variance | 0.566        |
| fps                | 1359         |
| nupdates           | 261          |
| policy_entropy     | 0.8600181    |
| policy_loss        | 0.0019359196 |
| serial_timesteps   | 104400       |
| time_elapsed       | 2.38e+03     |
| time_remaining     | 74.3         |
| total_timesteps    | 3132000      |
| true_eprew         | 81.2         |
| value_loss         | 25.756493    |
-------------------------------------
Current reward shaping 0.21699999999999997
SP envs: 0/30
Other agent actions took 4.890016794204712 seconds
Total simulation time for 400 steps: 8.254050731658936 	 Other agent action time: 0 	 48.46105421496558 steps/s
Curr learning rate 0.001239 	 Curr reward per step 0.2698105

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.41it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.02it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.14it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.25it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.82it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.75it/s]
-------------------------------------
| approxkl           | 0.0049965256 |
| clipfrac           | 0.34625006   |
| eplenmean          | 400          |
| eprewmean          | 103          |
| explained_variance | 0.533        |
| fps                | 1338         |
| nupdates           | 262          |
| policy_entropy     | 0.8142897    |
| policy_loss        | 0.0031681198 |
| serial_timesteps   | 104800       |
| time_elapsed       | 2.39e+03     |
| time_remaining     | 74.2         |
| total_timesteps    | 3144000      |
| true_eprew         | 84.8         |
| value_loss         | 22.534243    |
-------------------------------------
Current reward shaping 0.21399999999999997
SP envs: 0/30
Other agent actions took 4.940174579620361 seconds
Total simulation time for 400 steps: 8.25179409980774 	 Other agent action time: 0 	 48.474306940028924 steps/s
Curr learning rate 0.001238 	 Curr reward per step 0.23173816666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 154.46it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 159.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 159.95it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.30it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.51it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.77it/s]
-------------------------------------
| approxkl           | 0.0058832713 |
| clipfrac           | 0.3834792    |
| eplenmean          | 400          |
| eprewmean          | 101          |
| explained_variance | 0.574        |
| fps                | 1336         |
| nupdates           | 263          |
| policy_entropy     | 0.86709875   |
| policy_loss        | 0.004170419  |
| serial_timesteps   | 105200       |
| time_elapsed       | 2.4e+03      |
| time_remaining     | 74           |
| total_timesteps    | 3156000      |
| true_eprew         | 83.6         |
| value_loss         | 26.365215    |
-------------------------------------
Current reward shaping 0.21099999999999997
SP envs: 0/30
Other agent actions took 4.89933705329895 seconds
Total simulation time for 400 steps: 8.16387939453125 	 Other agent action time: 0 	 48.99631421159266 steps/s
Curr learning rate 0.001237 	 Curr reward per step 0.24498825000000007

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.50it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.74it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 157.50it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.74it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.50it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.54it/s]
-------------------------------------
| approxkl           | 0.004748562  |
| clipfrac           | 0.36862496   |
| eplenmean          | 400          |
| eprewmean          | 100          |
| explained_variance | 0.539        |
| fps                | 1349         |
| nupdates           | 264          |
| policy_entropy     | 0.862018     |
| policy_loss        | 0.0053199762 |
| serial_timesteps   | 105600       |
| time_elapsed       | 2.41e+03     |
| time_remaining     | 73.8         |
| total_timesteps    | 3168000      |
| true_eprew         | 83.4         |
| value_loss         | 24.297998    |
-------------------------------------
Current reward shaping 0.20799999999999996
SP envs: 0/30
Other agent actions took 4.993413686752319 seconds
Total simulation time for 400 steps: 8.44442343711853 	 Other agent action time: 0 	 47.36853889180278 steps/s
Curr learning rate 0.0012360000000000001 	 Curr reward per step 0.24677333333333326

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 141.03it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 140.62it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 146.83it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 146.39it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.27it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.20it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.98it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.06it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.83it/s]
-------------------------------------
| approxkl           | 0.0053883367 |
| clipfrac           | 0.37215626   |
| eplenmean          | 400          |
| eprewmean          | 97.1         |
| explained_variance | 0.511        |
| fps                | 1306         |
| nupdates           | 265          |
| policy_entropy     | 0.82480925   |
| policy_loss        | 0.005931556  |
| serial_timesteps   | 106000       |
| time_elapsed       | 2.42e+03     |
| time_remaining     | 73.7         |
| total_timesteps    | 3180000      |
| true_eprew         | 80.6         |
| value_loss         | 25.64416     |
-------------------------------------
Current reward shaping 0.20499999999999996
SP envs: 0/30
Other agent actions took 4.980870962142944 seconds
Total simulation time for 400 steps: 8.289161443710327 	 Other agent action time: 0 	 48.25578590986584 steps/s
Curr learning rate 0.001235 	 Curr reward per step 0.2628791666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.81it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.01it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.67it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 195.47it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.09it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.03it/s]
-------------------------------------
| approxkl           | 0.0045418967 |
| clipfrac           | 0.34085417   |
| eplenmean          | 400          |
| eprewmean          | 99.9         |
| explained_variance | 0.529        |
| fps                | 1338         |
| nupdates           | 266          |
| policy_entropy     | 0.8092601    |
| policy_loss        | 0.004048469  |
| serial_timesteps   | 106400       |
| time_elapsed       | 2.42e+03     |
| time_remaining     | 73.5         |
| total_timesteps    | 3192000      |
| true_eprew         | 83.2         |
| value_loss         | 24.78403     |
-------------------------------------
Current reward shaping 0.20199999999999996
SP envs: 0/30
Other agent actions took 4.818292856216431 seconds
Total simulation time for 400 steps: 8.062872886657715 	 Other agent action time: 0 	 49.61010865766124 steps/s
Curr learning rate 0.001234 	 Curr reward per step 0.25287466666666664

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.78it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.26it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.53it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.05it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.63it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.31it/s]
-------------------------------------
| approxkl           | 0.0047679716 |
| clipfrac           | 0.36261463   |
| eplenmean          | 400          |
| eprewmean          | 102          |
| explained_variance | 0.542        |
| fps                | 1373         |
| nupdates           | 267          |
| policy_entropy     | 0.8543729    |
| policy_loss        | 0.0045232098 |
| serial_timesteps   | 106800       |
| time_elapsed       | 2.43e+03     |
| time_remaining     | 73.4         |
| total_timesteps    | 3204000      |
| true_eprew         | 85           |
| value_loss         | 26.40952     |
-------------------------------------
Current reward shaping 0.19899999999999995
SP envs: 0/30
Other agent actions took 4.761327505111694 seconds
Total simulation time for 400 steps: 8.000947952270508 	 Other agent action time: 0 	 49.99407600026795 steps/s
Curr learning rate 0.0012330000000000002 	 Curr reward per step 0.2617236666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.60it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.34it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.96it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.81it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.57it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.54it/s]
-------------------------------------
| approxkl           | 0.0064256946 |
| clipfrac           | 0.38974997   |
| eplenmean          | 400          |
| eprewmean          | 104          |
| explained_variance | 0.52         |
| fps                | 1379         |
| nupdates           | 268          |
| policy_entropy     | 0.81569755   |
| policy_loss        | 0.0057038446 |
| serial_timesteps   | 107200       |
| time_elapsed       | 2.44e+03     |
| time_remaining     | 73.2         |
| total_timesteps    | 3216000      |
| true_eprew         | 87.4         |
| value_loss         | 25.472895    |
-------------------------------------
Current reward shaping 0.19599999999999995
SP envs: 0/30
Other agent actions took 4.984783411026001 seconds
Total simulation time for 400 steps: 8.387134552001953 	 Other agent action time: 0 	 47.69209287390324 steps/s
Curr learning rate 0.001232 	 Curr reward per step 0.24890600000000002

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.02it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.25it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.97it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.98it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.14it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.86it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.66it/s]
-------------------------------------
| approxkl           | 0.004798219  |
| clipfrac           | 0.35905212   |
| eplenmean          | 400          |
| eprewmean          | 101          |
| explained_variance | 0.609        |
| fps                | 1321         |
| nupdates           | 269          |
| policy_entropy     | 0.83524203   |
| policy_loss        | 0.0038363046 |
| serial_timesteps   | 107600       |
| time_elapsed       | 2.45e+03     |
| time_remaining     | 73.1         |
| total_timesteps    | 3228000      |
| true_eprew         | 85.2         |
| value_loss         | 21.792551    |
-------------------------------------
Current reward shaping 0.19299999999999995
SP envs: 0/30
Other agent actions took 4.996317625045776 seconds
Total simulation time for 400 steps: 8.310173273086548 	 Other agent action time: 0 	 48.13377373194444 steps/s
Curr learning rate 0.0012309999999999999 	 Curr reward per step 0.2514407499999999

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 194.46it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 161.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 165.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 161.84it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 160.89it/s]
-------------------------------------
| approxkl           | 0.003667622  |
| clipfrac           | 0.32176036   |
| eplenmean          | 400          |
| eprewmean          | 101          |
| explained_variance | 0.553        |
| fps                | 1327         |
| nupdates           | 270          |
| policy_entropy     | 0.8282785    |
| policy_loss        | 0.0020661415 |
| serial_timesteps   | 108000       |
| time_elapsed       | 2.46e+03     |
| time_remaining     | 72.9         |
| total_timesteps    | 3240000      |
| true_eprew         | 85.2         |
| value_loss         | 23.93596     |
-------------------------------------
Current reward shaping 0.18999999999999995
SP envs: 0/30
Other agent actions took 5.007957935333252 seconds
Total simulation time for 400 steps: 8.331211566925049 	 Other agent action time: 0 	 48.012224487012425 steps/s
Curr learning rate 0.00123 	 Curr reward per step 0.2460008333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.83it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.96it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.29it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.96it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.03it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.22it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.49it/s]
-------------------------------------
| approxkl           | 0.0051897    |
| clipfrac           | 0.36863545   |
| eplenmean          | 400          |
| eprewmean          | 101          |
| explained_variance | 0.519        |
| fps                | 1326         |
| nupdates           | 271          |
| policy_entropy     | 0.84986156   |
| policy_loss        | 0.0037745936 |
| serial_timesteps   | 108400       |
| time_elapsed       | 2.47e+03     |
| time_remaining     | 72.7         |
| total_timesteps    | 3252000      |
| true_eprew         | 85.4         |
| value_loss         | 23.960827    |
-------------------------------------
Current reward shaping 0.18700000000000006
SP envs: 0/30
Other agent actions took 4.9626171588897705 seconds
Total simulation time for 400 steps: 8.303256750106812 	 Other agent action time: 0 	 48.17386864435505 steps/s
Curr learning rate 0.001229 	 Curr reward per step 0.221324

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.51it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.73it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.94it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.44it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.62it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.38it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.29it/s]
-------------------------------------
| approxkl           | 0.0055958973 |
| clipfrac           | 0.3774687    |
| eplenmean          | 400          |
| eprewmean          | 96.4         |
| explained_variance | 0.518        |
| fps                | 1330         |
| nupdates           | 272          |
| policy_entropy     | 0.84245616   |
| policy_loss        | 0.0040588654 |
| serial_timesteps   | 108800       |
| time_elapsed       | 2.48e+03     |
| time_remaining     | 72.6         |
| total_timesteps    | 3264000      |
| true_eprew         | 81.4         |
| value_loss         | 27.97029     |
-------------------------------------
Current reward shaping 0.18400000000000005
SP envs: 0/30
Other agent actions took 4.8388285636901855 seconds
Total simulation time for 400 steps: 8.189235210418701 	 Other agent action time: 0 	 48.844609993751625 steps/s
Curr learning rate 0.001228 	 Curr reward per step 0.27974866666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.32it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.06it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.39it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.29it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.45it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.52it/s]
-------------------------------------
| approxkl           | 0.0029903473 |
| clipfrac           | 0.29545835   |
| eplenmean          | 400          |
| eprewmean          | 99.8         |
| explained_variance | 0.603        |
| fps                | 1346         |
| nupdates           | 273          |
| policy_entropy     | 0.7680914    |
| policy_loss        | 0.0009542349 |
| serial_timesteps   | 109200       |
| time_elapsed       | 2.49e+03     |
| time_remaining     | 72.4         |
| total_timesteps    | 3276000      |
| true_eprew         | 84.6         |
| value_loss         | 22.501652    |
-------------------------------------
Current reward shaping 0.18100000000000005
SP envs: 0/30
Other agent actions took 4.902055740356445 seconds
Total simulation time for 400 steps: 8.11036491394043 	 Other agent action time: 0 	 49.31960574455331 steps/s
Curr learning rate 0.001227 	 Curr reward per step 0.23939758333333327

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.11it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.97it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.67it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.51it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.18it/s]
-------------------------------------
| approxkl           | 0.00459376   |
| clipfrac           | 0.35627082   |
| eplenmean          | 400          |
| eprewmean          | 98.3         |
| explained_variance | 0.565        |
| fps                | 1366         |
| nupdates           | 274          |
| policy_entropy     | 0.82932985   |
| policy_loss        | 0.0047457423 |
| serial_timesteps   | 109600       |
| time_elapsed       | 2.5e+03      |
| time_remaining     | 72.3         |
| total_timesteps    | 3288000      |
| true_eprew         | 83.4         |
| value_loss         | 25.982975    |
-------------------------------------
Current reward shaping 0.17800000000000005
SP envs: 0/30
Other agent actions took 4.96730637550354 seconds
Total simulation time for 400 steps: 8.325807094573975 	 Other agent action time: 0 	 48.043390323165745 steps/s
Curr learning rate 0.001226 	 Curr reward per step 0.24170299999999997

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.67it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.28it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 160.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 163.46it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.00it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.31it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.21it/s]
-------------------------------------
| approxkl           | 0.0051698964 |
| clipfrac           | 0.36180216   |
| eplenmean          | 400          |
| eprewmean          | 102          |
| explained_variance | 0.61         |
| fps                | 1322         |
| nupdates           | 275          |
| policy_entropy     | 0.8273718    |
| policy_loss        | 0.005605452  |
| serial_timesteps   | 110000       |
| time_elapsed       | 2.51e+03     |
| time_remaining     | 72.1         |
| total_timesteps    | 3300000      |
| true_eprew         | 87           |
| value_loss         | 23.086782    |
-------------------------------------
Current reward shaping 0.17500000000000004
SP envs: 0/30
Other agent actions took 4.884375095367432 seconds
Total simulation time for 400 steps: 8.305989503860474 	 Other agent action time: 0 	 48.15801895897981 steps/s
Curr learning rate 0.001225 	 Curr reward per step 0.21205833333333338

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.36it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.32it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.82it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.52it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.36it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.68it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.63it/s]
-------------------------------------
| approxkl           | 0.0056039966 |
| clipfrac           | 0.38097918   |
| eplenmean          | 400          |
| eprewmean          | 94.1         |
| explained_variance | 0.577        |
| fps                | 1332         |
| nupdates           | 276          |
| policy_entropy     | 0.8693179    |
| policy_loss        | 0.004655548  |
| serial_timesteps   | 110400       |
| time_elapsed       | 2.51e+03     |
| time_remaining     | 72           |
| total_timesteps    | 3312000      |
| true_eprew         | 80.4         |
| value_loss         | 23.637138    |
-------------------------------------
Current reward shaping 0.17200000000000004
SP envs: 0/30
Other agent actions took 4.900413990020752 seconds
Total simulation time for 400 steps: 8.182227373123169 	 Other agent action time: 0 	 48.88644396682408 steps/s
Curr learning rate 0.001224 	 Curr reward per step 0.23833933333333338

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 144.89it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 144.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 151.91it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 154.42it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 159.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 160.47it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 159.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.69it/s]
-------------------------------------
| approxkl           | 0.007527707  |
| clipfrac           | 0.40469795   |
| eplenmean          | 400          |
| eprewmean          | 92.5         |
| explained_variance | 0.536        |
| fps                | 1338         |
| nupdates           | 277          |
| policy_entropy     | 0.8455248    |
| policy_loss        | 0.0071274913 |
| serial_timesteps   | 110800       |
| time_elapsed       | 2.52e+03     |
| time_remaining     | 71.8         |
| total_timesteps    | 3324000      |
| true_eprew         | 79.2         |
| value_loss         | 23.30616     |
-------------------------------------
Current reward shaping 0.16900000000000004
SP envs: 0/30
Other agent actions took 4.7778565883636475 seconds
Total simulation time for 400 steps: 8.068576574325562 	 Other agent action time: 0 	 49.57503920490899 steps/s
Curr learning rate 0.0012230000000000001 	 Curr reward per step 0.24764033333333327

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.85it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.86it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 165.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 167.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 171.42it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 169.48it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 169.70it/s]
-------------------------------------
| approxkl           | 0.0053625754 |
| clipfrac           | 0.3806876    |
| eplenmean          | 400          |
| eprewmean          | 94.5         |
| explained_variance | 0.547        |
| fps                | 1361         |
| nupdates           | 278          |
| policy_entropy     | 0.87264794   |
| policy_loss        | 0.0042222138 |
| serial_timesteps   | 111200       |
| time_elapsed       | 2.53e+03     |
| time_remaining     | 71.7         |
| total_timesteps    | 3336000      |
| true_eprew         | 81.2         |
| value_loss         | 20.646961    |
-------------------------------------
Current reward shaping 0.16600000000000004
SP envs: 0/30
Other agent actions took 4.861234903335571 seconds
Total simulation time for 400 steps: 8.26233434677124 	 Other agent action time: 0 	 48.412468342716274 steps/s
Curr learning rate 0.001222 	 Curr reward per step 0.23949316666666673

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.15it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.83it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.00it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.89it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 171.48it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.31it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.96it/s]
-------------------------------------
| approxkl           | 0.0049050287 |
| clipfrac           | 0.36288545   |
| eplenmean          | 400          |
| eprewmean          | 94.6         |
| explained_variance | 0.557        |
| fps                | 1335         |
| nupdates           | 279          |
| policy_entropy     | 0.84519714   |
| policy_loss        | 0.0034364846 |
| serial_timesteps   | 111600       |
| time_elapsed       | 2.54e+03     |
| time_remaining     | 71.5         |
| total_timesteps    | 3348000      |
| true_eprew         | 81.4         |
| value_loss         | 23.041185    |
-------------------------------------
Current reward shaping 0.16300000000000003
SP envs: 0/30
Other agent actions took 4.835289478302002 seconds
Total simulation time for 400 steps: 8.130037784576416 	 Other agent action time: 0 	 49.20026334426691 steps/s
Curr learning rate 0.001221 	 Curr reward per step 0.24453833333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.39it/s]
-------------------------------------
| approxkl           | 0.0047409753 |
| clipfrac           | 0.34794796   |
| eplenmean          | 400          |
| eprewmean          | 97.3         |
| explained_variance | 0.572        |
| fps                | 1357         |
| nupdates           | 280          |
| policy_entropy     | 0.83098996   |
| policy_loss        | 0.0029128857 |
| serial_timesteps   | 112000       |
| time_elapsed       | 2.55e+03     |
| time_remaining     | 71.3         |
| total_timesteps    | 3360000      |
| true_eprew         | 84           |
| value_loss         | 22.525408    |
-------------------------------------
Current reward shaping 0.16000000000000003
SP envs: 0/30
Other agent actions took 4.797508716583252 seconds
Total simulation time for 400 steps: 8.055405855178833 	 Other agent action time: 0 	 49.65609519759198 steps/s
Curr learning rate 0.0012200000000000002 	 Curr reward per step 0.24244000000000007

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.61it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.90it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.09it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.10it/s]
-------------------------------------
| approxkl           | 0.0037931136 |
| clipfrac           | 0.33338547   |
| eplenmean          | 400          |
| eprewmean          | 96.9         |
| explained_variance | 0.568        |
| fps                | 1371         |
| nupdates           | 281          |
| policy_entropy     | 0.8546261    |
| policy_loss        | 0.0027946136 |
| serial_timesteps   | 112400       |
| time_elapsed       | 2.56e+03     |
| time_remaining     | 71.2         |
| total_timesteps    | 3372000      |
| true_eprew         | 83.8         |
| value_loss         | 23.38254     |
-------------------------------------
Current reward shaping 0.15700000000000003
SP envs: 0/30
Other agent actions took 4.695350408554077 seconds
Total simulation time for 400 steps: 8.102195024490356 	 Other agent action time: 0 	 49.369337419171885 steps/s
Curr learning rate 0.001219 	 Curr reward per step 0.2238829166666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.13it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.45it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.00it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.05it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.97it/s]
------------------------------------
| approxkl           | 0.006186946 |
| clipfrac           | 0.37953138  |
| eplenmean          | 400         |
| eprewmean          | 95.2        |
| explained_variance | 0.593       |
| fps                | 1360        |
| nupdates           | 282         |
| policy_entropy     | 0.8386314   |
| policy_loss        | 0.005921503 |
| serial_timesteps   | 112800      |
| time_elapsed       | 2.57e+03    |
| time_remaining     | 71          |
| total_timesteps    | 3384000     |
| true_eprew         | 82.4        |
| value_loss         | 25.636946   |
------------------------------------
Current reward shaping 0.15400000000000003
SP envs: 0/30
Other agent actions took 4.84466814994812 seconds
Total simulation time for 400 steps: 8.265614986419678 	 Other agent action time: 0 	 48.393253334107136 steps/s
Curr learning rate 0.001218 	 Curr reward per step 0.22982466666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.01it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.04it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.17it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.88it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.88it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.69it/s]
-------------------------------------
| approxkl           | 0.0063507217 |
| clipfrac           | 0.3947916    |
| eplenmean          | 400          |
| eprewmean          | 93.9         |
| explained_variance | 0.493        |
| fps                | 1341         |
| nupdates           | 283          |
| policy_entropy     | 0.83420527   |
| policy_loss        | 0.006151421  |
| serial_timesteps   | 113200       |
| time_elapsed       | 2.58e+03     |
| time_remaining     | 70.9         |
| total_timesteps    | 3396000      |
| true_eprew         | 81.4         |
| value_loss         | 27.385181    |
-------------------------------------
Current reward shaping 0.15100000000000002
SP envs: 0/30
Other agent actions took 4.94548487663269 seconds
Total simulation time for 400 steps: 8.53485894203186 	 Other agent action time: 0 	 46.866621079126304 steps/s
Curr learning rate 0.001217 	 Curr reward per step 0.2346966666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 151.45it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 155.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 150.78it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 152.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 162.45it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 153.78it/s]
------------------------------------
| approxkl           | 0.005457074 |
| clipfrac           | 0.38764578  |
| eplenmean          | 400         |
| eprewmean          | 92.3        |
| explained_variance | 0.526       |
| fps                | 1286        |
| nupdates           | 284         |
| policy_entropy     | 0.88070923  |
| policy_loss        | 0.005187429 |
| serial_timesteps   | 113600      |
| time_elapsed       | 2.59e+03    |
| time_remaining     | 70.7        |
| total_timesteps    | 3408000     |
| true_eprew         | 80.2        |
| value_loss         | 26.962425   |
------------------------------------
Current reward shaping 0.14800000000000002
SP envs: 0/30
Other agent actions took 4.957367181777954 seconds
Total simulation time for 400 steps: 8.512788772583008 	 Other agent action time: 0 	 46.988127003488344 steps/s
Curr learning rate 0.001216 	 Curr reward per step 0.240872

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.98it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.79it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.02it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.42it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.25it/s]
------------------------------------
| approxkl           | 0.006672098 |
| clipfrac           | 0.39499992  |
| eplenmean          | 400         |
| eprewmean          | 94.3        |
| explained_variance | 0.619       |
| fps                | 1304        |
| nupdates           | 285         |
| policy_entropy     | 0.8602558   |
| policy_loss        | 0.005265348 |
| serial_timesteps   | 114000      |
| time_elapsed       | 2.59e+03    |
| time_remaining     | 70.6        |
| total_timesteps    | 3420000     |
| true_eprew         | 82.4        |
| value_loss         | 19.830076   |
------------------------------------
Current reward shaping 0.14500000000000002
SP envs: 0/30
Other agent actions took 4.7907514572143555 seconds
Total simulation time for 400 steps: 8.170768976211548 	 Other agent action time: 0 	 48.95500058373498 steps/s
Curr learning rate 0.001215 	 Curr reward per step 0.23377041666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 153.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.12it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.39it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.39it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 167.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.03it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.68it/s]
-------------------------------------
| approxkl           | 0.003959279  |
| clipfrac           | 0.35433328   |
| eplenmean          | 400          |
| eprewmean          | 93.8         |
| explained_variance | 0.594        |
| fps                | 1347         |
| nupdates           | 286          |
| policy_entropy     | 0.8913097    |
| policy_loss        | 0.0033716557 |
| serial_timesteps   | 114400       |
| time_elapsed       | 2.6e+03      |
| time_remaining     | 70.4         |
| total_timesteps    | 3432000      |
| true_eprew         | 82.2         |
| value_loss         | 22.555792    |
-------------------------------------
Current reward shaping 0.14200000000000002
SP envs: 0/30
Other agent actions took 4.797626495361328 seconds
Total simulation time for 400 steps: 8.064462900161743 	 Other agent action time: 0 	 49.60032738100605 steps/s
Curr learning rate 0.001214 	 Curr reward per step 0.2285756666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.90it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.45it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.54it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.57it/s]
-------------------------------------
| approxkl           | 0.0061054607 |
| clipfrac           | 0.3960937    |
| eplenmean          | 400          |
| eprewmean          | 93.1         |
| explained_variance | 0.585        |
| fps                | 1366         |
| nupdates           | 287          |
| policy_entropy     | 0.8831443    |
| policy_loss        | 0.0051697018 |
| serial_timesteps   | 114800       |
| time_elapsed       | 2.61e+03     |
| time_remaining     | 70.2         |
| total_timesteps    | 3444000      |
| true_eprew         | 81.8         |
| value_loss         | 21.877695    |
-------------------------------------
Current reward shaping 0.139
SP envs: 0/30
Other agent actions took 4.788621187210083 seconds
Total simulation time for 400 steps: 8.106746673583984 	 Other agent action time: 0 	 49.34161829719053 steps/s
Curr learning rate 0.001213 	 Curr reward per step 0.24869191666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.54it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.12it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.21it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.00it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.00it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.44it/s]
-------------------------------------
| approxkl           | 0.0056325933 |
| clipfrac           | 0.37963542   |
| eplenmean          | 400          |
| eprewmean          | 94           |
| explained_variance | 0.523        |
| fps                | 1360         |
| nupdates           | 288          |
| policy_entropy     | 0.87515444   |
| policy_loss        | 0.0037443158 |
| serial_timesteps   | 115200       |
| time_elapsed       | 2.62e+03     |
| time_remaining     | 70.1         |
| total_timesteps    | 3456000      |
| true_eprew         | 82.8         |
| value_loss         | 24.049906    |
-------------------------------------
Current reward shaping 0.136
SP envs: 0/30
Other agent actions took 4.72247314453125 seconds
Total simulation time for 400 steps: 8.023298263549805 	 Other agent action time: 0 	 49.85480869098654 steps/s
Curr learning rate 0.001212 	 Curr reward per step 0.22854933333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.20it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.94it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.77it/s]
------------------------------------
| approxkl           | 0.005415415 |
| clipfrac           | 0.3876978   |
| eplenmean          | 400         |
| eprewmean          | 93.1        |
| explained_variance | 0.557       |
| fps                | 1373        |
| nupdates           | 289         |
| policy_entropy     | 0.8630726   |
| policy_loss        | 0.005707267 |
| serial_timesteps   | 115600      |
| time_elapsed       | 2.63e+03    |
| time_remaining     | 69.9        |
| total_timesteps    | 3468000     |
| true_eprew         | 82.2        |
| value_loss         | 25.122456   |
------------------------------------
Current reward shaping 0.133
SP envs: 0/30
Other agent actions took 4.896851539611816 seconds
Total simulation time for 400 steps: 8.217512130737305 	 Other agent action time: 0 	 48.676532950138835 steps/s
Curr learning rate 0.001211 	 Curr reward per step 0.23480033333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.05it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.61it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.39it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.70it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.30it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.61it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.64it/s]
-------------------------------------
| approxkl           | 0.0035255575 |
| clipfrac           | 0.32813543   |
| eplenmean          | 400          |
| eprewmean          | 93.7         |
| explained_variance | 0.563        |
| fps                | 1345         |
| nupdates           | 290          |
| policy_entropy     | 0.8743153    |
| policy_loss        | 0.0016638205 |
| serial_timesteps   | 116000       |
| time_elapsed       | 2.64e+03     |
| time_remaining     | 69.8         |
| total_timesteps    | 3480000      |
| true_eprew         | 82.8         |
| value_loss         | 23.668222    |
-------------------------------------
Current reward shaping 0.13
SP envs: 0/30
Other agent actions took 4.767781019210815 seconds
Total simulation time for 400 steps: 8.053941249847412 	 Other agent action time: 0 	 49.66512513455177 steps/s
Curr learning rate 0.00121 	 Curr reward per step 0.20727500000000001

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 180.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.57it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.02it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.07it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.82it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.40it/s]
-------------------------------------
| approxkl           | 0.0049034227 |
| clipfrac           | 0.36094803   |
| eplenmean          | 400          |
| eprewmean          | 90.6         |
| explained_variance | 0.477        |
| fps                | 1370         |
| nupdates           | 291          |
| policy_entropy     | 0.8824318    |
| policy_loss        | 0.00448001   |
| serial_timesteps   | 116400       |
| time_elapsed       | 2.65e+03     |
| time_remaining     | 69.6         |
| total_timesteps    | 3492000      |
| true_eprew         | 80.2         |
| value_loss         | 28.348825    |
-------------------------------------
Current reward shaping 0.127
SP envs: 0/30
Other agent actions took 4.70225191116333 seconds
Total simulation time for 400 steps: 8.01408052444458 	 Other agent action time: 0 	 49.912151341619094 steps/s
Curr learning rate 0.001209 	 Curr reward per step 0.2349660833333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.84it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.52it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.85it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.09it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.26it/s]
-------------------------------------
| approxkl           | 0.006204201  |
| clipfrac           | 0.38985428   |
| eplenmean          | 400          |
| eprewmean          | 91.9         |
| explained_variance | 0.53         |
| fps                | 1376         |
| nupdates           | 292          |
| policy_entropy     | 0.8661664    |
| policy_loss        | 0.0053169383 |
| serial_timesteps   | 116800       |
| time_elapsed       | 2.66e+03     |
| time_remaining     | 69.4         |
| total_timesteps    | 3504000      |
| true_eprew         | 81.6         |
| value_loss         | 22.636656    |
-------------------------------------
Current reward shaping 0.124
SP envs: 0/30
Other agent actions took 4.617670059204102 seconds
Total simulation time for 400 steps: 7.812807083129883 	 Other agent action time: 0 	 51.19798757910151 steps/s
Curr learning rate 0.001208 	 Curr reward per step 0.21284699999999993

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.17it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.90it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.82it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 170.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.72it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.90it/s]
-------------------------------------
| approxkl           | 0.0055120313 |
| clipfrac           | 0.38294798   |
| eplenmean          | 400          |
| eprewmean          | 87.4         |
| explained_variance | 0.583        |
| fps                | 1409         |
| nupdates           | 293          |
| policy_entropy     | 0.8720514    |
| policy_loss        | 0.0054233065 |
| serial_timesteps   | 117200       |
| time_elapsed       | 2.67e+03     |
| time_remaining     | 69.3         |
| total_timesteps    | 3516000      |
| true_eprew         | 77.8         |
| value_loss         | 22.146185    |
-------------------------------------
Current reward shaping 0.121
SP envs: 0/30
Other agent actions took 4.681990385055542 seconds
Total simulation time for 400 steps: 7.9416773319244385 	 Other agent action time: 0 	 50.367193639567255 steps/s
Curr learning rate 0.001207 	 Curr reward per step 0.2012254166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.79it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.12it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.00it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.36it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.22it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.55it/s]
-------------------------------------
| approxkl           | 0.0040200977 |
| clipfrac           | 0.34527084   |
| eplenmean          | 400          |
| eprewmean          | 85.6         |
| explained_variance | 0.581        |
| fps                | 1387         |
| nupdates           | 294          |
| policy_entropy     | 0.86202693   |
| policy_loss        | 0.0021774617 |
| serial_timesteps   | 117600       |
| time_elapsed       | 2.67e+03     |
| time_remaining     | 69.1         |
| total_timesteps    | 3528000      |
| true_eprew         | 76.4         |
| value_loss         | 23.022774    |
-------------------------------------
Current reward shaping 0.118
SP envs: 0/30
Other agent actions took 4.595512866973877 seconds
Total simulation time for 400 steps: 7.8932530879974365 	 Other agent action time: 0 	 50.67619086080544 steps/s
Curr learning rate 0.001206 	 Curr reward per step 0.22301983333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.79it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.74it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.27it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.07it/s]
-------------------------------------
| approxkl           | 0.0047661425 |
| clipfrac           | 0.345        |
| eplenmean          | 400          |
| eprewmean          | 85           |
| explained_variance | 0.573        |
| fps                | 1394         |
| nupdates           | 295          |
| policy_entropy     | 0.81553787   |
| policy_loss        | 0.0021168247 |
| serial_timesteps   | 118000       |
| time_elapsed       | 2.68e+03     |
| time_remaining     | 69           |
| total_timesteps    | 3540000      |
| true_eprew         | 76           |
| value_loss         | 24.700996    |
-------------------------------------
Current reward shaping 0.11499999999999999
SP envs: 0/30
Other agent actions took 4.6634509563446045 seconds
Total simulation time for 400 steps: 7.915107727050781 	 Other agent action time: 0 	 50.53626732494802 steps/s
Curr learning rate 0.001205 	 Curr reward per step 0.20560416666666673

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.41it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.93it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.30it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.18it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.99it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.25it/s]
-------------------------------------
| approxkl           | 0.0063544386 |
| clipfrac           | 0.38423952   |
| eplenmean          | 400          |
| eprewmean          | 84.6         |
| explained_variance | 0.58         |
| fps                | 1397         |
| nupdates           | 296          |
| policy_entropy     | 0.85509294   |
| policy_loss        | 0.0040637185 |
| serial_timesteps   | 118400       |
| time_elapsed       | 2.69e+03     |
| time_remaining     | 68.8         |
| total_timesteps    | 3552000      |
| true_eprew         | 75.8         |
| value_loss         | 23.35874     |
-------------------------------------
Current reward shaping 0.11199999999999999
SP envs: 0/30
Other agent actions took 4.658155679702759 seconds
Total simulation time for 400 steps: 7.8635594844818115 	 Other agent action time: 0 	 50.8675493317463 steps/s
Curr learning rate 0.001204 	 Curr reward per step 0.22295599999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.93it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.90it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.97it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.04it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.60it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.65it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 165.32it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.00it/s]
-------------------------------------
| approxkl           | 0.005143778  |
| clipfrac           | 0.37322912   |
| eplenmean          | 400          |
| eprewmean          | 85.4         |
| explained_variance | 0.608        |
| fps                | 1397         |
| nupdates           | 297          |
| policy_entropy     | 0.79397935   |
| policy_loss        | 0.0054278607 |
| serial_timesteps   | 118800       |
| time_elapsed       | 2.7e+03      |
| time_remaining     | 68.6         |
| total_timesteps    | 3564000      |
| true_eprew         | 76.8         |
| value_loss         | 20.39719     |
-------------------------------------
Current reward shaping 0.10899999999999999
SP envs: 0/30
Other agent actions took 4.6385722160339355 seconds
Total simulation time for 400 steps: 7.917264699935913 	 Other agent action time: 0 	 50.52249926710646 steps/s
Curr learning rate 0.001203 	 Curr reward per step 0.23717241666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 195.41it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 201.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 201.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 196.58it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.58it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.03it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.47it/s]
------------------------------------
| approxkl           | 0.005794465 |
| clipfrac           | 0.39337495  |
| eplenmean          | 400         |
| eprewmean          | 88.4        |
| explained_variance | 0.575       |
| fps                | 1400        |
| nupdates           | 298         |
| policy_entropy     | 0.83775866  |
| policy_loss        | 0.005567123 |
| serial_timesteps   | 119200      |
| time_elapsed       | 2.71e+03    |
| time_remaining     | 68.5        |
| total_timesteps    | 3576000     |
| true_eprew         | 79.8        |
| value_loss         | 21.649517   |
------------------------------------
Current reward shaping 0.10599999999999998
SP envs: 0/30
Other agent actions took 4.6779773235321045 seconds
Total simulation time for 400 steps: 7.941920280456543 	 Other agent action time: 0 	 50.36565287419454 steps/s
Curr learning rate 0.001202 	 Curr reward per step 0.22334966666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 182.04it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.72it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 192.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 196.10it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.49it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.85it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 196.48it/s]
-------------------------------------
| approxkl           | 0.003962704  |
| clipfrac           | 0.34392706   |
| eplenmean          | 400          |
| eprewmean          | 89.1         |
| explained_variance | 0.576        |
| fps                | 1397         |
| nupdates           | 299          |
| policy_entropy     | 0.8588471    |
| policy_loss        | 0.0016333295 |
| serial_timesteps   | 119600       |
| time_elapsed       | 2.72e+03     |
| time_remaining     | 68.3         |
| total_timesteps    | 3588000      |
| true_eprew         | 80.8         |
| value_loss         | 22.023748    |
-------------------------------------
Current reward shaping 0.10299999999999998
SP envs: 0/30
Other agent actions took 4.7563371658325195 seconds
Total simulation time for 400 steps: 8.06609058380127 	 Other agent action time: 0 	 49.59031836355771 steps/s
Curr learning rate 0.001201 	 Curr reward per step 0.23264433333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.74it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.43it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 170.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.37it/s]
------------------------------------
| approxkl           | 0.005782151 |
| clipfrac           | 0.38724992  |
| eplenmean          | 400         |
| eprewmean          | 92.7        |
| explained_variance | 0.631       |
| fps                | 1365        |
| nupdates           | 300         |
| policy_entropy     | 0.8527147   |
| policy_loss        | 0.004074595 |
| serial_timesteps   | 120000      |
| time_elapsed       | 2.73e+03    |
| time_remaining     | 68.1        |
| total_timesteps    | 3600000     |
| true_eprew         | 84.2        |
| value_loss         | 21.071144   |
------------------------------------
Current reward shaping 0.09999999999999998
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø2X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø3X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø6X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø7X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X ø9X 
O ←1X →oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø10X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø11X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø13X 
O →1Xo←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø14X 
O →1X ←oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø15X 
O →1X →oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 3 
X X X ø16X 
O ←1X →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø17X 
O ←oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø18X 
O →oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø19X 
O →1Xo←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1X ←oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←1X →oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←oX →oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø20X 
O ←oX →0ø1
O   X   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX →0ø2
O   X   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX →0ø3
O   X   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX ←0ø4
O   X   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX ←0ø5
O   X   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo←0ø6
O   X   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø7
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø8
O   X ↓0X 
D ↓1X   X 
X X X S X 


Timestep: 61
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø9
O   X   X 
D ↓1X ↓0X 
X X X S X 


Timestep: 62
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø10
O   X   X 
D ↓1X →0X 
X X X S X 


Timestep: 63
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø11
O   X   X 
D ↓1X →0X 
X X X S X 


Timestep: 64
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø12
O   X   X 
D ←1X ↓0X 
X X X S X 


Timestep: 65
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   Xo  ø13
O   X   X 
D ←dX →0X 
X X X S X 


Timestep: 66
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø14
O   X   X 
D ←dX ←0X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø15
O   X   X 
D ←dX ←0X 
X X X S X 


Timestep: 68
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø16
O   X   X 
D →dX ←0X 
X X X S X 


Timestep: 69
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø17
O   X   X 
D →1Xd←0X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø18
O   X   X 
D →1X ←dX 
X X X S X 


Timestep: 71
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø19
O   X ↑dX 
D ←1X   X 
X X X S X 


Timestep: 72
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑dø20
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   Xo↑dø20
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 5 
X X X P X 
O   Xo↑sø20
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 75
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø20
O   X ↓sX 
D →dX   X 
X X X S X 


Timestep: 76
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø20
O ↑dX   X 
D   X ↓sX 
X X X S X 


Timestep: 77
Joint action taken: ('interact', '↑') 	 Reward: 20 + shape * 0 
X X X P X 
O ↑dXo  ø20
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 78
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dXo  ø20
O   X ↑0X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dXo↑0ø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dXo←0ø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX ←oø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX ↑oø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø-X 
O →1Xd↑0ø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd↑0ø20
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd↑0ø20
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd↑0ø20
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 87
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd←0ø20
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 88
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←dø20
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 89
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd←0ø20
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 90
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←dø20
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 91
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X →dø20
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 92
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   X →dø20
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 93
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X →dø20
O   X   X 
D →dX   X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 5 
X X X ø-X 
O   X →sP 
O   X   X 
D →dX   X 
X X X S X 


Timestep: 95
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X →sP 
O   X   X 
D →1Xd  X 
X X X S X 


Timestep: 96
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O   X ↓sX 
D →dX   X 
X X X S X 


Timestep: 97
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O ↑dX   X 
D   X ↓sX 
X X X S X 


Timestep: 98
Joint action taken: ('interact', '↑') 	 Reward: 20 + shape * 0 
X X X ø-X 
O ↑dX   P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 99
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑dX   P 
O   X ↑0X 
D   X   X 
X X X S X 


tot rew 160 tot rew shaped 145
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø-X 
O →1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O ↓1X ←0X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 48
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 49
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D →1X   X 
X X X S X 


Timestep: 50
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D →1X   X 
X X X S X 


Timestep: 51
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 52
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 54
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 55
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X →0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 56
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X →0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 57
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 59
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 60
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 61
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 62
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 63
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 64
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 65
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 66
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 68
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 69
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ↓dX   X 
X X X S X 


Timestep: 70
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ↓1X   X 
X XdX S X 


Timestep: 71
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ↓dX   X 
X X X S X 


Timestep: 72
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D →dX   X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D →1Xd  X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←1Xd  X 
X X X S X 


Timestep: 75
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←1Xd  X 
X X X S X 


Timestep: 76
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←1Xd  X 
X X X S X 


Timestep: 77
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ↓1Xd  X 
X X X S X 


Timestep: 78
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←1Xd  X 
X X X S X 


Timestep: 79
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 80
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 81
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 82
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 83
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 84
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 85
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 86
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 87
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 88
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 89
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 90
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 91
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 92
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 93
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ←dXd  X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O ↑dX   X 
D   Xd  X 
X X X S X 


Timestep: 95
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O ↑dX   X 
D   Xd  X 
X X X S X 


Timestep: 96
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O ↑dX   X 
D   Xd  X 
X X X S X 


Timestep: 97
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O ↑dX ↓0X 
D   Xd  X 
X X X S X 


Timestep: 98
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →dX   X 
D   Xd↓0X 
X X X S X 


Timestep: 99
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑dX   P 
O   X   X 
D   Xd↓0X 
X X X S X 


tot rew 0 tot rew shaped 9
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.67988133430481 seconds
Total simulation time for 400 steps: 7.978709697723389 	 Other agent action time: 0 	 50.13341945679942 steps/s
Curr learning rate 0.0012000000000000001 	 Curr reward per step 0.22129999999999994

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 183.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.52it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.58it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.22it/s]
-------------------------------------
| approxkl           | 0.0049960194 |
| clipfrac           | 0.35790634   |
| eplenmean          | 400          |
| eprewmean          | 91           |
| explained_variance | 0.534        |
| fps                | 1386         |
| nupdates           | 301          |
| policy_entropy     | 0.83843493   |
| policy_loss        | 0.0039146123 |
| serial_timesteps   | 120400       |
| time_elapsed       | 2.74e+03     |
| time_remaining     | 68           |
| total_timesteps    | 3612000      |
| true_eprew         | 82.8         |
| value_loss         | 22.503645    |
-------------------------------------
Current reward shaping 0.09699999999999998
SP envs: 0/30
Other agent actions took 4.60219669342041 seconds
Total simulation time for 400 steps: 7.79524827003479 	 Other agent action time: 0 	 51.31331115361831 steps/s
Curr learning rate 0.001199 	 Curr reward per step 0.22549275000000005

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.69it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.23it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.35it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.91it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.78it/s]
-------------------------------------
| approxkl           | 0.0051826853 |
| clipfrac           | 0.37080204   |
| eplenmean          | 400          |
| eprewmean          | 90.5         |
| explained_variance | 0.57         |
| fps                | 1412         |
| nupdates           | 302          |
| policy_entropy     | 0.8744616    |
| policy_loss        | 0.003067759  |
| serial_timesteps   | 120800       |
| time_elapsed       | 2.74e+03     |
| time_remaining     | 67.9         |
| total_timesteps    | 3624000      |
| true_eprew         | 82.6         |
| value_loss         | 22.005941    |
-------------------------------------
Current reward shaping 0.09399999999999997
SP envs: 0/30
Other agent actions took 4.669615983963013 seconds
Total simulation time for 400 steps: 7.874559640884399 	 Other agent action time: 0 	 50.79649126323407 steps/s
Curr learning rate 0.0011979999999999998 	 Curr reward per step 0.21402533333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 179.39it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.15it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.96it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.53it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.11it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.63it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.55it/s]
------------------------------------
| approxkl           | 0.005121743 |
| clipfrac           | 0.37607294  |
| eplenmean          | 400         |
| eprewmean          | 89.2        |
| explained_variance | 0.604       |
| fps                | 1400        |
| nupdates           | 303         |
| policy_entropy     | 0.8403711   |
| policy_loss        | 0.004633671 |
| serial_timesteps   | 121200      |
| time_elapsed       | 2.75e+03    |
| time_remaining     | 67.7        |
| total_timesteps    | 3636000     |
| true_eprew         | 81.6        |
| value_loss         | 20.080896   |
------------------------------------
Current reward shaping 0.09099999999999997
SP envs: 0/30
Other agent actions took 4.681406021118164 seconds
Total simulation time for 400 steps: 7.9944140911102295 	 Other agent action time: 0 	 50.034936324451735 steps/s
Curr learning rate 0.001197 	 Curr reward per step 0.22250991666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.30it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.99it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.96it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.08it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.41it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.72it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.23it/s]
-------------------------------------
| approxkl           | 0.005732546  |
| clipfrac           | 0.38279167   |
| eplenmean          | 400          |
| eprewmean          | 89.1         |
| explained_variance | 0.55         |
| fps                | 1383         |
| nupdates           | 304          |
| policy_entropy     | 0.81743133   |
| policy_loss        | 0.0039349534 |
| serial_timesteps   | 121600       |
| time_elapsed       | 2.76e+03     |
| time_remaining     | 67.5         |
| total_timesteps    | 3648000      |
| true_eprew         | 81.8         |
| value_loss         | 21.262005    |
-------------------------------------
Current reward shaping 0.08799999999999997
SP envs: 0/30
Other agent actions took 4.641045093536377 seconds
Total simulation time for 400 steps: 7.974523305892944 	 Other agent action time: 0 	 50.159738037809916 steps/s
Curr learning rate 0.001196 	 Curr reward per step 0.22528066666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.08it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.99it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.64it/s]
-------------------------------------
| approxkl           | 0.0055016195 |
| clipfrac           | 0.37135413   |
| eplenmean          | 400          |
| eprewmean          | 88.8         |
| explained_variance | 0.595        |
| fps                | 1381         |
| nupdates           | 305          |
| policy_entropy     | 0.84440315   |
| policy_loss        | 0.0017388343 |
| serial_timesteps   | 122000       |
| time_elapsed       | 2.77e+03     |
| time_remaining     | 67.4         |
| total_timesteps    | 3660000      |
| true_eprew         | 81.8         |
| value_loss         | 18.490675    |
-------------------------------------
Current reward shaping 0.08499999999999996
SP envs: 0/30
Other agent actions took 4.754938840866089 seconds
Total simulation time for 400 steps: 8.09249234199524 	 Other agent action time: 0 	 49.42852993808064 steps/s
Curr learning rate 0.0011949999999999999 	 Curr reward per step 0.2306308333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.31it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.12it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.43it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.60it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.42it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.61it/s]
-------------------------------------
| approxkl           | 0.0041809143 |
| clipfrac           | 0.33057293   |
| eplenmean          | 400          |
| eprewmean          | 89.9         |
| explained_variance | 0.555        |
| fps                | 1365         |
| nupdates           | 306          |
| policy_entropy     | 0.8266976    |
| policy_loss        | 0.0030264608 |
| serial_timesteps   | 122400       |
| time_elapsed       | 2.78e+03     |
| time_remaining     | 67.2         |
| total_timesteps    | 3672000      |
| true_eprew         | 83           |
| value_loss         | 21.856619    |
-------------------------------------
Current reward shaping 0.08199999999999996
SP envs: 0/30
Other agent actions took 4.709712505340576 seconds
Total simulation time for 400 steps: 8.049043893814087 	 Other agent action time: 0 	 49.69534335716706 steps/s
Curr learning rate 0.0011940000000000002 	 Curr reward per step 0.20865366666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.42it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.12it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.00it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 165.82it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.39it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 165.04it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 168.96it/s]
------------------------------------
| approxkl           | 0.004389555 |
| clipfrac           | 0.34234375  |
| eplenmean          | 400         |
| eprewmean          | 89.3        |
| explained_variance | 0.513       |
| fps                | 1367        |
| nupdates           | 307         |
| policy_entropy     | 0.8494901   |
| policy_loss        | 0.003224219 |
| serial_timesteps   | 122800      |
| time_elapsed       | 2.79e+03    |
| time_remaining     | 67.1        |
| total_timesteps    | 3684000     |
| true_eprew         | 82.6        |
| value_loss         | 24.77516    |
------------------------------------
Current reward shaping 0.07899999999999996
SP envs: 0/30
Other agent actions took 4.614017724990845 seconds
Total simulation time for 400 steps: 7.903676509857178 	 Other agent action time: 0 	 50.60935875869092 steps/s
Curr learning rate 0.001193 	 Curr reward per step 0.21340916666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.29it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.38it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.20it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.05it/s]
-------------------------------------
| approxkl           | 0.0042875307 |
| clipfrac           | 0.34130213   |
| eplenmean          | 400          |
| eprewmean          | 88.1         |
| explained_variance | 0.625        |
| fps                | 1393         |
| nupdates           | 308          |
| policy_entropy     | 0.8386244    |
| policy_loss        | 0.001795085  |
| serial_timesteps   | 123200       |
| time_elapsed       | 2.8e+03      |
| time_remaining     | 66.9         |
| total_timesteps    | 3696000      |
| true_eprew         | 81.6         |
| value_loss         | 20.189545    |
-------------------------------------
Current reward shaping 0.07599999999999996
SP envs: 0/30
Other agent actions took 4.673587322235107 seconds
Total simulation time for 400 steps: 7.89178729057312 	 Other agent action time: 0 	 50.68560330785994 steps/s
Curr learning rate 0.001192 	 Curr reward per step 0.21114466666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.16it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.55it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.40it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.66it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.04it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.86it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.16it/s]
-------------------------------------
| approxkl           | 0.005412844  |
| clipfrac           | 0.3626979    |
| eplenmean          | 400          |
| eprewmean          | 85.5         |
| explained_variance | 0.496        |
| fps                | 1396         |
| nupdates           | 309          |
| policy_entropy     | 0.82322043   |
| policy_loss        | 0.0034426977 |
| serial_timesteps   | 123600       |
| time_elapsed       | 2.81e+03     |
| time_remaining     | 66.7         |
| total_timesteps    | 3708000      |
| true_eprew         | 79.4         |
| value_loss         | 23.86661     |
-------------------------------------
Current reward shaping 0.07299999999999995
SP envs: 0/30
Other agent actions took 4.699253559112549 seconds
Total simulation time for 400 steps: 7.9200439453125 	 Other agent action time: 0 	 50.50477027172824 steps/s
Curr learning rate 0.0011910000000000002 	 Curr reward per step 0.2035171666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 183.28it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 189.22it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 205.96it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 217.52it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 214.64it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 195.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 202.71it/s]
-------------------------------------
| approxkl           | 0.0048491117 |
| clipfrac           | 0.37982282   |
| eplenmean          | 400          |
| eprewmean          | 85.1         |
| explained_variance | 0.556        |
| fps                | 1404         |
| nupdates           | 310          |
| policy_entropy     | 0.8780165    |
| policy_loss        | 0.002450763  |
| serial_timesteps   | 124000       |
| time_elapsed       | 2.81e+03     |
| time_remaining     | 66.6         |
| total_timesteps    | 3720000      |
| true_eprew         | 79.2         |
| value_loss         | 22.363562    |
-------------------------------------
Current reward shaping 0.06999999999999995
SP envs: 0/30
Other agent actions took 4.607435464859009 seconds
Total simulation time for 400 steps: 7.865182638168335 	 Other agent action time: 0 	 50.85705169246433 steps/s
Curr learning rate 0.00119 	 Curr reward per step 0.21708833333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.97it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.41it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.26it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 168.66it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.22it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.08it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.54it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.95it/s]
-------------------------------------
| approxkl           | 0.0042777406 |
| clipfrac           | 0.33010423   |
| eplenmean          | 400          |
| eprewmean          | 84.2         |
| explained_variance | 0.539        |
| fps                | 1396         |
| nupdates           | 311          |
| policy_entropy     | 0.80776536   |
| policy_loss        | 0.0016359506 |
| serial_timesteps   | 124400       |
| time_elapsed       | 2.82e+03     |
| time_remaining     | 66.4         |
| total_timesteps    | 3732000      |
| true_eprew         | 78.6         |
| value_loss         | 22.134901    |
-------------------------------------
Current reward shaping 0.06699999999999995
SP envs: 0/30
Other agent actions took 4.726829767227173 seconds
Total simulation time for 400 steps: 8.029411315917969 	 Other agent action time: 0 	 49.81685260126317 steps/s
Curr learning rate 0.001189 	 Curr reward per step 0.23180033333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.40it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.93it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.97it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.91it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.92it/s]
------------------------------------
| approxkl           | 0.005269574 |
| clipfrac           | 0.35604176  |
| eplenmean          | 400         |
| eprewmean          | 87.5        |
| explained_variance | 0.647       |
| fps                | 1374        |
| nupdates           | 312         |
| policy_entropy     | 0.798071    |
| policy_loss        | 0.003655098 |
| serial_timesteps   | 124800      |
| time_elapsed       | 2.83e+03    |
| time_remaining     | 66.2        |
| total_timesteps    | 3744000     |
| true_eprew         | 82          |
| value_loss         | 17.904058   |
------------------------------------
Current reward shaping 0.06399999999999995
SP envs: 0/30





AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 










AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 










AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 










AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 










AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 










AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 










AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 










AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 








AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT 







AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 





INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT 







AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 





INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT 







AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 





INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT 







AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 





INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 





Other agent actions took 4.687846899032593 seconds
Total simulation time for 400 steps: 7.954660654067993 	 Other agent action time: 0 	 50.284986047197506 steps/s
Curr learning rate 0.001188 	 Curr reward per step 0.21950399999999995

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.29it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.47it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.77it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.60it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.18it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.51it/s]
------------------------------------
| approxkl           | 0.005248764 |
| clipfrac           | 0.35092703  |
| eplenmean          | 400         |
| eprewmean          | 88.1        |
| explained_variance | 0.575       |
| fps                | 1382        |
| nupdates           | 313         |
| policy_entropy     | 0.7956208   |
| policy_loss        | 0.004265592 |
| serial_timesteps   | 125200      |
| time_elapsed       | 2.84e+03    |
| time_remaining     | 66.1        |
| total_timesteps    | 3756000     |
| true_eprew         | 82.8        |
| value_loss         | 22.00752    |
------------------------------------
Current reward shaping 0.061000000000000054
SP envs: 0/30
Other agent actions took 4.729116916656494 seconds
Total simulation time for 400 steps: 7.813745737075806 	 Other agent action time: 0 	 51.191837239087704 steps/s
Curr learning rate 0.0011870000000000001 	 Curr reward per step 0.21168149999999994

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 182.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.33it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.35it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.96it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.62it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.63it/s]
-------------------------------------
| approxkl           | 0.0043751174 |
| clipfrac           | 0.33847913   |
| eplenmean          | 400          |
| eprewmean          | 88.7         |
| explained_variance | 0.589        |
| fps                | 1413         |
| nupdates           | 314          |
| policy_entropy     | 0.81088233   |
| policy_loss        | 0.0021989772 |
| serial_timesteps   | 125600       |
| time_elapsed       | 2.85e+03     |
| time_remaining     | 65.9         |
| total_timesteps    | 3768000      |
| true_eprew         | 83.6         |
| value_loss         | 21.353321    |
-------------------------------------
Current reward shaping 0.05800000000000005
SP envs: 0/30
Other agent actions took 4.701023817062378 seconds
Total simulation time for 400 steps: 7.955115079879761 	 Other agent action time: 0 	 50.28211358144751 steps/s
Curr learning rate 0.001186 	 Curr reward per step 0.20590399999999998

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 184.42it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 183.41it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.00it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.76it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.92it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.90it/s]
-------------------------------------
| approxkl           | 0.0052898554 |
| clipfrac           | 0.3527604    |
| eplenmean          | 400          |
| eprewmean          | 86.2         |
| explained_variance | 0.517        |
| fps                | 1392         |
| nupdates           | 315          |
| policy_entropy     | 0.7978903    |
| policy_loss        | 0.0032237647 |
| serial_timesteps   | 126000       |
| time_elapsed       | 2.86e+03     |
| time_remaining     | 65.8         |
| total_timesteps    | 3780000      |
| true_eprew         | 81.4         |
| value_loss         | 24.455639    |
-------------------------------------
Current reward shaping 0.05500000000000005
SP envs: 0/30
Other agent actions took 4.6058032512664795 seconds
Total simulation time for 400 steps: 7.845139265060425 	 Other agent action time: 0 	 50.98698525104119 steps/s
Curr learning rate 0.001185 	 Curr reward per step 0.22120166666666666

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.60it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.89it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.46it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.59it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 195.76it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.80it/s]
-------------------------------------
| approxkl           | 0.005150082  |
| clipfrac           | 0.3476145    |
| eplenmean          | 400          |
| eprewmean          | 85.4         |
| explained_variance | 0.516        |
| fps                | 1411         |
| nupdates           | 316          |
| policy_entropy     | 0.77323276   |
| policy_loss        | 0.0038695547 |
| serial_timesteps   | 126400       |
| time_elapsed       | 2.87e+03     |
| time_remaining     | 65.6         |
| total_timesteps    | 3792000      |
| true_eprew         | 80.8         |
| value_loss         | 24.226706    |
-------------------------------------
Current reward shaping 0.052000000000000046
SP envs: 0/30
Other agent actions took 4.572988033294678 seconds
Total simulation time for 400 steps: 7.771433115005493 	 Other agent action time: 0 	 51.47055814295807 steps/s
Curr learning rate 0.0011840000000000002 	 Curr reward per step 0.2221403333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.87it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.39it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.38it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.41it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.67it/s]
-------------------------------------
| approxkl           | 0.004656312  |
| clipfrac           | 0.34047917   |
| eplenmean          | 400          |
| eprewmean          | 85.3         |
| explained_variance | 0.567        |
| fps                | 1415         |
| nupdates           | 317          |
| policy_entropy     | 0.78111225   |
| policy_loss        | 0.0034254203 |
| serial_timesteps   | 126800       |
| time_elapsed       | 2.87e+03     |
| time_remaining     | 65.4         |
| total_timesteps    | 3804000      |
| true_eprew         | 81           |
| value_loss         | 22.016008    |
-------------------------------------
Current reward shaping 0.049000000000000044
SP envs: 0/30
Other agent actions took 4.657930850982666 seconds
Total simulation time for 400 steps: 7.867738723754883 	 Other agent action time: 0 	 50.84052915894235 steps/s
Curr learning rate 0.001183 	 Curr reward per step 0.22343958333333336

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.45it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.16it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.95it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.53it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.56it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.86it/s]
-------------------------------------
| approxkl           | 0.0045760837 |
| clipfrac           | 0.31766665   |
| eplenmean          | 400          |
| eprewmean          | 88.9         |
| explained_variance | 0.567        |
| fps                | 1399         |
| nupdates           | 318          |
| policy_entropy     | 0.78288066   |
| policy_loss        | 0.0024831565 |
| serial_timesteps   | 127200       |
| time_elapsed       | 2.88e+03     |
| time_remaining     | 65.3         |
| total_timesteps    | 3816000      |
| true_eprew         | 84.6         |
| value_loss         | 22.566286    |
-------------------------------------
Current reward shaping 0.04600000000000004
SP envs: 0/30
Other agent actions took 4.562337875366211 seconds
Total simulation time for 400 steps: 7.839041709899902 	 Other agent action time: 0 	 51.02664519501678 steps/s
Curr learning rate 0.001182 	 Curr reward per step 0.21239533333333338

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.04it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.52it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.97it/s]
--------------------------------------
| approxkl           | 0.0039114677  |
| clipfrac           | 0.3320417     |
| eplenmean          | 400           |
| eprewmean          | 87            |
| explained_variance | 0.563         |
| fps                | 1407          |
| nupdates           | 319           |
| policy_entropy     | 0.8047632     |
| policy_loss        | 0.00073199923 |
| serial_timesteps   | 127600        |
| time_elapsed       | 2.89e+03      |
| time_remaining     | 65.1          |
| total_timesteps    | 3828000       |
| true_eprew         | 83            |
| value_loss         | 22.906826     |
--------------------------------------
Current reward shaping 0.04300000000000004
SP envs: 0/30
Other agent actions took 4.583114147186279 seconds
Total simulation time for 400 steps: 7.789577960968018 	 Other agent action time: 0 	 51.3506639261226 steps/s
Curr learning rate 0.001181 	 Curr reward per step 0.20321658333333337

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.80it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.95it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.57it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.90it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.95it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.66it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.99it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.36it/s]
-------------------------------------
| approxkl           | 0.0057018497 |
| clipfrac           | 0.3618437    |
| eplenmean          | 400          |
| eprewmean          | 84.3         |
| explained_variance | 0.575        |
| fps                | 1416         |
| nupdates           | 320          |
| policy_entropy     | 0.81561494   |
| policy_loss        | 0.0034672103 |
| serial_timesteps   | 128000       |
| time_elapsed       | 2.9e+03      |
| time_remaining     | 64.9         |
| total_timesteps    | 3840000      |
| true_eprew         | 80.6         |
| value_loss         | 21.751705    |
-------------------------------------
Current reward shaping 0.040000000000000036
SP envs: 0/30
Other agent actions took 4.6070556640625 seconds
Total simulation time for 400 steps: 7.986723899841309 	 Other agent action time: 0 	 50.08311355397521 steps/s
Curr learning rate 0.00118 	 Curr reward per step 0.21624666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.74it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.45it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.16it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.23it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.53it/s]
-------------------------------------
| approxkl           | 0.0059926757 |
| clipfrac           | 0.35960418   |
| eplenmean          | 400          |
| eprewmean          | 86.5         |
| explained_variance | 0.566        |
| fps                | 1380         |
| nupdates           | 321          |
| policy_entropy     | 0.7984854    |
| policy_loss        | 0.0038627072 |
| serial_timesteps   | 128400       |
| time_elapsed       | 2.91e+03     |
| time_remaining     | 64.8         |
| total_timesteps    | 3852000      |
| true_eprew         | 83           |
| value_loss         | 20.544416    |
-------------------------------------
Current reward shaping 0.03700000000000003
SP envs: 0/30
Other agent actions took 4.626945734024048 seconds
Total simulation time for 400 steps: 7.908009767532349 	 Other agent action time: 0 	 50.5816269527469 steps/s
Curr learning rate 0.0011790000000000001 	 Curr reward per step 0.2292054166666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 191.33it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 194.41it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.20it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.96it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.48it/s]
-------------------------------------
| approxkl           | 0.0033236044 |
| clipfrac           | 0.31322917   |
| eplenmean          | 400          |
| eprewmean          | 87           |
| explained_variance | 0.629        |
| fps                | 1397         |
| nupdates           | 322          |
| policy_entropy     | 0.83808583   |
| policy_loss        | 0.0010475038 |
| serial_timesteps   | 128800       |
| time_elapsed       | 2.92e+03     |
| time_remaining     | 64.6         |
| total_timesteps    | 3864000      |
| true_eprew         | 83.8         |
| value_loss         | 17.676798    |
-------------------------------------
Current reward shaping 0.03400000000000003
SP envs: 0/30
Other agent actions took 4.596968412399292 seconds
Total simulation time for 400 steps: 7.919604539871216 	 Other agent action time: 0 	 50.507572440795705 steps/s
Curr learning rate 0.001178 	 Curr reward per step 0.19975933333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.97it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.37it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.30it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.37it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.29it/s]
------------------------------------
| approxkl           | 0.005298299 |
| clipfrac           | 0.37055203  |
| eplenmean          | 400         |
| eprewmean          | 86.2        |
| explained_variance | 0.627       |
| fps                | 1391        |
| nupdates           | 323         |
| policy_entropy     | 0.8630101   |
| policy_loss        | 0.003317264 |
| serial_timesteps   | 129200      |
| time_elapsed       | 2.93e+03    |
| time_remaining     | 64.5        |
| total_timesteps    | 3876000     |
| true_eprew         | 83.2        |
| value_loss         | 20.784845   |
------------------------------------
Current reward shaping 0.031000000000000028
SP envs: 0/30
Other agent actions took 4.594346046447754 seconds
Total simulation time for 400 steps: 7.789276361465454 	 Other agent action time: 0 	 51.35265221540362 steps/s
Curr learning rate 0.001177 	 Curr reward per step 0.21119225000000003

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 187.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 192.62it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.78it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.42it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.47it/s]
-------------------------------------
| approxkl           | 0.0043839864 |
| clipfrac           | 0.34741676   |
| eplenmean          | 400          |
| eprewmean          | 86           |
| explained_variance | 0.566        |
| fps                | 1421         |
| nupdates           | 324          |
| policy_entropy     | 0.84360486   |
| policy_loss        | 0.0048404164 |
| serial_timesteps   | 129600       |
| time_elapsed       | 2.93e+03     |
| time_remaining     | 64.3         |
| total_timesteps    | 3888000      |
| true_eprew         | 83.2         |
| value_loss         | 21.744392    |
-------------------------------------
Current reward shaping 0.028000000000000025
SP envs: 0/30
Other agent actions took 4.565998792648315 seconds
Total simulation time for 400 steps: 7.835299730300903 	 Other agent action time: 0 	 51.05101448169342 steps/s
Curr learning rate 0.001176 	 Curr reward per step 0.18663900000000005

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.61it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.57it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.25it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.57it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.19it/s]
-------------------------------------
| approxkl           | 0.0074696164 |
| clipfrac           | 0.40154162   |
| eplenmean          | 400          |
| eprewmean          | 80.8         |
| explained_variance | 0.552        |
| fps                | 1407         |
| nupdates           | 325          |
| policy_entropy     | 0.8599311    |
| policy_loss        | 0.0053373864 |
| serial_timesteps   | 130000       |
| time_elapsed       | 2.94e+03     |
| time_remaining     | 64.1         |
| total_timesteps    | 3900000      |
| true_eprew         | 78.4         |
| value_loss         | 21.695404    |
-------------------------------------
Current reward shaping 0.025000000000000022
SP envs: 0/30
Other agent actions took 4.68749737739563 seconds
Total simulation time for 400 steps: 7.978147983551025 	 Other agent action time: 0 	 50.13694917977222 steps/s
Curr learning rate 0.001175 	 Curr reward per step 0.19969583333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.42it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.34it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.44it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.45it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.07it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.34it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.84it/s]
-------------------------------------
| approxkl           | 0.005747074  |
| clipfrac           | 0.36794797   |
| eplenmean          | 400          |
| eprewmean          | 78.9         |
| explained_variance | 0.515        |
| fps                | 1382         |
| nupdates           | 326          |
| policy_entropy     | 0.82312894   |
| policy_loss        | 0.0042864266 |
| serial_timesteps   | 130400       |
| time_elapsed       | 2.95e+03     |
| time_remaining     | 64           |
| total_timesteps    | 3912000      |
| true_eprew         | 76.8         |
| value_loss         | 22.77045     |
-------------------------------------
Current reward shaping 0.02200000000000002
SP envs: 0/30
Other agent actions took 4.589224576950073 seconds
Total simulation time for 400 steps: 7.816357135772705 	 Other agent action time: 0 	 51.17473434898993 steps/s
Curr learning rate 0.0011740000000000001 	 Curr reward per step 0.2179020000000001

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.74it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.72it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.21it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.76it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.91it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.33it/s]
-------------------------------------
| approxkl           | 0.0040476383 |
| clipfrac           | 0.32164583   |
| eplenmean          | 400          |
| eprewmean          | 81.4         |
| explained_variance | 0.591        |
| fps                | 1415         |
| nupdates           | 327          |
| policy_entropy     | 0.7790728    |
| policy_loss        | 0.0021923075 |
| serial_timesteps   | 130800       |
| time_elapsed       | 2.96e+03     |
| time_remaining     | 63.8         |
| total_timesteps    | 3924000      |
| true_eprew         | 79.4         |
| value_loss         | 21.291204    |
-------------------------------------
Current reward shaping 0.019000000000000017
SP envs: 0/30
Other agent actions took 4.656169176101685 seconds
Total simulation time for 400 steps: 7.905006170272827 	 Other agent action time: 0 	 50.60084601884564 steps/s
Curr learning rate 0.001173 	 Curr reward per step 0.20030516666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.35it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 183.85it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.26it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.65it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.35it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.57it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.67it/s]
-------------------------------------
| approxkl           | 0.0034530945 |
| clipfrac           | 0.31291664   |
| eplenmean          | 400          |
| eprewmean          | 81.8         |
| explained_variance | 0.582        |
| fps                | 1399         |
| nupdates           | 328          |
| policy_entropy     | 0.83187497   |
| policy_loss        | 0.0018100215 |
| serial_timesteps   | 131200       |
| time_elapsed       | 2.97e+03     |
| time_remaining     | 63.7         |
| total_timesteps    | 3936000      |
| true_eprew         | 80           |
| value_loss         | 21.507536    |
-------------------------------------
Current reward shaping 0.016000000000000014
SP envs: 0/30
Other agent actions took 4.605591297149658 seconds
Total simulation time for 400 steps: 7.911233186721802 	 Other agent action time: 0 	 50.5610175505077 steps/s
Curr learning rate 0.001172 	 Curr reward per step 0.19976400000000002

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.98it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.24it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.64it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.19it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 167.70it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.38it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.07it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.22it/s]
-------------------------------------
| approxkl           | 0.0048017493 |
| clipfrac           | 0.34118754   |
| eplenmean          | 400          |
| eprewmean          | 80.9         |
| explained_variance | 0.593        |
| fps                | 1391         |
| nupdates           | 329          |
| policy_entropy     | 0.827657     |
| policy_loss        | 0.003361364  |
| serial_timesteps   | 131600       |
| time_elapsed       | 2.98e+03     |
| time_remaining     | 63.5         |
| total_timesteps    | 3948000      |
| true_eprew         | 79.4         |
| value_loss         | 20.867603    |
-------------------------------------
Current reward shaping 0.013000000000000012
SP envs: 0/30
Other agent actions took 4.654635667800903 seconds
Total simulation time for 400 steps: 7.87397313117981 	 Other agent action time: 0 	 50.800274948368454 steps/s
Curr learning rate 0.0011710000000000002 	 Curr reward per step 0.19910633333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.75it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.47it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.59it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.46it/s]
------------------------------------
| approxkl           | 0.005225944 |
| clipfrac           | 0.35959378  |
| eplenmean          | 400         |
| eprewmean          | 80.7        |
| explained_variance | 0.584       |
| fps                | 1396        |
| nupdates           | 330         |
| policy_entropy     | 0.8612076   |
| policy_loss        | 0.004654735 |
| serial_timesteps   | 132000      |
| time_elapsed       | 2.99e+03    |
| time_remaining     | 63.3        |
| total_timesteps    | 3960000     |
| true_eprew         | 79.4        |
| value_loss         | 19.876268   |
------------------------------------
Current reward shaping 0.010000000000000009
SP envs: 0/30
Other agent actions took 4.742298126220703 seconds
Total simulation time for 400 steps: 8.067976951599121 	 Other agent action time: 0 	 49.578723687444054 steps/s
Curr learning rate 0.00117 	 Curr reward per step 0.18004083333333334

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.11it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.70it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.47it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.05it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.13it/s]
------------------------------------
| approxkl           | 0.004734401 |
| clipfrac           | 0.3404167   |
| eplenmean          | 400         |
| eprewmean          | 77.4        |
| explained_variance | 0.616       |
| fps                | 1373        |
| nupdates           | 331         |
| policy_entropy     | 0.83285207  |
| policy_loss        | 0.002470205 |
| serial_timesteps   | 132400      |
| time_elapsed       | 2.99e+03    |
| time_remaining     | 63.2        |
| total_timesteps    | 3972000     |
| true_eprew         | 76.4        |
| value_loss         | 19.069653   |
------------------------------------
Current reward shaping 0.007000000000000006
SP envs: 0/30
Other agent actions took 4.61476469039917 seconds
Total simulation time for 400 steps: 7.90478515625 	 Other agent action time: 0 	 50.60226079436654 steps/s
Curr learning rate 0.001169 	 Curr reward per step 0.18796224999999997

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 188.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 189.79it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.14it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.19it/s]
-------------------------------------
| approxkl           | 0.0054165474 |
| clipfrac           | 0.3612604    |
| eplenmean          | 400          |
| eprewmean          | 76.2         |
| explained_variance | 0.528        |
| fps                | 1398         |
| nupdates           | 332          |
| policy_entropy     | 0.8282278    |
| policy_loss        | 0.004002986  |
| serial_timesteps   | 132800       |
| time_elapsed       | 3e+03        |
| time_remaining     | 63           |
| total_timesteps    | 3984000      |
| true_eprew         | 75.4         |
| value_loss         | 22.195007    |
-------------------------------------
Current reward shaping 0.0040000000000000036
SP envs: 0/30
Other agent actions took 4.645124435424805 seconds
Total simulation time for 400 steps: 7.878589391708374 	 Other agent action time: 0 	 50.77050980991218 steps/s
Curr learning rate 0.001168 	 Curr reward per step 0.18907199999999996

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.42it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.22it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.94it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.08it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.28it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.20it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 162.70it/s]
-------------------------------------
| approxkl           | 0.005881298  |
| clipfrac           | 0.37705216   |
| eplenmean          | 400          |
| eprewmean          | 74.5         |
| explained_variance | 0.568        |
| fps                | 1394         |
| nupdates           | 333          |
| policy_entropy     | 0.82702094   |
| policy_loss        | 0.0038287158 |
| serial_timesteps   | 133200       |
| time_elapsed       | 3.01e+03     |
| time_remaining     | 62.9         |
| total_timesteps    | 3996000      |
| true_eprew         | 74           |
| value_loss         | 21.59853     |
-------------------------------------
Current reward shaping 0.0010000000000000009
SP envs: 0/30
Other agent actions took 4.6515889167785645 seconds
Total simulation time for 400 steps: 7.946672439575195 	 Other agent action time: 0 	 50.33553390321733 steps/s
Curr learning rate 0.001167 	 Curr reward per step 0.18851916666666665

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.50it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.03it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.00it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.97it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.54it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.07it/s]
-------------------------------------
| approxkl           | 0.0047572856 |
| clipfrac           | 0.3479896    |
| eplenmean          | 400          |
| eprewmean          | 75.7         |
| explained_variance | 0.564        |
| fps                | 1383         |
| nupdates           | 334          |
| policy_entropy     | 0.826799     |
| policy_loss        | 0.0023751387 |
| serial_timesteps   | 133600       |
| time_elapsed       | 3.02e+03     |
| time_remaining     | 62.7         |
| total_timesteps    | 4008000      |
| true_eprew         | 75.4         |
| value_loss         | 21.461342    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.717034101486206 seconds
Total simulation time for 400 steps: 8.032953977584839 	 Other agent action time: 0 	 49.79488256949564 steps/s
Curr learning rate 0.001166 	 Curr reward per step 0.17666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 184.12it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 188.02it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.11it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 196.30it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 198.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.11it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.06it/s]
-------------------------------------
| approxkl           | 0.0044162613 |
| clipfrac           | 0.33268753   |
| eplenmean          | 400          |
| eprewmean          | 74.4         |
| explained_variance | 0.54         |
| fps                | 1382         |
| nupdates           | 335          |
| policy_entropy     | 0.8136394    |
| policy_loss        | 0.0027840617 |
| serial_timesteps   | 134000       |
| time_elapsed       | 3.03e+03     |
| time_remaining     | 62.5         |
| total_timesteps    | 4020000      |
| true_eprew         | 74.2         |
| value_loss         | 23.017025    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.616689443588257 seconds
Total simulation time for 400 steps: 7.8108251094818115 	 Other agent action time: 0 	 51.210978916225784 steps/s
Curr learning rate 0.001165 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.72it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.90it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.72it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.77it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.09it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.09it/s]
-------------------------------------
| approxkl           | 0.0049261055 |
| clipfrac           | 0.35038546   |
| eplenmean          | 400          |
| eprewmean          | 74.9         |
| explained_variance | 0.623        |
| fps                | 1411         |
| nupdates           | 336          |
| policy_entropy     | 0.7983558    |
| policy_loss        | 0.0021390528 |
| serial_timesteps   | 134400       |
| time_elapsed       | 3.04e+03     |
| time_remaining     | 62.4         |
| total_timesteps    | 4032000      |
| true_eprew         | 74.8         |
| value_loss         | 17.409105    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.590657472610474 seconds
Total simulation time for 400 steps: 7.852886438369751 	 Other agent action time: 0 	 50.93668463681992 steps/s
Curr learning rate 0.001164 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.98it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.16it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.84it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.83it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.30it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.56it/s]
-------------------------------------
| approxkl           | 0.0046354397 |
| clipfrac           | 0.33351037   |
| eplenmean          | 400          |
| eprewmean          | 76.4         |
| explained_variance | 0.564        |
| fps                | 1404         |
| nupdates           | 337          |
| policy_entropy     | 0.7625431    |
| policy_loss        | 0.0004908942 |
| serial_timesteps   | 134800       |
| time_elapsed       | 3.05e+03     |
| time_remaining     | 62.2         |
| total_timesteps    | 4044000      |
| true_eprew         | 76.4         |
| value_loss         | 21.297237    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.6263909339904785 seconds
Total simulation time for 400 steps: 7.86974835395813 	 Other agent action time: 0 	 50.8275464486508 steps/s
Curr learning rate 0.001163 	 Curr reward per step 0.175

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 191.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 191.77it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 194.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.76it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 173.87it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.81it/s]
------------------------------------
| approxkl           | 0.005704606 |
| clipfrac           | 0.3633646   |
| eplenmean          | 400         |
| eprewmean          | 74.8        |
| explained_variance | 0.552       |
| fps                | 1406        |
| nupdates           | 338         |
| policy_entropy     | 0.8359639   |
| policy_loss        | 0.004966987 |
| serial_timesteps   | 135200      |
| time_elapsed       | 3.05e+03    |
| time_remaining     | 62.1        |
| total_timesteps    | 4056000     |
| true_eprew         | 74.8        |
| value_loss         | 19.713068   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.635958909988403 seconds
Total simulation time for 400 steps: 7.896611928939819 	 Other agent action time: 0 	 50.654635633551145 steps/s
Curr learning rate 0.001162 	 Curr reward per step 0.17666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.13it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.85it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.07it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.99it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.05it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.62it/s]
-------------------------------------
| approxkl           | 0.0050699725 |
| clipfrac           | 0.36645836   |
| eplenmean          | 400          |
| eprewmean          | 74           |
| explained_variance | 0.619        |
| fps                | 1399         |
| nupdates           | 339          |
| policy_entropy     | 0.83410627   |
| policy_loss        | 0.003025648  |
| serial_timesteps   | 135600       |
| time_elapsed       | 3.06e+03     |
| time_remaining     | 61.9         |
| total_timesteps    | 4068000      |
| true_eprew         | 74           |
| value_loss         | 17.892443    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.66535496711731 seconds
Total simulation time for 400 steps: 7.921977519989014 	 Other agent action time: 0 	 50.49244320508432 steps/s
Curr learning rate 0.0011610000000000001 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.17it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.44it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.49it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.16it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.24it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.61it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 169.44it/s]
-------------------------------------
| approxkl           | 0.004213588  |
| clipfrac           | 0.32372916   |
| eplenmean          | 400          |
| eprewmean          | 74.4         |
| explained_variance | 0.642        |
| fps                | 1392         |
| nupdates           | 340          |
| policy_entropy     | 0.77768356   |
| policy_loss        | 0.0012148604 |
| serial_timesteps   | 136000       |
| time_elapsed       | 3.07e+03     |
| time_remaining     | 61.7         |
| total_timesteps    | 4080000      |
| true_eprew         | 74.4         |
| value_loss         | 17.087017    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.625481843948364 seconds
Total simulation time for 400 steps: 7.90481972694397 	 Other agent action time: 0 	 50.60203949200513 steps/s
Curr learning rate 0.00116 	 Curr reward per step 0.17666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.48it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.18it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 168.53it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.72it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 169.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.15it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 172.49it/s]
-------------------------------------
| approxkl           | 0.0049731005 |
| clipfrac           | 0.3558542    |
| eplenmean          | 400          |
| eprewmean          | 72.6         |
| explained_variance | 0.584        |
| fps                | 1389         |
| nupdates           | 341          |
| policy_entropy     | 0.8077504    |
| policy_loss        | 0.0038349691 |
| serial_timesteps   | 136400       |
| time_elapsed       | 3.08e+03     |
| time_remaining     | 61.6         |
| total_timesteps    | 4092000      |
| true_eprew         | 72.6         |
| value_loss         | 20.372616    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.66554856300354 seconds
Total simulation time for 400 steps: 7.849367380142212 	 Other agent action time: 0 	 50.95952076494003 steps/s
Curr learning rate 0.001159 	 Curr reward per step 0.1733333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 184.74it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.68it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.80it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.07it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.63it/s]
-------------------------------------
| approxkl           | 0.0051145703 |
| clipfrac           | 0.3560208    |
| eplenmean          | 400          |
| eprewmean          | 73           |
| explained_variance | 0.623        |
| fps                | 1411         |
| nupdates           | 342          |
| policy_entropy     | 0.8316211    |
| policy_loss        | 0.003082362  |
| serial_timesteps   | 136800       |
| time_elapsed       | 3.09e+03     |
| time_remaining     | 61.4         |
| total_timesteps    | 4104000      |
| true_eprew         | 73           |
| value_loss         | 17.892626    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.599673509597778 seconds
Total simulation time for 400 steps: 7.8461034297943115 	 Other agent action time: 0 	 50.9807197393122 steps/s
Curr learning rate 0.0011580000000000002 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.27it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.77it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.95it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.89it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.22it/s]
-------------------------------------
| approxkl           | 0.0049048834 |
| clipfrac           | 0.3552083    |
| eplenmean          | 400          |
| eprewmean          | 73           |
| explained_variance | 0.579        |
| fps                | 1404         |
| nupdates           | 343          |
| policy_entropy     | 0.8105459    |
| policy_loss        | 0.0022129458 |
| serial_timesteps   | 137200       |
| time_elapsed       | 3.1e+03      |
| time_remaining     | 61.3         |
| total_timesteps    | 4116000      |
| true_eprew         | 73           |
| value_loss         | 18.696087    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.569019317626953 seconds
Total simulation time for 400 steps: 7.775811433792114 	 Other agent action time: 0 	 51.4415766644855 steps/s
Curr learning rate 0.001157 	 Curr reward per step 0.22166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 179.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.39it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.92it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.97it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.19it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.04it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.17it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.02it/s]
--------------------------------------
| approxkl           | 0.0025967238  |
| clipfrac           | 0.26075       |
| eplenmean          | 400           |
| eprewmean          | 76.8          |
| explained_variance | 0.602         |
| fps                | 1417          |
| nupdates           | 344           |
| policy_entropy     | 0.74355775    |
| policy_loss        | 0.00041949117 |
| serial_timesteps   | 137600        |
| time_elapsed       | 3.11e+03      |
| time_remaining     | 61.1          |
| total_timesteps    | 4128000       |
| true_eprew         | 76.8          |
| value_loss         | 18.011192     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.583737850189209 seconds
Total simulation time for 400 steps: 7.805371999740601 	 Other agent action time: 0 	 51.246756722587136 steps/s
Curr learning rate 0.001156 	 Curr reward per step 0.19166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 179.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 185.31it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.38it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.90it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.45it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.33it/s]
-------------------------------------
| approxkl           | 0.005760992  |
| clipfrac           | 0.35542706   |
| eplenmean          | 400          |
| eprewmean          | 78.4         |
| explained_variance | 0.641        |
| fps                | 1415         |
| nupdates           | 345          |
| policy_entropy     | 0.7740376    |
| policy_loss        | 0.0017010088 |
| serial_timesteps   | 138000       |
| time_elapsed       | 3.11e+03     |
| time_remaining     | 60.9         |
| total_timesteps    | 4140000      |
| true_eprew         | 78.4         |
| value_loss         | 16.539268    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.739294767379761 seconds
Total simulation time for 400 steps: 8.010281562805176 	 Other agent action time: 0 	 49.935822712818755 steps/s
Curr learning rate 0.001155 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 188.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 193.35it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.11it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 195.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 198.89it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 197.59it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.48it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.33it/s]
-------------------------------------
| approxkl           | 0.0040152324 |
| clipfrac           | 0.31639585   |
| eplenmean          | 400          |
| eprewmean          | 83.4         |
| explained_variance | 0.605        |
| fps                | 1387         |
| nupdates           | 346          |
| policy_entropy     | 0.7805988    |
| policy_loss        | 0.0013784507 |
| serial_timesteps   | 138400       |
| time_elapsed       | 3.12e+03     |
| time_remaining     | 60.8         |
| total_timesteps    | 4152000      |
| true_eprew         | 83.4         |
| value_loss         | 17.859594    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.61899209022522 seconds
Total simulation time for 400 steps: 7.888553619384766 	 Other agent action time: 0 	 50.70638032009679 steps/s
Curr learning rate 0.001154 	 Curr reward per step 0.185

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 180.74it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.45it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.88it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.56it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.22it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.15it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.34it/s]
------------------------------------
| approxkl           | 0.004433964 |
| clipfrac           | 0.3347499   |
| eplenmean          | 400         |
| eprewmean          | 80.2        |
| explained_variance | 0.604       |
| fps                | 1401        |
| nupdates           | 347         |
| policy_entropy     | 0.8067364   |
| policy_loss        | 0.002337964 |
| serial_timesteps   | 138800      |
| time_elapsed       | 3.13e+03    |
| time_remaining     | 60.6        |
| total_timesteps    | 4164000     |
| true_eprew         | 80.2        |
| value_loss         | 17.385036   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.625823497772217 seconds
Total simulation time for 400 steps: 7.946400165557861 	 Other agent action time: 0 	 50.33725859084254 steps/s
Curr learning rate 0.001153 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 195.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 201.34it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 192.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.87it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.08it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 197.93it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 200.78it/s]
-------------------------------------
| approxkl           | 0.0042941095 |
| clipfrac           | 0.32878128   |
| eplenmean          | 400          |
| eprewmean          | 79.8         |
| explained_variance | 0.627        |
| fps                | 1398         |
| nupdates           | 348          |
| policy_entropy     | 0.79342854   |
| policy_loss        | 0.0019629693 |
| serial_timesteps   | 139200       |
| time_elapsed       | 3.14e+03     |
| time_remaining     | 60.5         |
| total_timesteps    | 4176000      |
| true_eprew         | 79.8         |
| value_loss         | 17.906805    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.695730447769165 seconds
Total simulation time for 400 steps: 7.959948778152466 	 Other agent action time: 0 	 50.25157964557173 steps/s
Curr learning rate 0.001152 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.66it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.49it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.84it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.56it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.45it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.30it/s]
-------------------------------------
| approxkl           | 0.0043172827 |
| clipfrac           | 0.3265208    |
| eplenmean          | 400          |
| eprewmean          | 78.6         |
| explained_variance | 0.582        |
| fps                | 1389         |
| nupdates           | 349          |
| policy_entropy     | 0.7991404    |
| policy_loss        | 0.0018512927 |
| serial_timesteps   | 139600       |
| time_elapsed       | 3.15e+03     |
| time_remaining     | 60.3         |
| total_timesteps    | 4188000      |
| true_eprew         | 78.6         |
| value_loss         | 19.050121    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.64879298210144 seconds
Total simulation time for 400 steps: 7.888231039047241 	 Other agent action time: 0 	 50.70845390049743 steps/s
Curr learning rate 0.0011510000000000001 	 Curr reward per step 0.195

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 181.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.97it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.59it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.91it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.68it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.56it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.67it/s]
-------------------------------------
| approxkl           | 0.0052294605 |
| clipfrac           | 0.35095844   |
| eplenmean          | 400          |
| eprewmean          | 79.6         |
| explained_variance | 0.62         |
| fps                | 1400         |
| nupdates           | 350          |
| policy_entropy     | 0.8157322    |
| policy_loss        | 0.0010581441 |
| serial_timesteps   | 140000       |
| time_elapsed       | 3.16e+03     |
| time_remaining     | 60.1         |
| total_timesteps    | 4200000      |
| true_eprew         | 79.6         |
| value_loss         | 17.876804    |
-------------------------------------
Current reward shaping 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 3 
X X X ø=X 
O   X ↑0P 
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X ↑0P 
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 21
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 22
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X   P 
O   X ↓0X 
D ←1X   X 
X X X S X 


Timestep: 23
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 3 
X X X ø=X 
O   X   P 
O   X ←0X 
D ←dX   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X   P 
O   X ←0X 
D ←dX   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X   P 
O   X ←0X 
D ←dX   X 
X X X S X 


Timestep: 26
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X   P 
O ↑dX ←0X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X ↑0P 
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ↑dX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X ←0P 
O ↓dX   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X ↑0P 
O ↓dX   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O   X ←0P 
O →dX   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ↑dX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ↑dX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ↑dX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →dX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xd←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1Xd←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX   P 
O   X ↓dX 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX   P 
O   X   X 
D   X ↓dX 
X X X S X 


Timestep: 42
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX   P 
O   X ↑dX 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo  P 
O   X ←dX 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo  P 
O   Xd←0X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1Xo  P 
O   Xd  X 
D   X ↓0X 
X X X S X 


Timestep: 46
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1Xo  P 
O   Xd↑0X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oXo  P 
O   Xd  X 
D   X ↓0X 
X X X S X 


Timestep: 48
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oXo  P 
O   Xd↑0X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oXo↑0P 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oXo↑0P 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oXo↑0P 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oXo  P 
O   Xd↓0X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oXo↑0P 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oXo↑0P 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oXo←0P 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø1X 
O →1Xo↑0P 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø2X 
O ←1Xo←0P 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø3X 
O ←oX ←oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø4X 
O ←oX ↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø5X 
O ←oX ↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø6X 
O →oX ↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø7X 
O →oX ↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø8X 
O →oX ↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø9X 
O →oX ↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø10X 
O →1Xo↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø11X 
O ←1Xo↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø12X 
O ←1Xo↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø13X 
O ←oXo↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø14X 
O ←oXo↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø15X 
O →oXo↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø16X 
O →oXo↑oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø17X 
O →oXo→oP 
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø18X 
O →oXo→0ø-
O   Xd  X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X ø19X 
O →oXo  ø-
O   Xd↓0X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓oXd↓0X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓oXd↓0X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O →oXd←0X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O →oX ←dX 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑dø-
O →oX   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 5 
X X X P X 
O   Xo↑sø-
O →oX   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø-
O →1Xo↓sX 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1Xo  ø-
O   Xo  X 
D   X ↓sX 
X X X S X 


Timestep: 85
Joint action taken: ('interact', '↑') 	 Reward: 20 + shape * 0 
X X X P X 
O ↑1Xo  ø-
O   Xo  X 
D   X ↓0X 
X X X S X 


Timestep: 86
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xo  ø-
O   Xo  X 
D   X ←0X 
X X X S X 


Timestep: 87
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xo  ø-
O   Xo  X 
D   X →0X 
X X X S X 


Timestep: 88
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xo  ø-
O   Xo  X 
D   X ←0X 
X X X S X 


Timestep: 89
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXo  ø-
O   Xo  X 
D   X ←0X 
X X X S X 


Timestep: 90
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXo  ø-
O   Xo↑0X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXo↑0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXo←0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←oø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oXo←0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←oø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXo←0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←oø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑oø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X ø-X 
O →oX ↑0ø-
O   Xo  X 
D   X   X 
X X X S X 


tot rew 120 tot rew shaped 96
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ↓0X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX →0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 16
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ↓oX ↓0X 
X X X S X 


Timestep: 17
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ↓1X ↓0X 
X XoX S X 


Timestep: 18
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←1X ←0X 
X XoX S X 


Timestep: 19
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X   X 
D   X ←0X 
X XoX S X 


Timestep: 20
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X   X 
D   X ←0X 
X XoX S X 


Timestep: 21
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →1X   X 
D   X ←0X 
X XoX S X 


Timestep: 22
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↑0X 
D   X   X 
X XoX S X 


Timestep: 23
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 24
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 25
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 26
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 27
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 28
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 29
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 30
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 31
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 32
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 33
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 34
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 35
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 36
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 37
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 38
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 39
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   X   X 
X XoX S X 


Timestep: 40
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   X   X 
X XoX S X 


Timestep: 41
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   X   X 
X XoX S X 


Timestep: 42
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X XoX S X 


Timestep: 43
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 44
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 45
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 46
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 47
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 48
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 49
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 50
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 51
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 52
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 53
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 54
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 55
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 56
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 57
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo  P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 58
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1Xo  P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 59
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1Xo  P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 60
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xo  P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 61
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xo  P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 62
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1Xo↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 63
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1Xo←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 64
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←oP 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 65
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑oP 
O ↓1X   X 
D   X   X 
X XoX S X 


Timestep: 66
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →oP 
O ↓1X   X 
D   X   X 
X XoX S X 


Timestep: 67
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 3 
X X X P X 
O ↑1X →0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 68
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 69
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 70
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 71
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 72
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 73
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 74
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 75
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   ø-
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 76
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   ø-
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 77
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   ø-
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 78
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   ø-
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 79
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   ø-
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 80
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   ø-
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 81
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   ø-
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 82
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   ø-
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 83
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   ø-
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 84
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 85
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 86
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 87
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 88
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 89
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 90
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 91
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 92
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 93
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 94
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 95
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 96
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 97
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 98
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0ø-
O   X   X 
D   X   X 
X XoX S X 


Timestep: 99
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0ø-
O   X   X 
D   X   X 
X XoX S X 


tot rew 0 tot rew shaped 18
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.669447660446167 seconds
Total simulation time for 400 steps: 7.9018189907073975 	 Other agent action time: 0 	 50.62125574762003 steps/s
Curr learning rate 0.00115 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.63it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.75it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.90it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.47it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.19it/s]
-------------------------------------
| approxkl           | 0.004215169  |
| clipfrac           | 0.32483336   |
| eplenmean          | 400          |
| eprewmean          | 80.4         |
| explained_variance | 0.583        |
| fps                | 1394         |
| nupdates           | 351          |
| policy_entropy     | 0.7965959    |
| policy_loss        | 0.0020597642 |
| serial_timesteps   | 140400       |
| time_elapsed       | 3.17e+03     |
| time_remaining     | 60           |
| total_timesteps    | 4212000      |
| true_eprew         | 80.4         |
| value_loss         | 18.349352    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.726088047027588 seconds
Total simulation time for 400 steps: 8.021465301513672 	 Other agent action time: 0 	 49.86620087037202 steps/s
Curr learning rate 0.001149 	 Curr reward per step 0.185

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.22it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.50it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.03it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.14it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.33it/s]
------------------------------------
| approxkl           | 0.005921659 |
| clipfrac           | 0.37281245  |
| eplenmean          | 400         |
| eprewmean          | 77.4        |
| explained_variance | 0.625       |
| fps                | 1374        |
| nupdates           | 352         |
| policy_entropy     | 0.8268515   |
| policy_loss        | 0.004694085 |
| serial_timesteps   | 140800      |
| time_elapsed       | 3.18e+03    |
| time_remaining     | 59.9        |
| total_timesteps    | 4224000     |
| true_eprew         | 77.4        |
| value_loss         | 17.371002   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.627532720565796 seconds
Total simulation time for 400 steps: 7.8475470542907715 	 Other agent action time: 0 	 50.97134139275962 steps/s
Curr learning rate 0.001148 	 Curr reward per step 0.18333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.36it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.71it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.03it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.19it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.80it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 169.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.77it/s]
-------------------------------------
| approxkl           | 0.004999597  |
| clipfrac           | 0.3627918    |
| eplenmean          | 400          |
| eprewmean          | 75.4         |
| explained_variance | 0.619        |
| fps                | 1400         |
| nupdates           | 353          |
| policy_entropy     | 0.8581162    |
| policy_loss        | 0.0014725447 |
| serial_timesteps   | 141200       |
| time_elapsed       | 3.19e+03     |
| time_remaining     | 59.7         |
| total_timesteps    | 4236000      |
| true_eprew         | 75.4         |
| value_loss         | 16.881575    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.604794025421143 seconds
Total simulation time for 400 steps: 7.844696044921875 	 Other agent action time: 0 	 50.98986598198829 steps/s
Curr learning rate 0.001147 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.54it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.54it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.03it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.42it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.80it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.06it/s]
-------------------------------------
| approxkl           | 0.0038929502 |
| clipfrac           | 0.33035415   |
| eplenmean          | 400          |
| eprewmean          | 75.6         |
| explained_variance | 0.54         |
| fps                | 1407         |
| nupdates           | 354          |
| policy_entropy     | 0.8293964    |
| policy_loss        | 0.0015405951 |
| serial_timesteps   | 141600       |
| time_elapsed       | 3.19e+03     |
| time_remaining     | 59.5         |
| total_timesteps    | 4248000      |
| true_eprew         | 75.6         |
| value_loss         | 19.252296    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.641696929931641 seconds
Total simulation time for 400 steps: 7.880253076553345 	 Other agent action time: 0 	 50.759791102413615 steps/s
Curr learning rate 0.001146 	 Curr reward per step 0.19

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.45it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.96it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.75it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.75it/s]
-------------------------------------
| approxkl           | 0.0054811775 |
| clipfrac           | 0.3759062    |
| eplenmean          | 400          |
| eprewmean          | 75.8         |
| explained_variance | 0.597        |
| fps                | 1396         |
| nupdates           | 355          |
| policy_entropy     | 0.85378426   |
| policy_loss        | 0.001500799  |
| serial_timesteps   | 142000       |
| time_elapsed       | 3.2e+03      |
| time_remaining     | 59.4         |
| total_timesteps    | 4260000      |
| true_eprew         | 75.8         |
| value_loss         | 17.849833    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.696239709854126 seconds
Total simulation time for 400 steps: 8.059814929962158 	 Other agent action time: 0 	 49.62893112011916 steps/s
Curr learning rate 0.001145 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.74it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.19it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.75it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.43it/s]
-------------------------------------
| approxkl           | 0.0046038935 |
| clipfrac           | 0.32675      |
| eplenmean          | 400          |
| eprewmean          | 79           |
| explained_variance | 0.641        |
| fps                | 1370         |
| nupdates           | 356          |
| policy_entropy     | 0.77971953   |
| policy_loss        | 0.0017164662 |
| serial_timesteps   | 142400       |
| time_elapsed       | 3.21e+03     |
| time_remaining     | 59.2         |
| total_timesteps    | 4272000      |
| true_eprew         | 79           |
| value_loss         | 16.35848     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.594394683837891 seconds
Total simulation time for 400 steps: 7.943302154541016 	 Other agent action time: 0 	 50.35689090227149 steps/s
Curr learning rate 0.001144 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.60it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.24it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.49it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.98it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.45it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.99it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.07it/s]
---------------------------------------
| approxkl           | 0.0031850678   |
| clipfrac           | 0.29360422     |
| eplenmean          | 400            |
| eprewmean          | 78.2           |
| explained_variance | 0.64           |
| fps                | 1387           |
| nupdates           | 357            |
| policy_entropy     | 0.80379117     |
| policy_loss        | -0.00026783018 |
| serial_timesteps   | 142800         |
| time_elapsed       | 3.22e+03       |
| time_remaining     | 59.1           |
| total_timesteps    | 4284000        |
| true_eprew         | 78.2           |
| value_loss         | 16.494246      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.675710916519165 seconds
Total simulation time for 400 steps: 7.947794198989868 	 Other agent action time: 0 	 50.32842949693367 steps/s
Curr learning rate 0.001143 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.94it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.48it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.29it/s]
-------------------------------------
| approxkl           | 0.0053699864 |
| clipfrac           | 0.3601146    |
| eplenmean          | 400          |
| eprewmean          | 79.2         |
| explained_variance | 0.612        |
| fps                | 1387         |
| nupdates           | 358          |
| policy_entropy     | 0.81279486   |
| policy_loss        | 0.0030415505 |
| serial_timesteps   | 143200       |
| time_elapsed       | 3.23e+03     |
| time_remaining     | 58.9         |
| total_timesteps    | 4296000      |
| true_eprew         | 79.2         |
| value_loss         | 16.922342    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.715822219848633 seconds
Total simulation time for 400 steps: 8.022443294525146 	 Other agent action time: 0 	 49.86012182510244 steps/s
Curr learning rate 0.001142 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.36it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.84it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.16it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.49it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.87it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.44it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.95it/s]
-------------------------------------
| approxkl           | 0.0040476224 |
| clipfrac           | 0.30982295   |
| eplenmean          | 400          |
| eprewmean          | 82.4         |
| explained_variance | 0.59         |
| fps                | 1374         |
| nupdates           | 359          |
| policy_entropy     | 0.77284354   |
| policy_loss        | 0.0015245613 |
| serial_timesteps   | 143600       |
| time_elapsed       | 3.24e+03     |
| time_remaining     | 58.8         |
| total_timesteps    | 4308000      |
| true_eprew         | 82.4         |
| value_loss         | 17.986753    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.696462631225586 seconds
Total simulation time for 400 steps: 7.967989921569824 	 Other agent action time: 0 	 50.20086671008156 steps/s
Curr learning rate 0.001141 	 Curr reward per step 0.17

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 184.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.30it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.07it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.68it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.57it/s]
-------------------------------------
| approxkl           | 0.0046179    |
| clipfrac           | 0.33073965   |
| eplenmean          | 400          |
| eprewmean          | 79           |
| explained_variance | 0.502        |
| fps                | 1386         |
| nupdates           | 360          |
| policy_entropy     | 0.827424     |
| policy_loss        | 0.0031390511 |
| serial_timesteps   | 144000       |
| time_elapsed       | 3.25e+03     |
| time_remaining     | 58.6         |
| total_timesteps    | 4320000      |
| true_eprew         | 79           |
| value_loss         | 21.169924    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.5798561573028564 seconds
Total simulation time for 400 steps: 7.8624043464660645 	 Other agent action time: 0 	 50.87502275048841 steps/s
Curr learning rate 0.00114 	 Curr reward per step 0.1716666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.78it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.66it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.88it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 196.49it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.43it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.12it/s]
-------------------------------------
| approxkl           | 0.0057828147 |
| clipfrac           | 0.38210422   |
| eplenmean          | 400          |
| eprewmean          | 75.4         |
| explained_variance | 0.656        |
| fps                | 1405         |
| nupdates           | 361          |
| policy_entropy     | 0.83976805   |
| policy_loss        | 0.003705415  |
| serial_timesteps   | 144400       |
| time_elapsed       | 3.25e+03     |
| time_remaining     | 58.4         |
| total_timesteps    | 4332000      |
| true_eprew         | 75.4         |
| value_loss         | 15.022115    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.632417678833008 seconds
Total simulation time for 400 steps: 7.866962432861328 	 Other agent action time: 0 	 50.84554596690939 steps/s
Curr learning rate 0.001139 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 183.20it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 192.88it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.54it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.64it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 197.01it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 200.39it/s]
-------------------------------------
| approxkl           | 0.004486184  |
| clipfrac           | 0.33426034   |
| eplenmean          | 400          |
| eprewmean          | 73           |
| explained_variance | 0.651        |
| fps                | 1409         |
| nupdates           | 362          |
| policy_entropy     | 0.79829955   |
| policy_loss        | 0.0008925795 |
| serial_timesteps   | 144800       |
| time_elapsed       | 3.26e+03     |
| time_remaining     | 58.3         |
| total_timesteps    | 4344000      |
| true_eprew         | 73           |
| value_loss         | 15.168581    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.619539976119995 seconds
Total simulation time for 400 steps: 7.852284908294678 	 Other agent action time: 0 	 50.94058667910333 steps/s
Curr learning rate 0.0011380000000000001 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 181.03it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.86it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.75it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.40it/s]
---------------------------------------
| approxkl           | 0.003872625    |
| clipfrac           | 0.31013533     |
| eplenmean          | 400            |
| eprewmean          | 77.8           |
| explained_variance | 0.658          |
| fps                | 1406           |
| nupdates           | 363            |
| policy_entropy     | 0.7649505      |
| policy_loss        | -0.00037303977 |
| serial_timesteps   | 145200         |
| time_elapsed       | 3.27e+03       |
| time_remaining     | 58.1           |
| total_timesteps    | 4356000        |
| true_eprew         | 77.8           |
| value_loss         | 16.115332      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.616693496704102 seconds
Total simulation time for 400 steps: 7.8303797245025635 	 Other agent action time: 0 	 51.08309099600027 steps/s
Curr learning rate 0.001137 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.87it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.01it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 162.46it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 166.42it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.59it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.68it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.27it/s]
-------------------------------------
| approxkl           | 0.005184774  |
| clipfrac           | 0.3461978    |
| eplenmean          | 400          |
| eprewmean          | 82           |
| explained_variance | 0.654        |
| fps                | 1401         |
| nupdates           | 364          |
| policy_entropy     | 0.78994244   |
| policy_loss        | 0.0026691312 |
| serial_timesteps   | 145600       |
| time_elapsed       | 3.28e+03     |
| time_remaining     | 58           |
| total_timesteps    | 4368000      |
| true_eprew         | 82           |
| value_loss         | 15.867433    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.641927003860474 seconds
Total simulation time for 400 steps: 7.879474401473999 	 Other agent action time: 0 	 50.764807348720204 steps/s
Curr learning rate 0.0011359999999999999 	 Curr reward per step 0.19

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 182.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 188.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.22it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.88it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.49it/s]
-------------------------------------
| approxkl           | 0.0031537488 |
| clipfrac           | 0.29270828   |
| eplenmean          | 400          |
| eprewmean          | 82.4         |
| explained_variance | 0.643        |
| fps                | 1400         |
| nupdates           | 365          |
| policy_entropy     | 0.8296469    |
| policy_loss        | 0.0006235241 |
| serial_timesteps   | 146000       |
| time_elapsed       | 3.29e+03     |
| time_remaining     | 57.8         |
| total_timesteps    | 4380000      |
| true_eprew         | 82.4         |
| value_loss         | 16.672575    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.630845785140991 seconds
Total simulation time for 400 steps: 7.899536848068237 	 Other agent action time: 0 	 50.63588001337275 steps/s
Curr learning rate 0.001135 	 Curr reward per step 0.19166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.32it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.07it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.09it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.62it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.03it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.31it/s]
-------------------------------------
| approxkl           | 0.0035627896 |
| clipfrac           | 0.31790626   |
| eplenmean          | 400          |
| eprewmean          | 78.4         |
| explained_variance | 0.612        |
| fps                | 1394         |
| nupdates           | 366          |
| policy_entropy     | 0.8269891    |
| policy_loss        | 0.0018529978 |
| serial_timesteps   | 146400       |
| time_elapsed       | 3.3e+03      |
| time_remaining     | 57.7         |
| total_timesteps    | 4392000      |
| true_eprew         | 78.4         |
| value_loss         | 18.605314    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.518393039703369 seconds
Total simulation time for 400 steps: 7.758196592330933 	 Other agent action time: 0 	 51.558373810146115 steps/s
Curr learning rate 0.001134 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 210.23it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 214.48it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 216.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 228.95it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 225.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 225.60it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 198.49it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.48it/s]
--------------------------------------
| approxkl           | 0.004221772   |
| clipfrac           | 0.33819792    |
| eplenmean          | 400           |
| eprewmean          | 80.4          |
| explained_variance | 0.615         |
| fps                | 1437          |
| nupdates           | 367           |
| policy_entropy     | 0.812233      |
| policy_loss        | 0.00087252766 |
| serial_timesteps   | 146800        |
| time_elapsed       | 3.31e+03      |
| time_remaining     | 57.5          |
| total_timesteps    | 4404000       |
| true_eprew         | 80.4          |
| value_loss         | 16.955715     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.603428840637207 seconds
Total simulation time for 400 steps: 7.993548631668091 	 Other agent action time: 0 	 50.040353594061784 steps/s
Curr learning rate 0.001133 	 Curr reward per step 0.18

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 204.07it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 197.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.23it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.02it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.24it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 168.04it/s]
-------------------------------------
| approxkl           | 0.00520445   |
| clipfrac           | 0.36659387   |
| eplenmean          | 400          |
| eprewmean          | 77           |
| explained_variance | 0.582        |
| fps                | 1384         |
| nupdates           | 368          |
| policy_entropy     | 0.846616     |
| policy_loss        | 0.0020407417 |
| serial_timesteps   | 147200       |
| time_elapsed       | 3.31e+03     |
| time_remaining     | 57.3         |
| total_timesteps    | 4416000      |
| true_eprew         | 77           |
| value_loss         | 19.353935    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.647315263748169 seconds
Total simulation time for 400 steps: 7.937307596206665 	 Other agent action time: 0 	 50.39492235265833 steps/s
Curr learning rate 0.0011320000000000002 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 183.26it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 195.04it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 196.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.60it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 199.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 201.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.20it/s]
-------------------------------------
| approxkl           | 0.004756585  |
| clipfrac           | 0.34197915   |
| eplenmean          | 400          |
| eprewmean          | 77.8         |
| explained_variance | 0.626        |
| fps                | 1399         |
| nupdates           | 369          |
| policy_entropy     | 0.82223386   |
| policy_loss        | 0.0010684349 |
| serial_timesteps   | 147600       |
| time_elapsed       | 3.32e+03     |
| time_remaining     | 57.2         |
| total_timesteps    | 4428000      |
| true_eprew         | 77.8         |
| value_loss         | 15.469832    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.607707738876343 seconds
Total simulation time for 400 steps: 7.818058967590332 	 Other agent action time: 0 	 51.163594654145626 steps/s
Curr learning rate 0.001131 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 180.66it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.87it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.47it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 206.75it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.70it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.58it/s]
-------------------------------------
| approxkl           | 0.0052549853 |
| clipfrac           | 0.36161444   |
| eplenmean          | 400          |
| eprewmean          | 77.6         |
| explained_variance | 0.595        |
| fps                | 1414         |
| nupdates           | 370          |
| policy_entropy     | 0.82840574   |
| policy_loss        | 0.0024341468 |
| serial_timesteps   | 148000       |
| time_elapsed       | 3.33e+03     |
| time_remaining     | 57           |
| total_timesteps    | 4440000      |
| true_eprew         | 77.6         |
| value_loss         | 19.273703    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.6478071212768555 seconds
Total simulation time for 400 steps: 7.888403654098511 	 Other agent action time: 0 	 50.70734429166482 steps/s
Curr learning rate 0.00113 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 188.81it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.50it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 160.84it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.75it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 166.02it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.88it/s]
--------------------------------------
| approxkl           | 0.0037842765  |
| clipfrac           | 0.31361467    |
| eplenmean          | 400           |
| eprewmean          | 81.4          |
| explained_variance | 0.661         |
| fps                | 1394          |
| nupdates           | 371           |
| policy_entropy     | 0.7952408     |
| policy_loss        | 0.00064287224 |
| serial_timesteps   | 148400        |
| time_elapsed       | 3.34e+03      |
| time_remaining     | 56.9          |
| total_timesteps    | 4452000       |
| true_eprew         | 81.4          |
| value_loss         | 15.244434     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.689023494720459 seconds
Total simulation time for 400 steps: 8.021278381347656 	 Other agent action time: 0 	 49.86736290441474 steps/s
Curr learning rate 0.001129 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.79it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.60it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.68it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.63it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.56it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.24it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.88it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.54it/s]
-------------------------------------
| approxkl           | 0.006325695  |
| clipfrac           | 0.36096874   |
| eplenmean          | 400          |
| eprewmean          | 81           |
| explained_variance | 0.598        |
| fps                | 1375         |
| nupdates           | 372          |
| policy_entropy     | 0.7795664    |
| policy_loss        | 0.0017565963 |
| serial_timesteps   | 148800       |
| time_elapsed       | 3.35e+03     |
| time_remaining     | 56.7         |
| total_timesteps    | 4464000      |
| true_eprew         | 81           |
| value_loss         | 17.346666    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.625384092330933 seconds
Total simulation time for 400 steps: 7.82412052154541 	 Other agent action time: 0 	 51.123956858603265 steps/s
Curr learning rate 0.001128 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 185.85it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.07it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.06it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.30it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.27it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 200.17it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.27it/s]
-------------------------------------
| approxkl           | 0.0057261116 |
| clipfrac           | 0.36301047   |
| eplenmean          | 400          |
| eprewmean          | 82.2         |
| explained_variance | 0.669        |
| fps                | 1415         |
| nupdates           | 373          |
| policy_entropy     | 0.81321204   |
| policy_loss        | 0.00273491   |
| serial_timesteps   | 149200       |
| time_elapsed       | 3.36e+03     |
| time_remaining     | 56.6         |
| total_timesteps    | 4476000      |
| true_eprew         | 82.2         |
| value_loss         | 15.280446    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.656766891479492 seconds
Total simulation time for 400 steps: 7.9222495555877686 	 Other agent action time: 0 	 50.490709386687975 steps/s
Curr learning rate 0.001127 	 Curr reward per step 0.18333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.65it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.66it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.14it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 171.53it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.74it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.56it/s]
-------------------------------------
| approxkl           | 0.0067213206 |
| clipfrac           | 0.38175005   |
| eplenmean          | 400          |
| eprewmean          | 79.2         |
| explained_variance | 0.601        |
| fps                | 1388         |
| nupdates           | 374          |
| policy_entropy     | 0.78873426   |
| policy_loss        | 0.0037713395 |
| serial_timesteps   | 149600       |
| time_elapsed       | 3.37e+03     |
| time_remaining     | 56.4         |
| total_timesteps    | 4488000      |
| true_eprew         | 79.2         |
| value_loss         | 18.043543    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.635237216949463 seconds
Total simulation time for 400 steps: 7.945440053939819 	 Other agent action time: 0 	 50.34334124787164 steps/s
Curr learning rate 0.001126 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.50it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.45it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 192.49it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.62it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.43it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.61it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 201.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 202.23it/s]
-------------------------------------
| approxkl           | 0.005193092  |
| clipfrac           | 0.36072928   |
| eplenmean          | 400          |
| eprewmean          | 80           |
| explained_variance | 0.534        |
| fps                | 1395         |
| nupdates           | 375          |
| policy_entropy     | 0.80144656   |
| policy_loss        | 0.0034166973 |
| serial_timesteps   | 150000       |
| time_elapsed       | 3.37e+03     |
| time_remaining     | 56.2         |
| total_timesteps    | 4500000      |
| true_eprew         | 80           |
| value_loss         | 20.455637    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.603610038757324 seconds
Total simulation time for 400 steps: 7.8712077140808105 	 Other agent action time: 0 	 50.818122774785834 steps/s
Curr learning rate 0.0011250000000000001 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 180.64it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.90it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.24it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.24it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.49it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.78it/s]
-------------------------------------
| approxkl           | 0.0064354516 |
| clipfrac           | 0.38322914   |
| eplenmean          | 400          |
| eprewmean          | 78.8         |
| explained_variance | 0.607        |
| fps                | 1403         |
| nupdates           | 376          |
| policy_entropy     | 0.8327831    |
| policy_loss        | 0.0033938617 |
| serial_timesteps   | 150400       |
| time_elapsed       | 3.38e+03     |
| time_remaining     | 56.1         |
| total_timesteps    | 4512000      |
| true_eprew         | 78.8         |
| value_loss         | 16.821026    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.717526197433472 seconds
Total simulation time for 400 steps: 7.970773220062256 	 Other agent action time: 0 	 50.18333716899749 steps/s
Curr learning rate 0.001124 	 Curr reward per step 0.18166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 180.72it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.04it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.35it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.53it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.92it/s]
------------------------------------
| approxkl           | 0.005101417 |
| clipfrac           | 0.3571251   |
| eplenmean          | 400         |
| eprewmean          | 77.4        |
| explained_variance | 0.61        |
| fps                | 1386        |
| nupdates           | 377         |
| policy_entropy     | 0.81138533  |
| policy_loss        | 0.002529596 |
| serial_timesteps   | 150800      |
| time_elapsed       | 3.39e+03    |
| time_remaining     | 55.9        |
| total_timesteps    | 4524000     |
| true_eprew         | 77.4        |
| value_loss         | 17.64337    |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.584517955780029 seconds
Total simulation time for 400 steps: 7.798838376998901 	 Other agent action time: 0 	 51.289689651694694 steps/s
Curr learning rate 0.0011229999999999999 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 199.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 207.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 200.97it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.68it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.40it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.84it/s]
--------------------------------------
| approxkl           | 0.0040952116  |
| clipfrac           | 0.32251045    |
| eplenmean          | 400           |
| eprewmean          | 81.4          |
| explained_variance | 0.635         |
| fps                | 1421          |
| nupdates           | 378           |
| policy_entropy     | 0.77895576    |
| policy_loss        | 0.00070508505 |
| serial_timesteps   | 151200        |
| time_elapsed       | 3.4e+03       |
| time_remaining     | 55.8          |
| total_timesteps    | 4536000       |
| true_eprew         | 81.4          |
| value_loss         | 16.135355     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.694439649581909 seconds
Total simulation time for 400 steps: 8.028511047363281 	 Other agent action time: 0 	 49.82243876109104 steps/s
Curr learning rate 0.001122 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 192.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.01it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.73it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 199.45it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.16it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.89it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.70it/s]
--------------------------------------
| approxkl           | 0.0026760476  |
| clipfrac           | 0.2691562     |
| eplenmean          | 400           |
| eprewmean          | 83            |
| explained_variance | 0.624         |
| fps                | 1379          |
| nupdates           | 379           |
| policy_entropy     | 0.742629      |
| policy_loss        | 0.00021342574 |
| serial_timesteps   | 151600        |
| time_elapsed       | 3.41e+03      |
| time_remaining     | 55.6          |
| total_timesteps    | 4548000       |
| true_eprew         | 83            |
| value_loss         | 17.615107     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.640887260437012 seconds
Total simulation time for 400 steps: 7.827635049819946 	 Other agent action time: 0 	 51.10100272357497 steps/s
Curr learning rate 0.001121 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 191.08it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 192.75it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 192.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.57it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 197.22it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 201.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.12it/s]
-------------------------------------
| approxkl           | 0.0041710814 |
| clipfrac           | 0.31605208   |
| eplenmean          | 400          |
| eprewmean          | 88.8         |
| explained_variance | 0.602        |
| fps                | 1416         |
| nupdates           | 380          |
| policy_entropy     | 0.7475639    |
| policy_loss        | 0.0011568948 |
| serial_timesteps   | 152000       |
| time_elapsed       | 3.42e+03     |
| time_remaining     | 55.5         |
| total_timesteps    | 4560000      |
| true_eprew         | 88.8         |
| value_loss         | 17.541067    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.690876007080078 seconds
Total simulation time for 400 steps: 7.938413858413696 	 Other agent action time: 0 	 50.38789953940881 steps/s
Curr learning rate 0.00112 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.65it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 166.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 171.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.25it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.69it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.61it/s]
-------------------------------------
| approxkl           | 0.0039384672 |
| clipfrac           | 0.32000002   |
| eplenmean          | 400          |
| eprewmean          | 86.8         |
| explained_variance | 0.624        |
| fps                | 1383         |
| nupdates           | 381          |
| policy_entropy     | 0.8147554    |
| policy_loss        | 0.0010268006 |
| serial_timesteps   | 152400       |
| time_elapsed       | 3.43e+03     |
| time_remaining     | 55.3         |
| total_timesteps    | 4572000      |
| true_eprew         | 86.8         |
| value_loss         | 17.809345    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.627833843231201 seconds
Total simulation time for 400 steps: 7.983839750289917 	 Other agent action time: 0 	 50.10120599996697 steps/s
Curr learning rate 0.001119 	 Curr reward per step 0.185

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.95it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.43it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.29it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.03it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.94it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.94it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.97it/s]
-------------------------------------
| approxkl           | 0.005224597  |
| clipfrac           | 0.3466563    |
| eplenmean          | 400          |
| eprewmean          | 82           |
| explained_variance | 0.618        |
| fps                | 1382         |
| nupdates           | 382          |
| policy_entropy     | 0.7805951    |
| policy_loss        | 0.0026296624 |
| serial_timesteps   | 152800       |
| time_elapsed       | 3.43e+03     |
| time_remaining     | 55.1         |
| total_timesteps    | 4584000      |
| true_eprew         | 82           |
| value_loss         | 17.710592    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.661660194396973 seconds
Total simulation time for 400 steps: 7.96334433555603 	 Other agent action time: 0 	 50.23015245165466 steps/s
Curr learning rate 0.001118 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.50it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.56it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.88it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.17it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.07it/s]
-------------------------------------
| approxkl           | 0.0054718107 |
| clipfrac           | 0.32811457   |
| eplenmean          | 400          |
| eprewmean          | 80.8         |
| explained_variance | 0.606        |
| fps                | 1382         |
| nupdates           | 383          |
| policy_entropy     | 0.73099405   |
| policy_loss        | 0.00110847   |
| serial_timesteps   | 153200       |
| time_elapsed       | 3.44e+03     |
| time_remaining     | 55           |
| total_timesteps    | 4596000      |
| true_eprew         | 80.8         |
| value_loss         | 18.535034    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.677435398101807 seconds
Total simulation time for 400 steps: 7.949845552444458 	 Other agent action time: 0 	 50.31544290530349 steps/s
Curr learning rate 0.001117 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.01it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.70it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.49it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.02it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.09it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.91it/s]
-------------------------------------
| approxkl           | 0.00369946   |
| clipfrac           | 0.29505208   |
| eplenmean          | 400          |
| eprewmean          | 80.2         |
| explained_variance | 0.64         |
| fps                | 1388         |
| nupdates           | 384          |
| policy_entropy     | 0.72959137   |
| policy_loss        | 0.0018795886 |
| serial_timesteps   | 153600       |
| time_elapsed       | 3.45e+03     |
| time_remaining     | 54.8         |
| total_timesteps    | 4608000      |
| true_eprew         | 80.2         |
| value_loss         | 16.76638     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.671373605728149 seconds
Total simulation time for 400 steps: 7.9389238357543945 	 Other agent action time: 0 	 50.38466274213728 steps/s
Curr learning rate 0.001116 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.84it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 188.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 197.01it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 200.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 196.34it/s]
------------------------------------
| approxkl           | 0.004353985 |
| clipfrac           | 0.33514574  |
| eplenmean          | 400         |
| eprewmean          | 82.2        |
| explained_variance | 0.547       |
| fps                | 1394        |
| nupdates           | 385         |
| policy_entropy     | 0.7798706   |
| policy_loss        | 0.002785344 |
| serial_timesteps   | 154000      |
| time_elapsed       | 3.46e+03    |
| time_remaining     | 54.7        |
| total_timesteps    | 4620000     |
| true_eprew         | 82.2        |
| value_loss         | 20.757627   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.680030822753906 seconds
Total simulation time for 400 steps: 7.959572076797485 	 Other agent action time: 0 	 50.25395789379409 steps/s
Curr learning rate 0.001115 	 Curr reward per step 0.19166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.97it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.34it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.67it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.63it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.35it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.32it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.94it/s]
-------------------------------------
| approxkl           | 0.0056519303 |
| clipfrac           | 0.35383335   |
| eplenmean          | 400          |
| eprewmean          | 79.8         |
| explained_variance | 0.632        |
| fps                | 1387         |
| nupdates           | 386          |
| policy_entropy     | 0.7954635    |
| policy_loss        | 0.001328398  |
| serial_timesteps   | 154400       |
| time_elapsed       | 3.47e+03     |
| time_remaining     | 54.5         |
| total_timesteps    | 4632000      |
| true_eprew         | 79.8         |
| value_loss         | 15.479771    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.73529314994812 seconds
Total simulation time for 400 steps: 7.972442865371704 	 Other agent action time: 0 	 50.17282741998685 steps/s
Curr learning rate 0.001114 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.54it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.82it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.53it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.37it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.72it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.47it/s]
------------------------------------
| approxkl           | 0.003795421 |
| clipfrac           | 0.30154172  |
| eplenmean          | 400         |
| eprewmean          | 82.4        |
| explained_variance | 0.643       |
| fps                | 1383        |
| nupdates           | 387         |
| policy_entropy     | 0.73438984  |
| policy_loss        | 0.00364604  |
| serial_timesteps   | 154800      |
| time_elapsed       | 3.48e+03    |
| time_remaining     | 54.4        |
| total_timesteps    | 4644000     |
| true_eprew         | 82.4        |
| value_loss         | 16.597034   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.666682958602905 seconds
Total simulation time for 400 steps: 7.916083574295044 	 Other agent action time: 0 	 50.53003751739969 steps/s
Curr learning rate 0.001113 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.60it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 197.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 197.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.77it/s]
-------------------------------------
| approxkl           | 0.0066520274 |
| clipfrac           | 0.33302075   |
| eplenmean          | 400          |
| eprewmean          | 85.2         |
| explained_variance | 0.657        |
| fps                | 1396         |
| nupdates           | 388          |
| policy_entropy     | 0.7281434    |
| policy_loss        | 0.0028172666 |
| serial_timesteps   | 155200       |
| time_elapsed       | 3.49e+03     |
| time_remaining     | 54.2         |
| total_timesteps    | 4656000      |
| true_eprew         | 85.2         |
| value_loss         | 15.826107    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.642969608306885 seconds
Total simulation time for 400 steps: 7.920353412628174 	 Other agent action time: 0 	 50.50279692851103 steps/s
Curr learning rate 0.0011120000000000001 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.61it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.50it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.32it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.18it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.07it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.56it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.29it/s]
-------------------------------------
| approxkl           | 0.0047394424 |
| clipfrac           | 0.33994797   |
| eplenmean          | 400          |
| eprewmean          | 86.8         |
| explained_variance | 0.658        |
| fps                | 1395         |
| nupdates           | 389          |
| policy_entropy     | 0.7663602    |
| policy_loss        | 0.0023927623 |
| serial_timesteps   | 155600       |
| time_elapsed       | 3.49e+03     |
| time_remaining     | 54.1         |
| total_timesteps    | 4668000      |
| true_eprew         | 86.8         |
| value_loss         | 16.690353    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.764351844787598 seconds
Total simulation time for 400 steps: 8.184299945831299 	 Other agent action time: 0 	 48.874064079694605 steps/s
Curr learning rate 0.001111 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 193.92it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 202.34it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.01it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.92it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.87it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.55it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.69it/s]
-------------------------------------
| approxkl           | 0.004430288  |
| clipfrac           | 0.3309375    |
| eplenmean          | 400          |
| eprewmean          | 85.8         |
| explained_variance | 0.694        |
| fps                | 1353         |
| nupdates           | 390          |
| policy_entropy     | 0.74491245   |
| policy_loss        | 0.0011320725 |
| serial_timesteps   | 156000       |
| time_elapsed       | 3.5e+03      |
| time_remaining     | 53.9         |
| total_timesteps    | 4680000      |
| true_eprew         | 85.8         |
| value_loss         | 14.949802    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.682415723800659 seconds
Total simulation time for 400 steps: 8.047963380813599 	 Other agent action time: 0 	 49.70201541344023 steps/s
Curr learning rate 0.0011099999999999999 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 197.16it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 201.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 199.43it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 206.21it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 209.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 217.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 218.91it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 222.09it/s]
-------------------------------------
| approxkl           | 0.0053276895 |
| clipfrac           | 0.3514166    |
| eplenmean          | 400          |
| eprewmean          | 83.2         |
| explained_variance | 0.677        |
| fps                | 1387         |
| nupdates           | 391          |
| policy_entropy     | 0.7466657    |
| policy_loss        | 0.0028098708 |
| serial_timesteps   | 156400       |
| time_elapsed       | 3.51e+03     |
| time_remaining     | 53.8         |
| total_timesteps    | 4692000      |
| true_eprew         | 83.2         |
| value_loss         | 14.418486    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.640496492385864 seconds
Total simulation time for 400 steps: 7.9099297523498535 	 Other agent action time: 0 	 50.569349226036984 steps/s
Curr learning rate 0.001109 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 182.11it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 188.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.12it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.90it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.03it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.78it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.96it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.52it/s]
--------------------------------------
| approxkl           | 0.004643221   |
| clipfrac           | 0.32720837    |
| eplenmean          | 400           |
| eprewmean          | 83.2          |
| explained_variance | 0.635         |
| fps                | 1397          |
| nupdates           | 392           |
| policy_entropy     | 0.7473687     |
| policy_loss        | 0.00097354007 |
| serial_timesteps   | 156800        |
| time_elapsed       | 3.52e+03      |
| time_remaining     | 53.6          |
| total_timesteps    | 4704000       |
| true_eprew         | 83.2          |
| value_loss         | 16.514057     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.671121835708618 seconds
Total simulation time for 400 steps: 7.967725515365601 	 Other agent action time: 0 	 50.202532608409754 steps/s
Curr learning rate 0.001108 	 Curr reward per step 0.22

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.43it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.59it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.67it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.71it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.60it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.62it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.35it/s]
-------------------------------------
| approxkl           | 0.0049899253 |
| clipfrac           | 0.32305205   |
| eplenmean          | 400          |
| eprewmean          | 85.2         |
| explained_variance | 0.62         |
| fps                | 1383         |
| nupdates           | 393          |
| policy_entropy     | 0.727734     |
| policy_loss        | 0.0014644739 |
| serial_timesteps   | 157200       |
| time_elapsed       | 3.53e+03     |
| time_remaining     | 53.4         |
| total_timesteps    | 4716000      |
| true_eprew         | 85.2         |
| value_loss         | 16.939848    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.598899841308594 seconds
Total simulation time for 400 steps: 7.829468488693237 	 Other agent action time: 0 	 51.08903632189741 steps/s
Curr learning rate 0.001107 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 188.89it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 190.24it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 191.33it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 197.65it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 200.20it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.02it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 198.13it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 204.02it/s]
-------------------------------------
| approxkl           | 0.0045906235 |
| clipfrac           | 0.34210414   |
| eplenmean          | 400          |
| eprewmean          | 82.6         |
| explained_variance | 0.636        |
| fps                | 1417         |
| nupdates           | 394          |
| policy_entropy     | 0.7959073    |
| policy_loss        | 0.0006950259 |
| serial_timesteps   | 157600       |
| time_elapsed       | 3.54e+03     |
| time_remaining     | 53.3         |
| total_timesteps    | 4728000      |
| true_eprew         | 82.6         |
| value_loss         | 17.006458    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.753127336502075 seconds
Total simulation time for 400 steps: 8.036483526229858 	 Other agent action time: 0 	 49.77301312128133 steps/s
Curr learning rate 0.001106 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 181.08it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.59it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.10it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.89it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.25it/s]
-------------------------------------
| approxkl           | 0.004641698  |
| clipfrac           | 0.3260937    |
| eplenmean          | 400          |
| eprewmean          | 81.4         |
| explained_variance | 0.584        |
| fps                | 1372         |
| nupdates           | 395          |
| policy_entropy     | 0.76594454   |
| policy_loss        | 0.0027252987 |
| serial_timesteps   | 158000       |
| time_elapsed       | 3.55e+03     |
| time_remaining     | 53.1         |
| total_timesteps    | 4740000      |
| true_eprew         | 81.4         |
| value_loss         | 18.6697      |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.689882755279541 seconds
Total simulation time for 400 steps: 8.02747392654419 	 Other agent action time: 0 	 49.82887564135623 steps/s
Curr learning rate 0.001105 	 Curr reward per step 0.195

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 183.85it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.95it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.10it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.02it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.43it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.44it/s]
-------------------------------------
| approxkl           | 0.005607248  |
| clipfrac           | 0.3816771    |
| eplenmean          | 400          |
| eprewmean          | 78.2         |
| explained_variance | 0.632        |
| fps                | 1380         |
| nupdates           | 396          |
| policy_entropy     | 0.8027513    |
| policy_loss        | 0.0021687413 |
| serial_timesteps   | 158400       |
| time_elapsed       | 3.56e+03     |
| time_remaining     | 53           |
| total_timesteps    | 4752000      |
| true_eprew         | 78.2         |
| value_loss         | 17.947626    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.625280141830444 seconds
Total simulation time for 400 steps: 7.950396537780762 	 Other agent action time: 0 	 50.31195590046056 steps/s
Curr learning rate 0.001104 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.98it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.67it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.80it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.47it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 171.53it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 170.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 171.96it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.38it/s]
-------------------------------------
| approxkl           | 0.0050488454 |
| clipfrac           | 0.35598955   |
| eplenmean          | 400          |
| eprewmean          | 80.2         |
| explained_variance | 0.652        |
| fps                | 1383         |
| nupdates           | 397          |
| policy_entropy     | 0.8097364    |
| policy_loss        | 0.0020703091 |
| serial_timesteps   | 158800       |
| time_elapsed       | 3.56e+03     |
| time_remaining     | 52.8         |
| total_timesteps    | 4764000      |
| true_eprew         | 80.2         |
| value_loss         | 16.935823    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.600663900375366 seconds
Total simulation time for 400 steps: 7.869354486465454 	 Other agent action time: 0 	 50.83009040804582 steps/s
Curr learning rate 0.001103 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.99it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.35it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.39it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.91it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.62it/s]
-------------------------------------
| approxkl           | 0.0034961144 |
| clipfrac           | 0.30758336   |
| eplenmean          | 400          |
| eprewmean          | 80           |
| explained_variance | 0.617        |
| fps                | 1399         |
| nupdates           | 398          |
| policy_entropy     | 0.74397916   |
| policy_loss        | 0.0017825685 |
| serial_timesteps   | 159200       |
| time_elapsed       | 3.57e+03     |
| time_remaining     | 52.7         |
| total_timesteps    | 4776000      |
| true_eprew         | 80           |
| value_loss         | 18.090006    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.592115640640259 seconds
Total simulation time for 400 steps: 7.846590042114258 	 Other agent action time: 0 	 50.977558130744434 steps/s
Curr learning rate 0.0011020000000000001 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.50it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.87it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.93it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.86it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.38it/s]
-------------------------------------
| approxkl           | 0.0060308683 |
| clipfrac           | 0.35471874   |
| eplenmean          | 400          |
| eprewmean          | 81.8         |
| explained_variance | 0.671        |
| fps                | 1404         |
| nupdates           | 399          |
| policy_entropy     | 0.7476729    |
| policy_loss        | 0.001890357  |
| serial_timesteps   | 159600       |
| time_elapsed       | 3.58e+03     |
| time_remaining     | 52.5         |
| total_timesteps    | 4788000      |
| true_eprew         | 81.8         |
| value_loss         | 14.832881    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.61583399772644 seconds
Total simulation time for 400 steps: 7.852155923843384 	 Other agent action time: 0 	 50.941423461215805 steps/s
Curr learning rate 0.001101 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.07it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.96it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.92it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.43it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.13it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.18it/s]
-------------------------------------
| approxkl           | 0.0052731847 |
| clipfrac           | 0.33852088   |
| eplenmean          | 400          |
| eprewmean          | 84           |
| explained_variance | 0.619        |
| fps                | 1408         |
| nupdates           | 400          |
| policy_entropy     | 0.7463586    |
| policy_loss        | 0.002851403  |
| serial_timesteps   | 160000       |
| time_elapsed       | 3.59e+03     |
| time_remaining     | 52.4         |
| total_timesteps    | 4800000      |
| true_eprew         | 84           |
| value_loss         | 15.826212    |
-------------------------------------
Current reward shaping 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓1Xo  X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓1Xo  X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓1Xo  X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓1Xo  X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D ←1X   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D ←dX   X 
X X X S X 


Timestep: 33
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O   Xo  X 
D ←dX   X 
X X X S X 


Timestep: 34
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O   Xo  X 
D →dX   X 
X X X S X 


Timestep: 35
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D →dX   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D →dX   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D →dX   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   Xo  X 
D →1Xd  X 
X X X S X 


Timestep: 39
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1Xo  X 
D   Xd  X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1Xo  X 
D   Xd  X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1Xo  X 
D   Xd  X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1Xo  X 
D   Xd  X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1Xo  X 
D   Xd  X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oXo  X 
D   Xd  X 
X X X S X 


Timestep: 45
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oXo  X 
D   Xd  X 
X X X S X 


Timestep: 46
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oXo↓0X 
D   Xd  X 
X X X S X 


Timestep: 47
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oXo←0X 
D   Xd  X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O →oX ←oX 
D   Xd  X 
X X X S X 


Timestep: 49
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑oP 
O ←oX   X 
D   Xd  X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   X ↑0P 
O ←oX   X 
D   Xd  X 
X X X S X 


Timestep: 51
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oX ↓0X 
D   Xd  X 
X X X S X 


Timestep: 52
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O →oX   X 
D   Xd  X 
X X X S X 


Timestep: 53
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oX ↓0X 
D   Xd  X 
X X X S X 


Timestep: 54
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oX ←0X 
D   Xd  X 
X X X S X 


Timestep: 55
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oX ←0X 
D   Xd  X 
X X X S X 


Timestep: 56
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →1Xo  X 
D   Xd↓0X 
X X X S X 


Timestep: 57
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O ←1Xo↑0X 
D   Xd  X 
X X X S X 


Timestep: 58
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O ←oXo  X 
D   Xd  X 
X X X S X 


Timestep: 59
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oXo↓0X 
D   Xd  X 
X X X S X 


Timestep: 60
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oXo←0X 
D   Xd  X 
X X X S X 


Timestep: 61
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O →oXo  X 
D   Xd↓0X 
X X X S X 


Timestep: 62
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X   P 
O ←oXo↑0X 
D   Xd  X 
X X X S X 


Timestep: 63
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O ←oXo  X 
D   Xd  X 
X X X S X 


Timestep: 64
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑oX   P 
O   Xo↓0X 
D   Xd  X 
X X X S X 


Timestep: 65
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑oX ↑0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 66
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑oX   P 
O   Xo↓0X 
D   Xd  X 
X X X S X 


Timestep: 67
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑oX ↑0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX ø-X 
O ↑1X ↑0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 69
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X XoX ø-X 
O ←1X ←0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX ø-X 
O ←oX ←0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 71
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X XoX ø-X 
O →oX ←0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 72
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX ø-X 
O →1Xo←0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 73
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX ø-X 
O ←1X ←oP 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 74
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø-X 
O ←1X ↑oP 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 75
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X XoX ø=X 
O ←oX ↑0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 76
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø=X 
O ←oX ↑0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 77
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X XoX ø=X 
O →oX ↑0P 
O   Xo  X 
D   Xd  X 
X X X S X 


Timestep: 78
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX ø=X 
O →1Xo  P 
O   Xo↓0X 
D   Xd  X 
X X X S X 


Timestep: 79
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø=X 
O →1Xo  P 
O   Xo←0X 
D   Xd  X 
X X X S X 


Timestep: 80
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø=X 
O →1Xo  P 
O   X ←oX 
D   Xd  X 
X X X S X 


Timestep: 81
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X XoX ø=X 
O ←1Xo↑oP 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 82
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X XoX ø1X 
O ←oXo↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 83
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø2X 
O ←oXo↑0P 
O   X   X 
D   Xd  X 
X X X S X 


Timestep: 84
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X XoX ø3X 
O →oXo  P 
O   X ↓0X 
D   Xd  X 
X X X S X 


Timestep: 85
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø4X 
O →oXo  P 
O   X ←0X 
D   Xd  X 
X X X S X 


Timestep: 86
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø5X 
O →oXo  P 
O   X   X 
D   Xd↓0X 
X X X S X 


Timestep: 87
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø6X 
O →oXo  P 
O   X   X 
D   Xd←0X 
X X X S X 


Timestep: 88
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX ø7X 
O →oXo  P 
O   X   X 
D   X ←dX 
X X X S X 


Timestep: 89
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X XoX ø8X 
O →oXo  P 
O   X ↑dX 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X XoX ø9X 
O ←oXo↑dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X XoX ø10X 
O →oXo↑dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø11X 
O →oXo  P 
O   X ↓dX 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø12X 
O →oXo↑dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX ø13X 
O →oXo↑dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X XoX ø14X 
O →oXo↑dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX ø15X 
O ←oXo↑dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X XoX ø16X 
O →oXo↑dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX ø17X 
O →oXo↑dP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X XoX ø18X 
O →oXo↑dP 
O   X   X 
D   X   X 
X X X S X 


tot rew 120 tot rew shaped 111
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X XoX P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O →oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O →1Xo  P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O →oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ↑0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ↑0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ↑0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ↑0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ↓oX ↓0X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 12
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.559911251068115 seconds
Total simulation time for 400 steps: 7.724306106567383 	 Other agent action time: 0 	 51.78458679413427 steps/s
Curr learning rate 0.0011 	 Curr reward per step 0.195

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.81it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.36it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.94it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.44it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.34it/s]
-------------------------------------
| approxkl           | 0.005552265  |
| clipfrac           | 0.33926037   |
| eplenmean          | 400          |
| eprewmean          | 79.6         |
| explained_variance | 0.596        |
| fps                | 1427         |
| nupdates           | 401          |
| policy_entropy     | 0.7641781    |
| policy_loss        | 0.0030441838 |
| serial_timesteps   | 160400       |
| time_elapsed       | 3.6e+03      |
| time_remaining     | 52.2         |
| total_timesteps    | 4812000      |
| true_eprew         | 79.6         |
| value_loss         | 17.790667    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.6805195808410645 seconds
Total simulation time for 400 steps: 7.960818290710449 	 Other agent action time: 0 	 50.24609096614648 steps/s
Curr learning rate 0.0010990000000000002 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.48it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.99it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.43it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.51it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.22it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.84it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.15it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.54it/s]
-------------------------------------
| approxkl           | 0.0038862466 |
| clipfrac           | 0.30423963   |
| eplenmean          | 400          |
| eprewmean          | 81           |
| explained_variance | 0.629        |
| fps                | 1385         |
| nupdates           | 402          |
| policy_entropy     | 0.76124316   |
| policy_loss        | 0.0011091272 |
| serial_timesteps   | 160800       |
| time_elapsed       | 3.61e+03     |
| time_remaining     | 52.1         |
| total_timesteps    | 4824000      |
| true_eprew         | 81           |
| value_loss         | 16.96823     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.598350763320923 seconds
Total simulation time for 400 steps: 7.887925624847412 	 Other agent action time: 0 	 50.7104172914584 steps/s
Curr learning rate 0.001098 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 187.33it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.94it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.25it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.57it/s]
-------------------------------------
| approxkl           | 0.0040932563 |
| clipfrac           | 0.31553125   |
| eplenmean          | 400          |
| eprewmean          | 81.8         |
| explained_variance | 0.633        |
| fps                | 1396         |
| nupdates           | 403          |
| policy_entropy     | 0.77057683   |
| policy_loss        | 0.0012390622 |
| serial_timesteps   | 161200       |
| time_elapsed       | 3.62e+03     |
| time_remaining     | 51.9         |
| total_timesteps    | 4836000      |
| true_eprew         | 81.8         |
| value_loss         | 17.18604     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.594134569168091 seconds
Total simulation time for 400 steps: 7.862162351608276 	 Other agent action time: 0 	 50.87658866751542 steps/s
Curr learning rate 0.001097 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 185.62it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 196.62it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 197.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 202.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 202.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 205.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 206.83it/s]
------------------------------------
| approxkl           | 0.004661706 |
| clipfrac           | 0.3259167   |
| eplenmean          | 400         |
| eprewmean          | 82.8        |
| explained_variance | 0.645       |
| fps                | 1413        |
| nupdates           | 404         |
| policy_entropy     | 0.782141    |
| policy_loss        | 0.002280029 |
| serial_timesteps   | 161600      |
| time_elapsed       | 3.63e+03    |
| time_remaining     | 51.8        |
| total_timesteps    | 4848000     |
| true_eprew         | 82.8        |
| value_loss         | 15.672593   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.651876449584961 seconds
Total simulation time for 400 steps: 7.8543381690979 	 Other agent action time: 0 	 50.92726992246903 steps/s
Curr learning rate 0.0010960000000000002 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.17it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.77it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.95it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.75it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.14it/s]
-------------------------------------
| approxkl           | 0.0035421674 |
| clipfrac           | 0.30958325   |
| eplenmean          | 400          |
| eprewmean          | 82.8         |
| explained_variance | 0.657        |
| fps                | 1401         |
| nupdates           | 405          |
| policy_entropy     | 0.7948843    |
| policy_loss        | 0.0003889049 |
| serial_timesteps   | 162000       |
| time_elapsed       | 3.63e+03     |
| time_remaining     | 51.6         |
| total_timesteps    | 4860000      |
| true_eprew         | 82.8         |
| value_loss         | 16.4843      |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.675938606262207 seconds
Total simulation time for 400 steps: 7.985393285751343 	 Other agent action time: 0 	 50.09145895340384 steps/s
Curr learning rate 0.001095 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.17it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.35it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.19it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.88it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.83it/s]
-------------------------------------
| approxkl           | 0.0058602993 |
| clipfrac           | 0.3613647    |
| eplenmean          | 400          |
| eprewmean          | 84           |
| explained_variance | 0.616        |
| fps                | 1381         |
| nupdates           | 406          |
| policy_entropy     | 0.79823977   |
| policy_loss        | 0.0038075484 |
| serial_timesteps   | 162400       |
| time_elapsed       | 3.64e+03     |
| time_remaining     | 51.5         |
| total_timesteps    | 4872000      |
| true_eprew         | 84           |
| value_loss         | 17.580025    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.683560371398926 seconds
Total simulation time for 400 steps: 7.918299198150635 	 Other agent action time: 0 	 50.51589867852207 steps/s
Curr learning rate 0.001094 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.60it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.35it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.71it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 199.58it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.19it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 202.07it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 201.43it/s]
-------------------------------------
| approxkl           | 0.003873097  |
| clipfrac           | 0.3347813    |
| eplenmean          | 400          |
| eprewmean          | 84.8         |
| explained_variance | 0.672        |
| fps                | 1401         |
| nupdates           | 407          |
| policy_entropy     | 0.8032305    |
| policy_loss        | 0.0005311025 |
| serial_timesteps   | 162800       |
| time_elapsed       | 3.65e+03     |
| time_remaining     | 51.3         |
| total_timesteps    | 4884000      |
| true_eprew         | 84.8         |
| value_loss         | 14.3784      |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.663372993469238 seconds
Total simulation time for 400 steps: 7.87666392326355 	 Other agent action time: 0 	 50.782920776727444 steps/s
Curr learning rate 0.001093 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.34it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.90it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.87it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.09it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.50it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.56it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.70it/s]
-------------------------------------
| approxkl           | 0.0054530236 |
| clipfrac           | 0.34660417   |
| eplenmean          | 400          |
| eprewmean          | 85           |
| explained_variance | 0.602        |
| fps                | 1397         |
| nupdates           | 408          |
| policy_entropy     | 0.7742933    |
| policy_loss        | 0.0009003492 |
| serial_timesteps   | 163200       |
| time_elapsed       | 3.66e+03     |
| time_remaining     | 51.1         |
| total_timesteps    | 4896000      |
| true_eprew         | 85           |
| value_loss         | 17.968267    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.671106576919556 seconds
Total simulation time for 400 steps: 7.90458083152771 	 Other agent action time: 0 	 50.60356880716373 steps/s
Curr learning rate 0.001092 	 Curr reward per step 0.175

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.26it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.72it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.44it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.12it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.64it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.01it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 196.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.69it/s]
-------------------------------------
| approxkl           | 0.0056431806 |
| clipfrac           | 0.38732296   |
| eplenmean          | 400          |
| eprewmean          | 80.6         |
| explained_variance | 0.534        |
| fps                | 1400         |
| nupdates           | 409          |
| policy_entropy     | 0.8575765    |
| policy_loss        | 0.0030882107 |
| serial_timesteps   | 163600       |
| time_elapsed       | 3.67e+03     |
| time_remaining     | 51           |
| total_timesteps    | 4908000      |
| true_eprew         | 80.6         |
| value_loss         | 19.996527    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.601873397827148 seconds
Total simulation time for 400 steps: 7.923539161682129 	 Other agent action time: 0 	 50.48249170451275 steps/s
Curr learning rate 0.001091 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.61it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.29it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.14it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.90it/s]
-------------------------------------
| approxkl           | 0.004039974  |
| clipfrac           | 0.3148126    |
| eplenmean          | 400          |
| eprewmean          | 81.6         |
| explained_variance | 0.607        |
| fps                | 1391         |
| nupdates           | 410          |
| policy_entropy     | 0.77537805   |
| policy_loss        | 0.0012971613 |
| serial_timesteps   | 164000       |
| time_elapsed       | 3.68e+03     |
| time_remaining     | 50.8         |
| total_timesteps    | 4920000      |
| true_eprew         | 81.6         |
| value_loss         | 18.878773    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.69769024848938 seconds
Total simulation time for 400 steps: 8.017736196517944 	 Other agent action time: 0 	 49.88939398800844 steps/s
Curr learning rate 0.00109 	 Curr reward per step 0.195

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.73it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 201.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 211.24it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 213.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.20it/s]
------------------------------------
| approxkl           | 0.005322174 |
| clipfrac           | 0.36702082  |
| eplenmean          | 400         |
| eprewmean          | 79          |
| explained_variance | 0.614       |
| fps                | 1384        |
| nupdates           | 411         |
| policy_entropy     | 0.83867973  |
| policy_loss        | 0.001115019 |
| serial_timesteps   | 164400      |
| time_elapsed       | 3.69e+03    |
| time_remaining     | 50.7        |
| total_timesteps    | 4932000     |
| true_eprew         | 79          |
| value_loss         | 17.178507   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.650860071182251 seconds
Total simulation time for 400 steps: 7.9400200843811035 	 Other agent action time: 0 	 50.37770632178175 steps/s
Curr learning rate 0.0010890000000000001 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.35it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.83it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.44it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.33it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.59it/s]
------------------------------------
| approxkl           | 0.00508173  |
| clipfrac           | 0.34552085  |
| eplenmean          | 400         |
| eprewmean          | 79.6        |
| explained_variance | 0.624       |
| fps                | 1391        |
| nupdates           | 412         |
| policy_entropy     | 0.8065299   |
| policy_loss        | 0.001997981 |
| serial_timesteps   | 164800      |
| time_elapsed       | 3.7e+03     |
| time_remaining     | 50.5        |
| total_timesteps    | 4944000     |
| true_eprew         | 79.6        |
| value_loss         | 16.599705   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.6674134731292725 seconds
Total simulation time for 400 steps: 7.914040803909302 	 Other agent action time: 0 	 50.543080319021335 steps/s
Curr learning rate 0.001088 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.39it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.83it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.53it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 164.57it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 164.45it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.13it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.31it/s]
-------------------------------------
| approxkl           | 0.0047745835 |
| clipfrac           | 0.3236666    |
| eplenmean          | 400          |
| eprewmean          | 83           |
| explained_variance | 0.628        |
| fps                | 1388         |
| nupdates           | 413          |
| policy_entropy     | 0.76402223   |
| policy_loss        | 0.0007344342 |
| serial_timesteps   | 165200       |
| time_elapsed       | 3.7e+03      |
| time_remaining     | 50.4         |
| total_timesteps    | 4956000      |
| true_eprew         | 83           |
| value_loss         | 17.082037    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.546951532363892 seconds
Total simulation time for 400 steps: 7.781491279602051 	 Other agent action time: 0 	 51.404028563077205 steps/s
Curr learning rate 0.001087 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.57it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.31it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.67it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.08it/s]
-------------------------------------
| approxkl           | 0.004307735  |
| clipfrac           | 0.34622923   |
| eplenmean          | 400          |
| eprewmean          | 80.4         |
| explained_variance | 0.585        |
| fps                | 1412         |
| nupdates           | 414          |
| policy_entropy     | 0.81443876   |
| policy_loss        | 0.0022304936 |
| serial_timesteps   | 165600       |
| time_elapsed       | 3.71e+03     |
| time_remaining     | 50.2         |
| total_timesteps    | 4968000      |
| true_eprew         | 80.4         |
| value_loss         | 18.059061    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.5466978549957275 seconds
Total simulation time for 400 steps: 7.716980218887329 	 Other agent action time: 0 	 51.83374696503679 steps/s
Curr learning rate 0.001086 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.76it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.72it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.51it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.69it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.78it/s]
-------------------------------------
| approxkl           | 0.004394623  |
| clipfrac           | 0.34177092   |
| eplenmean          | 400          |
| eprewmean          | 81.2         |
| explained_variance | 0.625        |
| fps                | 1425         |
| nupdates           | 415          |
| policy_entropy     | 0.81062984   |
| policy_loss        | 0.0007229752 |
| serial_timesteps   | 166000       |
| time_elapsed       | 3.72e+03     |
| time_remaining     | 50.1         |
| total_timesteps    | 4980000      |
| true_eprew         | 81.2         |
| value_loss         | 16.442038    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.585261344909668 seconds
Total simulation time for 400 steps: 7.83568263053894 	 Other agent action time: 0 	 51.04851981128387 steps/s
Curr learning rate 0.001085 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.26it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.29it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.93it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.71it/s]
---------------------------------------
| approxkl           | 0.003000852    |
| clipfrac           | 0.28005216     |
| eplenmean          | 400            |
| eprewmean          | 83.6           |
| explained_variance | 0.597          |
| fps                | 1408           |
| nupdates           | 416            |
| policy_entropy     | 0.76868016     |
| policy_loss        | -0.00041657095 |
| serial_timesteps   | 166400         |
| time_elapsed       | 3.73e+03       |
| time_remaining     | 49.9           |
| total_timesteps    | 4992000        |
| true_eprew         | 83.6           |
| value_loss         | 16.328472      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.612476110458374 seconds
Total simulation time for 400 steps: 7.8945088386535645 	 Other agent action time: 0 	 50.66812998441349 steps/s
Curr learning rate 0.0010840000000000001 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.76it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.49it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.40it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.61it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.47it/s]
-------------------------------------
| approxkl           | 0.004514454  |
| clipfrac           | 0.3396146    |
| eplenmean          | 400          |
| eprewmean          | 82.8         |
| explained_variance | 0.654        |
| fps                | 1398         |
| nupdates           | 417          |
| policy_entropy     | 0.79718673   |
| policy_loss        | 0.0009761484 |
| serial_timesteps   | 166800       |
| time_elapsed       | 3.74e+03     |
| time_remaining     | 49.7         |
| total_timesteps    | 5004000      |
| true_eprew         | 82.8         |
| value_loss         | 14.7857685   |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.63821005821228 seconds
Total simulation time for 400 steps: 7.884585618972778 	 Other agent action time: 0 	 50.73189883783809 steps/s
Curr learning rate 0.001083 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.17it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.82it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.60it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.99it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.39it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.17it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.15it/s]
--------------------------------------
| approxkl           | 0.004281291   |
| clipfrac           | 0.3335312     |
| eplenmean          | 400           |
| eprewmean          | 84            |
| explained_variance | 0.61          |
| fps                | 1397          |
| nupdates           | 418           |
| policy_entropy     | 0.7908785     |
| policy_loss        | 0.00032516278 |
| serial_timesteps   | 167200        |
| time_elapsed       | 3.75e+03      |
| time_remaining     | 49.6          |
| total_timesteps    | 5016000       |
| true_eprew         | 84            |
| value_loss         | 16.46479      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.588013648986816 seconds
Total simulation time for 400 steps: 7.817226886749268 	 Other agent action time: 0 	 51.16904060671787 steps/s
Curr learning rate 0.001082 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.52it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.94it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.33it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.63it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.75it/s]
-------------------------------------
| approxkl           | 0.0069531724 |
| clipfrac           | 0.40609387   |
| eplenmean          | 400          |
| eprewmean          | 82.2         |
| explained_variance | 0.705        |
| fps                | 1406         |
| nupdates           | 419          |
| policy_entropy     | 0.8200496    |
| policy_loss        | 0.0026290757 |
| serial_timesteps   | 167600       |
| time_elapsed       | 3.75e+03     |
| time_remaining     | 49.4         |
| total_timesteps    | 5028000      |
| true_eprew         | 82.2         |
| value_loss         | 13.083546    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.629452466964722 seconds
Total simulation time for 400 steps: 7.928254127502441 	 Other agent action time: 0 	 50.452469555993915 steps/s
Curr learning rate 0.001081 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 183.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 187.85it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.53it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.69it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.66it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.48it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.14it/s]
-------------------------------------
| approxkl           | 0.005846959  |
| clipfrac           | 0.35829172   |
| eplenmean          | 400          |
| eprewmean          | 80.8         |
| explained_variance | 0.649        |
| fps                | 1396         |
| nupdates           | 420          |
| policy_entropy     | 0.77845764   |
| policy_loss        | 0.0024193681 |
| serial_timesteps   | 168000       |
| time_elapsed       | 3.76e+03     |
| time_remaining     | 49.3         |
| total_timesteps    | 5040000      |
| true_eprew         | 80.8         |
| value_loss         | 15.667726    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.6859307289123535 seconds
Total simulation time for 400 steps: 7.989362478256226 	 Other agent action time: 0 	 50.06657303240856 steps/s
Curr learning rate 0.00108 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.49it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 158.73it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.06it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.12it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.09it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.58it/s]
-------------------------------------
| approxkl           | 0.004796986  |
| clipfrac           | 0.35132286   |
| eplenmean          | 400          |
| eprewmean          | 80.6         |
| explained_variance | 0.608        |
| fps                | 1380         |
| nupdates           | 421          |
| policy_entropy     | 0.7962862    |
| policy_loss        | 0.0015484988 |
| serial_timesteps   | 168400       |
| time_elapsed       | 3.77e+03     |
| time_remaining     | 49.1         |
| total_timesteps    | 5052000      |
| true_eprew         | 80.6         |
| value_loss         | 16.209953    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.683786869049072 seconds
Total simulation time for 400 steps: 7.919667720794678 	 Other agent action time: 0 	 50.50716950532151 steps/s
Curr learning rate 0.001079 	 Curr reward per step 0.18

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 184.87it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.39it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.83it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.93it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.10it/s]
-------------------------------------
| approxkl           | 0.0046523707 |
| clipfrac           | 0.34296876   |
| eplenmean          | 400          |
| eprewmean          | 76.8         |
| explained_variance | 0.594        |
| fps                | 1398         |
| nupdates           | 422          |
| policy_entropy     | 0.8169493    |
| policy_loss        | 0.0021502567 |
| serial_timesteps   | 168800       |
| time_elapsed       | 3.78e+03     |
| time_remaining     | 49           |
| total_timesteps    | 5064000      |
| true_eprew         | 76.8         |
| value_loss         | 17.137207    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.648454666137695 seconds
Total simulation time for 400 steps: 7.940290689468384 	 Other agent action time: 0 	 50.3759894496735 steps/s
Curr learning rate 0.001078 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 185.62it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 188.75it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.68it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.70it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.86it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 201.79it/s]
-------------------------------------
| approxkl           | 0.0057724942 |
| clipfrac           | 0.36899996   |
| eplenmean          | 400          |
| eprewmean          | 77.2         |
| explained_variance | 0.635        |
| fps                | 1395         |
| nupdates           | 423          |
| policy_entropy     | 0.8228231    |
| policy_loss        | 0.0016287622 |
| serial_timesteps   | 169200       |
| time_elapsed       | 3.79e+03     |
| time_remaining     | 48.8         |
| total_timesteps    | 5076000      |
| true_eprew         | 77.2         |
| value_loss         | 14.966339    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.686626672744751 seconds
Total simulation time for 400 steps: 7.922967433929443 	 Other agent action time: 0 	 50.486134562037144 steps/s
Curr learning rate 0.001077 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 183.74it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.29it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.15it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.70it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.70it/s]
-------------------------------------
| approxkl           | 0.005353583  |
| clipfrac           | 0.3291771    |
| eplenmean          | 400          |
| eprewmean          | 78           |
| explained_variance | 0.649        |
| fps                | 1390         |
| nupdates           | 424          |
| policy_entropy     | 0.73851866   |
| policy_loss        | 0.0021300698 |
| serial_timesteps   | 169600       |
| time_elapsed       | 3.8e+03      |
| time_remaining     | 48.7         |
| total_timesteps    | 5088000      |
| true_eprew         | 78           |
| value_loss         | 15.47548     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.620006799697876 seconds
Total simulation time for 400 steps: 7.825055360794067 	 Other agent action time: 0 	 51.11784921089798 steps/s
Curr learning rate 0.0010760000000000001 	 Curr reward per step 0.19166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.43it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.34it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.86it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.84it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.33it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.94it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.62it/s]
-------------------------------------
| approxkl           | 0.0058002505 |
| clipfrac           | 0.3591979    |
| eplenmean          | 400          |
| eprewmean          | 78           |
| explained_variance | 0.626        |
| fps                | 1410         |
| nupdates           | 425          |
| policy_entropy     | 0.785272     |
| policy_loss        | 0.0027589032 |
| serial_timesteps   | 170000       |
| time_elapsed       | 3.81e+03     |
| time_remaining     | 48.5         |
| total_timesteps    | 5100000      |
| true_eprew         | 78           |
| value_loss         | 17.191845    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.695561647415161 seconds
Total simulation time for 400 steps: 7.977027416229248 	 Other agent action time: 0 	 50.14399213248292 steps/s
Curr learning rate 0.001075 	 Curr reward per step 0.195

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 187.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 185.84it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.45it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.07it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 195.02it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.98it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.38it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.24it/s]
-------------------------------------
| approxkl           | 0.0036364468 |
| clipfrac           | 0.30817702   |
| eplenmean          | 400          |
| eprewmean          | 77.2         |
| explained_variance | 0.677        |
| fps                | 1390         |
| nupdates           | 426          |
| policy_entropy     | 0.78607005   |
| policy_loss        | 0.0011304443 |
| serial_timesteps   | 170400       |
| time_elapsed       | 3.82e+03     |
| time_remaining     | 48.4         |
| total_timesteps    | 5112000      |
| true_eprew         | 77.2         |
| value_loss         | 16.074242    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.688709497451782 seconds
Total simulation time for 400 steps: 7.948452711105347 	 Other agent action time: 0 	 50.32425989540476 steps/s
Curr learning rate 0.001074 	 Curr reward per step 0.185

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.27it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.35it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.05it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.83it/s]
--------------------------------------
| approxkl           | 0.0042472673  |
| clipfrac           | 0.3082916     |
| eplenmean          | 400           |
| eprewmean          | 74.8          |
| explained_variance | 0.624         |
| fps                | 1387          |
| nupdates           | 427           |
| policy_entropy     | 0.7744146     |
| policy_loss        | 0.00090559217 |
| serial_timesteps   | 170800        |
| time_elapsed       | 3.82e+03      |
| time_remaining     | 48.2          |
| total_timesteps    | 5124000       |
| true_eprew         | 74.8          |
| value_loss         | 16.811485     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.570125102996826 seconds
Total simulation time for 400 steps: 7.753511428833008 	 Other agent action time: 0 	 51.589528650531 steps/s
Curr learning rate 0.001073 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.15it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.59it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.05it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.83it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.80it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.02it/s]
-------------------------------------
| approxkl           | 0.006176128  |
| clipfrac           | 0.35165632   |
| eplenmean          | 400          |
| eprewmean          | 78.2         |
| explained_variance | 0.647        |
| fps                | 1419         |
| nupdates           | 428          |
| policy_entropy     | 0.7547068    |
| policy_loss        | 0.0033164958 |
| serial_timesteps   | 171200       |
| time_elapsed       | 3.83e+03     |
| time_remaining     | 48.1         |
| total_timesteps    | 5136000      |
| true_eprew         | 78.2         |
| value_loss         | 16.67425     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.707504749298096 seconds
Total simulation time for 400 steps: 8.0189790725708 	 Other agent action time: 0 	 49.88166154070834 steps/s
Curr learning rate 0.001072 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.52it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.86it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.04it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.18it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.87it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.45it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.52it/s]
-------------------------------------
| approxkl           | 0.003931669  |
| clipfrac           | 0.28134376   |
| eplenmean          | 400          |
| eprewmean          | 78.4         |
| explained_variance | 0.591        |
| fps                | 1375         |
| nupdates           | 429          |
| policy_entropy     | 0.6991908    |
| policy_loss        | 0.0015975502 |
| serial_timesteps   | 171600       |
| time_elapsed       | 3.84e+03     |
| time_remaining     | 47.9         |
| total_timesteps    | 5148000      |
| true_eprew         | 78.4         |
| value_loss         | 19.16809     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.591358184814453 seconds
Total simulation time for 400 steps: 7.844614028930664 	 Other agent action time: 0 	 50.990399084622126 steps/s
Curr learning rate 0.0010710000000000001 	 Curr reward per step 0.19

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.02it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.97it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.93it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.04it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.37it/s]
-------------------------------------
| approxkl           | 0.0037067472 |
| clipfrac           | 0.28535423   |
| eplenmean          | 400          |
| eprewmean          | 80.6         |
| explained_variance | 0.552        |
| fps                | 1408         |
| nupdates           | 430          |
| policy_entropy     | 0.7483683    |
| policy_loss        | 0.0015188364 |
| serial_timesteps   | 172000       |
| time_elapsed       | 3.85e+03     |
| time_remaining     | 47.7         |
| total_timesteps    | 5160000      |
| true_eprew         | 80.6         |
| value_loss         | 19.794003    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.670448064804077 seconds
Total simulation time for 400 steps: 7.9235148429870605 	 Other agent action time: 0 	 50.482646644378 steps/s
Curr learning rate 0.00107 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.24it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.02it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.37it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.72it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.97it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.17it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.30it/s]
------------------------------------
| approxkl           | 0.0046656   |
| clipfrac           | 0.32951033  |
| eplenmean          | 400         |
| eprewmean          | 80.6        |
| explained_variance | 0.562       |
| fps                | 1393        |
| nupdates           | 431         |
| policy_entropy     | 0.77726996  |
| policy_loss        | 0.002544389 |
| serial_timesteps   | 172400      |
| time_elapsed       | 3.86e+03    |
| time_remaining     | 47.6        |
| total_timesteps    | 5172000     |
| true_eprew         | 80.6        |
| value_loss         | 18.92298    |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.60303258895874 seconds
Total simulation time for 400 steps: 7.81986141204834 	 Other agent action time: 0 	 51.15180166539854 steps/s
Curr learning rate 0.001069 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.15it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.51it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.53it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.63it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.84it/s]
--------------------------------------
| approxkl           | 0.004503986   |
| clipfrac           | 0.3307188     |
| eplenmean          | 400           |
| eprewmean          | 81.2          |
| explained_variance | 0.658         |
| fps                | 1410          |
| nupdates           | 432           |
| policy_entropy     | 0.7784881     |
| policy_loss        | 0.00041119894 |
| serial_timesteps   | 172800        |
| time_elapsed       | 3.87e+03      |
| time_remaining     | 47.4          |
| total_timesteps    | 5184000       |
| true_eprew         | 81.2          |
| value_loss         | 14.866534     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.568250417709351 seconds
Total simulation time for 400 steps: 7.815245628356934 	 Other agent action time: 0 	 51.182012571509595 steps/s
Curr learning rate 0.001068 	 Curr reward per step 0.18666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.15it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 185.08it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 197.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 196.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.21it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.85it/s]
-------------------------------------
| approxkl           | 0.0048299204 |
| clipfrac           | 0.35170835   |
| eplenmean          | 400          |
| eprewmean          | 80.8         |
| explained_variance | 0.608        |
| fps                | 1415         |
| nupdates           | 433          |
| policy_entropy     | 0.8105517    |
| policy_loss        | 0.0009710459 |
| serial_timesteps   | 173200       |
| time_elapsed       | 3.88e+03     |
| time_remaining     | 47.3         |
| total_timesteps    | 5196000      |
| true_eprew         | 80.8         |
| value_loss         | 16.571655    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.620667219161987 seconds
Total simulation time for 400 steps: 7.876679182052612 	 Other agent action time: 0 	 50.782822399497874 steps/s
Curr learning rate 0.001067 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.07it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.83it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.63it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.61it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.51it/s]
-------------------------------------
| approxkl           | 0.005797827  |
| clipfrac           | 0.3582396    |
| eplenmean          | 400          |
| eprewmean          | 79.6         |
| explained_variance | 0.656        |
| fps                | 1397         |
| nupdates           | 434          |
| policy_entropy     | 0.799231     |
| policy_loss        | 0.0023717333 |
| serial_timesteps   | 173600       |
| time_elapsed       | 3.88e+03     |
| time_remaining     | 47.1         |
| total_timesteps    | 5208000      |
| true_eprew         | 79.6         |
| value_loss         | 15.051406    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.665477514266968 seconds
Total simulation time for 400 steps: 7.9403603076934814 	 Other agent action time: 0 	 50.37554777110513 steps/s
Curr learning rate 0.001066 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.45it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.54it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.65it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.35it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.85it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.51it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.91it/s]
-------------------------------------
| approxkl           | 0.005052725  |
| clipfrac           | 0.33835417   |
| eplenmean          | 400          |
| eprewmean          | 80.8         |
| explained_variance | 0.618        |
| fps                | 1387         |
| nupdates           | 435          |
| policy_entropy     | 0.7632279    |
| policy_loss        | 0.0022444867 |
| serial_timesteps   | 174000       |
| time_elapsed       | 3.89e+03     |
| time_remaining     | 47           |
| total_timesteps    | 5220000      |
| true_eprew         | 80.8         |
| value_loss         | 15.805203    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.600194692611694 seconds
Total simulation time for 400 steps: 7.846004009246826 	 Other agent action time: 0 	 50.981365740902525 steps/s
Curr learning rate 0.001065 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.03it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.79it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.89it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.12it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.00it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.45it/s]
--------------------------------------
| approxkl           | 0.004620471   |
| clipfrac           | 0.31733328    |
| eplenmean          | 400           |
| eprewmean          | 82.2          |
| explained_variance | 0.61          |
| fps                | 1403          |
| nupdates           | 436           |
| policy_entropy     | 0.76387906    |
| policy_loss        | 0.00093872234 |
| serial_timesteps   | 174400        |
| time_elapsed       | 3.9e+03       |
| time_remaining     | 46.8          |
| total_timesteps    | 5232000       |
| true_eprew         | 82.2          |
| value_loss         | 16.409163     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.643668174743652 seconds
Total simulation time for 400 steps: 7.874948501586914 	 Other agent action time: 0 	 50.79398295993864 steps/s
Curr learning rate 0.001064 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.26it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.92it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.27it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.39it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.85it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.00it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]
-------------------------------------
| approxkl           | 0.0047785128 |
| clipfrac           | 0.3191667    |
| eplenmean          | 400          |
| eprewmean          | 83           |
| explained_variance | 0.601        |
| fps                | 1398         |
| nupdates           | 437          |
| policy_entropy     | 0.74086076   |
| policy_loss        | 0.0029353045 |
| serial_timesteps   | 174800       |
| time_elapsed       | 3.91e+03     |
| time_remaining     | 46.7         |
| total_timesteps    | 5244000      |
| true_eprew         | 83           |
| value_loss         | 16.630968    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.63630223274231 seconds
Total simulation time for 400 steps: 7.891135931015015 	 Other agent action time: 0 	 50.68978705940871 steps/s
Curr learning rate 0.0010630000000000001 	 Curr reward per step 0.17666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 179.89it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 185.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.12it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.62it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.42it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.99it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.85it/s]
--------------------------------------
| approxkl           | 0.0035946039  |
| clipfrac           | 0.2915937     |
| eplenmean          | 400           |
| eprewmean          | 79.2          |
| explained_variance | 0.597         |
| fps                | 1398          |
| nupdates           | 438           |
| policy_entropy     | 0.7910487     |
| policy_loss        | 0.00016660731 |
| serial_timesteps   | 175200        |
| time_elapsed       | 3.92e+03      |
| time_remaining     | 46.5          |
| total_timesteps    | 5256000       |
| true_eprew         | 79.2          |
| value_loss         | 18.448753     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.593592643737793 seconds
Total simulation time for 400 steps: 7.819977760314941 	 Other agent action time: 0 	 51.15104061164113 steps/s
Curr learning rate 0.001062 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.10it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 164.57it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.36it/s]
--------------------------------------
| approxkl           | 0.0047723786  |
| clipfrac           | 0.313698      |
| eplenmean          | 400           |
| eprewmean          | 77.8          |
| explained_variance | 0.633         |
| fps                | 1406          |
| nupdates           | 439           |
| policy_entropy     | 0.7055502     |
| policy_loss        | 0.00036794803 |
| serial_timesteps   | 175600        |
| time_elapsed       | 3.93e+03      |
| time_remaining     | 46.4          |
| total_timesteps    | 5268000       |
| true_eprew         | 77.8          |
| value_loss         | 16.752684     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.644991874694824 seconds
Total simulation time for 400 steps: 7.988409519195557 	 Other agent action time: 0 	 50.072545609840056 steps/s
Curr learning rate 0.0010609999999999999 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 186.38it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 187.07it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.77it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.79it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 199.33it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.08it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 200.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 200.75it/s]
--------------------------------------
| approxkl           | 0.0045051253  |
| clipfrac           | 0.33128124    |
| eplenmean          | 400           |
| eprewmean          | 78            |
| explained_variance | 0.631         |
| fps                | 1389          |
| nupdates           | 440           |
| policy_entropy     | 0.77636415    |
| policy_loss        | 0.00039438743 |
| serial_timesteps   | 176000        |
| time_elapsed       | 3.94e+03      |
| time_remaining     | 46.2          |
| total_timesteps    | 5280000       |
| true_eprew         | 78            |
| value_loss         | 16.914951     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.607017755508423 seconds
Total simulation time for 400 steps: 7.7571656703948975 	 Other agent action time: 0 	 51.565225882256684 steps/s
Curr learning rate 0.00106 	 Curr reward per step 0.18333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 179.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.68it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.49it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.54it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.75it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.43it/s]
-------------------------------------
| approxkl           | 0.0049896096 |
| clipfrac           | 0.32897916   |
| eplenmean          | 400          |
| eprewmean          | 77.4         |
| explained_variance | 0.61         |
| fps                | 1423         |
| nupdates           | 441          |
| policy_entropy     | 0.729886     |
| policy_loss        | 0.0013501627 |
| serial_timesteps   | 176400       |
| time_elapsed       | 3.94e+03     |
| time_remaining     | 46.1         |
| total_timesteps    | 5292000      |
| true_eprew         | 77.4         |
| value_loss         | 17.29525     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.668431997299194 seconds
Total simulation time for 400 steps: 7.89940881729126 	 Other agent action time: 0 	 50.6367007015041 steps/s
Curr learning rate 0.001059 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.54it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.81it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.07it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.07it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 198.18it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 203.14it/s]
--------------------------------------
| approxkl           | 0.004123846   |
| clipfrac           | 0.31595832    |
| eplenmean          | 400           |
| eprewmean          | 76.2          |
| explained_variance | 0.663         |
| fps                | 1398          |
| nupdates           | 442           |
| policy_entropy     | 0.7499948     |
| policy_loss        | 0.00083380693 |
| serial_timesteps   | 176800        |
| time_elapsed       | 3.95e+03      |
| time_remaining     | 45.9          |
| total_timesteps    | 5304000       |
| true_eprew         | 76.2          |
| value_loss         | 15.268655     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.70500111579895 seconds
Total simulation time for 400 steps: 8.048881769180298 	 Other agent action time: 0 	 49.69634434582286 steps/s
Curr learning rate 0.001058 	 Curr reward per step 0.185

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.58it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.74it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.29it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.26it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.28it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.36it/s]
-------------------------------------
| approxkl           | 0.0051376666 |
| clipfrac           | 0.35608333   |
| eplenmean          | 400          |
| eprewmean          | 76.4         |
| explained_variance | 0.587        |
| fps                | 1373         |
| nupdates           | 443          |
| policy_entropy     | 0.78928435   |
| policy_loss        | 0.001729006  |
| serial_timesteps   | 177200       |
| time_elapsed       | 3.96e+03     |
| time_remaining     | 45.7         |
| total_timesteps    | 5316000      |
| true_eprew         | 76.4         |
| value_loss         | 18.035534    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.605128765106201 seconds
Total simulation time for 400 steps: 7.827726364135742 	 Other agent action time: 0 	 51.10040660499812 steps/s
Curr learning rate 0.001057 	 Curr reward per step 0.18666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 181.79it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.01it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.67it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.47it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 196.14it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 197.39it/s]
--------------------------------------
| approxkl           | 0.0048749973  |
| clipfrac           | 0.33812505    |
| eplenmean          | 400           |
| eprewmean          | 75.4          |
| explained_variance | 0.628         |
| fps                | 1414          |
| nupdates           | 444           |
| policy_entropy     | 0.76638216    |
| policy_loss        | 0.00032196494 |
| serial_timesteps   | 177600        |
| time_elapsed       | 3.97e+03      |
| time_remaining     | 45.6          |
| total_timesteps    | 5328000       |
| true_eprew         | 75.4          |
| value_loss         | 18.05697      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.692052602767944 seconds
Total simulation time for 400 steps: 7.891278982162476 	 Other agent action time: 0 	 50.68886816752568 steps/s
Curr learning rate 0.001056 	 Curr reward per step 0.19166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.30it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.87it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.79it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 171.97it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.94it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.34it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.91it/s]
--------------------------------------
| approxkl           | 0.0038730113  |
| clipfrac           | 0.30289587    |
| eplenmean          | 400           |
| eprewmean          | 76.8          |
| explained_variance | 0.66          |
| fps                | 1394          |
| nupdates           | 445           |
| policy_entropy     | 0.72982997    |
| policy_loss        | 0.00086458126 |
| serial_timesteps   | 178000        |
| time_elapsed       | 3.98e+03      |
| time_remaining     | 45.4          |
| total_timesteps    | 5340000       |
| true_eprew         | 76.8          |
| value_loss         | 16.406366     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.666594743728638 seconds
Total simulation time for 400 steps: 7.914754629135132 	 Other agent action time: 0 	 50.5385218800787 steps/s
Curr learning rate 0.001055 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.96it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.54it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.92it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.38it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.68it/s]
-------------------------------------
| approxkl           | 0.0056454297 |
| clipfrac           | 0.33443746   |
| eplenmean          | 400          |
| eprewmean          | 75.4         |
| explained_variance | 0.686        |
| fps                | 1395         |
| nupdates           | 446          |
| policy_entropy     | 0.7263335    |
| policy_loss        | 0.0016558507 |
| serial_timesteps   | 178400       |
| time_elapsed       | 3.99e+03     |
| time_remaining     | 45.3         |
| total_timesteps    | 5352000      |
| true_eprew         | 75.4         |
| value_loss         | 14.051839    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.5677900314331055 seconds
Total simulation time for 400 steps: 7.969658613204956 	 Other agent action time: 0 	 50.19035562417172 steps/s
Curr learning rate 0.001054 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 196.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 185.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.21it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.78it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.18it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.16it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.68it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.36it/s]
--------------------------------------
| approxkl           | 0.0045940084  |
| clipfrac           | 0.31580204    |
| eplenmean          | 400           |
| eprewmean          | 77.4          |
| explained_variance | 0.616         |
| fps                | 1388          |
| nupdates           | 447           |
| policy_entropy     | 0.7222329     |
| policy_loss        | 0.00074215856 |
| serial_timesteps   | 178800        |
| time_elapsed       | 4e+03         |
| time_remaining     | 45.1          |
| total_timesteps    | 5364000       |
| true_eprew         | 77.4          |
| value_loss         | 17.396444     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.70771336555481 seconds
Total simulation time for 400 steps: 7.901325225830078 	 Other agent action time: 0 	 50.62441914077493 steps/s
Curr learning rate 0.0010530000000000001 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 193.17it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.29it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.68it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.02it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.07it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 200.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 202.14it/s]
-------------------------------------
| approxkl           | 0.0046289586 |
| clipfrac           | 0.32016656   |
| eplenmean          | 400          |
| eprewmean          | 77.8         |
| explained_variance | 0.611        |
| fps                | 1400         |
| nupdates           | 448          |
| policy_entropy     | 0.7364129    |
| policy_loss        | 0.0015150174 |
| serial_timesteps   | 179200       |
| time_elapsed       | 4e+03        |
| time_remaining     | 45           |
| total_timesteps    | 5376000      |
| true_eprew         | 77.8         |
| value_loss         | 16.578642    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.625966787338257 seconds
Total simulation time for 400 steps: 7.909396648406982 	 Other agent action time: 0 	 50.572757668002815 steps/s
Curr learning rate 0.001052 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 184.73it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.26it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.08it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.28it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.12it/s]
--------------------------------------
| approxkl           | 0.004265868   |
| clipfrac           | 0.2896146     |
| eplenmean          | 400           |
| eprewmean          | 79.2          |
| explained_variance | 0.588         |
| fps                | 1398          |
| nupdates           | 449           |
| policy_entropy     | 0.7306491     |
| policy_loss        | 0.00040369842 |
| serial_timesteps   | 179600        |
| time_elapsed       | 4.01e+03      |
| time_remaining     | 44.8          |
| total_timesteps    | 5388000       |
| true_eprew         | 79.2          |
| value_loss         | 18.168642     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.76038384437561 seconds
Total simulation time for 400 steps: 8.05023193359375 	 Other agent action time: 0 	 49.688009401417794 steps/s
Curr learning rate 0.001051 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.35it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.07it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.06it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.40it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.50it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.34it/s]
-------------------------------------
| approxkl           | 0.0046506883 |
| clipfrac           | 0.30927074   |
| eplenmean          | 400          |
| eprewmean          | 80.4         |
| explained_variance | 0.615        |
| fps                | 1371         |
| nupdates           | 450          |
| policy_entropy     | 0.7126397    |
| policy_loss        | 0.0016520034 |
| serial_timesteps   | 180000       |
| time_elapsed       | 4.02e+03     |
| time_remaining     | 44.7         |
| total_timesteps    | 5400000      |
| true_eprew         | 80.4         |
| value_loss         | 16.948523    |
-------------------------------------
Current reward shaping 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←1X ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←1X ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←1X ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø2X 
O ←oX   P 
O   Xo↓0X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø3X 
O →oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø6X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø7X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø9X 
O ←oX →oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø10X 
O ←oX →0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø11X 
O →oX ←0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →oX ←0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø13X 
O →1Xo←0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø14X 
O →1X ←oø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X ø15X 
O ←1X →oø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø16X 
O ←1X →0ø=
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø17X 
O ←oX   ø=
O   Xo↓0X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø18X 
O ←oX   ø=
O   Xo→0X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø19X 
O →oX   ø=
O   Xo→0X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo  ø=
O   Xo→0X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo  ø=
O   Xo←0X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo  ø=
O   X ←oX 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑oø=
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo→oø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 69
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo→oø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 70
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo→oø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 71
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   Xo→0ø1
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 72
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo→0ø2
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 73
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   Xo→0ø3
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo→0ø4
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 75
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø5
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dXo↑0ø6
O   X   X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dXo  ø7
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dXo↑0ø8
O   X   X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dXo←0ø9
O   X   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dX ←oø10
O   X   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø11
O ↓dX   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø12
O ↓dX ↓0X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø13
O ↓dX   X 
D   X ↓0X 
X X X S X 


Timestep: 84
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø14
O →dX   X 
D   X ←0X 
X X X S X 


Timestep: 85
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø15
O →dX   X 
D   X ←0X 
X X X S X 


Timestep: 86
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø16
O →dX   X 
D   X ←0X 
X X X S X 


Timestep: 87
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø17
O →dX   X 
D   X ←0X 
X X X S X 


Timestep: 88
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø18
O →1Xd  X 
D   X →0X 
X X X S X 


Timestep: 89
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø19
O   Xd  X 
D ↓1X →0X 
X X X S X 


Timestep: 90
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D ↓1X ↓0X 
X X X S X 


Timestep: 91
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D ↓1X ↓0X 
X X X S X 


Timestep: 92
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D ↓1X ↓0X 
X X X S X 


Timestep: 93
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D ←1X ↓0X 
X X X S X 


Timestep: 94
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D ←dX ←0X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D ←dX ←0X 
X X X S X 


Timestep: 96
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D ←dX ←0X 
X X X S X 


Timestep: 97
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D →dX ←0X 
X X X S X 


Timestep: 98
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D →1Xd←0X 
X X X S X 


Timestep: 99
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   Xd  X 
D →1Xd←0X 
X X X S X 


tot rew 140 tot rew shaped 125
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O →1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ↓oX   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ↓oX   X 
X X X S X 


Timestep: 9
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ↓oX ↓0X 
X X X S X 


Timestep: 10
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ↓oX ↓0X 
X X X S X 


Timestep: 11
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D →oX ↓0X 
X X X S X 


Timestep: 14
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX ↑0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ↓oX   X 
X X X S X 


Timestep: 16
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 17
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 20
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 21
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 22
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 23
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX   X 
D   X ↓0X 
X X X S X 


Timestep: 24
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↑0X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ↑0X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 45
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 46
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 47
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 48
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D →oX   X 
X X X S X 


Timestep: 49
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX   X 
D   X ↓0X 
X X X S X 


Timestep: 50
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 51
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 52
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↑0X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ↓oX   X 
D   X ↓0X 
X X X S X 


Timestep: 79
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑oX   P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 80
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX   P 
O   X ↑0X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 3
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.623149156570435 seconds
Total simulation time for 400 steps: 7.889344692230225 	 Other agent action time: 0 	 50.70129593829734 steps/s
Curr learning rate 0.0010500000000000002 	 Curr reward per step 0.19

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 208.31it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 212.28it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 191.53it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.19it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.90it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.61it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.62it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.89it/s]
-------------------------------------
| approxkl           | 0.005620739  |
| clipfrac           | 0.3471042    |
| eplenmean          | 400          |
| eprewmean          | 79.2         |
| explained_variance | 0.652        |
| fps                | 1406         |
| nupdates           | 451          |
| policy_entropy     | 0.77696455   |
| policy_loss        | 0.0023406728 |
| serial_timesteps   | 180400       |
| time_elapsed       | 4.03e+03     |
| time_remaining     | 44.5         |
| total_timesteps    | 5412000      |
| true_eprew         | 79.2         |
| value_loss         | 16.26653     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.68870735168457 seconds
Total simulation time for 400 steps: 7.970531702041626 	 Other agent action time: 0 	 50.18485779280462 steps/s
Curr learning rate 0.001049 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.34it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.68it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.45it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.47it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.42it/s]
-------------------------------------
| approxkl           | 0.0048220237 |
| clipfrac           | 0.32293755   |
| eplenmean          | 400          |
| eprewmean          | 81           |
| explained_variance | 0.642        |
| fps                | 1386         |
| nupdates           | 452          |
| policy_entropy     | 0.7410232    |
| policy_loss        | 0.0010753713 |
| serial_timesteps   | 180800       |
| time_elapsed       | 4.04e+03     |
| time_remaining     | 44.4         |
| total_timesteps    | 5424000      |
| true_eprew         | 81           |
| value_loss         | 16.304476    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.746353626251221 seconds
Total simulation time for 400 steps: 8.036526203155518 	 Other agent action time: 0 	 49.772748808177994 steps/s
Curr learning rate 0.0010479999999999999 	 Curr reward per step 0.17666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.16it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 193.14it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.00it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.22it/s]
-------------------------------------
| approxkl           | 0.0049526924 |
| clipfrac           | 0.34727088   |
| eplenmean          | 400          |
| eprewmean          | 79           |
| explained_variance | 0.608        |
| fps                | 1375         |
| nupdates           | 453          |
| policy_entropy     | 0.79905945   |
| policy_loss        | 0.0016026908 |
| serial_timesteps   | 181200       |
| time_elapsed       | 4.05e+03     |
| time_remaining     | 44.2         |
| total_timesteps    | 5436000      |
| true_eprew         | 79           |
| value_loss         | 17.717508    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.787411689758301 seconds
Total simulation time for 400 steps: 8.174763441085815 	 Other agent action time: 0 	 48.931079520861324 steps/s
Curr learning rate 0.001047 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 179.80it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 187.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.49it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 195.71it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.34it/s]
-------------------------------------
| approxkl           | 0.0046382146 |
| clipfrac           | 0.32922918   |
| eplenmean          | 400          |
| eprewmean          | 79.4         |
| explained_variance | 0.647        |
| fps                | 1357         |
| nupdates           | 454          |
| policy_entropy     | 0.7816382    |
| policy_loss        | 0.002383061  |
| serial_timesteps   | 181600       |
| time_elapsed       | 4.06e+03     |
| time_remaining     | 44.1         |
| total_timesteps    | 5448000      |
| true_eprew         | 79.4         |
| value_loss         | 17.027493    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.760279655456543 seconds
Total simulation time for 400 steps: 8.038301706314087 	 Other agent action time: 0 	 49.761754984364416 steps/s
Curr learning rate 0.001046 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.46it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.44it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.14it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.60it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.42it/s]
-------------------------------------
| approxkl           | 0.0050271275 |
| clipfrac           | 0.33082297   |
| eplenmean          | 400          |
| eprewmean          | 78.6         |
| explained_variance | 0.665        |
| fps                | 1371         |
| nupdates           | 455          |
| policy_entropy     | 0.74867725   |
| policy_loss        | 0.0013949362 |
| serial_timesteps   | 182000       |
| time_elapsed       | 4.07e+03     |
| time_remaining     | 43.9         |
| total_timesteps    | 5460000      |
| true_eprew         | 78.6         |
| value_loss         | 14.947916    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.788010835647583 seconds
Total simulation time for 400 steps: 8.119585990905762 	 Other agent action time: 0 	 49.263595514354414 steps/s
Curr learning rate 0.001045 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.28it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.33it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.21it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.57it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.91it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.70it/s]
-------------------------------------
| approxkl           | 0.005735286  |
| clipfrac           | 0.3397083    |
| eplenmean          | 400          |
| eprewmean          | 80           |
| explained_variance | 0.624        |
| fps                | 1361         |
| nupdates           | 456          |
| policy_entropy     | 0.71784246   |
| policy_loss        | 0.0014009207 |
| serial_timesteps   | 182400       |
| time_elapsed       | 4.08e+03     |
| time_remaining     | 43.8         |
| total_timesteps    | 5472000      |
| true_eprew         | 80           |
| value_loss         | 15.84957     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8088672161102295 seconds
Total simulation time for 400 steps: 8.12896990776062 	 Other agent action time: 0 	 49.20672662573462 steps/s
Curr learning rate 0.001044 	 Curr reward per step 0.195

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.08it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.71it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.98it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.37it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.51it/s]
--------------------------------------
| approxkl           | 0.002985494   |
| clipfrac           | 0.28547913    |
| eplenmean          | 400           |
| eprewmean          | 80.6          |
| explained_variance | 0.574         |
| fps                | 1360          |
| nupdates           | 457           |
| policy_entropy     | 0.7484227     |
| policy_loss        | 0.00040727353 |
| serial_timesteps   | 182800        |
| time_elapsed       | 4.08e+03      |
| time_remaining     | 43.6          |
| total_timesteps    | 5484000       |
| true_eprew         | 80.6          |
| value_loss         | 19.302402     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8341591358184814 seconds
Total simulation time for 400 steps: 8.263413667678833 	 Other agent action time: 0 	 48.40614497668719 steps/s
Curr learning rate 0.001043 	 Curr reward per step 0.18666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.46it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.27it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.30it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.43it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.90it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.36it/s]
-------------------------------------
| approxkl           | 0.0045453426 |
| clipfrac           | 0.32710418   |
| eplenmean          | 400          |
| eprewmean          | 78.8         |
| explained_variance | 0.557        |
| fps                | 1340         |
| nupdates           | 458          |
| policy_entropy     | 0.7549417    |
| policy_loss        | 0.0011343786 |
| serial_timesteps   | 183200       |
| time_elapsed       | 4.09e+03     |
| time_remaining     | 43.5         |
| total_timesteps    | 5496000      |
| true_eprew         | 78.8         |
| value_loss         | 18.441383    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.6847333908081055 seconds
Total simulation time for 400 steps: 7.992788314819336 	 Other agent action time: 0 	 50.045113700604915 steps/s
Curr learning rate 0.001042 	 Curr reward per step 0.18666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.37it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.57it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.77it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.40it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.61it/s]
-------------------------------------
| approxkl           | 0.0031970215 |
| clipfrac           | 0.2804063    |
| eplenmean          | 400          |
| eprewmean          | 77           |
| explained_variance | 0.613        |
| fps                | 1383         |
| nupdates           | 459          |
| policy_entropy     | 0.7544814    |
| policy_loss        | 0.0003463358 |
| serial_timesteps   | 183600       |
| time_elapsed       | 4.1e+03      |
| time_remaining     | 43.3         |
| total_timesteps    | 5508000      |
| true_eprew         | 77           |
| value_loss         | 18.055822    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.718813180923462 seconds
Total simulation time for 400 steps: 8.022719621658325 	 Other agent action time: 0 	 49.85840448918973 steps/s
Curr learning rate 0.001041 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.92it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.02it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.53it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.67it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.05it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.87it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.57it/s]
------------------------------------
| approxkl           | 0.004679591 |
| clipfrac           | 0.31970826  |
| eplenmean          | 400         |
| eprewmean          | 75.8        |
| explained_variance | 0.636       |
| fps                | 1378        |
| nupdates           | 460         |
| policy_entropy     | 0.74103516  |
| policy_loss        | 0.001517716 |
| serial_timesteps   | 184000      |
| time_elapsed       | 4.11e+03    |
| time_remaining     | 43.2        |
| total_timesteps    | 5520000     |
| true_eprew         | 75.8        |
| value_loss         | 17.586853   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.746906757354736 seconds
Total simulation time for 400 steps: 8.128709554672241 	 Other agent action time: 0 	 49.208302659809874 steps/s
Curr learning rate 0.0010400000000000001 	 Curr reward per step 0.205

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.98it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.64it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.43it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.12it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.02it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.79it/s]
-------------------------------------
| approxkl           | 0.0027280173 |
| clipfrac           | 0.2520416    |
| eplenmean          | 400          |
| eprewmean          | 77.6         |
| explained_variance | 0.57         |
| fps                | 1358         |
| nupdates           | 461          |
| policy_entropy     | 0.7049627    |
| policy_loss        | -0.000393804 |
| serial_timesteps   | 184400       |
| time_elapsed       | 4.12e+03     |
| time_remaining     | 43           |
| total_timesteps    | 5532000      |
| true_eprew         | 77.6         |
| value_loss         | 17.069548    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.869830846786499 seconds
Total simulation time for 400 steps: 8.183462858200073 	 Other agent action time: 0 	 48.87906341496841 steps/s
Curr learning rate 0.001039 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.89it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.64it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 158.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.93it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.47it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.99it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.92it/s]
-------------------------------------
| approxkl           | 0.004571284  |
| clipfrac           | 0.2933125    |
| eplenmean          | 400          |
| eprewmean          | 81.4         |
| explained_variance | 0.573        |
| fps                | 1348         |
| nupdates           | 462          |
| policy_entropy     | 0.6732059    |
| policy_loss        | 0.0006235294 |
| serial_timesteps   | 184800       |
| time_elapsed       | 4.13e+03     |
| time_remaining     | 42.9         |
| total_timesteps    | 5544000      |
| true_eprew         | 81.4         |
| value_loss         | 17.515814    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.753429412841797 seconds
Total simulation time for 400 steps: 8.102308750152588 	 Other agent action time: 0 	 49.36864446105771 steps/s
Curr learning rate 0.001038 	 Curr reward per step 0.205

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.48it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.02it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.70it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.84it/s]
-------------------------------------
| approxkl           | 0.005716361  |
| clipfrac           | 0.3396146    |
| eplenmean          | 400          |
| eprewmean          | 83           |
| explained_variance | 0.593        |
| fps                | 1362         |
| nupdates           | 463          |
| policy_entropy     | 0.7198893    |
| policy_loss        | 0.0030785396 |
| serial_timesteps   | 185200       |
| time_elapsed       | 4.14e+03     |
| time_remaining     | 42.7         |
| total_timesteps    | 5556000      |
| true_eprew         | 83           |
| value_loss         | 17.994253    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.908556222915649 seconds
Total simulation time for 400 steps: 8.254003763198853 	 Other agent action time: 0 	 48.46132997702673 steps/s
Curr learning rate 0.0010370000000000002 	 Curr reward per step 0.195

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.43it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.39it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 188.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.65it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.85it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.65it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.67it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.90it/s]
-------------------------------------
| approxkl           | 0.0049739573 |
| clipfrac           | 0.33035424   |
| eplenmean          | 400          |
| eprewmean          | 82.4         |
| explained_variance | 0.662        |
| fps                | 1341         |
| nupdates           | 464          |
| policy_entropy     | 0.72257644   |
| policy_loss        | 0.0018140728 |
| serial_timesteps   | 185600       |
| time_elapsed       | 4.15e+03     |
| time_remaining     | 42.6         |
| total_timesteps    | 5568000      |
| true_eprew         | 82.4         |
| value_loss         | 15.130045    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.818537473678589 seconds
Total simulation time for 400 steps: 8.12700629234314 	 Other agent action time: 0 	 49.21861576222231 steps/s
Curr learning rate 0.001036 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.66it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.24it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.50it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.78it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.13it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.26it/s]
-------------------------------------
| approxkl           | 0.003740519  |
| clipfrac           | 0.29760417   |
| eplenmean          | 400          |
| eprewmean          | 82.6         |
| explained_variance | 0.629        |
| fps                | 1363         |
| nupdates           | 465          |
| policy_entropy     | 0.7124932    |
| policy_loss        | 0.0014863326 |
| serial_timesteps   | 186000       |
| time_elapsed       | 4.16e+03     |
| time_remaining     | 42.4         |
| total_timesteps    | 5580000      |
| true_eprew         | 82.6         |
| value_loss         | 17.191769    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.868762731552124 seconds
Total simulation time for 400 steps: 8.194448947906494 	 Other agent action time: 0 	 48.81353249533532 steps/s
Curr learning rate 0.001035 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.87it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 172.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.67it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.33it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.14it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.99it/s]
-------------------------------------
| approxkl           | 0.0040413956 |
| clipfrac           | 0.2978229    |
| eplenmean          | 400          |
| eprewmean          | 81           |
| explained_variance | 0.655        |
| fps                | 1350         |
| nupdates           | 466          |
| policy_entropy     | 0.6856132    |
| policy_loss        | 8.19458e-05  |
| serial_timesteps   | 186400       |
| time_elapsed       | 4.16e+03     |
| time_remaining     | 42.3         |
| total_timesteps    | 5592000      |
| true_eprew         | 81           |
| value_loss         | 16.902464    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.718619346618652 seconds
Total simulation time for 400 steps: 8.03263258934021 	 Other agent action time: 0 	 49.79687487895615 steps/s
Curr learning rate 0.001034 	 Curr reward per step 0.205

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.24it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.84it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.85it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.84it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.40it/s]
-------------------------------------
| approxkl           | 0.0063737803 |
| clipfrac           | 0.33737502   |
| eplenmean          | 400          |
| eprewmean          | 82.6         |
| explained_variance | 0.617        |
| fps                | 1370         |
| nupdates           | 467          |
| policy_entropy     | 0.7024536    |
| policy_loss        | 0.0025386254 |
| serial_timesteps   | 186800       |
| time_elapsed       | 4.17e+03     |
| time_remaining     | 42.1         |
| total_timesteps    | 5604000      |
| true_eprew         | 82.6         |
| value_loss         | 17.364714    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.945091009140015 seconds
Total simulation time for 400 steps: 8.373964786529541 	 Other agent action time: 0 	 47.76709840521956 steps/s
Curr learning rate 0.001033 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.97it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 148.05it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 147.59it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 157.21it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 162.30it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.36it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.95it/s]
-------------------------------------
| approxkl           | 0.0045508444 |
| clipfrac           | 0.3119584    |
| eplenmean          | 400          |
| eprewmean          | 83           |
| explained_variance | 0.623        |
| fps                | 1313         |
| nupdates           | 468          |
| policy_entropy     | 0.7029155    |
| policy_loss        | 0.0011874295 |
| serial_timesteps   | 187200       |
| time_elapsed       | 4.18e+03     |
| time_remaining     | 42           |
| total_timesteps    | 5616000      |
| true_eprew         | 83           |
| value_loss         | 18.057482    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7585179805755615 seconds
Total simulation time for 400 steps: 8.213187217712402 	 Other agent action time: 0 	 48.70216511531208 steps/s
Curr learning rate 0.001032 	 Curr reward per step 0.17666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.61it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.84it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.53it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 167.88it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.39it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.12it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.76it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 167.99it/s]
--------------------------------------
| approxkl           | 0.0039714742  |
| clipfrac           | 0.3118959     |
| eplenmean          | 400           |
| eprewmean          | 81            |
| explained_variance | 0.643         |
| fps                | 1338          |
| nupdates           | 469           |
| policy_entropy     | 0.7740841     |
| policy_loss        | 0.00010951584 |
| serial_timesteps   | 187600        |
| time_elapsed       | 4.19e+03      |
| time_remaining     | 41.8          |
| total_timesteps    | 5628000       |
| true_eprew         | 81            |
| value_loss         | 17.756992     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.747225522994995 seconds
Total simulation time for 400 steps: 8.115052461624146 	 Other agent action time: 0 	 49.29111695723333 steps/s
Curr learning rate 0.001031 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.60it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.30it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 197.39it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 196.55it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.21it/s]
------------------------------------
| approxkl           | 0.003770746 |
| clipfrac           | 0.29148954  |
| eplenmean          | 400         |
| eprewmean          | 81          |
| explained_variance | 0.641       |
| fps                | 1366        |
| nupdates           | 470         |
| policy_entropy     | 0.7034916   |
| policy_loss        | 0.000648497 |
| serial_timesteps   | 188000      |
| time_elapsed       | 4.2e+03     |
| time_remaining     | 41.7        |
| total_timesteps    | 5640000     |
| true_eprew         | 81          |
| value_loss         | 16.680767   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.82806658744812 seconds
Total simulation time for 400 steps: 8.111124038696289 	 Other agent action time: 0 	 49.31498989433436 steps/s
Curr learning rate 0.00103 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.89it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 157.70it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.89it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.71it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 166.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.27it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 167.86it/s]
-------------------------------------
| approxkl           | 0.005018317  |
| clipfrac           | 0.31834373   |
| eplenmean          | 400          |
| eprewmean          | 78.6         |
| explained_variance | 0.613        |
| fps                | 1357         |
| nupdates           | 471          |
| policy_entropy     | 0.70667523   |
| policy_loss        | 0.0026312815 |
| serial_timesteps   | 188400       |
| time_elapsed       | 4.21e+03     |
| time_remaining     | 41.5         |
| total_timesteps    | 5652000      |
| true_eprew         | 78.6         |
| value_loss         | 17.126223    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.871056318283081 seconds
Total simulation time for 400 steps: 8.236703872680664 	 Other agent action time: 0 	 48.56311531688204 steps/s
Curr learning rate 0.001029 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.10it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.58it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.84it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.99it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.30it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.27it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.70it/s]
-------------------------------------
| approxkl           | 0.0042633247 |
| clipfrac           | 0.29784372   |
| eplenmean          | 400          |
| eprewmean          | 82.2         |
| explained_variance | 0.641        |
| fps                | 1346         |
| nupdates           | 472          |
| policy_entropy     | 0.6844241    |
| policy_loss        | 0.0020727464 |
| serial_timesteps   | 188800       |
| time_elapsed       | 4.22e+03     |
| time_remaining     | 41.4         |
| total_timesteps    | 5664000      |
| true_eprew         | 82.2         |
| value_loss         | 16.593416    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.720280408859253 seconds
Total simulation time for 400 steps: 7.957615375518799 	 Other agent action time: 0 	 50.26631485992396 steps/s
Curr learning rate 0.001028 	 Curr reward per step 0.225

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.09it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.53it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.30it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.02it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.94it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.09it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.36it/s]
-------------------------------------
| approxkl           | 0.0064969338 |
| clipfrac           | 0.32865626   |
| eplenmean          | 400          |
| eprewmean          | 84           |
| explained_variance | 0.646        |
| fps                | 1387         |
| nupdates           | 473          |
| policy_entropy     | 0.6636147    |
| policy_loss        | 0.0017877453 |
| serial_timesteps   | 189200       |
| time_elapsed       | 4.23e+03     |
| time_remaining     | 41.2         |
| total_timesteps    | 5676000      |
| true_eprew         | 84           |
| value_loss         | 15.811629    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.728620529174805 seconds
Total simulation time for 400 steps: 7.964484214782715 	 Other agent action time: 0 	 50.222963498071636 steps/s
Curr learning rate 0.001027 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.11it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.97it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.75it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.27it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.06it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.40it/s]
-------------------------------------
| approxkl           | 0.0053560394 |
| clipfrac           | 0.3310834    |
| eplenmean          | 400          |
| eprewmean          | 85.2         |
| explained_variance | 0.653        |
| fps                | 1386         |
| nupdates           | 474          |
| policy_entropy     | 0.71283567   |
| policy_loss        | 0.001273136  |
| serial_timesteps   | 189600       |
| time_elapsed       | 4.23e+03     |
| time_remaining     | 41.1         |
| total_timesteps    | 5688000      |
| true_eprew         | 85.2         |
| value_loss         | 15.353427    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.806508779525757 seconds
Total simulation time for 400 steps: 8.127619981765747 	 Other agent action time: 0 	 49.21489942903297 steps/s
Curr learning rate 0.001026 	 Curr reward per step 0.22166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.23it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 157.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.47it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.01it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.97it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.37it/s]
-------------------------------------
| approxkl           | 0.0055054934 |
| clipfrac           | 0.32775      |
| eplenmean          | 400          |
| eprewmean          | 86.6         |
| explained_variance | 0.675        |
| fps                | 1356         |
| nupdates           | 475          |
| policy_entropy     | 0.70986944   |
| policy_loss        | 0.0018372168 |
| serial_timesteps   | 190000       |
| time_elapsed       | 4.24e+03     |
| time_remaining     | 40.9         |
| total_timesteps    | 5700000      |
| true_eprew         | 86.6         |
| value_loss         | 15.227219    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.755815029144287 seconds
Total simulation time for 400 steps: 8.090922355651855 	 Other agent action time: 0 	 49.438121195240846 steps/s
Curr learning rate 0.001025 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.60it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.57it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.66it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.31it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.44it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.31it/s]
-------------------------------------
| approxkl           | 0.005193653  |
| clipfrac           | 0.33290628   |
| eplenmean          | 400          |
| eprewmean          | 83.6         |
| explained_variance | 0.623        |
| fps                | 1360         |
| nupdates           | 476          |
| policy_entropy     | 0.7432594    |
| policy_loss        | 0.0020714572 |
| serial_timesteps   | 190400       |
| time_elapsed       | 4.25e+03     |
| time_remaining     | 40.8         |
| total_timesteps    | 5712000      |
| true_eprew         | 83.6         |
| value_loss         | 16.366175    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.741677522659302 seconds
Total simulation time for 400 steps: 7.99601674079895 	 Other agent action time: 0 	 50.024907771770444 steps/s
Curr learning rate 0.001024 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.25it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.14it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.19it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.48it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.55it/s]
-------------------------------------
| approxkl           | 0.0045861807 |
| clipfrac           | 0.31683335   |
| eplenmean          | 400          |
| eprewmean          | 84.2         |
| explained_variance | 0.607        |
| fps                | 1379         |
| nupdates           | 477          |
| policy_entropy     | 0.7066697    |
| policy_loss        | 0.0016581707 |
| serial_timesteps   | 190800       |
| time_elapsed       | 4.26e+03     |
| time_remaining     | 40.6         |
| total_timesteps    | 5724000      |
| true_eprew         | 84.2         |
| value_loss         | 17.174871    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.820819854736328 seconds
Total simulation time for 400 steps: 8.089234828948975 	 Other agent action time: 0 	 49.44843467376154 steps/s
Curr learning rate 0.001023 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.99it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.32it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.12it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.80it/s]
------------------------------------
| approxkl           | 0.005460499 |
| clipfrac           | 0.34123957  |
| eplenmean          | 400         |
| eprewmean          | 80.4        |
| explained_variance | 0.594       |
| fps                | 1363        |
| nupdates           | 478         |
| policy_entropy     | 0.74185675  |
| policy_loss        | 0.001156462 |
| serial_timesteps   | 191200      |
| time_elapsed       | 4.27e+03    |
| time_remaining     | 40.5        |
| total_timesteps    | 5736000     |
| true_eprew         | 80.4        |
| value_loss         | 18.101696   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.942828416824341 seconds
Total simulation time for 400 steps: 8.435981750488281 	 Other agent action time: 0 	 47.41593946393349 steps/s
Curr learning rate 0.0010220000000000001 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 155.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.92it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.90it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.43it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.05it/s]
-------------------------------------
| approxkl           | 0.0049836976 |
| clipfrac           | 0.32005212   |
| eplenmean          | 400          |
| eprewmean          | 80.4         |
| explained_variance | 0.65         |
| fps                | 1308         |
| nupdates           | 479          |
| policy_entropy     | 0.7227185    |
| policy_loss        | 0.0023919498 |
| serial_timesteps   | 191600       |
| time_elapsed       | 4.28e+03     |
| time_remaining     | 40.3         |
| total_timesteps    | 5748000      |
| true_eprew         | 80.4         |
| value_loss         | 16.345404    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8049914836883545 seconds
Total simulation time for 400 steps: 8.119471311569214 	 Other agent action time: 0 	 49.26429131291478 steps/s
Curr learning rate 0.001021 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.01it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.86it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.75it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.08it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.08it/s]
-------------------------------------
| approxkl           | 0.0040112706 |
| clipfrac           | 0.30904168   |
| eplenmean          | 400          |
| eprewmean          | 84           |
| explained_variance | 0.674        |
| fps                | 1361         |
| nupdates           | 480          |
| policy_entropy     | 0.73302376   |
| policy_loss        | 0.000262389  |
| serial_timesteps   | 192000       |
| time_elapsed       | 4.29e+03     |
| time_remaining     | 40.2         |
| total_timesteps    | 5760000      |
| true_eprew         | 84           |
| value_loss         | 14.851573    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.794422626495361 seconds
Total simulation time for 400 steps: 8.087017297744751 	 Other agent action time: 0 	 49.46199386905592 steps/s
Curr learning rate 0.00102 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.26it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.00it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.56it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.63it/s]
-------------------------------------
| approxkl           | 0.0053040083 |
| clipfrac           | 0.33791664   |
| eplenmean          | 400          |
| eprewmean          | 86.2         |
| explained_variance | 0.652        |
| fps                | 1363         |
| nupdates           | 481          |
| policy_entropy     | 0.72627425   |
| policy_loss        | 0.0010101616 |
| serial_timesteps   | 192400       |
| time_elapsed       | 4.3e+03      |
| time_remaining     | 40           |
| total_timesteps    | 5772000      |
| true_eprew         | 86.2         |
| value_loss         | 15.734911    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.893707513809204 seconds
Total simulation time for 400 steps: 8.234102249145508 	 Other agent action time: 0 	 48.57845918072124 steps/s
Curr learning rate 0.001019 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 160.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.73it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.18it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.40it/s]
-------------------------------------
| approxkl           | 0.005262676  |
| clipfrac           | 0.31814587   |
| eplenmean          | 400          |
| eprewmean          | 85.6         |
| explained_variance | 0.612        |
| fps                | 1340         |
| nupdates           | 482          |
| policy_entropy     | 0.70232594   |
| policy_loss        | 0.0014096673 |
| serial_timesteps   | 192800       |
| time_elapsed       | 4.31e+03     |
| time_remaining     | 39.9         |
| total_timesteps    | 5784000      |
| true_eprew         | 85.6         |
| value_loss         | 16.793556    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.788197994232178 seconds
Total simulation time for 400 steps: 8.078649520874023 	 Other agent action time: 0 	 49.51322606166535 steps/s
Curr learning rate 0.001018 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.57it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 191.02it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.51it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.10it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.20it/s]
-------------------------------------
| approxkl           | 0.0044060256 |
| clipfrac           | 0.31927076   |
| eplenmean          | 400          |
| eprewmean          | 85.4         |
| explained_variance | 0.628        |
| fps                | 1371         |
| nupdates           | 483          |
| policy_entropy     | 0.7489961    |
| policy_loss        | 0.001921781  |
| serial_timesteps   | 193200       |
| time_elapsed       | 4.31e+03     |
| time_remaining     | 39.7         |
| total_timesteps    | 5796000      |
| true_eprew         | 85.4         |
| value_loss         | 16.657902    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.848689794540405 seconds
Total simulation time for 400 steps: 8.164666891098022 	 Other agent action time: 0 	 48.99158843040149 steps/s
Curr learning rate 0.0010170000000000001 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.78it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.28it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.91it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.39it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.48it/s]
-------------------------------------
| approxkl           | 0.0035945154 |
| clipfrac           | 0.28380206   |
| eplenmean          | 400          |
| eprewmean          | 83.8         |
| explained_variance | 0.578        |
| fps                | 1357         |
| nupdates           | 484          |
| policy_entropy     | 0.7049795    |
| policy_loss        | 0.0012817645 |
| serial_timesteps   | 193600       |
| time_elapsed       | 4.32e+03     |
| time_remaining     | 39.6         |
| total_timesteps    | 5808000      |
| true_eprew         | 83.8         |
| value_loss         | 20.042215    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.753716468811035 seconds
Total simulation time for 400 steps: 7.993465185165405 	 Other agent action time: 0 	 50.040875982338186 steps/s
Curr learning rate 0.001016 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.26it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.10it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.64it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 195.64it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.23it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.24it/s]
--------------------------------------
| approxkl           | 0.004267969   |
| clipfrac           | 0.2990833     |
| eplenmean          | 400           |
| eprewmean          | 81.2          |
| explained_variance | 0.584         |
| fps                | 1382          |
| nupdates           | 485           |
| policy_entropy     | 0.67525584    |
| policy_loss        | 0.00082881865 |
| serial_timesteps   | 194000        |
| time_elapsed       | 4.33e+03      |
| time_remaining     | 39.4          |
| total_timesteps    | 5820000       |
| true_eprew         | 81.2          |
| value_loss         | 17.752443     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.833055019378662 seconds
Total simulation time for 400 steps: 8.15321159362793 	 Other agent action time: 0 	 49.06042182354454 steps/s
Curr learning rate 0.001015 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.89it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.90it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.82it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.24it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.15it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.81it/s]
-------------------------------------
| approxkl           | 0.0045183753 |
| clipfrac           | 0.30554166   |
| eplenmean          | 400          |
| eprewmean          | 83           |
| explained_variance | 0.652        |
| fps                | 1352         |
| nupdates           | 486          |
| policy_entropy     | 0.71498495   |
| policy_loss        | 0.0024704307 |
| serial_timesteps   | 194400       |
| time_elapsed       | 4.34e+03     |
| time_remaining     | 39.3         |
| total_timesteps    | 5832000      |
| true_eprew         | 83           |
| value_loss         | 14.410715    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.665675640106201 seconds
Total simulation time for 400 steps: 7.975871324539185 	 Other agent action time: 0 	 50.15126043587601 steps/s
Curr learning rate 0.001014 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.39it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.81it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.57it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.99it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.09it/s]
-------------------------------------
| approxkl           | 0.0049230168 |
| clipfrac           | 0.31261456   |
| eplenmean          | 400          |
| eprewmean          | 82.4         |
| explained_variance | 0.636        |
| fps                | 1382         |
| nupdates           | 487          |
| policy_entropy     | 0.704779     |
| policy_loss        | 0.0017142948 |
| serial_timesteps   | 194800       |
| time_elapsed       | 4.35e+03     |
| time_remaining     | 39.1         |
| total_timesteps    | 5844000      |
| true_eprew         | 82.4         |
| value_loss         | 17.266687    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7156312465667725 seconds
Total simulation time for 400 steps: 7.949447870254517 	 Other agent action time: 0 	 50.31796000533975 steps/s
Curr learning rate 0.001013 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.03it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.76it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.44it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.34it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.25it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.38it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.15it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.61it/s]
---------------------------------------
| approxkl           | 0.0034223117   |
| clipfrac           | 0.27415618     |
| eplenmean          | 400            |
| eprewmean          | 84             |
| explained_variance | 0.632          |
| fps                | 1387           |
| nupdates           | 488            |
| policy_entropy     | 0.6688675      |
| policy_loss        | 0.000100788464 |
| serial_timesteps   | 195200         |
| time_elapsed       | 4.36e+03       |
| time_remaining     | 39             |
| total_timesteps    | 5856000        |
| true_eprew         | 84             |
| value_loss         | 15.727107      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.776909828186035 seconds
Total simulation time for 400 steps: 8.138951539993286 	 Other agent action time: 0 	 49.14637936280549 steps/s
Curr learning rate 0.001012 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 154.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.66it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.43it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.40it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.70it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.07it/s]
------------------------------------
| approxkl           | 0.004405471 |
| clipfrac           | 0.29024997  |
| eplenmean          | 400         |
| eprewmean          | 81.6        |
| explained_variance | 0.598       |
| fps                | 1356        |
| nupdates           | 489         |
| policy_entropy     | 0.66911685  |
| policy_loss        | 0.001726458 |
| serial_timesteps   | 195600      |
| time_elapsed       | 4.37e+03    |
| time_remaining     | 38.8        |
| total_timesteps    | 5868000     |
| true_eprew         | 81.6        |
| value_loss         | 17.632133   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.808772325515747 seconds
Total simulation time for 400 steps: 8.129099130630493 	 Other agent action time: 0 	 49.205944419203554 steps/s
Curr learning rate 0.001011 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.73it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.37it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.43it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.74it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.84it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.42it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.99it/s]
-------------------------------------
| approxkl           | 0.004044401  |
| clipfrac           | 0.27531245   |
| eplenmean          | 400          |
| eprewmean          | 82.8         |
| explained_variance | 0.606        |
| fps                | 1360         |
| nupdates           | 490          |
| policy_entropy     | 0.6521307    |
| policy_loss        | 0.0012338806 |
| serial_timesteps   | 196000       |
| time_elapsed       | 4.38e+03     |
| time_remaining     | 38.7         |
| total_timesteps    | 5880000      |
| true_eprew         | 82.8         |
| value_loss         | 16.47389     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.9623284339904785 seconds
Total simulation time for 400 steps: 8.980296850204468 	 Other agent action time: 0 	 44.541957428822926 steps/s
Curr learning rate 0.00101 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.93it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.93it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 205.05it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 218.02it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 210.10it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 201.91it/s]
--------------------------------------
| approxkl           | 0.0054946053  |
| clipfrac           | 0.32379162    |
| eplenmean          | 400           |
| eprewmean          | 81.6          |
| explained_variance | 0.631         |
| fps                | 1244          |
| nupdates           | 491           |
| policy_entropy     | 0.6912728     |
| policy_loss        | 0.00063610513 |
| serial_timesteps   | 196400        |
| time_elapsed       | 4.39e+03      |
| time_remaining     | 38.6          |
| total_timesteps    | 5892000       |
| true_eprew         | 81.6          |
| value_loss         | 16.257607     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.833516597747803 seconds
Total simulation time for 400 steps: 8.408036708831787 	 Other agent action time: 0 	 47.57353159267736 steps/s
Curr learning rate 0.0010090000000000001 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.83it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.23it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.05it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.88it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.02it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.47it/s]
---------------------------------------
| approxkl           | 0.0045350213   |
| clipfrac           | 0.30098957     |
| eplenmean          | 400            |
| eprewmean          | 82.4           |
| explained_variance | 0.654          |
| fps                | 1318           |
| nupdates           | 492            |
| policy_entropy     | 0.67497087     |
| policy_loss        | -0.00043014725 |
| serial_timesteps   | 196800         |
| time_elapsed       | 4.39e+03       |
| time_remaining     | 38.4           |
| total_timesteps    | 5904000        |
| true_eprew         | 82.4           |
| value_loss         | 16.142277      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.740089416503906 seconds
Total simulation time for 400 steps: 8.0388503074646 	 Other agent action time: 0 	 49.758359056465295 steps/s
Curr learning rate 0.001008 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.83it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.46it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 198.84it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.49it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.72it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.05it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.36it/s]
--------------------------------------
| approxkl           | 0.005028439   |
| clipfrac           | 0.29911458    |
| eplenmean          | 400           |
| eprewmean          | 83.2          |
| explained_variance | 0.628         |
| fps                | 1373          |
| nupdates           | 493           |
| policy_entropy     | 0.63029915    |
| policy_loss        | -6.799401e-05 |
| serial_timesteps   | 197200        |
| time_elapsed       | 4.4e+03       |
| time_remaining     | 38.3          |
| total_timesteps    | 5916000       |
| true_eprew         | 83.2          |
| value_loss         | 16.63537      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.813721656799316 seconds
Total simulation time for 400 steps: 8.090310335159302 	 Other agent action time: 0 	 49.44186111893121 steps/s
Curr learning rate 0.001007 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.37it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.91it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.92it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.61it/s]
--------------------------------------
| approxkl           | 0.0047686608  |
| clipfrac           | 0.30327082    |
| eplenmean          | 400           |
| eprewmean          | 83            |
| explained_variance | 0.633         |
| fps                | 1366          |
| nupdates           | 494           |
| policy_entropy     | 0.6903982     |
| policy_loss        | 0.00058398646 |
| serial_timesteps   | 197600        |
| time_elapsed       | 4.41e+03      |
| time_remaining     | 38.1          |
| total_timesteps    | 5928000       |
| true_eprew         | 83            |
| value_loss         | 16.623098     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.806054592132568 seconds
Total simulation time for 400 steps: 8.199254274368286 	 Other agent action time: 0 	 48.78492441080175 steps/s
Curr learning rate 0.001006 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.22it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.14it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.51it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.58it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.48it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.21it/s]
--------------------------------------
| approxkl           | 0.004142634   |
| clipfrac           | 0.29323962    |
| eplenmean          | 400           |
| eprewmean          | 81.2          |
| explained_variance | 0.557         |
| fps                | 1348          |
| nupdates           | 495           |
| policy_entropy     | 0.6737004     |
| policy_loss        | 0.00046868957 |
| serial_timesteps   | 198000        |
| time_elapsed       | 4.42e+03      |
| time_remaining     | 38            |
| total_timesteps    | 5940000       |
| true_eprew         | 81.2          |
| value_loss         | 19.047825     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7518815994262695 seconds
Total simulation time for 400 steps: 8.023993730545044 	 Other agent action time: 0 	 49.85048760411099 steps/s
Curr learning rate 0.001005 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.72it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.44it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.31it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.99it/s]
---------------------------------------
| approxkl           | 0.0049524256   |
| clipfrac           | 0.3136354      |
| eplenmean          | 400            |
| eprewmean          | 81.4           |
| explained_variance | 0.629          |
| fps                | 1375           |
| nupdates           | 496            |
| policy_entropy     | 0.6645602      |
| policy_loss        | -0.00020810022 |
| serial_timesteps   | 198400         |
| time_elapsed       | 4.43e+03       |
| time_remaining     | 37.8           |
| total_timesteps    | 5952000        |
| true_eprew         | 81.4           |
| value_loss         | 15.41843       |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.806455850601196 seconds
Total simulation time for 400 steps: 8.246342420578003 	 Other agent action time: 0 	 48.50635343517098 steps/s
Curr learning rate 0.0010040000000000001 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.33it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 150.27it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 151.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.93it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.74it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.60it/s]
-------------------------------------
| approxkl           | 0.0033174055 |
| clipfrac           | 0.26261458   |
| eplenmean          | 400          |
| eprewmean          | 81.4         |
| explained_variance | 0.605        |
| fps                | 1336         |
| nupdates           | 497          |
| policy_entropy     | 0.6751495    |
| policy_loss        | 0.0010990008 |
| serial_timesteps   | 198800       |
| time_elapsed       | 4.44e+03     |
| time_remaining     | 37.7         |
| total_timesteps    | 5964000      |
| true_eprew         | 81.4         |
| value_loss         | 19.126595    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.888171911239624 seconds
Total simulation time for 400 steps: 8.222326278686523 	 Other agent action time: 0 	 48.64803298269234 steps/s
Curr learning rate 0.001003 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.02it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.88it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.88it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.22it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.73it/s]
-------------------------------------
| approxkl           | 0.0051854653 |
| clipfrac           | 0.3117291    |
| eplenmean          | 400          |
| eprewmean          | 81.4         |
| explained_variance | 0.602        |
| fps                | 1343         |
| nupdates           | 498          |
| policy_entropy     | 0.690773     |
| policy_loss        | 0.0010556602 |
| serial_timesteps   | 199200       |
| time_elapsed       | 4.45e+03     |
| time_remaining     | 37.5         |
| total_timesteps    | 5976000      |
| true_eprew         | 81.4         |
| value_loss         | 17.538298    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.814333438873291 seconds
Total simulation time for 400 steps: 8.15031361579895 	 Other agent action time: 0 	 49.07786606206432 steps/s
Curr learning rate 0.001002 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.93it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.07it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.93it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.83it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.04it/s]
------------------------------------
| approxkl           | 0.005278794 |
| clipfrac           | 0.3030313   |
| eplenmean          | 400         |
| eprewmean          | 80.6        |
| explained_variance | 0.594       |
| fps                | 1354        |
| nupdates           | 499         |
| policy_entropy     | 0.65171087  |
| policy_loss        | 0.001748893 |
| serial_timesteps   | 199600      |
| time_elapsed       | 4.46e+03    |
| time_remaining     | 37.4        |
| total_timesteps    | 5988000     |
| true_eprew         | 80.6        |
| value_loss         | 17.727436   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.887414455413818 seconds
Total simulation time for 400 steps: 8.237872838973999 	 Other agent action time: 0 	 48.556224139266845 steps/s
Curr learning rate 0.0010010000000000002 	 Curr reward per step 0.18166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.43it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.39it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.92it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.52it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.87it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.41it/s]
-------------------------------------
| approxkl           | 0.0052758674 |
| clipfrac           | 0.3119272    |
| eplenmean          | 400          |
| eprewmean          | 77.8         |
| explained_variance | 0.596        |
| fps                | 1340         |
| nupdates           | 500          |
| policy_entropy     | 0.66796076   |
| policy_loss        | 0.0023101412 |
| serial_timesteps   | 200000       |
| time_elapsed       | 4.47e+03     |
| time_remaining     | 37.2         |
| total_timesteps    | 6000000      |
| true_eprew         | 77.8         |
| value_loss         | 18.592102    |
-------------------------------------
Current reward shaping 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø2X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø3X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø6X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø7X 
O ←1X →oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø8X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø9X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø10X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø11X 
O →1Xo→0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →1Xo←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø13X 
O   X ←oø-
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø14X 
O   X →oø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 47
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø15X 
O   X →0ø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø16X 
O   X →0ø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø17X 
O   X →0ø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 50
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø18X 
O   X ↑0ø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 51
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø19X 
O   X ←0ø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 52
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X ←0ø=
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←0ø=
O →dX   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O →dX   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O →dX   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dX   ø=
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xd  ø=
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd  ø=
O ↓1X ←0X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd  ø=
O   X ←0X 
D ↓1X   X 
X X X S X 


Timestep: 65
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd  ø=
O   X ←0X 
D ↓1X   X 
X X X S X 


Timestep: 66
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd↑0ø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd↑0ø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 68
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd↑0ø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 69
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd←0ø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X ←dø=
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 71
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xd←0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX ←dø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dXd←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX ←dø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX ↑dø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 5 
X X X P X 
O →dX ↑sø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX   ø=
O   X ↓sX 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX   ø=
O   X   X 
D   X ↓sX 
X X X S X 


Timestep: 79
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xd  ø=
O   X   X 
D   X ↓sX 
X X X S X 


Timestep: 80
Joint action taken: ('interact', '←') 	 Reward: 20 + shape * 0 
X X X P X 
O ←1Xd  ø=
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 81
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xd  ø=
O   X   X 
D   X ←0X 
X X X S X 


Timestep: 82
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXd  ø=
O   X   X 
D   X ←0X 
X X X S X 


Timestep: 83
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oXd  ø=
O   X   X 
D   X ←0X 
X X X S X 


Timestep: 84
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O ↓oX   X 
D   X →0X 
X X X S X 


Timestep: 85
Joint action taken: ('stay', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →oX   X 
D   X →0X 
X X X S X 


Timestep: 86
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →oX   X 
D   X ↓0X 
X X X S X 


Timestep: 87
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →oX ←0X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →oX ←0X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →oX   X 
D   X ↓0X 
X X X S X 


Timestep: 91
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →oX ↑0X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O →1Xo←0X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd  ø=
O ←1X ←oX 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xd↑oø=
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   Xd↑0ø=
O →oX   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd←0ø=
O →oX   X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd  ø=
O →oX ↓0X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd  ø=
O →1Xo←0X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xd  ø=
O ←1X ←oX 
D   X   X 
X X X S X 


tot rew 100 tot rew shaped 94
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ↓0X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 23
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 24
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 25
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 26
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ←oX   X 
X X X S X 


Timestep: 27
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 28
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ←oX   X 
X X X S X 


Timestep: 29
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 32
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX   X 
D   X ↓0X 
X X X S X 


Timestep: 33
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX ↑0X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX ↑0X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X XoX S X 


Timestep: 41
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X XoX S X 


Timestep: 42
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 43
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 44
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 45
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 46
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 47
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 48
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 49
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 50
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 51
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 52
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 53
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 54
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 55
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 56
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 57
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 58
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 59
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 60
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 61
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 62
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 63
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 64
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 65
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 66
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 67
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 68
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 69
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 70
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 71
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↓1X ↓0X 
D   X   X 
X XoX S X 


Timestep: 72
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 73
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 74
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 75
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 76
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 77
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 78
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 79
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 80
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 81
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 82
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 83
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 84
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 85
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 86
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 87
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 88
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X XoX S X 


Timestep: 89
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 90
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 91
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 92
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X XoX S X 


Timestep: 93
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 94
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 95
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 96
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 97
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 98
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


Timestep: 99
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X XoX S X 


tot rew 0 tot rew shaped 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.826784372329712 seconds
Total simulation time for 400 steps: 8.12285590171814 	 Other agent action time: 0 	 49.243764119389624 steps/s
Curr learning rate 0.001 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.09it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.15it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.55it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.19it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.23it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.73it/s]
-------------------------------------
| approxkl           | 0.005528274  |
| clipfrac           | 0.30208337   |
| eplenmean          | 400          |
| eprewmean          | 78.6         |
| explained_variance | 0.687        |
| fps                | 1362         |
| nupdates           | 501          |
| policy_entropy     | 0.63677996   |
| policy_loss        | 0.0014121993 |
| serial_timesteps   | 200400       |
| time_elapsed       | 4.48e+03     |
| time_remaining     | 37.1         |
| total_timesteps    | 6012000      |
| true_eprew         | 78.6         |
| value_loss         | 14.685762    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.823732852935791 seconds
Total simulation time for 400 steps: 8.121318340301514 	 Other agent action time: 0 	 49.253087151506676 steps/s
Curr learning rate 0.0009989999999999999 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.57it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.17it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 165.69it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.85it/s]
-------------------------------------
| approxkl           | 0.0042929873 |
| clipfrac           | 0.2693334    |
| eplenmean          | 400          |
| eprewmean          | 79.2         |
| explained_variance | 0.637        |
| fps                | 1355         |
| nupdates           | 502          |
| policy_entropy     | 0.6035853    |
| policy_loss        | 0.0015249487 |
| serial_timesteps   | 200800       |
| time_elapsed       | 4.49e+03     |
| time_remaining     | 36.9         |
| total_timesteps    | 6024000      |
| true_eprew         | 79.2         |
| value_loss         | 16.33415     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.6863250732421875 seconds
Total simulation time for 400 steps: 8.046845436096191 	 Other agent action time: 0 	 49.708920492706035 steps/s
Curr learning rate 0.000998 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.36it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.42it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.46it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.01it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.23it/s]
-------------------------------------
| approxkl           | 0.0037706285 |
| clipfrac           | 0.26265624   |
| eplenmean          | 400          |
| eprewmean          | 81.8         |
| explained_variance | 0.573        |
| fps                | 1371         |
| nupdates           | 503          |
| policy_entropy     | 0.60954124   |
| policy_loss        | 0.0005103409 |
| serial_timesteps   | 201200       |
| time_elapsed       | 4.49e+03     |
| time_remaining     | 36.8         |
| total_timesteps    | 6036000      |
| true_eprew         | 81.8         |
| value_loss         | 18.021662    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.80028510093689 seconds
Total simulation time for 400 steps: 8.174686908721924 	 Other agent action time: 0 	 48.93153761928458 steps/s
Curr learning rate 0.000997 	 Curr reward per step 0.18833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.15it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.40it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.72it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.74it/s]
-------------------------------------
| approxkl           | 0.0047143986 |
| clipfrac           | 0.29861456   |
| eplenmean          | 400          |
| eprewmean          | 82           |
| explained_variance | 0.567        |
| fps                | 1353         |
| nupdates           | 504          |
| policy_entropy     | 0.6538965    |
| policy_loss        | 0.0022015537 |
| serial_timesteps   | 201600       |
| time_elapsed       | 4.5e+03      |
| time_remaining     | 36.6         |
| total_timesteps    | 6048000      |
| true_eprew         | 82           |
| value_loss         | 18.79456     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.787404775619507 seconds
Total simulation time for 400 steps: 8.09771990776062 	 Other agent action time: 0 	 49.39662084590646 steps/s
Curr learning rate 0.000996 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.73it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.45it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.74it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.42it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.15it/s]
-------------------------------------
| approxkl           | 0.005531299  |
| clipfrac           | 0.3044167    |
| eplenmean          | 400          |
| eprewmean          | 82.4         |
| explained_variance | 0.59         |
| fps                | 1365         |
| nupdates           | 505          |
| policy_entropy     | 0.6263243    |
| policy_loss        | 0.0037623548 |
| serial_timesteps   | 202000       |
| time_elapsed       | 4.51e+03     |
| time_remaining     | 36.5         |
| total_timesteps    | 6060000      |
| true_eprew         | 82.4         |
| value_loss         | 17.594574    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8993895053863525 seconds
Total simulation time for 400 steps: 8.255458354949951 	 Other agent action time: 0 	 48.45279120815394 steps/s
Curr learning rate 0.000995 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.54it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.57it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.29it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.95it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.97it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.61it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 171.54it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.36it/s]
-------------------------------------
| approxkl           | 0.0039773467 |
| clipfrac           | 0.2736354    |
| eplenmean          | 400          |
| eprewmean          | 81.6         |
| explained_variance | 0.576        |
| fps                | 1335         |
| nupdates           | 506          |
| policy_entropy     | 0.6502539    |
| policy_loss        | 0.0007012448 |
| serial_timesteps   | 202400       |
| time_elapsed       | 4.52e+03     |
| time_remaining     | 36.3         |
| total_timesteps    | 6072000      |
| true_eprew         | 81.6         |
| value_loss         | 18.201572    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.909487247467041 seconds
Total simulation time for 400 steps: 8.242116451263428 	 Other agent action time: 0 	 48.531224032716054 steps/s
Curr learning rate 0.000994 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 167.02it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 170.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.54it/s]
-------------------------------------
| approxkl           | 0.0029250847 |
| clipfrac           | 0.24148957   |
| eplenmean          | 400          |
| eprewmean          | 83.8         |
| explained_variance | 0.624        |
| fps                | 1337         |
| nupdates           | 507          |
| policy_entropy     | 0.62732846   |
| policy_loss        | 0.0002225347 |
| serial_timesteps   | 202800       |
| time_elapsed       | 4.53e+03     |
| time_remaining     | 36.2         |
| total_timesteps    | 6084000      |
| true_eprew         | 83.8         |
| value_loss         | 17.207336    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.797105312347412 seconds
Total simulation time for 400 steps: 8.19868016242981 	 Other agent action time: 0 	 48.78834057132601 steps/s
Curr learning rate 0.000993 	 Curr reward per step 0.19166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.52it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.20it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.93it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.66it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.14it/s]
-------------------------------------
| approxkl           | 0.0053927717 |
| clipfrac           | 0.3032603    |
| eplenmean          | 400          |
| eprewmean          | 82.2         |
| explained_variance | 0.63         |
| fps                | 1348         |
| nupdates           | 508          |
| policy_entropy     | 0.6423398    |
| policy_loss        | 0.0010590643 |
| serial_timesteps   | 203200       |
| time_elapsed       | 4.54e+03     |
| time_remaining     | 36           |
| total_timesteps    | 6096000      |
| true_eprew         | 82.2         |
| value_loss         | 17.283289    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.731375217437744 seconds
Total simulation time for 400 steps: 8.090216636657715 	 Other agent action time: 0 	 49.44243373997593 steps/s
Curr learning rate 0.000992 	 Curr reward per step 0.19166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.78it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.03it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.47it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.85it/s]
-------------------------------------
| approxkl           | 0.0041037635 |
| clipfrac           | 0.29208332   |
| eplenmean          | 400          |
| eprewmean          | 81           |
| explained_variance | 0.613        |
| fps                | 1368         |
| nupdates           | 509          |
| policy_entropy     | 0.66415554   |
| policy_loss        | 0.0012907139 |
| serial_timesteps   | 203600       |
| time_elapsed       | 4.55e+03     |
| time_remaining     | 35.9         |
| total_timesteps    | 6108000      |
| true_eprew         | 81           |
| value_loss         | 16.683453    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.738738775253296 seconds
Total simulation time for 400 steps: 8.054670095443726 	 Other agent action time: 0 	 49.660631069951265 steps/s
Curr learning rate 0.0009910000000000001 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.49it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.66it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.34it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.16it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.23it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.66it/s]
--------------------------------------
| approxkl           | 0.0036259184  |
| clipfrac           | 0.25398964    |
| eplenmean          | 400           |
| eprewmean          | 80            |
| explained_variance | 0.633         |
| fps                | 1368          |
| nupdates           | 510           |
| policy_entropy     | 0.6093628     |
| policy_loss        | 0.00023142042 |
| serial_timesteps   | 204000        |
| time_elapsed       | 4.56e+03      |
| time_remaining     | 35.7          |
| total_timesteps    | 6120000       |
| true_eprew         | 80            |
| value_loss         | 17.412987     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.977101564407349 seconds
Total simulation time for 400 steps: 8.335976839065552 	 Other agent action time: 0 	 47.98477823564098 steps/s
Curr learning rate 0.00099 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.14it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.66it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.75it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.98it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 168.76it/s]
-------------------------------------
| approxkl           | 0.003934804  |
| clipfrac           | 0.27047917   |
| eplenmean          | 400          |
| eprewmean          | 83.8         |
| explained_variance | 0.604        |
| fps                | 1326         |
| nupdates           | 511          |
| policy_entropy     | 0.61806774   |
| policy_loss        | 0.0009836622 |
| serial_timesteps   | 204400       |
| time_elapsed       | 4.57e+03     |
| time_remaining     | 35.6         |
| total_timesteps    | 6132000      |
| true_eprew         | 83.8         |
| value_loss         | 17.158653    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.809358835220337 seconds
Total simulation time for 400 steps: 8.170716524124146 	 Other agent action time: 0 	 48.95531485139582 steps/s
Curr learning rate 0.000989 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.47it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.84it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.10it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.21it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.07it/s]
-------------------------------------
| approxkl           | 0.006041317  |
| clipfrac           | 0.31027085   |
| eplenmean          | 400          |
| eprewmean          | 84.6         |
| explained_variance | 0.612        |
| fps                | 1349         |
| nupdates           | 512          |
| policy_entropy     | 0.63519806   |
| policy_loss        | 0.0025509717 |
| serial_timesteps   | 204800       |
| time_elapsed       | 4.57e+03     |
| time_remaining     | 35.4         |
| total_timesteps    | 6144000      |
| true_eprew         | 84.6         |
| value_loss         | 18.166256    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8301756381988525 seconds
Total simulation time for 400 steps: 8.157527208328247 	 Other agent action time: 0 	 49.034467159561395 steps/s
Curr learning rate 0.000988 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.79it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.03it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.39it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 196.29it/s]
-------------------------------------
| approxkl           | 0.0045105997 |
| clipfrac           | 0.3013542    |
| eplenmean          | 400          |
| eprewmean          | 83           |
| explained_variance | 0.614        |
| fps                | 1355         |
| nupdates           | 513          |
| policy_entropy     | 0.68983686   |
| policy_loss        | 0.0015632556 |
| serial_timesteps   | 205200       |
| time_elapsed       | 4.58e+03     |
| time_remaining     | 35.3         |
| total_timesteps    | 6156000      |
| true_eprew         | 83           |
| value_loss         | 18.662495    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.857469081878662 seconds
Total simulation time for 400 steps: 8.256235361099243 	 Other agent action time: 0 	 48.448231246491936 steps/s
Curr learning rate 0.000987 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.40it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.11it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.63it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.00it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.63it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.78it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.16it/s]
-------------------------------------
| approxkl           | 0.0032053657 |
| clipfrac           | 0.26143754   |
| eplenmean          | 400          |
| eprewmean          | 80.8         |
| explained_variance | 0.583        |
| fps                | 1337         |
| nupdates           | 514          |
| policy_entropy     | 0.6752856    |
| policy_loss        | 0.0008761852 |
| serial_timesteps   | 205600       |
| time_elapsed       | 4.59e+03     |
| time_remaining     | 35.1         |
| total_timesteps    | 6168000      |
| true_eprew         | 80.8         |
| value_loss         | 18.156343    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.851478576660156 seconds
Total simulation time for 400 steps: 8.257421970367432 	 Other agent action time: 0 	 48.44126913162961 steps/s
Curr learning rate 0.000986 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.39it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.93it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 167.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.27it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.24it/s]
--------------------------------------
| approxkl           | 0.0051621487  |
| clipfrac           | 0.31205204    |
| eplenmean          | 400           |
| eprewmean          | 79.4          |
| explained_variance | 0.606         |
| fps                | 1338          |
| nupdates           | 515           |
| policy_entropy     | 0.68672746    |
| policy_loss        | 0.00059214554 |
| serial_timesteps   | 206000        |
| time_elapsed       | 4.6e+03       |
| time_remaining     | 35            |
| total_timesteps    | 6180000       |
| true_eprew         | 79.4          |
| value_loss         | 17.277256     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.770427227020264 seconds
Total simulation time for 400 steps: 8.158711433410645 	 Other agent action time: 0 	 49.02734987806587 steps/s
Curr learning rate 0.000985 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.04it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.02it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.97it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.59it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.06it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.92it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.32it/s]
------------------------------------
| approxkl           | 0.005191025 |
| clipfrac           | 0.31560418  |
| eplenmean          | 400         |
| eprewmean          | 83.4        |
| explained_variance | 0.594       |
| fps                | 1354        |
| nupdates           | 516         |
| policy_entropy     | 0.6660036   |
| policy_loss        | 0.002820646 |
| serial_timesteps   | 206400      |
| time_elapsed       | 4.61e+03    |
| time_remaining     | 34.8        |
| total_timesteps    | 6192000     |
| true_eprew         | 83.4        |
| value_loss         | 17.169409   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.741748809814453 seconds
Total simulation time for 400 steps: 8.122515439987183 	 Other agent action time: 0 	 49.24582821114726 steps/s
Curr learning rate 0.000984 	 Curr reward per step 0.18333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.45it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.12it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.03it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.09it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.83it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.89it/s]
-------------------------------------
| approxkl           | 0.0054063755 |
| clipfrac           | 0.33119795   |
| eplenmean          | 400          |
| eprewmean          | 78.8         |
| explained_variance | 0.68         |
| fps                | 1359         |
| nupdates           | 517          |
| policy_entropy     | 0.71807164   |
| policy_loss        | 0.0016866792 |
| serial_timesteps   | 206800       |
| time_elapsed       | 4.62e+03     |
| time_remaining     | 34.7         |
| total_timesteps    | 6204000      |
| true_eprew         | 78.8         |
| value_loss         | 14.685378    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.6928791999816895 seconds
Total simulation time for 400 steps: 7.887112617492676 	 Other agent action time: 0 	 50.7156445456158 steps/s
Curr learning rate 0.000983 	 Curr reward per step 0.19

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.13it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.82it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 196.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.24it/s]
-------------------------------------
| approxkl           | 0.0053426544 |
| clipfrac           | 0.31293744   |
| eplenmean          | 400          |
| eprewmean          | 79.6         |
| explained_variance | 0.652        |
| fps                | 1397         |
| nupdates           | 518          |
| policy_entropy     | 0.68642724   |
| policy_loss        | 0.0014040116 |
| serial_timesteps   | 207200       |
| time_elapsed       | 4.63e+03     |
| time_remaining     | 34.5         |
| total_timesteps    | 6216000      |
| true_eprew         | 79.6         |
| value_loss         | 16.935947    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.87404990196228 seconds
Total simulation time for 400 steps: 8.354516983032227 	 Other agent action time: 0 	 47.87829156519617 steps/s
Curr learning rate 0.000982 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.81it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.92it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.62it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.99it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.05it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.16it/s]
-------------------------------------
| approxkl           | 0.0039053222 |
| clipfrac           | 0.28813535   |
| eplenmean          | 400          |
| eprewmean          | 77.2         |
| explained_variance | 0.635        |
| fps                | 1325         |
| nupdates           | 519          |
| policy_entropy     | 0.6721814    |
| policy_loss        | 0.0012975599 |
| serial_timesteps   | 207600       |
| time_elapsed       | 4.64e+03     |
| time_remaining     | 34.4         |
| total_timesteps    | 6228000      |
| true_eprew         | 77.2         |
| value_loss         | 17.1612      |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.785055160522461 seconds
Total simulation time for 400 steps: 8.080388069152832 	 Other agent action time: 0 	 49.50257296762938 steps/s
Curr learning rate 0.000981 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.51it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.86it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.05it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.76it/s]
-------------------------------------
| approxkl           | 0.0042980025 |
| clipfrac           | 0.28711462   |
| eplenmean          | 400          |
| eprewmean          | 78.8         |
| explained_variance | 0.58         |
| fps                | 1367         |
| nupdates           | 520          |
| policy_entropy     | 0.6498408    |
| policy_loss        | 0.0020237782 |
| serial_timesteps   | 208000       |
| time_elapsed       | 4.65e+03     |
| time_remaining     | 34.2         |
| total_timesteps    | 6240000      |
| true_eprew         | 78.8         |
| value_loss         | 18.080679    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.88288688659668 seconds
Total simulation time for 400 steps: 8.244027614593506 	 Other agent action time: 0 	 48.51997333098733 steps/s
Curr learning rate 0.00098 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.30it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.05it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.56it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.19it/s]
-------------------------------------
| approxkl           | 0.0032219798 |
| clipfrac           | 0.23871873   |
| eplenmean          | 400          |
| eprewmean          | 80.2         |
| explained_variance | 0.576        |
| fps                | 1342         |
| nupdates           | 521          |
| policy_entropy     | 0.5958126    |
| policy_loss        | 0.001452614  |
| serial_timesteps   | 208400       |
| time_elapsed       | 4.65e+03     |
| time_remaining     | 34.1         |
| total_timesteps    | 6252000      |
| true_eprew         | 80.2         |
| value_loss         | 18.086248    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.869803428649902 seconds
Total simulation time for 400 steps: 8.272751331329346 	 Other agent action time: 0 	 48.351507736631575 steps/s
Curr learning rate 0.000979 	 Curr reward per step 0.2333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.64it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.29it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.72it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.30it/s]
-------------------------------------
| approxkl           | 0.0028551356 |
| clipfrac           | 0.22207293   |
| eplenmean          | 400          |
| eprewmean          | 85.4         |
| explained_variance | 0.617        |
| fps                | 1337         |
| nupdates           | 522          |
| policy_entropy     | 0.55007005   |
| policy_loss        | -6.35752e-05 |
| serial_timesteps   | 208800       |
| time_elapsed       | 4.66e+03     |
| time_remaining     | 33.9         |
| total_timesteps    | 6264000      |
| true_eprew         | 85.4         |
| value_loss         | 17.0753      |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.813705205917358 seconds
Total simulation time for 400 steps: 8.113748788833618 	 Other agent action time: 0 	 49.29903678438897 steps/s
Curr learning rate 0.0009780000000000001 	 Curr reward per step 0.19166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 178.65it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 186.29it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.59it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 195.32it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 202.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 202.74it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 206.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 204.60it/s]
-------------------------------------
| approxkl           | 0.0044136522 |
| clipfrac           | 0.2857083    |
| eplenmean          | 400          |
| eprewmean          | 84.4         |
| explained_variance | 0.56         |
| fps                | 1371         |
| nupdates           | 523          |
| policy_entropy     | 0.66308635   |
| policy_loss        | 0.0019439225 |
| serial_timesteps   | 209200       |
| time_elapsed       | 4.67e+03     |
| time_remaining     | 33.8         |
| total_timesteps    | 6276000      |
| true_eprew         | 84.4         |
| value_loss         | 19.014696    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.765898942947388 seconds
Total simulation time for 400 steps: 7.963139533996582 	 Other agent action time: 0 	 50.23144430564133 steps/s
Curr learning rate 0.000977 	 Curr reward per step 0.195

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.83it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.62it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.36it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.49it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.05it/s]
-------------------------------------
| approxkl           | 0.0047856146 |
| clipfrac           | 0.3031042    |
| eplenmean          | 400          |
| eprewmean          | 82.6         |
| explained_variance | 0.664        |
| fps                | 1386         |
| nupdates           | 524          |
| policy_entropy     | 0.64295447   |
| policy_loss        | 0.0009941047 |
| serial_timesteps   | 209600       |
| time_elapsed       | 4.68e+03     |
| time_remaining     | 33.6         |
| total_timesteps    | 6288000      |
| true_eprew         | 82.6         |
| value_loss         | 15.082934    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.774693012237549 seconds
Total simulation time for 400 steps: 8.102863311767578 	 Other agent action time: 0 	 49.36526566097819 steps/s
Curr learning rate 0.0009760000000000001 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.51it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.66it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.06it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.91it/s]
--------------------------------------
| approxkl           | 0.00504767    |
| clipfrac           | 0.27573952    |
| eplenmean          | 400           |
| eprewmean          | 82.4          |
| explained_variance | 0.621         |
| fps                | 1360          |
| nupdates           | 525           |
| policy_entropy     | 0.59415776    |
| policy_loss        | 0.00069548003 |
| serial_timesteps   | 210000        |
| time_elapsed       | 4.69e+03      |
| time_remaining     | 33.5          |
| total_timesteps    | 6300000       |
| true_eprew         | 82.4          |
| value_loss         | 17.267925     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.807664394378662 seconds
Total simulation time for 400 steps: 8.13232135772705 	 Other agent action time: 0 	 49.18644780557446 steps/s
Curr learning rate 0.0009750000000000001 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.09it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.86it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.00it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.65it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.78it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.74it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.26it/s]
-------------------------------------
| approxkl           | 0.0051335366 |
| clipfrac           | 0.2952291    |
| eplenmean          | 400          |
| eprewmean          | 83.2         |
| explained_variance | 0.604        |
| fps                | 1358         |
| nupdates           | 526          |
| policy_entropy     | 0.6153399    |
| policy_loss        | 0.001486154  |
| serial_timesteps   | 210400       |
| time_elapsed       | 4.7e+03      |
| time_remaining     | 33.3         |
| total_timesteps    | 6312000      |
| true_eprew         | 83.2         |
| value_loss         | 17.57551     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.832324266433716 seconds
Total simulation time for 400 steps: 8.191997766494751 	 Other agent action time: 0 	 48.82813831273233 steps/s
Curr learning rate 0.000974 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.95it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.32it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.12it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.69it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.68it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.48it/s]
-------------------------------------
| approxkl           | 0.0037758453 |
| clipfrac           | 0.25808337   |
| eplenmean          | 400          |
| eprewmean          | 82.8         |
| explained_variance | 0.63         |
| fps                | 1350         |
| nupdates           | 527          |
| policy_entropy     | 0.5958678    |
| policy_loss        | 0.0015094522 |
| serial_timesteps   | 210800       |
| time_elapsed       | 4.71e+03     |
| time_remaining     | 33.2         |
| total_timesteps    | 6324000      |
| true_eprew         | 82.8         |
| value_loss         | 16.963104    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.891539812088013 seconds
Total simulation time for 400 steps: 8.339628458023071 	 Other agent action time: 0 	 47.96376745239571 steps/s
Curr learning rate 0.000973 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.77it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.90it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.59it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.14it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.07it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.93it/s]
-------------------------------------
| approxkl           | 0.004446385  |
| clipfrac           | 0.27472913   |
| eplenmean          | 400          |
| eprewmean          | 84.6         |
| explained_variance | 0.662        |
| fps                | 1326         |
| nupdates           | 528          |
| policy_entropy     | 0.60503674   |
| policy_loss        | -0.000488468 |
| serial_timesteps   | 211200       |
| time_elapsed       | 4.72e+03     |
| time_remaining     | 33           |
| total_timesteps    | 6336000      |
| true_eprew         | 84.6         |
| value_loss         | 15.269885    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.875980615615845 seconds
Total simulation time for 400 steps: 8.326224327087402 	 Other agent action time: 0 	 48.04098283764642 steps/s
Curr learning rate 0.000972 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.97it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.91it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.02it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.81it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.18it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 169.78it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.06it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.57it/s]
-------------------------------------
| approxkl           | 0.0042212782 |
| clipfrac           | 0.27884385   |
| eplenmean          | 400          |
| eprewmean          | 82.6         |
| explained_variance | 0.635        |
| fps                | 1323         |
| nupdates           | 529          |
| policy_entropy     | 0.6420726    |
| policy_loss        | 0.0009874802 |
| serial_timesteps   | 211600       |
| time_elapsed       | 4.73e+03     |
| time_remaining     | 32.9         |
| total_timesteps    | 6348000      |
| true_eprew         | 82.6         |
| value_loss         | 16.270765    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.897546052932739 seconds
Total simulation time for 400 steps: 8.632168531417847 	 Other agent action time: 0 	 46.338298255432626 steps/s
Curr learning rate 0.000971 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.93it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 149.30it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 148.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.50it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.95it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 152.87it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.41it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.82it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.40it/s]
-------------------------------------
| approxkl           | 0.005110328  |
| clipfrac           | 0.28755215   |
| eplenmean          | 400          |
| eprewmean          | 85.4         |
| explained_variance | 0.628        |
| fps                | 1281         |
| nupdates           | 530          |
| policy_entropy     | 0.62495095   |
| policy_loss        | 0.0014904409 |
| serial_timesteps   | 212000       |
| time_elapsed       | 4.73e+03     |
| time_remaining     | 32.8         |
| total_timesteps    | 6360000      |
| true_eprew         | 85.4         |
| value_loss         | 16.644075    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 5.071246147155762 seconds
Total simulation time for 400 steps: 9.06847071647644 	 Other agent action time: 0 	 44.10887044860197 steps/s
Curr learning rate 0.00097 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.14it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.22it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.04it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.35it/s]
-------------------------------------
| approxkl           | 0.003620956  |
| clipfrac           | 0.27405208   |
| eplenmean          | 400          |
| eprewmean          | 84.8         |
| explained_variance | 0.602        |
| fps                | 1229         |
| nupdates           | 531          |
| policy_entropy     | 0.6406204    |
| policy_loss        | 0.0010954671 |
| serial_timesteps   | 212400       |
| time_elapsed       | 4.74e+03     |
| time_remaining     | 32.6         |
| total_timesteps    | 6372000      |
| true_eprew         | 84.8         |
| value_loss         | 16.508108    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.9163126945495605 seconds
Total simulation time for 400 steps: 8.326090335845947 	 Other agent action time: 0 	 48.04175595812332 steps/s
Curr learning rate 0.000969 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.13it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.70it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.11it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.66it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.35it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.17it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.60it/s]
--------------------------------------
| approxkl           | 0.0031709238  |
| clipfrac           | 0.25332296    |
| eplenmean          | 400           |
| eprewmean          | 85            |
| explained_variance | 0.606         |
| fps                | 1332          |
| nupdates           | 532           |
| policy_entropy     | 0.6226657     |
| policy_loss        | 4.7113896e-05 |
| serial_timesteps   | 212800        |
| time_elapsed       | 4.75e+03      |
| time_remaining     | 32.5          |
| total_timesteps    | 6384000       |
| true_eprew         | 85            |
| value_loss         | 16.472525     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.997540235519409 seconds
Total simulation time for 400 steps: 9.393706798553467 	 Other agent action time: 0 	 42.58169949072669 steps/s
Curr learning rate 0.000968 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.77it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 151.70it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 164.25it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 152.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.82it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 170.40it/s]
-------------------------------------
| approxkl           | 0.0045316815 |
| clipfrac           | 0.30029172   |
| eplenmean          | 400          |
| eprewmean          | 85.2         |
| explained_variance | 0.604        |
| fps                | 1182         |
| nupdates           | 533          |
| policy_entropy     | 0.66369885   |
| policy_loss        | 0.002312449  |
| serial_timesteps   | 213200       |
| time_elapsed       | 4.76e+03     |
| time_remaining     | 32.3         |
| total_timesteps    | 6396000      |
| true_eprew         | 85.2         |
| value_loss         | 17.177477    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.803503751754761 seconds
Total simulation time for 400 steps: 8.128319263458252 	 Other agent action time: 0 	 49.210665456786835 steps/s
Curr learning rate 0.000967 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.95it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.25it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.91it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 198.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.41it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.58it/s]
-------------------------------------
| approxkl           | 0.0037117866 |
| clipfrac           | 0.27674997   |
| eplenmean          | 400          |
| eprewmean          | 85           |
| explained_variance | 0.62         |
| fps                | 1360         |
| nupdates           | 534          |
| policy_entropy     | 0.633839     |
| policy_loss        | 0.0013578567 |
| serial_timesteps   | 213600       |
| time_elapsed       | 4.77e+03     |
| time_remaining     | 32.2         |
| total_timesteps    | 6408000      |
| true_eprew         | 85           |
| value_loss         | 16.189524    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.732081174850464 seconds
Total simulation time for 400 steps: 7.9894020557403564 	 Other agent action time: 0 	 50.06632501522457 steps/s
Curr learning rate 0.0009660000000000001 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.78it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.26it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.90it/s]
-------------------------------------
| approxkl           | 0.00427637   |
| clipfrac           | 0.29995835   |
| eplenmean          | 400          |
| eprewmean          | 85.6         |
| explained_variance | 0.601        |
| fps                | 1381         |
| nupdates           | 535          |
| policy_entropy     | 0.65422016   |
| policy_loss        | 0.0016283556 |
| serial_timesteps   | 214000       |
| time_elapsed       | 4.78e+03     |
| time_remaining     | 32           |
| total_timesteps    | 6420000      |
| true_eprew         | 85.6         |
| value_loss         | 16.055918    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.737383842468262 seconds
Total simulation time for 400 steps: 8.061611652374268 	 Other agent action time: 0 	 49.61787012925559 steps/s
Curr learning rate 0.0009649999999999999 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 147.03it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 146.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 155.83it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.10it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.75it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 162.33it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 163.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 163.16it/s]
-------------------------------------
| approxkl           | 0.004395419  |
| clipfrac           | 0.28343752   |
| eplenmean          | 400          |
| eprewmean          | 87.2         |
| explained_variance | 0.624        |
| fps                | 1358         |
| nupdates           | 536          |
| policy_entropy     | 0.60433805   |
| policy_loss        | 0.0010550616 |
| serial_timesteps   | 214400       |
| time_elapsed       | 4.79e+03     |
| time_remaining     | 31.9         |
| total_timesteps    | 6432000      |
| true_eprew         | 87.2         |
| value_loss         | 17.03383     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.756100416183472 seconds
Total simulation time for 400 steps: 8.201355934143066 	 Other agent action time: 0 	 48.77242290323725 steps/s
Curr learning rate 0.000964 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.16it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.82it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.34it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.41it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.88it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.69it/s]
-------------------------------------
| approxkl           | 0.0042416696 |
| clipfrac           | 0.2968646    |
| eplenmean          | 400          |
| eprewmean          | 84.6         |
| explained_variance | 0.593        |
| fps                | 1351         |
| nupdates           | 537          |
| policy_entropy     | 0.6812834    |
| policy_loss        | 0.0008619607 |
| serial_timesteps   | 214800       |
| time_elapsed       | 4.8e+03      |
| time_remaining     | 31.7         |
| total_timesteps    | 6444000      |
| true_eprew         | 84.6         |
| value_loss         | 17.38604     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.771421194076538 seconds
Total simulation time for 400 steps: 8.044071674346924 	 Other agent action time: 0 	 49.72606115328714 steps/s
Curr learning rate 0.0009630000000000001 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 188.68it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.37it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.99it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.89it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 155.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.86it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.04it/s]
-------------------------------------
| approxkl           | 0.005976666  |
| clipfrac           | 0.32680213   |
| eplenmean          | 400          |
| eprewmean          | 85.4         |
| explained_variance | 0.593        |
| fps                | 1374         |
| nupdates           | 538          |
| policy_entropy     | 0.6592792    |
| policy_loss        | 0.0023816181 |
| serial_timesteps   | 215200       |
| time_elapsed       | 4.81e+03     |
| time_remaining     | 31.6         |
| total_timesteps    | 6456000      |
| true_eprew         | 85.4         |
| value_loss         | 17.71337     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.598713636398315 seconds
Total simulation time for 400 steps: 7.8370935916900635 	 Other agent action time: 0 	 51.03932922584127 steps/s
Curr learning rate 0.000962 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.61it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.03it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.97it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.16it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.79it/s]
-------------------------------------
| approxkl           | 0.0054915426 |
| clipfrac           | 0.3083645    |
| eplenmean          | 400          |
| eprewmean          | 83.4         |
| explained_variance | 0.607        |
| fps                | 1406         |
| nupdates           | 539          |
| policy_entropy     | 0.6416558    |
| policy_loss        | 0.0015839086 |
| serial_timesteps   | 215600       |
| time_elapsed       | 4.82e+03     |
| time_remaining     | 31.4         |
| total_timesteps    | 6468000      |
| true_eprew         | 83.4         |
| value_loss         | 16.407738    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.652613162994385 seconds
Total simulation time for 400 steps: 7.931307315826416 	 Other agent action time: 0 	 50.43304767699842 steps/s
Curr learning rate 0.000961 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 180.16it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.54it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.57it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.64it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.02it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.29it/s]
-------------------------------------
| approxkl           | 0.006125687  |
| clipfrac           | 0.34100005   |
| eplenmean          | 400          |
| eprewmean          | 82.6         |
| explained_variance | 0.656        |
| fps                | 1395         |
| nupdates           | 540          |
| policy_entropy     | 0.67046726   |
| policy_loss        | 0.0024000246 |
| serial_timesteps   | 216000       |
| time_elapsed       | 4.82e+03     |
| time_remaining     | 31.3         |
| total_timesteps    | 6480000      |
| true_eprew         | 82.6         |
| value_loss         | 14.091763    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.955989122390747 seconds
Total simulation time for 400 steps: 8.471307754516602 	 Other agent action time: 0 	 47.21821135428991 steps/s
Curr learning rate 0.00096 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.21it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.71it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.95it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.40it/s]
-------------------------------------
| approxkl           | 0.0057649733 |
| clipfrac           | 0.30793753   |
| eplenmean          | 400          |
| eprewmean          | 82.8         |
| explained_variance | 0.534        |
| fps                | 1306         |
| nupdates           | 541          |
| policy_entropy     | 0.63067967   |
| policy_loss        | 0.0011432983 |
| serial_timesteps   | 216400       |
| time_elapsed       | 4.83e+03     |
| time_remaining     | 31.1         |
| total_timesteps    | 6492000      |
| true_eprew         | 82.8         |
| value_loss         | 18.466953    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.895001173019409 seconds
Total simulation time for 400 steps: 8.179964780807495 	 Other agent action time: 0 	 48.89996604123686 steps/s
Curr learning rate 0.000959 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.62it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.51it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.93it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 195.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.83it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 193.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.58it/s]
-------------------------------------
| approxkl           | 0.0062922607 |
| clipfrac           | 0.32462493   |
| eplenmean          | 400          |
| eprewmean          | 80.4         |
| explained_variance | 0.577        |
| fps                | 1354         |
| nupdates           | 542          |
| policy_entropy     | 0.62264884   |
| policy_loss        | 0.0023647128 |
| serial_timesteps   | 216800       |
| time_elapsed       | 4.84e+03     |
| time_remaining     | 31           |
| total_timesteps    | 6504000      |
| true_eprew         | 80.4         |
| value_loss         | 18.048788    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.906617641448975 seconds
Total simulation time for 400 steps: 8.218699932098389 	 Other agent action time: 0 	 48.66949801121069 steps/s
Curr learning rate 0.000958 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.73it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.27it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.90it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.47it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.36it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.40it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 210.28it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.83it/s]
-------------------------------------
| approxkl           | 0.004594885  |
| clipfrac           | 0.29967704   |
| eplenmean          | 400          |
| eprewmean          | 80.6         |
| explained_variance | 0.585        |
| fps                | 1347         |
| nupdates           | 543          |
| policy_entropy     | 0.64249784   |
| policy_loss        | 0.0017885078 |
| serial_timesteps   | 217200       |
| time_elapsed       | 4.85e+03     |
| time_remaining     | 30.8         |
| total_timesteps    | 6516000      |
| true_eprew         | 80.6         |
| value_loss         | 17.32101     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.9402360916137695 seconds
Total simulation time for 400 steps: 8.263490200042725 	 Other agent action time: 0 	 48.405696662886086 steps/s
Curr learning rate 0.0009570000000000001 	 Curr reward per step 0.2383333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.39it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 155.58it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 157.77it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.17it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 167.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.07it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 170.51it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 164.01it/s]
--------------------------------------
| approxkl           | 0.003721769   |
| clipfrac           | 0.25759372    |
| eplenmean          | 400           |
| eprewmean          | 85            |
| explained_variance | 0.63          |
| fps                | 1329          |
| nupdates           | 544           |
| policy_entropy     | 0.5575816     |
| policy_loss        | 0.00093717064 |
| serial_timesteps   | 217600        |
| time_elapsed       | 4.86e+03      |
| time_remaining     | 30.7          |
| total_timesteps    | 6528000       |
| true_eprew         | 85            |
| value_loss         | 17.074608     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.837688207626343 seconds
Total simulation time for 400 steps: 8.197259187698364 	 Other agent action time: 0 	 48.79679791024303 steps/s
Curr learning rate 0.000956 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.10it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.51it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.55it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.19it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.35it/s]
-------------------------------------
| approxkl           | 0.0047893752 |
| clipfrac           | 0.3070834    |
| eplenmean          | 400          |
| eprewmean          | 86           |
| explained_variance | 0.634        |
| fps                | 1352         |
| nupdates           | 545          |
| policy_entropy     | 0.66127944   |
| policy_loss        | 0.0018770878 |
| serial_timesteps   | 218000       |
| time_elapsed       | 4.87e+03     |
| time_remaining     | 30.5         |
| total_timesteps    | 6540000      |
| true_eprew         | 86           |
| value_loss         | 15.441775    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.903128623962402 seconds
Total simulation time for 400 steps: 8.12037205696106 	 Other agent action time: 0 	 49.2588267131315 steps/s
Curr learning rate 0.000955 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.74it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.98it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.07it/s]
-------------------------------------
| approxkl           | 0.0043850997 |
| clipfrac           | 0.27255195   |
| eplenmean          | 400          |
| eprewmean          | 85.8         |
| explained_variance | 0.63         |
| fps                | 1359         |
| nupdates           | 546          |
| policy_entropy     | 0.5811936    |
| policy_loss        | 0.0013219714 |
| serial_timesteps   | 218400       |
| time_elapsed       | 4.88e+03     |
| time_remaining     | 30.4         |
| total_timesteps    | 6552000      |
| true_eprew         | 85.8         |
| value_loss         | 16.040546    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.756103277206421 seconds
Total simulation time for 400 steps: 8.107037782669067 	 Other agent action time: 0 	 49.33984652879077 steps/s
Curr learning rate 0.000954 	 Curr reward per step 0.195

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.74it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.58it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.45it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.44it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.50it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.51it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.59it/s]
-------------------------------------
| approxkl           | 0.0041521215 |
| clipfrac           | 0.27687502   |
| eplenmean          | 400          |
| eprewmean          | 83.6         |
| explained_variance | 0.627        |
| fps                | 1359         |
| nupdates           | 547          |
| policy_entropy     | 0.6266505    |
| policy_loss        | 0.0006976102 |
| serial_timesteps   | 218800       |
| time_elapsed       | 4.89e+03     |
| time_remaining     | 30.2         |
| total_timesteps    | 6564000      |
| true_eprew         | 83.6         |
| value_loss         | 16.151178    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 5.0068676471710205 seconds
Total simulation time for 400 steps: 8.388405084609985 	 Other agent action time: 0 	 47.684869288665 steps/s
Curr learning rate 0.0009530000000000001 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.04it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.44it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.97it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.15it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.60it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.88it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.89it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.94it/s]
--------------------------------------
| approxkl           | 0.002764729   |
| clipfrac           | 0.24235418    |
| eplenmean          | 400           |
| eprewmean          | 86            |
| explained_variance | 0.618         |
| fps                | 1317          |
| nupdates           | 548           |
| policy_entropy     | 0.5919711     |
| policy_loss        | 6.7510635e-05 |
| serial_timesteps   | 219200        |
| time_elapsed       | 4.9e+03       |
| time_remaining     | 30.1          |
| total_timesteps    | 6576000       |
| true_eprew         | 86            |
| value_loss         | 16.871737     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7925498485565186 seconds
Total simulation time for 400 steps: 8.07567548751831 	 Other agent action time: 0 	 49.53146032406036 steps/s
Curr learning rate 0.0009519999999999999 	 Curr reward per step 0.2383333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.72it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.60it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.00it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.43it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.22it/s]
----------------------------------------
| approxkl           | 0.0037137058    |
| clipfrac           | 0.24989581      |
| eplenmean          | 400             |
| eprewmean          | 88.6            |
| explained_variance | 0.597           |
| fps                | 1371            |
| nupdates           | 549             |
| policy_entropy     | 0.55268365      |
| policy_loss        | -0.000120332785 |
| serial_timesteps   | 219600          |
| time_elapsed       | 4.9e+03         |
| time_remaining     | 29.9            |
| total_timesteps    | 6588000         |
| true_eprew         | 88.6            |
| value_loss         | 17.56377        |
----------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.812347173690796 seconds
Total simulation time for 400 steps: 8.192941427230835 	 Other agent action time: 0 	 48.8225143012157 steps/s
Curr learning rate 0.000951 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.57it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.29it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.92it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.89it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.27it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.94it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.33it/s]
--------------------------------------
| approxkl           | 0.00484356    |
| clipfrac           | 0.27848956    |
| eplenmean          | 400           |
| eprewmean          | 90.4          |
| explained_variance | 0.559         |
| fps                | 1347          |
| nupdates           | 550           |
| policy_entropy     | 0.5924791     |
| policy_loss        | 0.00071274606 |
| serial_timesteps   | 220000        |
| time_elapsed       | 4.91e+03      |
| time_remaining     | 29.8          |
| total_timesteps    | 6600000       |
| true_eprew         | 90.4          |
| value_loss         | 18.444914     |
--------------------------------------
Current reward shaping 0
BEST REW 90.4 overwriting previous model with 89.6
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←1X ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 3 
X X X ø1X 
O   X ↑0P 
O ↓1Xo  X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø2X 
O   X   P 
O ↓1Xo↓0X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø3X 
O   X   P 
O ↓1Xo  X 
D   X ↓0X 
X X X S X 


Timestep: 37
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X ø4X 
O   X   P 
O   Xo  X 
D ↓1X ↓0X 
X X X S X 


Timestep: 38
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø5X 
O   X   P 
O   Xo↑0X 
D ↓1X   X 
X X X S X 


Timestep: 39
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø6X 
O   X ↑0P 
O   Xo  X 
D ↓1X   X 
X X X S X 


Timestep: 40
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø7X 
O   X   P 
O   Xo↓0X 
D ↓1X   X 
X X X S X 


Timestep: 41
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X ø8X 
O   X   P 
O   Xo  X 
D ←1X ↓0X 
X X X S X 


Timestep: 42
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 3 
X X X ø9X 
O   X   P 
O   Xo  X 
D ←dX ←0X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø10X 
O   X   P 
O ↑dXo  X 
D   X ←0X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø11X 
O   X   P 
O ↑dXo  X 
D   X ←0X 
X X X S X 


Timestep: 45
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø12X 
O   X   P 
O ↑dXo↑0X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø13X 
O ↑dX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X ø14X 
O ↑dX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø15X 
O →dX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø16X 
O →1Xd←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø17X 
O →1X ←dP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø18X 
O ←1X ↑dP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø19X 
O ←1X ↑dP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←oX ↑dP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 5 
X X X P X 
O ←oX ↑sP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX   P 
O   Xo↓sX 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX   P 
O   Xo  X 
D   X ↓sX 
X X X S X 


Timestep: 57
Joint action taken: ('interact', 'stay') 	 Reward: 20 + shape * 0 
X X X P X 
O →oX   P 
O   Xo  X 
D   X ↓0X 
X X X S X 


Timestep: 58
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX   P 
O   Xo↑0X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X ø-X 
O →oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←1X ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø2X 
O ←oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø3X 
O →oX ↑0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →oX ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø6X 
O →1Xo←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø7X 
O ←1X ←oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←oX →oP 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø9X 
O ←oX →0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø10X 
O ←oX →0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø11X 
O →oX →0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →1Xo→0ø-
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X ø13X 
O   Xo  ø-
O ↓1Xo↓0X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø14X 
O   Xo  ø-
O ↓1Xo←0X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø15X 
O   Xo  ø-
O ↓1X ←oX 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø16X 
O   Xo↑oø-
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø17X 
O   Xo↑oø-
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø18X 
O   Xo↑oø-
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø19X 
O   Xo↑oø-
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑oø-
O →oX   X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑oø-
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑oø-
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑oø-
O →1Xo  X 
D   X   X 
X X X S X 


tot rew 160 tot rew shaped 139
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.8620312213897705 seconds
Total simulation time for 400 steps: 8.131573677062988 	 Other agent action time: 0 	 49.19097039338079 steps/s
Curr learning rate 0.0009500000000000001 	 Curr reward per step 0.205

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.28it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.15it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 199.93it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.96it/s]
-------------------------------------
| approxkl           | 0.002657838  |
| clipfrac           | 0.22983335   |
| eplenmean          | 400          |
| eprewmean          | 89.2         |
| explained_variance | 0.563        |
| fps                | 1363         |
| nupdates           | 551          |
| policy_entropy     | 0.6006353    |
| policy_loss        | 0.0002882499 |
| serial_timesteps   | 220400       |
| time_elapsed       | 4.93e+03     |
| time_remaining     | 29.7         |
| total_timesteps    | 6612000      |
| true_eprew         | 89.2         |
| value_loss         | 18.657227    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.843977451324463 seconds
Total simulation time for 400 steps: 8.16729187965393 	 Other agent action time: 0 	 48.97584240823643 steps/s
Curr learning rate 0.000949 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.28it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.79it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.44it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.75it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.98it/s]
--------------------------------------
| approxkl           | 0.003225883   |
| clipfrac           | 0.24866667    |
| eplenmean          | 400           |
| eprewmean          | 87.6          |
| explained_variance | 0.647         |
| fps                | 1357          |
| nupdates           | 552           |
| policy_entropy     | 0.5892647     |
| policy_loss        | 0.00063266355 |
| serial_timesteps   | 220800        |
| time_elapsed       | 4.94e+03      |
| time_remaining     | 29.5          |
| total_timesteps    | 6624000       |
| true_eprew         | 87.6          |
| value_loss         | 17.043413     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.879391193389893 seconds
Total simulation time for 400 steps: 8.19377064704895 	 Other agent action time: 0 	 48.817573401821186 steps/s
Curr learning rate 0.0009480000000000001 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.45it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 169.60it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.87it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.02it/s]
-------------------------------------
| approxkl           | 0.00698458   |
| clipfrac           | 0.3044896    |
| eplenmean          | 400          |
| eprewmean          | 86.8         |
| explained_variance | 0.642        |
| fps                | 1347         |
| nupdates           | 553          |
| policy_entropy     | 0.58040255   |
| policy_loss        | 0.0025957956 |
| serial_timesteps   | 221200       |
| time_elapsed       | 4.95e+03     |
| time_remaining     | 29.4         |
| total_timesteps    | 6636000      |
| true_eprew         | 86.8         |
| value_loss         | 15.488687    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.937488794326782 seconds
Total simulation time for 400 steps: 8.242746591567993 	 Other agent action time: 0 	 48.527513924689174 steps/s
Curr learning rate 0.000947 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.50it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.30it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.71it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.59it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.41it/s]
-------------------------------------
| approxkl           | 0.005403954  |
| clipfrac           | 0.29238543   |
| eplenmean          | 400          |
| eprewmean          | 88.8         |
| explained_variance | 0.621        |
| fps                | 1339         |
| nupdates           | 554          |
| policy_entropy     | 0.58125645   |
| policy_loss        | 0.0021747286 |
| serial_timesteps   | 221600       |
| time_elapsed       | 4.96e+03     |
| time_remaining     | 29.2         |
| total_timesteps    | 6648000      |
| true_eprew         | 88.8         |
| value_loss         | 16.860638    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.880662202835083 seconds
Total simulation time for 400 steps: 8.15885853767395 	 Other agent action time: 0 	 49.026465914683946 steps/s
Curr learning rate 0.000946 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.66it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.60it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.21it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.09it/s]
---------------------------------------
| approxkl           | 0.0044959537   |
| clipfrac           | 0.27715623     |
| eplenmean          | 400            |
| eprewmean          | 87.8           |
| explained_variance | 0.624          |
| fps                | 1356           |
| nupdates           | 555            |
| policy_entropy     | 0.5751593      |
| policy_loss        | -0.00042507265 |
| serial_timesteps   | 222000         |
| time_elapsed       | 4.96e+03       |
| time_remaining     | 29.1           |
| total_timesteps    | 6660000        |
| true_eprew         | 87.8           |
| value_loss         | 16.252779      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.80630898475647 seconds
Total simulation time for 400 steps: 8.08695101737976 	 Other agent action time: 0 	 49.46239925781117 steps/s
Curr learning rate 0.0009450000000000001 	 Curr reward per step 0.22

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.45it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.27it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 191.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.48it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.00it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.15it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.17it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.87it/s]
--------------------------------------
| approxkl           | 0.0033674582  |
| clipfrac           | 0.25232285    |
| eplenmean          | 400           |
| eprewmean          | 89.4          |
| explained_variance | 0.593         |
| fps                | 1369          |
| nupdates           | 556           |
| policy_entropy     | 0.57776165    |
| policy_loss        | -0.0006268172 |
| serial_timesteps   | 222400        |
| time_elapsed       | 4.97e+03      |
| time_remaining     | 28.9          |
| total_timesteps    | 6672000       |
| true_eprew         | 89.4          |
| value_loss         | 17.71794      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.889786958694458 seconds
Total simulation time for 400 steps: 8.319738626480103 	 Other agent action time: 0 	 48.078433465070425 steps/s
Curr learning rate 0.0009440000000000001 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.83it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.94it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.02it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.77it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 162.88it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 162.82it/s]
-------------------------------------
| approxkl           | 0.0044033662 |
| clipfrac           | 0.26805204   |
| eplenmean          | 400          |
| eprewmean          | 89.6         |
| explained_variance | 0.614        |
| fps                | 1327         |
| nupdates           | 557          |
| policy_entropy     | 0.5578815    |
| policy_loss        | 0.0013604163 |
| serial_timesteps   | 222800       |
| time_elapsed       | 4.98e+03     |
| time_remaining     | 28.8         |
| total_timesteps    | 6684000      |
| true_eprew         | 89.6         |
| value_loss         | 17.758585    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.899901628494263 seconds
Total simulation time for 400 steps: 8.210429430007935 	 Other agent action time: 0 	 48.718523605849136 steps/s
Curr learning rate 0.000943 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.62it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.03it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.41it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.37it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.20it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.24it/s]
------------------------------------
| approxkl           | 0.005833798 |
| clipfrac           | 0.29108337  |
| eplenmean          | 400         |
| eprewmean          | 91.4        |
| explained_variance | 0.642       |
| fps                | 1347        |
| nupdates           | 558         |
| policy_entropy     | 0.54046756  |
| policy_loss        | 0.001380232 |
| serial_timesteps   | 223200      |
| time_elapsed       | 4.99e+03    |
| time_remaining     | 28.6        |
| total_timesteps    | 6696000     |
| true_eprew         | 91.4        |
| value_loss         | 16.1354     |
------------------------------------
Current reward shaping 0
BEST REW 91.4 overwriting previous model with 90.4
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.998667001724243 seconds
Total simulation time for 400 steps: 8.367681741714478 	 Other agent action time: 0 	 47.802965307096265 steps/s
Curr learning rate 0.000942 	 Curr reward per step 0.185

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 154.97it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 165.75it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 167.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 166.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 170.55it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 170.81it/s]
-------------------------------------
| approxkl           | 0.005836156  |
| clipfrac           | 0.30854163   |
| eplenmean          | 400          |
| eprewmean          | 86.2         |
| explained_variance | 0.586        |
| fps                | 1314         |
| nupdates           | 559          |
| policy_entropy     | 0.6312548    |
| policy_loss        | 0.0032023734 |
| serial_timesteps   | 223600       |
| time_elapsed       | 5e+03        |
| time_remaining     | 28.5         |
| total_timesteps    | 6708000      |
| true_eprew         | 86.2         |
| value_loss         | 18.29498     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.91661810874939 seconds
Total simulation time for 400 steps: 8.349133253097534 	 Other agent action time: 0 	 47.90916468504078 steps/s
Curr learning rate 0.000941 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 163.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 163.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.30it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 167.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 170.88it/s]
-------------------------------------
| approxkl           | 0.0056608645 |
| clipfrac           | 0.2843438    |
| eplenmean          | 400          |
| eprewmean          | 84.4         |
| explained_variance | 0.574        |
| fps                | 1319         |
| nupdates           | 560          |
| policy_entropy     | 0.5693939    |
| policy_loss        | 0.0024102305 |
| serial_timesteps   | 224000       |
| time_elapsed       | 5.01e+03     |
| time_remaining     | 28.3         |
| total_timesteps    | 6720000      |
| true_eprew         | 84.4         |
| value_loss         | 18.32212     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.878561496734619 seconds
Total simulation time for 400 steps: 8.263335704803467 	 Other agent action time: 0 	 48.406601678724066 steps/s
Curr learning rate 0.00094 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.98it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.20it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.80it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.06it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.45it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 164.00it/s]
-------------------------------------
| approxkl           | 0.0050154394 |
| clipfrac           | 0.28516668   |
| eplenmean          | 400          |
| eprewmean          | 83.2         |
| explained_variance | 0.695        |
| fps                | 1334         |
| nupdates           | 561          |
| policy_entropy     | 0.57623416   |
| policy_loss        | 0.0015474949 |
| serial_timesteps   | 224400       |
| time_elapsed       | 5.02e+03     |
| time_remaining     | 28.2         |
| total_timesteps    | 6732000      |
| true_eprew         | 83.2         |
| value_loss         | 14.559735    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.905197620391846 seconds
Total simulation time for 400 steps: 8.292450904846191 	 Other agent action time: 0 	 48.23664373656237 steps/s
Curr learning rate 0.0009390000000000001 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.40it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.80it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.40it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.15it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.12it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.08it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.59it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.45it/s]
-------------------------------------
| approxkl           | 0.005418646  |
| clipfrac           | 0.3110521    |
| eplenmean          | 400          |
| eprewmean          | 84           |
| explained_variance | 0.61         |
| fps                | 1334         |
| nupdates           | 562          |
| policy_entropy     | 0.6300605    |
| policy_loss        | 0.0012148864 |
| serial_timesteps   | 224800       |
| time_elapsed       | 5.03e+03     |
| time_remaining     | 28.1         |
| total_timesteps    | 6744000      |
| true_eprew         | 84           |
| value_loss         | 17.064976    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8919837474823 seconds
Total simulation time for 400 steps: 8.24938678741455 	 Other agent action time: 0 	 48.488452573256595 steps/s
Curr learning rate 0.000938 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 153.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.66it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.81it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.41it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.51it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.77it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.97it/s]
-------------------------------------
| approxkl           | 0.005335158  |
| clipfrac           | 0.31183338   |
| eplenmean          | 400          |
| eprewmean          | 82.6         |
| explained_variance | 0.569        |
| fps                | 1336         |
| nupdates           | 563          |
| policy_entropy     | 0.63688976   |
| policy_loss        | 0.0025241293 |
| serial_timesteps   | 225200       |
| time_elapsed       | 5.04e+03     |
| time_remaining     | 27.9         |
| total_timesteps    | 6756000      |
| true_eprew         | 82.6         |
| value_loss         | 18.599638    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.886042594909668 seconds
Total simulation time for 400 steps: 8.28651237487793 	 Other agent action time: 0 	 48.27121253238851 steps/s
Curr learning rate 0.000937 	 Curr reward per step 0.24166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.61it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.47it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.94it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.13it/s]
-------------------------------------
| approxkl           | 0.0062771565 |
| clipfrac           | 0.29741672   |
| eplenmean          | 400          |
| eprewmean          | 87           |
| explained_variance | 0.574        |
| fps                | 1334         |
| nupdates           | 564          |
| policy_entropy     | 0.5469105    |
| policy_loss        | 0.0011991158 |
| serial_timesteps   | 225600       |
| time_elapsed       | 5.05e+03     |
| time_remaining     | 27.8         |
| total_timesteps    | 6768000      |
| true_eprew         | 87           |
| value_loss         | 17.920704    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.820912837982178 seconds
Total simulation time for 400 steps: 8.183050870895386 	 Other agent action time: 0 	 48.88152430075657 steps/s
Curr learning rate 0.000936 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.14it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.12it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.82it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.35it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.95it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.11it/s]
-------------------------------------
| approxkl           | 0.0044519943 |
| clipfrac           | 0.28158337   |
| eplenmean          | 400          |
| eprewmean          | 87.8         |
| explained_variance | 0.625        |
| fps                | 1346         |
| nupdates           | 565          |
| policy_entropy     | 0.6033688    |
| policy_loss        | 0.0004813236 |
| serial_timesteps   | 226000       |
| time_elapsed       | 5.06e+03     |
| time_remaining     | 27.6         |
| total_timesteps    | 6780000      |
| true_eprew         | 87.8         |
| value_loss         | 17.902905    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.840468168258667 seconds
Total simulation time for 400 steps: 8.215816974639893 	 Other agent action time: 0 	 48.686576299678634 steps/s
Curr learning rate 0.0009350000000000001 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.72it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.91it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.71it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.31it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.63it/s]
--------------------------------------
| approxkl           | 0.0035149057  |
| clipfrac           | 0.2509062     |
| eplenmean          | 400           |
| eprewmean          | 89.6          |
| explained_variance | 0.566         |
| fps                | 1341          |
| nupdates           | 566           |
| policy_entropy     | 0.5872459     |
| policy_loss        | 0.00028370562 |
| serial_timesteps   | 226400        |
| time_elapsed       | 5.07e+03      |
| time_remaining     | 27.5          |
| total_timesteps    | 6792000       |
| true_eprew         | 89.6          |
| value_loss         | 18.910078     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.930134296417236 seconds
Total simulation time for 400 steps: 8.350014448165894 	 Other agent action time: 0 	 47.90410872736409 steps/s
Curr learning rate 0.0009339999999999999 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.92it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.25it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.01it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 165.85it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.31it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.71it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 166.31it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 159.92it/s]
-------------------------------------
| approxkl           | 0.0053053694 |
| clipfrac           | 0.28959373   |
| eplenmean          | 400          |
| eprewmean          | 88.6         |
| explained_variance | 0.619        |
| fps                | 1319         |
| nupdates           | 567          |
| policy_entropy     | 0.5810889    |
| policy_loss        | 0.0008227844 |
| serial_timesteps   | 226800       |
| time_elapsed       | 5.08e+03     |
| time_remaining     | 27.3         |
| total_timesteps    | 6804000      |
| true_eprew         | 88.6         |
| value_loss         | 15.241439    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.825763702392578 seconds
Total simulation time for 400 steps: 8.153500318527222 	 Other agent action time: 0 	 49.058684537128045 steps/s
Curr learning rate 0.000933 	 Curr reward per step 0.24833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.48it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.41it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.41it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.75it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.06it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.23it/s]
-------------------------------------
| approxkl           | 0.0048236097 |
| clipfrac           | 0.2629375    |
| eplenmean          | 400          |
| eprewmean          | 93           |
| explained_variance | 0.628        |
| fps                | 1356         |
| nupdates           | 568          |
| policy_entropy     | 0.5434135    |
| policy_loss        | 0.0016497314 |
| serial_timesteps   | 227200       |
| time_elapsed       | 5.09e+03     |
| time_remaining     | 27.2         |
| total_timesteps    | 6816000      |
| true_eprew         | 93           |
| value_loss         | 17.709764    |
-------------------------------------
Current reward shaping 0
BEST REW 93.0 overwriting previous model with 91.4
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.879976272583008 seconds
Total simulation time for 400 steps: 8.168919086456299 	 Other agent action time: 0 	 48.9660866715135 steps/s
Curr learning rate 0.0009320000000000001 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.40it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.71it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.81it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 168.89it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.84it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.57it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 171.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.66it/s]
--------------------------------------
| approxkl           | 0.004668196   |
| clipfrac           | 0.27852085    |
| eplenmean          | 400           |
| eprewmean          | 94.2          |
| explained_variance | 0.603         |
| fps                | 1345          |
| nupdates           | 569           |
| policy_entropy     | 0.58728814    |
| policy_loss        | 0.00047134658 |
| serial_timesteps   | 227600        |
| time_elapsed       | 5.1e+03       |
| time_remaining     | 27            |
| total_timesteps    | 6828000       |
| true_eprew         | 94.2          |
| value_loss         | 18.030931     |
--------------------------------------
Current reward shaping 0
BEST REW 94.2 overwriting previous model with 93.0
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.8463215827941895 seconds
Total simulation time for 400 steps: 8.259742259979248 	 Other agent action time: 0 	 48.42766122837893 steps/s
Curr learning rate 0.000931 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.92it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.70it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.53it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.18it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.05it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.69it/s]
-------------------------------------
| approxkl           | 0.004557323  |
| clipfrac           | 0.28805214   |
| eplenmean          | 400          |
| eprewmean          | 89.8         |
| explained_variance | 0.616        |
| fps                | 1340         |
| nupdates           | 570          |
| policy_entropy     | 0.608942     |
| policy_loss        | 0.0010858119 |
| serial_timesteps   | 228000       |
| time_elapsed       | 5.11e+03     |
| time_remaining     | 26.9         |
| total_timesteps    | 6840000      |
| true_eprew         | 89.8         |
| value_loss         | 19.158176    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.969943523406982 seconds
Total simulation time for 400 steps: 8.272947311401367 	 Other agent action time: 0 	 48.35036232477146 steps/s
Curr learning rate 0.00093 	 Curr reward per step 0.225

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.39it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 150.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.33it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 167.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 167.93it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.48it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 170.97it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.89it/s]
--------------------------------------
| approxkl           | 0.002978694   |
| clipfrac           | 0.23957293    |
| eplenmean          | 400           |
| eprewmean          | 89            |
| explained_variance | 0.652         |
| fps                | 1328          |
| nupdates           | 571           |
| policy_entropy     | 0.5787892     |
| policy_loss        | -0.0011122371 |
| serial_timesteps   | 228400        |
| time_elapsed       | 5.12e+03      |
| time_remaining     | 26.8          |
| total_timesteps    | 6852000       |
| true_eprew         | 89            |
| value_loss         | 15.38054      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.920823097229004 seconds
Total simulation time for 400 steps: 8.280266046524048 	 Other agent action time: 0 	 48.307626560853684 steps/s
Curr learning rate 0.000929 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 177.85it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.12it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 192.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.52it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.31it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.31it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.90it/s]
-------------------------------------
| approxkl           | 0.004220967  |
| clipfrac           | 0.26990622   |
| eplenmean          | 400          |
| eprewmean          | 88.6         |
| explained_variance | 0.614        |
| fps                | 1340         |
| nupdates           | 572          |
| policy_entropy     | 0.57201564   |
| policy_loss        | 0.0014368352 |
| serial_timesteps   | 228800       |
| time_elapsed       | 5.13e+03     |
| time_remaining     | 26.6         |
| total_timesteps    | 6864000      |
| true_eprew         | 88.6         |
| value_loss         | 18.47832     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.960350036621094 seconds
Total simulation time for 400 steps: 8.357253074645996 	 Other agent action time: 0 	 47.862616630996726 steps/s
Curr learning rate 0.000928 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 151.58it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.33it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 164.77it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.99it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.19it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.50it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 156.69it/s]
--------------------------------------
| approxkl           | 0.0058723753  |
| clipfrac           | 0.3021771     |
| eplenmean          | 400           |
| eprewmean          | 92            |
| explained_variance | 0.616         |
| fps                | 1315          |
| nupdates           | 573           |
| policy_entropy     | 0.57548386    |
| policy_loss        | 0.00046735862 |
| serial_timesteps   | 229200        |
| time_elapsed       | 5.14e+03      |
| time_remaining     | 26.5          |
| total_timesteps    | 6876000       |
| true_eprew         | 92            |
| value_loss         | 15.779849     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.84735631942749 seconds
Total simulation time for 400 steps: 8.142639875411987 	 Other agent action time: 0 	 49.124117745629945 steps/s
Curr learning rate 0.000927 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 152.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 157.82it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 159.86it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.45it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 195.18it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.32it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.87it/s]
-------------------------------------
| approxkl           | 0.005173059  |
| clipfrac           | 0.288948     |
| eplenmean          | 400          |
| eprewmean          | 91.4         |
| explained_variance | 0.601        |
| fps                | 1356         |
| nupdates           | 574          |
| policy_entropy     | 0.5919405    |
| policy_loss        | 0.0003783694 |
| serial_timesteps   | 229600       |
| time_elapsed       | 5.15e+03     |
| time_remaining     | 26.3         |
| total_timesteps    | 6888000      |
| true_eprew         | 91.4         |
| value_loss         | 17.28655     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8176209926605225 seconds
Total simulation time for 400 steps: 8.183825016021729 	 Other agent action time: 0 	 48.87690037566878 steps/s
Curr learning rate 0.0009260000000000001 	 Curr reward per step 0.22

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 154.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.08it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.04it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 169.40it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 168.31it/s]
-------------------------------------
| approxkl           | 0.0035966984 |
| clipfrac           | 0.26131248   |
| eplenmean          | 400          |
| eprewmean          | 91.4         |
| explained_variance | 0.569        |
| fps                | 1346         |
| nupdates           | 575          |
| policy_entropy     | 0.61095524   |
| policy_loss        | 0.0006844492 |
| serial_timesteps   | 230000       |
| time_elapsed       | 5.16e+03     |
| time_remaining     | 26.2         |
| total_timesteps    | 6900000      |
| true_eprew         | 91.4         |
| value_loss         | 18.678677    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.911033868789673 seconds
Total simulation time for 400 steps: 8.38242244720459 	 Other agent action time: 0 	 47.71890256299286 steps/s
Curr learning rate 0.000925 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 155.09it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 151.07it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 155.84it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 158.65it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 166.56it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.23it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.92it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.68it/s]
-------------------------------------
| approxkl           | 0.0051610945 |
| clipfrac           | 0.3040104    |
| eplenmean          | 400          |
| eprewmean          | 89.2         |
| explained_variance | 0.644        |
| fps                | 1312         |
| nupdates           | 576          |
| policy_entropy     | 0.6076127    |
| policy_loss        | 0.0020707485 |
| serial_timesteps   | 230400       |
| time_elapsed       | 5.17e+03     |
| time_remaining     | 26           |
| total_timesteps    | 6912000      |
| true_eprew         | 89.2         |
| value_loss         | 17.747227    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.760742902755737 seconds
Total simulation time for 400 steps: 8.14572262763977 	 Other agent action time: 0 	 49.10552670216569 steps/s
Curr learning rate 0.000924 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.57it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.40it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.54it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.07it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 173.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.68it/s]
-------------------------------------
| approxkl           | 0.004980939  |
| clipfrac           | 0.2726458    |
| eplenmean          | 400          |
| eprewmean          | 87.2         |
| explained_variance | 0.645        |
| fps                | 1352         |
| nupdates           | 577          |
| policy_entropy     | 0.57117313   |
| policy_loss        | 0.0015096911 |
| serial_timesteps   | 230800       |
| time_elapsed       | 5.17e+03     |
| time_remaining     | 25.9         |
| total_timesteps    | 6924000      |
| true_eprew         | 87.2         |
| value_loss         | 16.450117    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.872277736663818 seconds
Total simulation time for 400 steps: 8.259425401687622 	 Other agent action time: 0 	 48.42951907020908 steps/s
Curr learning rate 0.000923 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 153.08it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 151.08it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 159.02it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 162.92it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 159.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 164.86it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 164.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 163.83it/s]
---------------------------------------
| approxkl           | 0.004479401    |
| clipfrac           | 0.29017708     |
| eplenmean          | 400            |
| eprewmean          | 87.4           |
| explained_variance | 0.682          |
| fps                | 1327           |
| nupdates           | 578            |
| policy_entropy     | 0.6310179      |
| policy_loss        | -0.00012315885 |
| serial_timesteps   | 231200         |
| time_elapsed       | 5.18e+03       |
| time_remaining     | 25.7           |
| total_timesteps    | 6936000        |
| true_eprew         | 87.4           |
| value_loss         | 15.380041      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7917821407318115 seconds
Total simulation time for 400 steps: 8.096304178237915 	 Other agent action time: 0 	 49.40525839866064 steps/s
Curr learning rate 0.000922 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.49it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.27it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.22it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.29it/s]
-------------------------------------
| approxkl           | 0.006065685  |
| clipfrac           | 0.31301042   |
| eplenmean          | 400          |
| eprewmean          | 87.4         |
| explained_variance | 0.641        |
| fps                | 1366         |
| nupdates           | 579          |
| policy_entropy     | 0.61958206   |
| policy_loss        | 0.0025475903 |
| serial_timesteps   | 231600       |
| time_elapsed       | 5.19e+03     |
| time_remaining     | 25.6         |
| total_timesteps    | 6948000      |
| true_eprew         | 87.4         |
| value_loss         | 17.21281     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.862605571746826 seconds
Total simulation time for 400 steps: 8.222235679626465 	 Other agent action time: 0 	 48.648569024984695 steps/s
Curr learning rate 0.0009209999999999999 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.67it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.29it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.98it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.61it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.07it/s]
-------------------------------------
| approxkl           | 0.006576683  |
| clipfrac           | 0.34084377   |
| eplenmean          | 400          |
| eprewmean          | 85.4         |
| explained_variance | 0.597        |
| fps                | 1345         |
| nupdates           | 580          |
| policy_entropy     | 0.68036264   |
| policy_loss        | 0.0027325707 |
| serial_timesteps   | 232000       |
| time_elapsed       | 5.2e+03      |
| time_remaining     | 25.4         |
| total_timesteps    | 6960000      |
| true_eprew         | 85.4         |
| value_loss         | 19.513514    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.764681100845337 seconds
Total simulation time for 400 steps: 8.102766513824463 	 Other agent action time: 0 	 49.36585539241981 steps/s
Curr learning rate 0.00092 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.41it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.89it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.98it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.26it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.94it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.87it/s]
-------------------------------------
| approxkl           | 0.0063609746 |
| clipfrac           | 0.33129168   |
| eplenmean          | 400          |
| eprewmean          | 82.4         |
| explained_variance | 0.625        |
| fps                | 1361         |
| nupdates           | 581          |
| policy_entropy     | 0.63739514   |
| policy_loss        | 0.0020148754 |
| serial_timesteps   | 232400       |
| time_elapsed       | 5.21e+03     |
| time_remaining     | 25.3         |
| total_timesteps    | 6972000      |
| true_eprew         | 82.4         |
| value_loss         | 17.676886    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.817350149154663 seconds
Total simulation time for 400 steps: 8.134675025939941 	 Other agent action time: 0 	 49.17221631158904 steps/s
Curr learning rate 0.0009190000000000001 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 180.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.71it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 191.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 195.79it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.37it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 199.41it/s]
-------------------------------------
| approxkl           | 0.005998386  |
| clipfrac           | 0.29971883   |
| eplenmean          | 400          |
| eprewmean          | 81.4         |
| explained_variance | 0.664        |
| fps                | 1365         |
| nupdates           | 582          |
| policy_entropy     | 0.602931     |
| policy_loss        | 0.0029019294 |
| serial_timesteps   | 232800       |
| time_elapsed       | 5.22e+03     |
| time_remaining     | 25.1         |
| total_timesteps    | 6984000      |
| true_eprew         | 81.4         |
| value_loss         | 16.112362    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.789546489715576 seconds
Total simulation time for 400 steps: 8.063118696212769 	 Other agent action time: 0 	 49.608596260387344 steps/s
Curr learning rate 0.000918 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.09it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.27it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.19it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.26it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.57it/s]
-------------------------------------
| approxkl           | 0.004164668  |
| clipfrac           | 0.28295836   |
| eplenmean          | 400          |
| eprewmean          | 82           |
| explained_variance | 0.627        |
| fps                | 1366         |
| nupdates           | 583          |
| policy_entropy     | 0.59314674   |
| policy_loss        | 0.0017036543 |
| serial_timesteps   | 233200       |
| time_elapsed       | 5.23e+03     |
| time_remaining     | 25           |
| total_timesteps    | 6996000      |
| true_eprew         | 82           |
| value_loss         | 16.69987     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.882043361663818 seconds
Total simulation time for 400 steps: 8.224737882614136 	 Other agent action time: 0 	 48.633768724172974 steps/s
Curr learning rate 0.0009170000000000001 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.39it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.41it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.81it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.40it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.09it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.82it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.39it/s]
-------------------------------------
| approxkl           | 0.003987845  |
| clipfrac           | 0.25634372   |
| eplenmean          | 400          |
| eprewmean          | 86           |
| explained_variance | 0.614        |
| fps                | 1341         |
| nupdates           | 584          |
| policy_entropy     | 0.5771475    |
| policy_loss        | 0.0003172151 |
| serial_timesteps   | 233600       |
| time_elapsed       | 5.24e+03     |
| time_remaining     | 24.8         |
| total_timesteps    | 7008000      |
| true_eprew         | 86           |
| value_loss         | 17.825836    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.776923894882202 seconds
Total simulation time for 400 steps: 8.092466354370117 	 Other agent action time: 0 	 49.42868866967743 steps/s
Curr learning rate 0.000916 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 152.69it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 148.07it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 147.60it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 150.50it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 152.13it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 157.98it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 166.39it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 170.28it/s]
--------------------------------------
| approxkl           | 0.0042970097  |
| clipfrac           | 0.29126033    |
| eplenmean          | 400           |
| eprewmean          | 85.6          |
| explained_variance | 0.595         |
| fps                | 1351          |
| nupdates           | 585           |
| policy_entropy     | 0.6190457     |
| policy_loss        | -7.030452e-05 |
| serial_timesteps   | 234000        |
| time_elapsed       | 5.24e+03      |
| time_remaining     | 24.7          |
| total_timesteps    | 7020000       |
| true_eprew         | 85.6          |
| value_loss         | 18.827904     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.849628210067749 seconds
Total simulation time for 400 steps: 8.26523756980896 	 Other agent action time: 0 	 48.39546312148478 steps/s
Curr learning rate 0.000915 	 Curr reward per step 0.22

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 149.37it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.95it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 155.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 161.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 164.37it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.29it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 169.23it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 165.76it/s]
--------------------------------------
| approxkl           | 0.0036982629  |
| clipfrac           | 0.2695312     |
| eplenmean          | 400           |
| eprewmean          | 87            |
| explained_variance | 0.671         |
| fps                | 1329          |
| nupdates           | 586           |
| policy_entropy     | 0.625341      |
| policy_loss        | 0.00015621074 |
| serial_timesteps   | 234400        |
| time_elapsed       | 5.25e+03      |
| time_remaining     | 24.5          |
| total_timesteps    | 7032000       |
| true_eprew         | 87            |
| value_loss         | 15.821025     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.817551612854004 seconds
Total simulation time for 400 steps: 8.255484104156494 	 Other agent action time: 0 	 48.45264008183444 steps/s
Curr learning rate 0.000914 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 173.01it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.95it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 199.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 197.88it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.07it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.93it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.93it/s]
-------------------------------------
| approxkl           | 0.005673749  |
| clipfrac           | 0.3100729    |
| eplenmean          | 400          |
| eprewmean          | 88.8         |
| explained_variance | 0.672        |
| fps                | 1345         |
| nupdates           | 587          |
| policy_entropy     | 0.6225344    |
| policy_loss        | 0.0013915434 |
| serial_timesteps   | 234800       |
| time_elapsed       | 5.26e+03     |
| time_remaining     | 24.4         |
| total_timesteps    | 7044000      |
| true_eprew         | 88.8         |
| value_loss         | 15.5126505   |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.850074529647827 seconds
Total simulation time for 400 steps: 8.095732927322388 	 Other agent action time: 0 	 49.408744531336396 steps/s
Curr learning rate 0.0009130000000000001 	 Curr reward per step 0.175

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.78it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.21it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.62it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.82it/s]
-------------------------------------
| approxkl           | 0.005671486  |
| clipfrac           | 0.33545834   |
| eplenmean          | 400          |
| eprewmean          | 84.6         |
| explained_variance | 0.596        |
| fps                | 1361         |
| nupdates           | 588          |
| policy_entropy     | 0.7130158    |
| policy_loss        | 0.0025875575 |
| serial_timesteps   | 235200       |
| time_elapsed       | 5.27e+03     |
| time_remaining     | 24.2         |
| total_timesteps    | 7056000      |
| true_eprew         | 84.6         |
| value_loss         | 18.978228    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.841330289840698 seconds
Total simulation time for 400 steps: 8.282898426055908 	 Other agent action time: 0 	 48.292273963145675 steps/s
Curr learning rate 0.000912 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 145.67it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 145.23it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 148.33it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 147.99it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.51it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.77it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.74it/s]
--------------------------------------
| approxkl           | 0.003213612   |
| clipfrac           | 0.25126043    |
| eplenmean          | 400           |
| eprewmean          | 83.6          |
| explained_variance | 0.589         |
| fps                | 1329          |
| nupdates           | 589           |
| policy_entropy     | 0.5850366     |
| policy_loss        | -0.0007178138 |
| serial_timesteps   | 235600        |
| time_elapsed       | 5.28e+03      |
| time_remaining     | 24.1          |
| total_timesteps    | 7068000       |
| true_eprew         | 83.6          |
| value_loss         | 17.99298      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.959973096847534 seconds
Total simulation time for 400 steps: 8.39302110671997 	 Other agent action time: 0 	 47.65864340311683 steps/s
Curr learning rate 0.000911 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.66it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.15it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 156.99it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.62it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.51it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.63it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 163.17it/s]
---------------------------------------
| approxkl           | 0.0039287363   |
| clipfrac           | 0.26986456     |
| eplenmean          | 400            |
| eprewmean          | 80             |
| explained_variance | 0.572          |
| fps                | 1312           |
| nupdates           | 590            |
| policy_entropy     | 0.62532353     |
| policy_loss        | -0.00022224005 |
| serial_timesteps   | 236000         |
| time_elapsed       | 5.29e+03       |
| time_remaining     | 23.9           |
| total_timesteps    | 7080000        |
| true_eprew         | 80             |
| value_loss         | 19.558912      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.914283514022827 seconds
Total simulation time for 400 steps: 8.223843336105347 	 Other agent action time: 0 	 48.639058850242186 steps/s
Curr learning rate 0.00091 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.94it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.88it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.41it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.04it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.76it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.99it/s]
-------------------------------------
| approxkl           | 0.0046480917 |
| clipfrac           | 0.28347906   |
| eplenmean          | 400          |
| eprewmean          | 81           |
| explained_variance | 0.577        |
| fps                | 1345         |
| nupdates           | 591          |
| policy_entropy     | 0.6126754    |
| policy_loss        | 0.0012746447 |
| serial_timesteps   | 236400       |
| time_elapsed       | 5.3e+03      |
| time_remaining     | 23.8         |
| total_timesteps    | 7092000      |
| true_eprew         | 81           |
| value_loss         | 18.637932    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.947293519973755 seconds
Total simulation time for 400 steps: 8.319206953048706 	 Other agent action time: 0 	 48.08150611680764 steps/s
Curr learning rate 0.000909 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 150.58it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 156.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 166.65it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.07it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 161.07it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 165.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 162.53it/s]
-------------------------------------
| approxkl           | 0.004449094  |
| clipfrac           | 0.29509374   |
| eplenmean          | 400          |
| eprewmean          | 82.8         |
| explained_variance | 0.64         |
| fps                | 1320         |
| nupdates           | 592          |
| policy_entropy     | 0.6119986    |
| policy_loss        | 0.0011645437 |
| serial_timesteps   | 236800       |
| time_elapsed       | 5.31e+03     |
| time_remaining     | 23.6         |
| total_timesteps    | 7104000      |
| true_eprew         | 82.8         |
| value_loss         | 16.347057    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.9891955852508545 seconds
Total simulation time for 400 steps: 8.30935788154602 	 Other agent action time: 0 	 48.138497065861955 steps/s
Curr learning rate 0.000908 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.30it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 147.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 157.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.75it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.30it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.48it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.65it/s]
-------------------------------------
| approxkl           | 0.004246904  |
| clipfrac           | 0.26956245   |
| eplenmean          | 400          |
| eprewmean          | 83.8         |
| explained_variance | 0.613        |
| fps                | 1326         |
| nupdates           | 593          |
| policy_entropy     | 0.58066547   |
| policy_loss        | 0.0007282178 |
| serial_timesteps   | 237200       |
| time_elapsed       | 5.32e+03     |
| time_remaining     | 23.5         |
| total_timesteps    | 7116000      |
| true_eprew         | 83.8         |
| value_loss         | 16.804594    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.945885181427002 seconds
Total simulation time for 400 steps: 8.337132215499878 	 Other agent action time: 0 	 47.97812840923224 steps/s
Curr learning rate 0.000907 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.81it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.44it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 160.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.49it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.31it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.64it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.59it/s]
--------------------------------------
| approxkl           | 0.0049685254  |
| clipfrac           | 0.28060415    |
| eplenmean          | 400           |
| eprewmean          | 88            |
| explained_variance | 0.582         |
| fps                | 1324          |
| nupdates           | 594           |
| policy_entropy     | 0.55962306    |
| policy_loss        | 0.00092733785 |
| serial_timesteps   | 237600        |
| time_elapsed       | 5.33e+03      |
| time_remaining     | 23.3          |
| total_timesteps    | 7128000       |
| true_eprew         | 88            |
| value_loss         | 19.295374     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.999687671661377 seconds
Total simulation time for 400 steps: 8.344232320785522 	 Other agent action time: 0 	 47.937303831246176 steps/s
Curr learning rate 0.000906 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.81it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.01it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.69it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.82it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.05it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.86it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.88it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.85it/s]
-------------------------------------
| approxkl           | 0.0046565714 |
| clipfrac           | 0.28422907   |
| eplenmean          | 400          |
| eprewmean          | 89.8         |
| explained_variance | 0.65         |
| fps                | 1322         |
| nupdates           | 595          |
| policy_entropy     | 0.59326375   |
| policy_loss        | 0.0005832408 |
| serial_timesteps   | 238000       |
| time_elapsed       | 5.34e+03     |
| time_remaining     | 23.2         |
| total_timesteps    | 7140000      |
| true_eprew         | 89.8         |
| value_loss         | 15.679995    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.786778688430786 seconds
Total simulation time for 400 steps: 8.235030174255371 	 Other agent action time: 0 	 48.57298534867468 steps/s
Curr learning rate 0.000905 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.55it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.16it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.03it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.97it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.29it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.79it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.46it/s]
------------------------------------
| approxkl           | 0.004775918 |
| clipfrac           | 0.2750834   |
| eplenmean          | 400         |
| eprewmean          | 89.2        |
| explained_variance | 0.614       |
| fps                | 1345        |
| nupdates           | 596         |
| policy_entropy     | 0.573099    |
| policy_loss        | 0.002136717 |
| serial_timesteps   | 238400      |
| time_elapsed       | 5.34e+03    |
| time_remaining     | 23          |
| total_timesteps    | 7152000     |
| true_eprew         | 89.2        |
| value_loss         | 18.33382    |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.888257265090942 seconds
Total simulation time for 400 steps: 8.311205625534058 	 Other agent action time: 0 	 48.12779493399876 steps/s
Curr learning rate 0.0009040000000000001 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.65it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.90it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.75it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 171.21it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.94it/s]
--------------------------------------
| approxkl           | 0.004703185   |
| clipfrac           | 0.2710313     |
| eplenmean          | 400           |
| eprewmean          | 87.2          |
| explained_variance | 0.6           |
| fps                | 1327          |
| nupdates           | 597           |
| policy_entropy     | 0.5541279     |
| policy_loss        | -0.0008900533 |
| serial_timesteps   | 238800        |
| time_elapsed       | 5.35e+03      |
| time_remaining     | 22.9          |
| total_timesteps    | 7164000       |
| true_eprew         | 87.2          |
| value_loss         | 17.031488     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.814307689666748 seconds
Total simulation time for 400 steps: 8.102293014526367 	 Other agent action time: 0 	 49.368740340895044 steps/s
Curr learning rate 0.0009029999999999999 	 Curr reward per step 0.185

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.96it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.79it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.13it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.75it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.21it/s]
--------------------------------------
| approxkl           | 0.0029471004  |
| clipfrac           | 0.2390521     |
| eplenmean          | 400           |
| eprewmean          | 82.6          |
| explained_variance | 0.513         |
| fps                | 1364          |
| nupdates           | 598           |
| policy_entropy     | 0.6049822     |
| policy_loss        | 0.00037168618 |
| serial_timesteps   | 239200        |
| time_elapsed       | 5.36e+03      |
| time_remaining     | 22.7          |
| total_timesteps    | 7176000       |
| true_eprew         | 82.6          |
| value_loss         | 21.479551     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.880514621734619 seconds
Total simulation time for 400 steps: 8.225559949874878 	 Other agent action time: 0 	 48.62890823695043 steps/s
Curr learning rate 0.000902 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.64it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.47it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.05it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.29it/s]
-------------------------------------
| approxkl           | 0.005240008  |
| clipfrac           | 0.28698954   |
| eplenmean          | 400          |
| eprewmean          | 79.8         |
| explained_variance | 0.539        |
| fps                | 1343         |
| nupdates           | 599          |
| policy_entropy     | 0.6068403    |
| policy_loss        | 0.0008985336 |
| serial_timesteps   | 239600       |
| time_elapsed       | 5.37e+03     |
| time_remaining     | 22.6         |
| total_timesteps    | 7188000      |
| true_eprew         | 79.8         |
| value_loss         | 19.94993     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7871434688568115 seconds
Total simulation time for 400 steps: 8.139983654022217 	 Other agent action time: 0 	 49.14014781864429 steps/s
Curr learning rate 0.0009010000000000001 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.07it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.17it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 194.69it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.63it/s]
--------------------------------------
| approxkl           | 0.0037935781  |
| clipfrac           | 0.2565728     |
| eplenmean          | 400           |
| eprewmean          | 82            |
| explained_variance | 0.624         |
| fps                | 1360          |
| nupdates           | 600           |
| policy_entropy     | 0.54909205    |
| policy_loss        | -0.0002868764 |
| serial_timesteps   | 240000        |
| time_elapsed       | 5.38e+03      |
| time_remaining     | 22.4          |
| total_timesteps    | 7200000       |
| true_eprew         | 82            |
| value_loss         | 17.579395     |
--------------------------------------
Current reward shaping 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   Xo↓0X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   Xo←0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   X ←oX 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('←', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø=X 
O →1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø2X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø3X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø6X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø7X 
O ←1X →oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø8X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø9X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø10X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø11X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø13X 
O →1Xo→0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø14X 
O ←1Xo←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø15X 
O ←oX ←oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø16X 
O ←oX →oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X ø17X 
O →oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø18X 
O →1Xo→0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø19X 
O →1Xo←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←1Xo←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←oX ←oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('→', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←oX →oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø20X 
O ←oX →0ø1
O   X   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX →0ø2
O   X   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo→0ø3
O   X   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo→0ø4
O   X   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo←0ø5
O   X   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø6
O ↓1X ↓0X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø7
O   X   X 
D ↓1X ↓0X 
X X X S X 


Timestep: 57
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø8
O   X   X 
D ↓1X ←0X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø9
O   X   X 
D ↓1X ←0X 
X X X S X 


Timestep: 59
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø10
O   X   X 
D ↓1X ←0X 
X X X S X 


Timestep: 60
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø11
O   X   X 
D ←1X ←0X 
X X X S X 


Timestep: 61
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   Xo  ø12
O   X   X 
D ←dX ←0X 
X X X S X 


Timestep: 62
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø13
O   X   X 
D ←dX ←0X 
X X X S X 


Timestep: 63
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø14
O   X   X 
D ←dX ←0X 
X X X S X 


Timestep: 64
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø15
O   X   X 
D →dX ←0X 
X X X S X 


Timestep: 65
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø16
O   X   X 
D →dX ←0X 
X X X S X 


Timestep: 66
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø17
O   X   X 
D →dX ←0X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø18
O   X   X 
D →1Xd←0X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø19
O   X   X 
D ←1X ←dX 
X X X S X 


Timestep: 69
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X ↑dX 
D ←1X   X 
X X X S X 


Timestep: 70
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   Xo↑dø20
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 71
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 5 
X X X P X 
O   Xo↑sø20
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 72
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø20
O   X ↓sX 
D →dX   X 
X X X S X 


Timestep: 73
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø20
O   X   X 
D →dX ↓sX 
X X X S X 


Timestep: 74
Joint action taken: ('interact', 'interact') 	 Reward: 20 + shape * 0 
X X X P X 
O   Xo  ø20
O   X   X 
D →1Xd↓0X 
X X X S X 


Timestep: 75
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø20
O ↑1X   X 
D   Xd↓0X 
X X X S X 


Timestep: 76
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø20
O ←1X   X 
D   Xd←0X 
X X X S X 


Timestep: 77
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø20
O ←1X   X 
D   X ←dX 
X X X S X 


Timestep: 78
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø20
O ←1X ↑dX 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo↑dø20
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo→dø20
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 5 
X X X P X 
O   Xo→sP 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  P 
O →1Xo↓sX 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  P 
O →1Xo  X 
D   X ↓sX 
X X X S X 


Timestep: 84
Joint action taken: ('interact', 'stay') 	 Reward: 20 + shape * 0 
X X X P X 
O   Xo  P 
O →1Xo  X 
D   X ↓0X 
X X X S X 


Timestep: 85
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  P 
O   Xo↑0X 
D ↓1X   X 
X X X S X 


Timestep: 86
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  P 
O   Xo←0X 
D ↓1X   X 
X X X S X 


Timestep: 87
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  P 
O   X ←oX 
D ↓1X   X 
X X X S X 


Timestep: 88
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo↑oP 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 89
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   Xo↑0P 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 90
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xo←0P 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 91
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←oP 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 92
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   Xo←0P 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 93
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   X ←oP 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 94
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑oP 
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø=X 
O   X ↑0P 
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ↑dX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ↑dX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ↑dX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ↑dX ↑0P 
O   X   X 
D   X   X 
X X X S X 


tot rew 160 tot rew shaped 133
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ↓0X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↓oX   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.915752172470093 seconds
Total simulation time for 400 steps: 8.239725351333618 	 Other agent action time: 0 	 48.54530739125414 steps/s
Curr learning rate 0.0009 	 Curr reward per step 0.19166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 172.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 201.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 198.60it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.67it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.16it/s]
-------------------------------------
| approxkl           | 0.003411155  |
| clipfrac           | 0.25792703   |
| eplenmean          | 400          |
| eprewmean          | 80           |
| explained_variance | 0.578        |
| fps                | 1348         |
| nupdates           | 601          |
| policy_entropy     | 0.5848145    |
| policy_loss        | 0.0007234318 |
| serial_timesteps   | 240400       |
| time_elapsed       | 5.39e+03     |
| time_remaining     | 22.3         |
| total_timesteps    | 7212000      |
| true_eprew         | 80           |
| value_loss         | 18.652357    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.756389379501343 seconds
Total simulation time for 400 steps: 8.120216131210327 	 Other agent action time: 0 	 49.259772589375594 steps/s
Curr learning rate 0.0008990000000000001 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.73it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.93it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.77it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.74it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.97it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 200.12it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 201.71it/s]
-------------------------------------
| approxkl           | 0.0041321865 |
| clipfrac           | 0.2717083    |
| eplenmean          | 400          |
| eprewmean          | 83.6         |
| explained_variance | 0.664        |
| fps                | 1366         |
| nupdates           | 602          |
| policy_entropy     | 0.6085761    |
| policy_loss        | 0.001045129  |
| serial_timesteps   | 240800       |
| time_elapsed       | 5.4e+03      |
| time_remaining     | 22.1         |
| total_timesteps    | 7224000      |
| true_eprew         | 83.6         |
| value_loss         | 17.09739     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.763849973678589 seconds
Total simulation time for 400 steps: 8.070757150650024 	 Other agent action time: 0 	 49.56164490314068 steps/s
Curr learning rate 0.000898 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.62it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.85it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.70it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.93it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.04it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 184.51it/s]
-------------------------------------
| approxkl           | 0.0038839239 |
| clipfrac           | 0.2669584    |
| eplenmean          | 400          |
| eprewmean          | 82.4         |
| explained_variance | 0.622        |
| fps                | 1368         |
| nupdates           | 603          |
| policy_entropy     | 0.58782524   |
| policy_loss        | 0.0015887932 |
| serial_timesteps   | 241200       |
| time_elapsed       | 5.41e+03     |
| time_remaining     | 22           |
| total_timesteps    | 7236000      |
| true_eprew         | 82.4         |
| value_loss         | 17.990845    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.914487838745117 seconds
Total simulation time for 400 steps: 8.248265504837036 	 Other agent action time: 0 	 48.49504417206596 steps/s
Curr learning rate 0.000897 	 Curr reward per step 0.2366666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.68it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.78it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.64it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.48it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.30it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.58it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.27it/s]
-------------------------------------
| approxkl           | 0.004851393  |
| clipfrac           | 0.27347916   |
| eplenmean          | 400          |
| eprewmean          | 85.8         |
| explained_variance | 0.599        |
| fps                | 1337         |
| nupdates           | 604          |
| policy_entropy     | 0.55528504   |
| policy_loss        | 0.0011814191 |
| serial_timesteps   | 241600       |
| time_elapsed       | 5.42e+03     |
| time_remaining     | 21.8         |
| total_timesteps    | 7248000      |
| true_eprew         | 85.8         |
| value_loss         | 18.431309    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.872720003128052 seconds
Total simulation time for 400 steps: 8.16775631904602 	 Other agent action time: 0 	 48.97305751730841 steps/s
Curr learning rate 0.000896 	 Curr reward per step 0.2366666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.14it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.76it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.40it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.36it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.27it/s]
-------------------------------------
| approxkl           | 0.0050169756 |
| clipfrac           | 0.27615625   |
| eplenmean          | 400          |
| eprewmean          | 90.6         |
| explained_variance | 0.6          |
| fps                | 1354         |
| nupdates           | 605          |
| policy_entropy     | 0.55093074   |
| policy_loss        | 0.0010769783 |
| serial_timesteps   | 242000       |
| time_elapsed       | 5.43e+03     |
| time_remaining     | 21.7         |
| total_timesteps    | 7260000      |
| true_eprew         | 90.6         |
| value_loss         | 16.868986    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.924168348312378 seconds
Total simulation time for 400 steps: 8.173881530761719 	 Other agent action time: 0 	 48.93635887609008 steps/s
Curr learning rate 0.0008950000000000001 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.03it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.06it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.60it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.43it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.21it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.69it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.20it/s]
--------------------------------------
| approxkl           | 0.004006156   |
| clipfrac           | 0.26419792    |
| eplenmean          | 400           |
| eprewmean          | 92.6          |
| explained_variance | 0.645         |
| fps                | 1351          |
| nupdates           | 606           |
| policy_entropy     | 0.5863573     |
| policy_loss        | 0.00024825337 |
| serial_timesteps   | 242400        |
| time_elapsed       | 5.44e+03      |
| time_remaining     | 21.5          |
| total_timesteps    | 7272000       |
| true_eprew         | 92.6          |
| value_loss         | 15.050589     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.84005331993103 seconds
Total simulation time for 400 steps: 8.135154485702515 	 Other agent action time: 0 	 49.16931825978199 steps/s
Curr learning rate 0.000894 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.80it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.37it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.40it/s]
-------------------------------------
| approxkl           | 0.0049706544 |
| clipfrac           | 0.27580208   |
| eplenmean          | 400          |
| eprewmean          | 90.4         |
| explained_variance | 0.638        |
| fps                | 1359         |
| nupdates           | 607          |
| policy_entropy     | 0.593454     |
| policy_loss        | 0.0020342295 |
| serial_timesteps   | 242800       |
| time_elapsed       | 5.44e+03     |
| time_remaining     | 21.4         |
| total_timesteps    | 7284000      |
| true_eprew         | 90.4         |
| value_loss         | 15.71126     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.893129348754883 seconds
Total simulation time for 400 steps: 8.21365761756897 	 Other agent action time: 0 	 48.69937592046717 steps/s
Curr learning rate 0.000893 	 Curr reward per step 0.235

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.05it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.62it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 167.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.49it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.88it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.11it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.65it/s]
-------------------------------------
| approxkl           | 0.0050092507 |
| clipfrac           | 0.28343758   |
| eplenmean          | 400          |
| eprewmean          | 90.2         |
| explained_variance | 0.571        |
| fps                | 1345         |
| nupdates           | 608          |
| policy_entropy     | 0.55804837   |
| policy_loss        | 0.0016129015 |
| serial_timesteps   | 243200       |
| time_elapsed       | 5.45e+03     |
| time_remaining     | 21.2         |
| total_timesteps    | 7296000      |
| true_eprew         | 90.2         |
| value_loss         | 19.307016    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7280590534210205 seconds
Total simulation time for 400 steps: 8.088599681854248 	 Other agent action time: 0 	 49.452317549766924 steps/s
Curr learning rate 0.000892 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.41it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.55it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.52it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.81it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.56it/s]
-------------------------------------
| approxkl           | 0.00439453   |
| clipfrac           | 0.270573     |
| eplenmean          | 400          |
| eprewmean          | 87.8         |
| explained_variance | 0.599        |
| fps                | 1366         |
| nupdates           | 609          |
| policy_entropy     | 0.6055746    |
| policy_loss        | 0.0017418117 |
| serial_timesteps   | 243600       |
| time_elapsed       | 5.46e+03     |
| time_remaining     | 21.1         |
| total_timesteps    | 7308000      |
| true_eprew         | 87.8         |
| value_loss         | 18.923471    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.755212306976318 seconds
Total simulation time for 400 steps: 8.052320957183838 	 Other agent action time: 0 	 49.67511877965346 steps/s
Curr learning rate 0.000891 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.38it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.50it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.72it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.18it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.95it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.01it/s]
-------------------------------------
| approxkl           | 0.0049618063 |
| clipfrac           | 0.28247917   |
| eplenmean          | 400          |
| eprewmean          | 86.6         |
| explained_variance | 0.642        |
| fps                | 1372         |
| nupdates           | 610          |
| policy_entropy     | 0.6012041    |
| policy_loss        | 0.0022448264 |
| serial_timesteps   | 244000       |
| time_elapsed       | 5.47e+03     |
| time_remaining     | 20.9         |
| total_timesteps    | 7320000      |
| true_eprew         | 86.6         |
| value_loss         | 17.665865    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.775256395339966 seconds
Total simulation time for 400 steps: 8.199285984039307 	 Other agent action time: 0 	 48.78473574145824 steps/s
Curr learning rate 0.00089 	 Curr reward per step 0.245

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.81it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.26it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.15it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.78it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 188.41it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.57it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.02it/s]
-------------------------------------
| approxkl           | 0.003991853  |
| clipfrac           | 0.2696146    |
| eplenmean          | 400          |
| eprewmean          | 90.4         |
| explained_variance | 0.622        |
| fps                | 1349         |
| nupdates           | 611          |
| policy_entropy     | 0.5784939    |
| policy_loss        | 0.0019676615 |
| serial_timesteps   | 244400       |
| time_elapsed       | 5.48e+03     |
| time_remaining     | 20.8         |
| total_timesteps    | 7332000      |
| true_eprew         | 90.4         |
| value_loss         | 18.349651    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.803192138671875 seconds
Total simulation time for 400 steps: 8.106621503829956 	 Other agent action time: 0 	 49.342380153189694 steps/s
Curr learning rate 0.000889 	 Curr reward per step 0.19

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.11it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.54it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.36it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.44it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.70it/s]
-------------------------------------
| approxkl           | 0.004654211  |
| clipfrac           | 0.3015104    |
| eplenmean          | 400          |
| eprewmean          | 87           |
| explained_variance | 0.65         |
| fps                | 1360         |
| nupdates           | 612          |
| policy_entropy     | 0.6481731    |
| policy_loss        | 0.0014437712 |
| serial_timesteps   | 244800       |
| time_elapsed       | 5.49e+03     |
| time_remaining     | 20.6         |
| total_timesteps    | 7344000      |
| true_eprew         | 87           |
| value_loss         | 16.892042    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.83423924446106 seconds
Total simulation time for 400 steps: 8.110708951950073 	 Other agent action time: 0 	 49.31751371793796 steps/s
Curr learning rate 0.0008880000000000001 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 182.49it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.91it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.42it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.78it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.26it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 198.99it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 198.55it/s]
--------------------------------------
| approxkl           | 0.0033433842  |
| clipfrac           | 0.252802      |
| eplenmean          | 400           |
| eprewmean          | 84.6          |
| explained_variance | 0.608         |
| fps                | 1368          |
| nupdates           | 613           |
| policy_entropy     | 0.6062177     |
| policy_loss        | 0.00020692732 |
| serial_timesteps   | 245200        |
| time_elapsed       | 5.5e+03       |
| time_remaining     | 20.5          |
| total_timesteps    | 7356000       |
| true_eprew         | 84.6          |
| value_loss         | 18.862577     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.879036903381348 seconds
Total simulation time for 400 steps: 8.02495551109314 	 Other agent action time: 0 	 49.844513087588815 steps/s
Curr learning rate 0.000887 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 174.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.36it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 160.73it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 167.83it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 167.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 169.87it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 169.82it/s]
--------------------------------------
| approxkl           | 0.0046442053  |
| clipfrac           | 0.2845521     |
| eplenmean          | 400           |
| eprewmean          | 82            |
| explained_variance | 0.594         |
| fps                | 1371          |
| nupdates           | 614           |
| policy_entropy     | 0.61890984    |
| policy_loss        | 0.00055537134 |
| serial_timesteps   | 245600        |
| time_elapsed       | 5.51e+03      |
| time_remaining     | 20.3          |
| total_timesteps    | 7368000       |
| true_eprew         | 82            |
| value_loss         | 20.07136      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.931130409240723 seconds
Total simulation time for 400 steps: 8.419687986373901 	 Other agent action time: 0 	 47.507698699446415 steps/s
Curr learning rate 0.0008860000000000001 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  93%|█████████▎| 14/15 [00:00<00:00, 139.60it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 139.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 142.80it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 142.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 159.23it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 161.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 159.56it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 153.35it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 151.05it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 159.57it/s]
---------------------------------------
| approxkl           | 0.0026986368   |
| clipfrac           | 0.23925003     |
| eplenmean          | 400            |
| eprewmean          | 83             |
| explained_variance | 0.583          |
| fps                | 1299           |
| nupdates           | 615            |
| policy_entropy     | 0.6021645      |
| policy_loss        | -0.00061336544 |
| serial_timesteps   | 246000         |
| time_elapsed       | 5.51e+03       |
| time_remaining     | 20.2           |
| total_timesteps    | 7380000        |
| true_eprew         | 83             |
| value_loss         | 18.494635      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.917320966720581 seconds
Total simulation time for 400 steps: 8.238551139831543 	 Other agent action time: 0 	 48.55222638190469 steps/s
Curr learning rate 0.000885 	 Curr reward per step 0.22166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.99it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.20it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.17it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.39it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.46it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.95it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.73it/s]
-------------------------------------
| approxkl           | 0.0051352233 |
| clipfrac           | 0.29899997   |
| eplenmean          | 400          |
| eprewmean          | 85.2         |
| explained_variance | 0.598        |
| fps                | 1339         |
| nupdates           | 616          |
| policy_entropy     | 0.6112806    |
| policy_loss        | 0.0016818686 |
| serial_timesteps   | 246400       |
| time_elapsed       | 5.52e+03     |
| time_remaining     | 20           |
| total_timesteps    | 7392000      |
| true_eprew         | 85.2         |
| value_loss         | 17.46382     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.938084840774536 seconds
Total simulation time for 400 steps: 8.24114441871643 	 Other agent action time: 0 	 48.536948229127205 steps/s
Curr learning rate 0.000884 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.79it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.07it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.82it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.98it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.72it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 201.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.38it/s]
-------------------------------------
| approxkl           | 0.005791381  |
| clipfrac           | 0.2931458    |
| eplenmean          | 400          |
| eprewmean          | 86.6         |
| explained_variance | 0.685        |
| fps                | 1345         |
| nupdates           | 617          |
| policy_entropy     | 0.59748363   |
| policy_loss        | 0.0012064582 |
| serial_timesteps   | 246800       |
| time_elapsed       | 5.53e+03     |
| time_remaining     | 19.9         |
| total_timesteps    | 7404000      |
| true_eprew         | 86.6         |
| value_loss         | 15.38973     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.866557836532593 seconds
Total simulation time for 400 steps: 8.089074850082397 	 Other agent action time: 0 	 49.44941262299304 steps/s
Curr learning rate 0.000883 	 Curr reward per step 0.24

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.70it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.67it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.85it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.28it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.36it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.95it/s]
-------------------------------------
| approxkl           | 0.00554099   |
| clipfrac           | 0.28055203   |
| eplenmean          | 400          |
| eprewmean          | 90.8         |
| explained_variance | 0.608        |
| fps                | 1362         |
| nupdates           | 618          |
| policy_entropy     | 0.55395263   |
| policy_loss        | 0.0021690943 |
| serial_timesteps   | 247200       |
| time_elapsed       | 5.54e+03     |
| time_remaining     | 19.7         |
| total_timesteps    | 7416000      |
| true_eprew         | 90.8         |
| value_loss         | 18.323488    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.896301746368408 seconds
Total simulation time for 400 steps: 8.266594886779785 	 Other agent action time: 0 	 48.38751692546267 steps/s
Curr learning rate 0.0008820000000000001 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.08it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 188.41it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.16it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.97it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 190.44it/s]
-------------------------------------
| approxkl           | 0.004845244  |
| clipfrac           | 0.305375     |
| eplenmean          | 400          |
| eprewmean          | 87.8         |
| explained_variance | 0.649        |
| fps                | 1341         |
| nupdates           | 619          |
| policy_entropy     | 0.6305798    |
| policy_loss        | 0.0018097014 |
| serial_timesteps   | 247600       |
| time_elapsed       | 5.55e+03     |
| time_remaining     | 19.6         |
| total_timesteps    | 7428000      |
| true_eprew         | 87.8         |
| value_loss         | 17.775263    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.886589527130127 seconds
Total simulation time for 400 steps: 8.166548013687134 	 Other agent action time: 0 	 48.98030346844224 steps/s
Curr learning rate 0.0008810000000000001 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.50it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.85it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.06it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.69it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.72it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.18it/s]
-------------------------------------
| approxkl           | 0.0049188724 |
| clipfrac           | 0.27702084   |
| eplenmean          | 400          |
| eprewmean          | 86.4         |
| explained_variance | 0.598        |
| fps                | 1353         |
| nupdates           | 620          |
| policy_entropy     | 0.584786     |
| policy_loss        | 0.0011458256 |
| serial_timesteps   | 248000       |
| time_elapsed       | 5.56e+03     |
| time_remaining     | 19.4         |
| total_timesteps    | 7440000      |
| true_eprew         | 86.4         |
| value_loss         | 17.896618    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.923075914382935 seconds
Total simulation time for 400 steps: 8.236047744750977 	 Other agent action time: 0 	 48.566984116250325 steps/s
Curr learning rate 0.00088 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.31it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.27it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.33it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.23it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.53it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.59it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.07it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]
--------------------------------------
| approxkl           | 0.0045061954  |
| clipfrac           | 0.28727087    |
| eplenmean          | 400           |
| eprewmean          | 87.4          |
| explained_variance | 0.593         |
| fps                | 1341          |
| nupdates           | 621           |
| policy_entropy     | 0.6003098     |
| policy_loss        | 0.00080830994 |
| serial_timesteps   | 248400        |
| time_elapsed       | 5.57e+03      |
| time_remaining     | 19.3          |
| total_timesteps    | 7452000       |
| true_eprew         | 87.4          |
| value_loss         | 17.520775     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.9737725257873535 seconds
Total simulation time for 400 steps: 8.396101474761963 	 Other agent action time: 0 	 47.64115836407758 steps/s
Curr learning rate 0.000879 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.55it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.20it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.67it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.51it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.36it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.54it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.75it/s]
--------------------------------------
| approxkl           | 0.004871384   |
| clipfrac           | 0.28156254    |
| eplenmean          | 400           |
| eprewmean          | 86.8          |
| explained_variance | 0.662         |
| fps                | 1319          |
| nupdates           | 622           |
| policy_entropy     | 0.56686246    |
| policy_loss        | 0.00045497742 |
| serial_timesteps   | 248800        |
| time_elapsed       | 5.58e+03      |
| time_remaining     | 19.1          |
| total_timesteps    | 7464000       |
| true_eprew         | 86.8          |
| value_loss         | 16.3682       |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8866496086120605 seconds
Total simulation time for 400 steps: 8.213367462158203 	 Other agent action time: 0 	 48.70109633386513 steps/s
Curr learning rate 0.000878 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.16it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.02it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.63it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.44it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.61it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.55it/s]
--------------------------------------
| approxkl           | 0.0031043037  |
| clipfrac           | 0.23733328    |
| eplenmean          | 400           |
| eprewmean          | 87            |
| explained_variance | 0.616         |
| fps                | 1344          |
| nupdates           | 623           |
| policy_entropy     | 0.5621147     |
| policy_loss        | -0.0009946462 |
| serial_timesteps   | 249200        |
| time_elapsed       | 5.59e+03      |
| time_remaining     | 19            |
| total_timesteps    | 7476000       |
| true_eprew         | 87            |
| value_loss         | 18.402859     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.884538888931274 seconds
Total simulation time for 400 steps: 8.103863954544067 	 Other agent action time: 0 	 49.3591701740882 steps/s
Curr learning rate 0.000877 	 Curr reward per step 0.2333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 154.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.28it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.54it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 169.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.15it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 172.16it/s]
--------------------------------------
| approxkl           | 0.0056937155  |
| clipfrac           | 0.28628123    |
| eplenmean          | 400           |
| eprewmean          | 88.6          |
| explained_variance | 0.599         |
| fps                | 1356          |
| nupdates           | 624           |
| policy_entropy     | 0.5432591     |
| policy_loss        | 0.00080291164 |
| serial_timesteps   | 249600        |
| time_elapsed       | 5.6e+03       |
| time_remaining     | 18.8          |
| total_timesteps    | 7488000       |
| true_eprew         | 88.6          |
| value_loss         | 17.151709     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.9895689487457275 seconds
Total simulation time for 400 steps: 8.373641014099121 	 Other agent action time: 0 	 47.76894535202785 steps/s
Curr learning rate 0.000876 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.29it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.84it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.54it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.44it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.46it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.88it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.17it/s]
--------------------------------------
| approxkl           | 0.0047197607  |
| clipfrac           | 0.28119788    |
| eplenmean          | 400           |
| eprewmean          | 87.2          |
| explained_variance | 0.644         |
| fps                | 1322          |
| nupdates           | 625           |
| policy_entropy     | 0.5780507     |
| policy_loss        | 0.00064923795 |
| serial_timesteps   | 250000        |
| time_elapsed       | 5.6e+03       |
| time_remaining     | 18.7          |
| total_timesteps    | 7500000       |
| true_eprew         | 87.2          |
| value_loss         | 15.716353     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.840325593948364 seconds
Total simulation time for 400 steps: 8.26223087310791 	 Other agent action time: 0 	 48.41307464572659 steps/s
Curr learning rate 0.000875 	 Curr reward per step 0.2366666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.58it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.74it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.70it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.65it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.45it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.60it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.93it/s]
-------------------------------------
| approxkl           | 0.004204015  |
| clipfrac           | 0.25554165   |
| eplenmean          | 400          |
| eprewmean          | 87.4         |
| explained_variance | 0.593        |
| fps                | 1337         |
| nupdates           | 626          |
| policy_entropy     | 0.53777385   |
| policy_loss        | 0.0010035939 |
| serial_timesteps   | 250400       |
| time_elapsed       | 5.61e+03     |
| time_remaining     | 18.5         |
| total_timesteps    | 7512000      |
| true_eprew         | 87.4         |
| value_loss         | 18.91941     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.894697189331055 seconds
Total simulation time for 400 steps: 8.235157489776611 	 Other agent action time: 0 	 48.572234410401116 steps/s
Curr learning rate 0.000874 	 Curr reward per step 0.19333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.62it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.39it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.02it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.90it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 161.75it/s]
-------------------------------------
| approxkl           | 0.0040484197 |
| clipfrac           | 0.26733333   |
| eplenmean          | 400          |
| eprewmean          | 84.2         |
| explained_variance | 0.6          |
| fps                | 1339         |
| nupdates           | 627          |
| policy_entropy     | 0.594018     |
| policy_loss        | 5.973545e-05 |
| serial_timesteps   | 250800       |
| time_elapsed       | 5.62e+03     |
| time_remaining     | 18.4         |
| total_timesteps    | 7524000      |
| true_eprew         | 84.2         |
| value_loss         | 20.271093    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.932171821594238 seconds
Total simulation time for 400 steps: 8.333520889282227 	 Other agent action time: 0 	 47.99891970204833 steps/s
Curr learning rate 0.0008730000000000001 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.09it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.96it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.47it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.83it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.85it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.96it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.07it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.46it/s]
---------------------------------------
| approxkl           | 0.0036218984   |
| clipfrac           | 0.24327084     |
| eplenmean          | 400            |
| eprewmean          | 86.8           |
| explained_variance | 0.601          |
| fps                | 1324           |
| nupdates           | 628            |
| policy_entropy     | 0.5505339      |
| policy_loss        | -0.00030454402 |
| serial_timesteps   | 251200         |
| time_elapsed       | 5.63e+03       |
| time_remaining     | 18.2           |
| total_timesteps    | 7536000        |
| true_eprew         | 86.8           |
| value_loss         | 17.751165      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30






AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 









AGENT INDEX 0 









AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT IN



AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 















AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 





DEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 









AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT IN



AGENT INDEX 0 









AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT IN



AGENT INDEX 0 









AGENT INDEX 0 





DEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 







DEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT IN





AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 













AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 





DEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 











AGENT INDEX 0 









AGENT INDEX 0 









AGENT INDEX 0 





Other agent actions took 4.959440469741821 seconds
Total simulation time for 400 steps: 8.433802127838135 	 Other agent action time: 0 	 47.428193587763644 steps/s
Curr learning rate 0.0008719999999999999 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.22it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.04it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.17it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.86it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.63it/s]
--------------------------------------
| approxkl           | 0.0030164088  |
| clipfrac           | 0.24017711    |
| eplenmean          | 400           |
| eprewmean          | 87.8          |
| explained_variance | 0.662         |
| fps                | 1312          |
| nupdates           | 629           |
| policy_entropy     | 0.5767393     |
| policy_loss        | -0.0009587016 |
| serial_timesteps   | 251600        |
| time_elapsed       | 5.64e+03      |
| time_remaining     | 18.1          |
| total_timesteps    | 7548000       |
| true_eprew         | 87.8          |
| value_loss         | 15.393981     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.92886757850647 seconds
Total simulation time for 400 steps: 8.206772804260254 	 Other agent action time: 0 	 48.740230726547495 steps/s
Curr learning rate 0.000871 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.14it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.76it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.81it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.90it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.41it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.97it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.62it/s]
-------------------------------------
| approxkl           | 0.003779949  |
| clipfrac           | 0.25137505   |
| eplenmean          | 400          |
| eprewmean          | 90           |
| explained_variance | 0.603        |
| fps                | 1343         |
| nupdates           | 630          |
| policy_entropy     | 0.5493806    |
| policy_loss        | 0.0003991696 |
| serial_timesteps   | 252000       |
| time_elapsed       | 5.65e+03     |
| time_remaining     | 17.9         |
| total_timesteps    | 7560000      |
| true_eprew         | 90           |
| value_loss         | 17.793282    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.927812099456787 seconds
Total simulation time for 400 steps: 8.223349332809448 	 Other agent action time: 0 	 48.64198075643989 steps/s
Curr learning rate 0.00087 	 Curr reward per step 0.235

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 187.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 192.23it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.64it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 201.35it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 195.13it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.84it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.96it/s]
--------------------------------------
| approxkl           | 0.0055187806  |
| clipfrac           | 0.26972917    |
| eplenmean          | 400           |
| eprewmean          | 92.4          |
| explained_variance | 0.652         |
| fps                | 1350          |
| nupdates           | 631           |
| policy_entropy     | 0.5306715     |
| policy_loss        | 0.00033010668 |
| serial_timesteps   | 252400        |
| time_elapsed       | 5.66e+03      |
| time_remaining     | 17.8          |
| total_timesteps    | 7572000       |
| true_eprew         | 92.4          |
| value_loss         | 16.731594     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 5.022835731506348 seconds
Total simulation time for 400 steps: 8.400091171264648 	 Other agent action time: 0 	 47.61853078075333 steps/s
Curr learning rate 0.000869 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.77it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.87it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.49it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 169.05it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.05it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.34it/s]
--------------------------------------
| approxkl           | 0.0044061155  |
| clipfrac           | 0.24026039    |
| eplenmean          | 400           |
| eprewmean          | 92            |
| explained_variance | 0.599         |
| fps                | 1314          |
| nupdates           | 632           |
| policy_entropy     | 0.5106085     |
| policy_loss        | 0.00016763754 |
| serial_timesteps   | 252800        |
| time_elapsed       | 5.67e+03      |
| time_remaining     | 17.6          |
| total_timesteps    | 7584000       |
| true_eprew         | 92            |
| value_loss         | 17.573214     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.830276012420654 seconds
Total simulation time for 400 steps: 8.230815649032593 	 Other agent action time: 0 	 48.59785676854686 steps/s
Curr learning rate 0.0008680000000000001 	 Curr reward per step 0.22166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.89it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.50it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.18it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 173.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.00it/s]
--------------------------------------
| approxkl           | 0.0042902078  |
| clipfrac           | 0.24087504    |
| eplenmean          | 400           |
| eprewmean          | 91.6          |
| explained_variance | 0.597         |
| fps                | 1340          |
| nupdates           | 633           |
| policy_entropy     | 0.5479731     |
| policy_loss        | -0.0005124042 |
| serial_timesteps   | 253200        |
| time_elapsed       | 5.68e+03      |
| time_remaining     | 17.5          |
| total_timesteps    | 7596000       |
| true_eprew         | 91.6          |
| value_loss         | 18.910727     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.759676218032837 seconds
Total simulation time for 400 steps: 8.10297155380249 	 Other agent action time: 0 	 49.36460622427973 steps/s
Curr learning rate 0.000867 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.33it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.15it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.21it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.63it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.53it/s]
--------------------------------------
| approxkl           | 0.0067221415  |
| clipfrac           | 0.27767712    |
| eplenmean          | 400           |
| eprewmean          | 90.6          |
| explained_variance | 0.65          |
| fps                | 1368          |
| nupdates           | 634           |
| policy_entropy     | 0.541113      |
| policy_loss        | 0.00030638475 |
| serial_timesteps   | 253600        |
| time_elapsed       | 5.69e+03      |
| time_remaining     | 17.3          |
| total_timesteps    | 7608000       |
| true_eprew         | 90.6          |
| value_loss         | 17.14715      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.828043699264526 seconds
Total simulation time for 400 steps: 8.123318433761597 	 Other agent action time: 0 	 49.24096023831179 steps/s
Curr learning rate 0.000866 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.61it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.90it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.55it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.40it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.21it/s]
-------------------------------------
| approxkl           | 0.00397269   |
| clipfrac           | 0.26176038   |
| eplenmean          | 400          |
| eprewmean          | 89.6         |
| explained_variance | 0.576        |
| fps                | 1358         |
| nupdates           | 635          |
| policy_entropy     | 0.553315     |
| policy_loss        | 0.0006005558 |
| serial_timesteps   | 254000       |
| time_elapsed       | 5.69e+03     |
| time_remaining     | 17.2         |
| total_timesteps    | 7620000      |
| true_eprew         | 89.6         |
| value_loss         | 17.810663    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7924652099609375 seconds
Total simulation time for 400 steps: 8.143993854522705 	 Other agent action time: 0 	 49.11595061897831 steps/s
Curr learning rate 0.000865 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.28it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.07it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.45it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.40it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.21it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.57it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.90it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.13it/s]
-------------------------------------
| approxkl           | 0.0037779552 |
| clipfrac           | 0.25197917   |
| eplenmean          | 400          |
| eprewmean          | 89.8         |
| explained_variance | 0.613        |
| fps                | 1356         |
| nupdates           | 636          |
| policy_entropy     | 0.5680258    |
| policy_loss        | 7.712223e-05 |
| serial_timesteps   | 254400       |
| time_elapsed       | 5.7e+03      |
| time_remaining     | 17           |
| total_timesteps    | 7632000      |
| true_eprew         | 89.8         |
| value_loss         | 18.442167    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8064656257629395 seconds
Total simulation time for 400 steps: 8.146112442016602 	 Other agent action time: 0 	 49.103176864690866 steps/s
Curr learning rate 0.0008640000000000001 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.42it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 195.53it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.61it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.12it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.88it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.01it/s]
-------------------------------------
| approxkl           | 0.004708622  |
| clipfrac           | 0.2603438    |
| eplenmean          | 400          |
| eprewmean          | 88.4         |
| explained_variance | 0.601        |
| fps                | 1358         |
| nupdates           | 637          |
| policy_entropy     | 0.5518061    |
| policy_loss        | 0.0017901786 |
| serial_timesteps   | 254800       |
| time_elapsed       | 5.71e+03     |
| time_remaining     | 16.9         |
| total_timesteps    | 7644000      |
| true_eprew         | 88.4         |
| value_loss         | 18.224495    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.802140474319458 seconds
Total simulation time for 400 steps: 8.095321893692017 	 Other agent action time: 0 	 49.411253221652046 steps/s
Curr learning rate 0.0008629999999999999 	 Curr reward per step 0.245

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.51it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.53it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.73it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.95it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.31it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.52it/s]
--------------------------------------
| approxkl           | 0.0030167683  |
| clipfrac           | 0.2220209     |
| eplenmean          | 400           |
| eprewmean          | 90.2          |
| explained_variance | 0.646         |
| fps                | 1364          |
| nupdates           | 638           |
| policy_entropy     | 0.5084043     |
| policy_loss        | 0.00013820519 |
| serial_timesteps   | 255200        |
| time_elapsed       | 5.72e+03      |
| time_remaining     | 16.7          |
| total_timesteps    | 7656000       |
| true_eprew         | 90.2          |
| value_loss         | 16.701612     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.857590198516846 seconds
Total simulation time for 400 steps: 8.192263841629028 	 Other agent action time: 0 	 48.82655243199054 steps/s
Curr learning rate 0.000862 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.28it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.63it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.28it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.96it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.99it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.24it/s]
-------------------------------------
| approxkl           | 0.00539112   |
| clipfrac           | 0.26668745   |
| eplenmean          | 400          |
| eprewmean          | 89.8         |
| explained_variance | 0.613        |
| fps                | 1347         |
| nupdates           | 639          |
| policy_entropy     | 0.55657494   |
| policy_loss        | 0.0015635046 |
| serial_timesteps   | 255600       |
| time_elapsed       | 5.73e+03     |
| time_remaining     | 16.6         |
| total_timesteps    | 7668000      |
| true_eprew         | 89.8         |
| value_loss         | 17.491995    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.910154342651367 seconds
Total simulation time for 400 steps: 8.255907773971558 	 Other agent action time: 0 	 48.45015362951147 steps/s
Curr learning rate 0.000861 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.53it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.90it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.92it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.60it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.68it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.33it/s]
-------------------------------------
| approxkl           | 0.0051325806 |
| clipfrac           | 0.28479162   |
| eplenmean          | 400          |
| eprewmean          | 91           |
| explained_variance | 0.612        |
| fps                | 1342         |
| nupdates           | 640          |
| policy_entropy     | 0.56042117   |
| policy_loss        | 0.0012776789 |
| serial_timesteps   | 256000       |
| time_elapsed       | 5.74e+03     |
| time_remaining     | 16.4         |
| total_timesteps    | 7680000      |
| true_eprew         | 91           |
| value_loss         | 18.714907    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.751557350158691 seconds
Total simulation time for 400 steps: 8.05614185333252 	 Other agent action time: 0 	 49.651558684326695 steps/s
Curr learning rate 0.00086 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.11it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.18it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.27it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 205.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 205.86it/s]
---------------------------------------
| approxkl           | 0.0039464342   |
| clipfrac           | 0.23745829     |
| eplenmean          | 400            |
| eprewmean          | 85.2           |
| explained_variance | 0.694          |
| fps                | 1375           |
| nupdates           | 641            |
| policy_entropy     | 0.5295736      |
| policy_loss        | -0.00046226813 |
| serial_timesteps   | 256400         |
| time_elapsed       | 5.75e+03       |
| time_remaining     | 16.3           |
| total_timesteps    | 7692000        |
| true_eprew         | 85.2           |
| value_loss         | 15.409954      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.904370069503784 seconds
Total simulation time for 400 steps: 8.29677939414978 	 Other agent action time: 0 	 48.21147833363482 steps/s
Curr learning rate 0.000859 	 Curr reward per step 0.22166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.65it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.13it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.48it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.93it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.74it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.66it/s]
-------------------------------------
| approxkl           | 0.004404156  |
| clipfrac           | 0.24561459   |
| eplenmean          | 400          |
| eprewmean          | 86.2         |
| explained_variance | 0.648        |
| fps                | 1333         |
| nupdates           | 642          |
| policy_entropy     | 0.5106484    |
| policy_loss        | 0.0008267624 |
| serial_timesteps   | 256800       |
| time_elapsed       | 5.76e+03     |
| time_remaining     | 16.1         |
| total_timesteps    | 7704000      |
| true_eprew         | 86.2         |
| value_loss         | 16.725977    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.850658178329468 seconds
Total simulation time for 400 steps: 8.133500814437866 	 Other agent action time: 0 	 49.17931517139036 steps/s
Curr learning rate 0.000858 	 Curr reward per step 0.2383333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 151.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.58it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.20it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.13it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.87it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.15it/s]
-------------------------------------
| approxkl           | 0.0026657747 |
| clipfrac           | 0.2108021    |
| eplenmean          | 400          |
| eprewmean          | 87.8         |
| explained_variance | 0.641        |
| fps                | 1354         |
| nupdates           | 643          |
| policy_entropy     | 0.5106223    |
| policy_loss        | 9.299664e-05 |
| serial_timesteps   | 257200       |
| time_elapsed       | 5.77e+03     |
| time_remaining     | 16           |
| total_timesteps    | 7716000      |
| true_eprew         | 87.8         |
| value_loss         | 17.610476    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.842244625091553 seconds
Total simulation time for 400 steps: 8.123891353607178 	 Other agent action time: 0 	 49.237487626221345 steps/s
Curr learning rate 0.000857 	 Curr reward per step 0.2366666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.77it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.45it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.59it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 197.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.71it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.74it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.97it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.93it/s]
--------------------------------------
| approxkl           | 0.0048046154  |
| clipfrac           | 0.2707813     |
| eplenmean          | 400           |
| eprewmean          | 91.6          |
| explained_variance | 0.617         |
| fps                | 1362          |
| nupdates           | 644           |
| policy_entropy     | 0.536821      |
| policy_loss        | 0.00042831033 |
| serial_timesteps   | 257600        |
| time_elapsed       | 5.77e+03      |
| time_remaining     | 15.8          |
| total_timesteps    | 7728000       |
| true_eprew         | 91.6          |
| value_loss         | 16.700218     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.864460229873657 seconds
Total simulation time for 400 steps: 8.156558752059937 	 Other agent action time: 0 	 49.04028919046039 steps/s
Curr learning rate 0.000856 	 Curr reward per step 0.22

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.27it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.14it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 174.88it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.32it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.73it/s]
--------------------------------------
| approxkl           | 0.0037996196  |
| clipfrac           | 0.23278123    |
| eplenmean          | 400           |
| eprewmean          | 91.4          |
| explained_variance | 0.668         |
| fps                | 1351          |
| nupdates           | 645           |
| policy_entropy     | 0.52125627    |
| policy_loss        | -0.0003245542 |
| serial_timesteps   | 258000        |
| time_elapsed       | 5.78e+03      |
| time_remaining     | 15.7          |
| total_timesteps    | 7740000       |
| true_eprew         | 91.4          |
| value_loss         | 16.378412     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.866051912307739 seconds
Total simulation time for 400 steps: 8.261234521865845 	 Other agent action time: 0 	 48.41891353420358 steps/s
Curr learning rate 0.0008550000000000001 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.64it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.95it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.23it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.39it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.79it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 185.20it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.78it/s]
--------------------------------------
| approxkl           | 0.0041926163  |
| clipfrac           | 0.25181246    |
| eplenmean          | 400           |
| eprewmean          | 91.4          |
| explained_variance | 0.661         |
| fps                | 1338          |
| nupdates           | 646           |
| policy_entropy     | 0.53757435    |
| policy_loss        | -0.0012164871 |
| serial_timesteps   | 258400        |
| time_elapsed       | 5.79e+03      |
| time_remaining     | 15.5          |
| total_timesteps    | 7752000       |
| true_eprew         | 91.4          |
| value_loss         | 16.677015     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.9382569789886475 seconds
Total simulation time for 400 steps: 8.327662467956543 	 Other agent action time: 0 	 48.03268642781013 steps/s
Curr learning rate 0.000854 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.71it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.35it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.05it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.09it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.98it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.88it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.32it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.51it/s]
--------------------------------------
| approxkl           | 0.00471125    |
| clipfrac           | 0.2589583     |
| eplenmean          | 400           |
| eprewmean          | 88.8          |
| explained_variance | 0.727         |
| fps                | 1328          |
| nupdates           | 647           |
| policy_entropy     | 0.52790225    |
| policy_loss        | 0.00015284553 |
| serial_timesteps   | 258800        |
| time_elapsed       | 5.8e+03       |
| time_remaining     | 15.4          |
| total_timesteps    | 7764000       |
| true_eprew         | 88.8          |
| value_loss         | 14.531791     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.858516216278076 seconds
Total simulation time for 400 steps: 8.142029047012329 	 Other agent action time: 0 	 49.12780311767344 steps/s
Curr learning rate 0.000853 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.31it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.88it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.91it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.47it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.47it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.40it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.38it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.03it/s]
--------------------------------------
| approxkl           | 0.0036708587  |
| clipfrac           | 0.24387492    |
| eplenmean          | 400           |
| eprewmean          | 88.6          |
| explained_variance | 0.616         |
| fps                | 1354          |
| nupdates           | 648           |
| policy_entropy     | 0.5383142     |
| policy_loss        | 0.00020261898 |
| serial_timesteps   | 259200        |
| time_elapsed       | 5.81e+03      |
| time_remaining     | 15.2          |
| total_timesteps    | 7776000       |
| true_eprew         | 88.6          |
| value_loss         | 17.453192     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.787251710891724 seconds
Total simulation time for 400 steps: 8.029901504516602 	 Other agent action time: 0 	 49.81381151126335 steps/s
Curr learning rate 0.000852 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 181.98it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 182.65it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.31it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.11it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.59it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.26it/s]
-------------------------------------
| approxkl           | 0.004497592  |
| clipfrac           | 0.25889587   |
| eplenmean          | 400          |
| eprewmean          | 88.8         |
| explained_variance | 0.696        |
| fps                | 1375         |
| nupdates           | 649          |
| policy_entropy     | 0.5152171    |
| policy_loss        | 2.266531e-05 |
| serial_timesteps   | 259600       |
| time_elapsed       | 5.82e+03     |
| time_remaining     | 15.1         |
| total_timesteps    | 7788000      |
| true_eprew         | 88.8         |
| value_loss         | 16.179087    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.845658540725708 seconds
Total simulation time for 400 steps: 8.140312433242798 	 Other agent action time: 0 	 49.13816309635856 steps/s
Curr learning rate 0.0008510000000000001 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.08it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.72it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.57it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.72it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 195.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.78it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.34it/s]
-------------------------------------
| approxkl           | 0.005182383  |
| clipfrac           | 0.27043742   |
| eplenmean          | 400          |
| eprewmean          | 89           |
| explained_variance | 0.566        |
| fps                | 1359         |
| nupdates           | 650          |
| policy_entropy     | 0.56383485   |
| policy_loss        | 0.0013473239 |
| serial_timesteps   | 260000       |
| time_elapsed       | 5.83e+03     |
| time_remaining     | 14.9         |
| total_timesteps    | 7800000      |
| true_eprew         | 89           |
| value_loss         | 18.202257    |
-------------------------------------
Current reward shaping 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   Xo↓0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X   P 
O   Xo←0X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   P 
O   X ←oX 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X ø-X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø2X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø3X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø6X 
O ←1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø7X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø9X 
O ←1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø10X 
O ←oX ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X ø11X 
O →oX →oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø12X 
O →1Xo→0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø13X 
O →1Xo←0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø14X 
O ←1X ←oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø15X 
O ←oX →oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø16X 
O ←oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø17X 
O ←oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø18X 
O →oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø19X 
O →oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo→0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←1Xo←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←1X ←oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←oX →oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø20X 
O ←oX →0ø1
O   X   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX →0ø2
O   X   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oX →0ø3
O   X   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo→0ø4
O   X   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xo→0ø5
O   X   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo→0ø6
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('↓', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø7
O   X ↓0X 
D ↓1X   X 
X X X S X 


Timestep: 61
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø8
O   X   X 
D ←1X ↓0X 
X X X S X 


Timestep: 62
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   Xo  ø9
O   X   X 
D ←dX ↓0X 
X X X S X 


Timestep: 63
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø10
O   X   X 
D ←dX ↓0X 
X X X S X 


Timestep: 64
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø11
O   X   X 
D ←dX ↓0X 
X X X S X 


Timestep: 65
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø12
O   X   X 
D →dX ↓0X 
X X X S X 


Timestep: 66
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø13
O   X   X 
D →dX ↓0X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø14
O   X   X 
D →dX ↓0X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø15
O   X   X 
D →dX ↓0X 
X X X S X 


Timestep: 69
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø16
O   X   X 
D →1Xd↓0X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø17
O   X   X 
D ←1Xd↓0X 
X X X S X 


Timestep: 71
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø18
O   X   X 
D ←dXd↓0X 
X X X S X 


Timestep: 72
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø19
O   X   X 
D ←dXd↓0X 
X X X S X 


Timestep: 73
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D ←dXd↓0X 
X X X S X 


Timestep: 74
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →dXd↓0X 
X X X S X 


Timestep: 75
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →dXd↓0X 
X X X S X 


Timestep: 76
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →dXd↓0X 
X X X S X 


Timestep: 77
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →dXd←0X 
X X X S X 


Timestep: 78
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →dX ←dX 
X X X S X 


Timestep: 79
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D →dXd←0X 
X X X S X 


Timestep: 80
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D ↓dX ←dX 
X X X S X 


Timestep: 81
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D ↓dXd←0X 
X X X S X 


Timestep: 82
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X   X 
D ↓dX ←dX 
X X X S X 


Timestep: 83
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø20
O   X ↑dX 
D ↓dX   X 
X X X S X 


Timestep: 84
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo↑dø20
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 85
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 5 
X X X P X 
O   Xo↑sø20
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 86
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   Xo  ø20
O ↑dX ↓sX 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dXo  ø20
O   X   X 
D   X ↓sX 
X X X S X 


Timestep: 88
Joint action taken: ('interact', 'stay') 	 Reward: 20 + shape * 0 
X X X P X 
O ↑dXo  ø20
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 89
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dXo  ø20
O   X ↑0X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑dXo↑0ø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →dXo↑0ø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →dXo←0ø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX ←oø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →dX ↑oø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 3 
X X X ø-X 
O →dX ↑0ø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xd←0ø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←dø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1Xd←0ø20
O   X   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←dø20
O   X   X 
D   X   X 
X X X S X 


tot rew 140 tot rew shaped 137
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('stay', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↓0X 
D ↓oX   X 
X X X S X 


Timestep: 34
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 35
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 36
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 37
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 38
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 39
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ←oX   X 
X X X S X 


Timestep: 40
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ←oX   X 
X X X S X 


Timestep: 41
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 42
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 45
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 46
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 47
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X   X 
D ←oX ↓0X 
X X X S X 


Timestep: 50
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ←oX   X 
X X X S X 


Timestep: 51
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ←oX   X 
X X X S X 


Timestep: 52
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ↑0X 
D ←oX   X 
X X X S X 


Timestep: 53
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 54
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 55
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O   X ←0X 
D ←oX   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX ←0X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX   X 
D   X ↓0X 
X X X S X 


Timestep: 58
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX   X 
D   X ↓0X 
X X X S X 


Timestep: 59
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX   X 
D   X ↓0X 
X X X S X 


Timestep: 60
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 61
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↑0X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ↓0X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X   P 
O   X ←0X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X XoX P X 
O ←1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('→', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX →0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('↑', '↑') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X XoX P X 
O ↑1X ←0P 
O   X   X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.921828269958496 seconds
Total simulation time for 400 steps: 8.203941106796265 	 Other agent action time: 0 	 48.75705405401243 steps/s
Curr learning rate 0.00085 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.65it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.74it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.38it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.62it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 186.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.08it/s]
-------------------------------------
| approxkl           | 0.0045222696 |
| clipfrac           | 0.26577082   |
| eplenmean          | 400          |
| eprewmean          | 88           |
| explained_variance | 0.698        |
| fps                | 1347         |
| nupdates           | 651          |
| policy_entropy     | 0.5430772    |
| policy_loss        | -8.4744e-05  |
| serial_timesteps   | 260400       |
| time_elapsed       | 5.84e+03     |
| time_remaining     | 14.8         |
| total_timesteps    | 7812000      |
| true_eprew         | 88           |
| value_loss         | 15.944472    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.824580907821655 seconds
Total simulation time for 400 steps: 8.154264211654663 	 Other agent action time: 0 	 49.05408870959701 steps/s
Curr learning rate 0.000849 	 Curr reward per step 0.225

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.39it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.85it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 195.99it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 196.83it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.26it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.60it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.59it/s]
-------------------------------------
| approxkl           | 0.004299743  |
| clipfrac           | 0.2502604    |
| eplenmean          | 400          |
| eprewmean          | 86.6         |
| explained_variance | 0.667        |
| fps                | 1360         |
| nupdates           | 652          |
| policy_entropy     | 0.53179336   |
| policy_loss        | 0.0009399351 |
| serial_timesteps   | 260800       |
| time_elapsed       | 5.85e+03     |
| time_remaining     | 14.6         |
| total_timesteps    | 7824000      |
| true_eprew         | 86.6         |
| value_loss         | 16.32692     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.963949203491211 seconds
Total simulation time for 400 steps: 8.250502586364746 	 Other agent action time: 0 	 48.48189498916865 steps/s
Curr learning rate 0.000848 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.24it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 154.84it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 166.33it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 169.82it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 166.78it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 210.20it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.46it/s]
--------------------------------------
| approxkl           | 0.004812011   |
| clipfrac           | 0.2605625     |
| eplenmean          | 400           |
| eprewmean          | 86.2          |
| explained_variance | 0.618         |
| fps                | 1336          |
| nupdates           | 653           |
| policy_entropy     | 0.55418515    |
| policy_loss        | 0.00096901495 |
| serial_timesteps   | 261200        |
| time_elapsed       | 5.86e+03      |
| time_remaining     | 14.5          |
| total_timesteps    | 7836000       |
| true_eprew         | 86.2          |
| value_loss         | 18.310852     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.970441102981567 seconds
Total simulation time for 400 steps: 8.378839015960693 	 Other agent action time: 0 	 47.7393108088182 steps/s
Curr learning rate 0.000847 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.21it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.56it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.33it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.93it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.89it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.78it/s]
--------------------------------------
| approxkl           | 0.004114816   |
| clipfrac           | 0.2328646     |
| eplenmean          | 400           |
| eprewmean          | 87            |
| explained_variance | 0.643         |
| fps                | 1319          |
| nupdates           | 654           |
| policy_entropy     | 0.5210795     |
| policy_loss        | 0.00091687153 |
| serial_timesteps   | 261600        |
| time_elapsed       | 5.87e+03      |
| time_remaining     | 14.3          |
| total_timesteps    | 7848000       |
| true_eprew         | 87            |
| value_loss         | 17.092827     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.906941652297974 seconds
Total simulation time for 400 steps: 8.270388841629028 	 Other agent action time: 0 	 48.36531965541919 steps/s
Curr learning rate 0.000846 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.11it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.84it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.61it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.13it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.52it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 190.32it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.72it/s]
---------------------------------------
| approxkl           | 0.00417484     |
| clipfrac           | 0.2532604      |
| eplenmean          | 400            |
| eprewmean          | 88             |
| explained_variance | 0.588          |
| fps                | 1338           |
| nupdates           | 655            |
| policy_entropy     | 0.5300966      |
| policy_loss        | -2.8922583e-05 |
| serial_timesteps   | 262000         |
| time_elapsed       | 5.87e+03       |
| time_remaining     | 14.2           |
| total_timesteps    | 7860000        |
| true_eprew         | 88             |
| value_loss         | 19.769312      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.817173004150391 seconds
Total simulation time for 400 steps: 8.066476345062256 	 Other agent action time: 0 	 49.58794681705756 steps/s
Curr learning rate 0.000845 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.04it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.07it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 160.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.68it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.49it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.93it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.47it/s]
--------------------------------------
| approxkl           | 0.0029081746  |
| clipfrac           | 0.2095417     |
| eplenmean          | 400           |
| eprewmean          | 90.2          |
| explained_variance | 0.565         |
| fps                | 1365          |
| nupdates           | 656           |
| policy_entropy     | 0.5077964     |
| policy_loss        | -0.0012035462 |
| serial_timesteps   | 262400        |
| time_elapsed       | 5.88e+03      |
| time_remaining     | 14            |
| total_timesteps    | 7872000       |
| true_eprew         | 90.2          |
| value_loss         | 19.73824      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8564536571502686 seconds
Total simulation time for 400 steps: 8.167929887771606 	 Other agent action time: 0 	 48.972016838544256 steps/s
Curr learning rate 0.000844 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.57it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 161.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.29it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 190.65it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 191.27it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.57it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.38it/s]
------------------------------------
| approxkl           | 0.005437474 |
| clipfrac           | 0.27289584  |
| eplenmean          | 400         |
| eprewmean          | 90          |
| explained_variance | 0.646       |
| fps                | 1353        |
| nupdates           | 657         |
| policy_entropy     | 0.5652206   |
| policy_loss        | 0.001054638 |
| serial_timesteps   | 262800      |
| time_elapsed       | 5.89e+03    |
| time_remaining     | 13.9        |
| total_timesteps    | 7884000     |
| true_eprew         | 90          |
| value_loss         | 17.146862   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8977251052856445 seconds
Total simulation time for 400 steps: 8.250004768371582 	 Other agent action time: 0 	 48.48482046137696 steps/s
Curr learning rate 0.000843 	 Curr reward per step 0.22166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 156.54it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.55it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 161.60it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.52it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.68it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.10it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.90it/s]
-------------------------------------
| approxkl           | 0.0046605165 |
| clipfrac           | 0.25372916   |
| eplenmean          | 400          |
| eprewmean          | 89.6         |
| explained_variance | 0.632        |
| fps                | 1336         |
| nupdates           | 658          |
| policy_entropy     | 0.5251349    |
| policy_loss        | 0.0015989618 |
| serial_timesteps   | 263200       |
| time_elapsed       | 5.9e+03      |
| time_remaining     | 13.8         |
| total_timesteps    | 7896000      |
| true_eprew         | 89.6         |
| value_loss         | 17.606758    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8125505447387695 seconds
Total simulation time for 400 steps: 8.159224510192871 	 Other agent action time: 0 	 49.02426688961702 steps/s
Curr learning rate 0.0008420000000000001 	 Curr reward per step 0.2533333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.10it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 174.42it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.33it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.99it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.03it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.21it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.50it/s]
--------------------------------------
| approxkl           | 0.00395235    |
| clipfrac           | 0.24045828    |
| eplenmean          | 400           |
| eprewmean          | 91.8          |
| explained_variance | 0.625         |
| fps                | 1358          |
| nupdates           | 659           |
| policy_entropy     | 0.5148437     |
| policy_loss        | 0.00090952194 |
| serial_timesteps   | 263600        |
| time_elapsed       | 5.91e+03      |
| time_remaining     | 13.6          |
| total_timesteps    | 7908000       |
| true_eprew         | 91.8          |
| value_loss         | 18.025236     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.971838474273682 seconds
Total simulation time for 400 steps: 8.266307592391968 	 Other agent action time: 0 	 48.3891986269839 steps/s
Curr learning rate 0.000841 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.78it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.43it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.51it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.60it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.78it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.98it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.54it/s]
-------------------------------------
| approxkl           | 0.0048630363 |
| clipfrac           | 0.2635313    |
| eplenmean          | 400          |
| eprewmean          | 92.6         |
| explained_variance | 0.586        |
| fps                | 1337         |
| nupdates           | 660          |
| policy_entropy     | 0.5633989    |
| policy_loss        | 0.0010943969 |
| serial_timesteps   | 264000       |
| time_elapsed       | 5.92e+03     |
| time_remaining     | 13.5         |
| total_timesteps    | 7920000      |
| true_eprew         | 92.6         |
| value_loss         | 16.909517    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.915157318115234 seconds
Total simulation time for 400 steps: 8.156404733657837 	 Other agent action time: 0 	 49.04121522432289 steps/s
Curr learning rate 0.00084 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 146.64it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 146.16it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 146.50it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 146.02it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 153.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 168.24it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.50it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 171.61it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 172.53it/s]
------------------------------------
| approxkl           | 0.005450301 |
| clipfrac           | 0.27020833  |
| eplenmean          | 400         |
| eprewmean          | 92.2        |
| explained_variance | 0.681       |
| fps                | 1344        |
| nupdates           | 661         |
| policy_entropy     | 0.5542084   |
| policy_loss        | 0.001816157 |
| serial_timesteps   | 264400      |
| time_elapsed       | 5.93e+03    |
| time_remaining     | 13.3        |
| total_timesteps    | 7932000     |
| true_eprew         | 92.2        |
| value_loss         | 16.051214   |
------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.802027225494385 seconds
Total simulation time for 400 steps: 8.092600345611572 	 Other agent action time: 0 	 49.42787026631194 steps/s
Curr learning rate 0.000839 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.84it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.77it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.92it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.04it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.12it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.10it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.92it/s]
-------------------------------------
| approxkl           | 0.005494795  |
| clipfrac           | 0.27766663   |
| eplenmean          | 400          |
| eprewmean          | 88.2         |
| explained_variance | 0.599        |
| fps                | 1365         |
| nupdates           | 662          |
| policy_entropy     | 0.5541351    |
| policy_loss        | 0.0023034292 |
| serial_timesteps   | 264800       |
| time_elapsed       | 5.94e+03     |
| time_remaining     | 13.2         |
| total_timesteps    | 7944000      |
| true_eprew         | 88.2         |
| value_loss         | 19.201214    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.944850206375122 seconds
Total simulation time for 400 steps: 8.366669654846191 	 Other agent action time: 0 	 47.8087478652046 steps/s
Curr learning rate 0.000838 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.31it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.76it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.25it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.59it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.53it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.91it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 169.43it/s]
-------------------------------------
| approxkl           | 0.0046286504 |
| clipfrac           | 0.2531875    |
| eplenmean          | 400          |
| eprewmean          | 87.2         |
| explained_variance | 0.63         |
| fps                | 1320         |
| nupdates           | 663          |
| policy_entropy     | 0.5429201    |
| policy_loss        | 0.0011692606 |
| serial_timesteps   | 265200       |
| time_elapsed       | 5.95e+03     |
| time_remaining     | 13           |
| total_timesteps    | 7956000      |
| true_eprew         | 87.2         |
| value_loss         | 16.332783    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.846341133117676 seconds
Total simulation time for 400 steps: 8.23872447013855 	 Other agent action time: 0 	 48.55120491646606 steps/s
Curr learning rate 0.0008370000000000001 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.88it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.71it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.80it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.38it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.89it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.94it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.09it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.84it/s]
--------------------------------------
| approxkl           | 0.00327938    |
| clipfrac           | 0.24129163    |
| eplenmean          | 400           |
| eprewmean          | 86.8          |
| explained_variance | 0.573         |
| fps                | 1340          |
| nupdates           | 664           |
| policy_entropy     | 0.57269984    |
| policy_loss        | -0.0006675054 |
| serial_timesteps   | 265600        |
| time_elapsed       | 5.95e+03      |
| time_remaining     | 12.9          |
| total_timesteps    | 7968000       |
| true_eprew         | 86.8          |
| value_loss         | 19.44021      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7932915687561035 seconds
Total simulation time for 400 steps: 8.034745931625366 	 Other agent action time: 0 	 49.783777035882345 steps/s
Curr learning rate 0.000836 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.23it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.60it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.76it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.65it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.48it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.99it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.47it/s]
--------------------------------------
| approxkl           | 0.004621227   |
| clipfrac           | 0.26837498    |
| eplenmean          | 400           |
| eprewmean          | 85.8          |
| explained_variance | 0.632         |
| fps                | 1375          |
| nupdates           | 665           |
| policy_entropy     | 0.5720564     |
| policy_loss        | 0.00013892709 |
| serial_timesteps   | 266000        |
| time_elapsed       | 5.96e+03      |
| time_remaining     | 12.7          |
| total_timesteps    | 7980000       |
| true_eprew         | 85.8          |
| value_loss         | 15.954937     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.846742153167725 seconds
Total simulation time for 400 steps: 8.162776470184326 	 Other agent action time: 0 	 49.00293441343831 steps/s
Curr learning rate 0.000835 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.09it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 182.48it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.18it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 194.61it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.46it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.50it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 198.35it/s]
---------------------------------------
| approxkl           | 0.0034354748   |
| clipfrac           | 0.23025002     |
| eplenmean          | 400            |
| eprewmean          | 85             |
| explained_variance | 0.616          |
| fps                | 1359           |
| nupdates           | 666            |
| policy_entropy     | 0.5376112      |
| policy_loss        | -0.00036206335 |
| serial_timesteps   | 266400         |
| time_elapsed       | 5.97e+03       |
| time_remaining     | 12.6           |
| total_timesteps    | 7992000        |
| true_eprew         | 85             |
| value_loss         | 17.60437       |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.81604528427124 seconds
Total simulation time for 400 steps: 8.234306812286377 	 Other agent action time: 0 	 48.57725235634426 steps/s
Curr learning rate 0.000834 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 154.02it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 153.79it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 157.14it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.51it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 169.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.02it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 149.57it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 149.07it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.09it/s]
--------------------------------------
| approxkl           | 0.004362547   |
| clipfrac           | 0.27487502    |
| eplenmean          | 400           |
| eprewmean          | 83.6          |
| explained_variance | 0.614         |
| fps                | 1334          |
| nupdates           | 667           |
| policy_entropy     | 0.5917277     |
| policy_loss        | 0.00081370986 |
| serial_timesteps   | 266800        |
| time_elapsed       | 5.98e+03      |
| time_remaining     | 12.4          |
| total_timesteps    | 8004000       |
| true_eprew         | 83.6          |
| value_loss         | 18.366205     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.78761625289917 seconds
Total simulation time for 400 steps: 8.091768741607666 	 Other agent action time: 0 	 49.43295004752302 steps/s
Curr learning rate 0.0008330000000000001 	 Curr reward per step 0.18833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.63it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.99it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.44it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 187.64it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.98it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.41it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.41it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.24it/s]
--------------------------------------
| approxkl           | 0.003328676   |
| clipfrac           | 0.26187497    |
| eplenmean          | 400           |
| eprewmean          | 81.4          |
| explained_variance | 0.586         |
| fps                | 1364          |
| nupdates           | 668           |
| policy_entropy     | 0.64943665    |
| policy_loss        | -0.0012783424 |
| serial_timesteps   | 267200        |
| time_elapsed       | 5.99e+03      |
| time_remaining     | 12.3          |
| total_timesteps    | 8016000       |
| true_eprew         | 81.4          |
| value_loss         | 18.362906     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.915787220001221 seconds
Total simulation time for 400 steps: 8.223558902740479 	 Other agent action time: 0 	 48.640741159730865 steps/s
Curr learning rate 0.000832 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.99it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.61it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 193.07it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.70it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.29it/s]
-------------------------------------
| approxkl           | 0.0046022516 |
| clipfrac           | 0.2833125    |
| eplenmean          | 400          |
| eprewmean          | 80.2         |
| explained_variance | 0.622        |
| fps                | 1347         |
| nupdates           | 669          |
| policy_entropy     | 0.6003851    |
| policy_loss        | 0.0016408601 |
| serial_timesteps   | 267600       |
| time_elapsed       | 6e+03        |
| time_remaining     | 12.1         |
| total_timesteps    | 8028000      |
| true_eprew         | 80.2         |
| value_loss         | 17.464697    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.905206680297852 seconds
Total simulation time for 400 steps: 8.158656358718872 	 Other agent action time: 0 	 49.02768083528042 steps/s
Curr learning rate 0.000831 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 143.20it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 142.74it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 155.83it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 154.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 165.30it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 161.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 166.04it/s]
-------------------------------------
| approxkl           | 0.005401062  |
| clipfrac           | 0.2870833    |
| eplenmean          | 400          |
| eprewmean          | 80           |
| explained_variance | 0.682        |
| fps                | 1343         |
| nupdates           | 670          |
| policy_entropy     | 0.60975844   |
| policy_loss        | 0.0006392294 |
| serial_timesteps   | 268000       |
| time_elapsed       | 6.01e+03     |
| time_remaining     | 12           |
| total_timesteps    | 8040000      |
| true_eprew         | 80           |
| value_loss         | 14.173322    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.905752897262573 seconds
Total simulation time for 400 steps: 8.236284255981445 	 Other agent action time: 0 	 48.5655894779867 steps/s
Curr learning rate 0.00083 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.06it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.30it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 154.47it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.04it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.29it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.53it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.80it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.81it/s]
--------------------------------------
| approxkl           | 0.0040202294  |
| clipfrac           | 0.26688543    |
| eplenmean          | 400           |
| eprewmean          | 83.6          |
| explained_variance | 0.631         |
| fps                | 1337          |
| nupdates           | 671           |
| policy_entropy     | 0.5878758     |
| policy_loss        | 0.00013874791 |
| serial_timesteps   | 268400        |
| time_elapsed       | 6.02e+03      |
| time_remaining     | 11.8          |
| total_timesteps    | 8052000       |
| true_eprew         | 83.6          |
| value_loss         | 17.523094     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 5.033292293548584 seconds
Total simulation time for 400 steps: 8.326740026473999 	 Other agent action time: 0 	 48.038007518938 steps/s
Curr learning rate 0.000829 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.36it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.07it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.57it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.91it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 197.67it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 197.12it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.05it/s]
--------------------------------------
| approxkl           | 0.004570812   |
| clipfrac           | 0.28512496    |
| eplenmean          | 400           |
| eprewmean          | 89.4          |
| explained_variance | 0.645         |
| fps                | 1332          |
| nupdates           | 672           |
| policy_entropy     | 0.60145843    |
| policy_loss        | -7.004637e-05 |
| serial_timesteps   | 268800        |
| time_elapsed       | 6.03e+03      |
| time_remaining     | 11.7          |
| total_timesteps    | 8064000       |
| true_eprew         | 89.4          |
| value_loss         | 15.713365     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.929095983505249 seconds
Total simulation time for 400 steps: 8.254221200942993 	 Other agent action time: 0 	 48.46005337902775 steps/s
Curr learning rate 0.000828 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.19it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.64it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.87it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.83it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.58it/s]
---------------------------------------
| approxkl           | 0.0037525387   |
| clipfrac           | 0.26658338     |
| eplenmean          | 400            |
| eprewmean          | 86.4           |
| explained_variance | 0.602          |
| fps                | 1339           |
| nupdates           | 673            |
| policy_entropy     | 0.63155764     |
| policy_loss        | -0.00040564867 |
| serial_timesteps   | 269200         |
| time_elapsed       | 6.03e+03       |
| time_remaining     | 11.5           |
| total_timesteps    | 8076000        |
| true_eprew         | 86.4           |
| value_loss         | 17.831001      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.89538311958313 seconds
Total simulation time for 400 steps: 8.2765634059906 	 Other agent action time: 0 	 48.32923767737692 steps/s
Curr learning rate 0.000827 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.03it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.48it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.59it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 168.62it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.05it/s]
-------------------------------------
| approxkl           | 0.0049945093 |
| clipfrac           | 0.28015625   |
| eplenmean          | 400          |
| eprewmean          | 88.2         |
| explained_variance | 0.631        |
| fps                | 1332         |
| nupdates           | 674          |
| policy_entropy     | 0.57887757   |
| policy_loss        | 0.0010382006 |
| serial_timesteps   | 269600       |
| time_elapsed       | 6.04e+03     |
| time_remaining     | 11.4         |
| total_timesteps    | 8088000      |
| true_eprew         | 88.2         |
| value_loss         | 17.304867    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.948389530181885 seconds
Total simulation time for 400 steps: 8.293477296829224 	 Other agent action time: 0 	 48.23067402052558 steps/s
Curr learning rate 0.000826 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.79it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.31it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.20it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.28it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 210.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 222.10it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 217.69it/s]
---------------------------------------
| approxkl           | 0.0042963657   |
| clipfrac           | 0.26238543     |
| eplenmean          | 400            |
| eprewmean          | 85.6           |
| explained_variance | 0.65           |
| fps                | 1338           |
| nupdates           | 675            |
| policy_entropy     | 0.5797822      |
| policy_loss        | -0.00010459118 |
| serial_timesteps   | 270000         |
| time_elapsed       | 6.05e+03       |
| time_remaining     | 11.2           |
| total_timesteps    | 8100000        |
| true_eprew         | 85.6           |
| value_loss         | 16.307398      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.893385648727417 seconds
Total simulation time for 400 steps: 8.271414756774902 	 Other agent action time: 0 	 48.359320837148246 steps/s
Curr learning rate 0.000825 	 Curr reward per step 0.22

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.01it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.64it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.37it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.64it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.90it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.55it/s]
--------------------------------------
| approxkl           | 0.0047737886  |
| clipfrac           | 0.2608854     |
| eplenmean          | 400           |
| eprewmean          | 85.6          |
| explained_variance | 0.568         |
| fps                | 1336          |
| nupdates           | 676           |
| policy_entropy     | 0.57324016    |
| policy_loss        | 0.00040083018 |
| serial_timesteps   | 270400        |
| time_elapsed       | 6.06e+03      |
| time_remaining     | 11.1          |
| total_timesteps    | 8112000       |
| true_eprew         | 85.6          |
| value_loss         | 19.22444      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 5.017277240753174 seconds
Total simulation time for 400 steps: 8.352024793624878 	 Other agent action time: 0 	 47.89257813330739 steps/s
Curr learning rate 0.0008240000000000001 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.26it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 157.47it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.10it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.44it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 192.32it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.96it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 187.31it/s]
---------------------------------------
| approxkl           | 0.0043151444   |
| clipfrac           | 0.27517706     |
| eplenmean          | 400            |
| eprewmean          | 86.4           |
| explained_variance | 0.641          |
| fps                | 1323           |
| nupdates           | 677            |
| policy_entropy     | 0.58988833     |
| policy_loss        | -0.00047188412 |
| serial_timesteps   | 270800         |
| time_elapsed       | 6.07e+03       |
| time_remaining     | 10.9           |
| total_timesteps    | 8124000        |
| true_eprew         | 86.4           |
| value_loss         | 17.314167      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.9892418384552 seconds
Total simulation time for 400 steps: 8.485163927078247 	 Other agent action time: 0 	 47.14110457235853 steps/s
Curr learning rate 0.0008230000000000001 	 Curr reward per step 0.2333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 158.72it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 151.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 147.91it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 147.53it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 163.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 171.59it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.21it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.86it/s]
--------------------------------------
| approxkl           | 0.0044634566  |
| clipfrac           | 0.24690631    |
| eplenmean          | 400           |
| eprewmean          | 87.8          |
| explained_variance | 0.654         |
| fps                | 1298          |
| nupdates           | 678           |
| policy_entropy     | 0.5589728     |
| policy_loss        | 0.00042707525 |
| serial_timesteps   | 271200        |
| time_elapsed       | 6.08e+03      |
| time_remaining     | 10.8          |
| total_timesteps    | 8136000       |
| true_eprew         | 87.8          |
| value_loss         | 17.170832     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.892805337905884 seconds
Total simulation time for 400 steps: 8.205163955688477 	 Other agent action time: 0 	 48.749787592323244 steps/s
Curr learning rate 0.000822 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.29it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 185.13it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.75it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.42it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.94it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.60it/s]
---------------------------------------
| approxkl           | 0.0039988277   |
| clipfrac           | 0.2513854      |
| eplenmean          | 400            |
| eprewmean          | 87.8           |
| explained_variance | 0.676          |
| fps                | 1348           |
| nupdates           | 679            |
| policy_entropy     | 0.5564987      |
| policy_loss        | -0.00044291947 |
| serial_timesteps   | 271600         |
| time_elapsed       | 6.09e+03       |
| time_remaining     | 10.6           |
| total_timesteps    | 8148000        |
| true_eprew         | 87.8           |
| value_loss         | 15.9839115     |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.835120677947998 seconds
Total simulation time for 400 steps: 8.126332759857178 	 Other agent action time: 0 	 49.22269513450617 steps/s
Curr learning rate 0.000821 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.11it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 183.18it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 191.66it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.19it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.85it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 214.60it/s]
---------------------------------------
| approxkl           | 0.0037387998   |
| clipfrac           | 0.25012505     |
| eplenmean          | 400            |
| eprewmean          | 85.4           |
| explained_variance | 0.617          |
| fps                | 1366           |
| nupdates           | 680            |
| policy_entropy     | 0.5731628      |
| policy_loss        | -0.00029472107 |
| serial_timesteps   | 272000         |
| time_elapsed       | 6.1e+03        |
| time_remaining     | 10.5           |
| total_timesteps    | 8160000        |
| true_eprew         | 85.4           |
| value_loss         | 18.814419      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.79836368560791 seconds
Total simulation time for 400 steps: 8.123277425765991 	 Other agent action time: 0 	 49.241208816930396 steps/s
Curr learning rate 0.0008200000000000001 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 176.23it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.43it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.66it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 176.58it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.01it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.67it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.94it/s]
--------------------------------------
| approxkl           | 0.0049815895  |
| clipfrac           | 0.28831252    |
| eplenmean          | 400           |
| eprewmean          | 84.6          |
| explained_variance | 0.67          |
| fps                | 1361          |
| nupdates           | 681           |
| policy_entropy     | 0.61297643    |
| policy_loss        | 0.00037682636 |
| serial_timesteps   | 272400        |
| time_elapsed       | 6.11e+03      |
| time_remaining     | 10.3          |
| total_timesteps    | 8172000       |
| true_eprew         | 84.6          |
| value_loss         | 15.524698     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.894524335861206 seconds
Total simulation time for 400 steps: 8.205248355865479 	 Other agent action time: 0 	 48.74928614611185 steps/s
Curr learning rate 0.000819 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.33it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.20it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 180.20it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.15it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 191.82it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.98it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.37it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.34it/s]
--------------------------------------
| approxkl           | 0.0025163586  |
| clipfrac           | 0.20828122    |
| eplenmean          | 400           |
| eprewmean          | 85.8          |
| explained_variance | 0.642         |
| fps                | 1350          |
| nupdates           | 682           |
| policy_entropy     | 0.5582841     |
| policy_loss        | 0.00012947187 |
| serial_timesteps   | 272800        |
| time_elapsed       | 6.12e+03      |
| time_remaining     | 10.2          |
| total_timesteps    | 8184000       |
| true_eprew         | 85.8          |
| value_loss         | 16.583073     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.852279186248779 seconds
Total simulation time for 400 steps: 8.137162446975708 	 Other agent action time: 0 	 49.15718502690894 steps/s
Curr learning rate 0.000818 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.73it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 148.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 157.40it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 157.38it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 163.84it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.16it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.33it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 187.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]
-------------------------------------
| approxkl           | 0.0055181975 |
| clipfrac           | 0.2766563    |
| eplenmean          | 400          |
| eprewmean          | 86.8         |
| explained_variance | 0.609        |
| fps                | 1353         |
| nupdates           | 683          |
| policy_entropy     | 0.5606388    |
| policy_loss        | 0.0007064565 |
| serial_timesteps   | 273200       |
| time_elapsed       | 6.12e+03     |
| time_remaining     | 10           |
| total_timesteps    | 8196000      |
| true_eprew         | 86.8         |
| value_loss         | 18.351841    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 5.103760719299316 seconds
Total simulation time for 400 steps: 8.6082603931427 	 Other agent action time: 0 	 46.46699585419583 steps/s
Curr learning rate 0.000817 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.27it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.29it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 179.07it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.26it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 171.06it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.83it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.01it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 161.75it/s]
--------------------------------------
| approxkl           | 0.0032637983  |
| clipfrac           | 0.24005212    |
| eplenmean          | 400           |
| eprewmean          | 84.6          |
| explained_variance | 0.561         |
| fps                | 1284          |
| nupdates           | 684           |
| policy_entropy     | 0.5782583     |
| policy_loss        | 0.00030460118 |
| serial_timesteps   | 273600        |
| time_elapsed       | 6.13e+03      |
| time_remaining     | 9.86          |
| total_timesteps    | 8208000       |
| true_eprew         | 84.6          |
| value_loss         | 19.975119     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 7.633502960205078 seconds
Total simulation time for 400 steps: 17.414788007736206 	 Other agent action time: 0 	 22.968984739998398 steps/s
Curr learning rate 0.000816 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  93%|█████████▎| 14/15 [00:00<00:00, 130.27it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 130.42it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8:  73%|███████▎  | 11/15 [00:00<00:00, 98.01it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 101.41it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  67%|██████▋   | 10/15 [00:00<00:00, 92.50it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 103.21it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8:  67%|██████▋   | 10/15 [00:00<00:00, 82.99it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 83.81it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8:  80%|████████  | 12/15 [00:00<00:00, 115.41it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 109.14it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8:  93%|█████████▎| 14/15 [00:00<00:00, 131.79it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 128.97it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8:  80%|████████  | 12/15 [00:00<00:00, 119.80it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 113.42it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8:  67%|██████▋   | 10/15 [00:00<00:00, 99.25it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 106.12it/s]
--------------------------------------
| approxkl           | 0.0041409964  |
| clipfrac           | 0.2619895     |
| eplenmean          | 400           |
| eprewmean          | 86.6          |
| explained_variance | 0.569         |
| fps                | 645           |
| nupdates           | 685           |
| policy_entropy     | 0.58806974    |
| policy_loss        | 0.00038299258 |
| serial_timesteps   | 274000        |
| time_elapsed       | 6.15e+03      |
| time_remaining     | 9.73          |
| total_timesteps    | 8220000       |
| true_eprew         | 86.6          |
| value_loss         | 19.75461      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 5.847105026245117 seconds
Total simulation time for 400 steps: 11.675041913986206 	 Other agent action time: 0 	 34.26111897044386 steps/s
Curr learning rate 0.000815 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.56it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.74it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.80it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 196.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 192.17it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.94it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.57it/s]
--------------------------------------
| approxkl           | 0.0036295343  |
| clipfrac           | 0.26328123    |
| eplenmean          | 400           |
| eprewmean          | 85.6          |
| explained_variance | 0.605         |
| fps                | 971           |
| nupdates           | 686           |
| policy_entropy     | 0.6193243     |
| policy_loss        | 0.00091170694 |
| serial_timesteps   | 274400        |
| time_elapsed       | 6.16e+03      |
| time_remaining     | 9.59          |
| total_timesteps    | 8232000       |
| true_eprew         | 85.6          |
| value_loss         | 19.665625     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.843400239944458 seconds
Total simulation time for 400 steps: 8.251748085021973 	 Other agent action time: 0 	 48.47457725061354 steps/s
Curr learning rate 0.000814 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.33it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.51it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.40it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.30it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.84it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.07it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.43it/s]
-------------------------------------
| approxkl           | 0.0043310737 |
| clipfrac           | 0.25855213   |
| eplenmean          | 400          |
| eprewmean          | 85.2         |
| explained_variance | 0.712        |
| fps                | 1340         |
| nupdates           | 687          |
| policy_entropy     | 0.5579072    |
| policy_loss        | 3.205223e-05 |
| serial_timesteps   | 274800       |
| time_elapsed       | 6.17e+03     |
| time_remaining     | 9.44         |
| total_timesteps    | 8244000      |
| true_eprew         | 85.2         |
| value_loss         | 15.859629    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.857510089874268 seconds
Total simulation time for 400 steps: 8.27231240272522 	 Other agent action time: 0 	 48.354073265925564 steps/s
Curr learning rate 0.000813 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.40it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.81it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.16it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 197.11it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.71it/s]
---------------------------------------
| approxkl           | 0.00408906     |
| clipfrac           | 0.26545832     |
| eplenmean          | 400            |
| eprewmean          | 83.8           |
| explained_variance | 0.617          |
| fps                | 1338           |
| nupdates           | 688            |
| policy_entropy     | 0.60871845     |
| policy_loss        | -0.00058557285 |
| serial_timesteps   | 275200         |
| time_elapsed       | 6.18e+03       |
| time_remaining     | 9.29           |
| total_timesteps    | 8256000        |
| true_eprew         | 83.8           |
| value_loss         | 17.438215      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.930930137634277 seconds
Total simulation time for 400 steps: 8.331768274307251 	 Other agent action time: 0 	 48.00901643334028 steps/s
Curr learning rate 0.000812 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.16it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 163.18it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.91it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.53it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.06it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.70it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 183.99it/s]
---------------------------------------
| approxkl           | 0.0041789906   |
| clipfrac           | 0.27387506     |
| eplenmean          | 400            |
| eprewmean          | 83.4           |
| explained_variance | 0.645          |
| fps                | 1325           |
| nupdates           | 689            |
| policy_entropy     | 0.59545887     |
| policy_loss        | -5.1893938e-05 |
| serial_timesteps   | 275600         |
| time_elapsed       | 6.19e+03       |
| time_remaining     | 9.14           |
| total_timesteps    | 8268000        |
| true_eprew         | 83.4           |
| value_loss         | 17.15207       |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.870542526245117 seconds
Total simulation time for 400 steps: 8.147990226745605 	 Other agent action time: 0 	 49.091860553171564 steps/s
Curr learning rate 0.0008110000000000001 	 Curr reward per step 0.24166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.84it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.88it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.19it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.10it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.23it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.41it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.08it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.24it/s]
--------------------------------------
| approxkl           | 0.0026401952  |
| clipfrac           | 0.20467706    |
| eplenmean          | 400           |
| eprewmean          | 86.8          |
| explained_variance | 0.63          |
| fps                | 1354          |
| nupdates           | 690           |
| policy_entropy     | 0.5336163     |
| policy_loss        | -0.0012324507 |
| serial_timesteps   | 276000        |
| time_elapsed       | 6.2e+03       |
| time_remaining     | 8.99          |
| total_timesteps    | 8280000       |
| true_eprew         | 86.8          |
| value_loss         | 16.930027     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.836849212646484 seconds
Total simulation time for 400 steps: 8.23045802116394 	 Other agent action time: 0 	 48.59996843084956 steps/s
Curr learning rate 0.00081 	 Curr reward per step 0.2016666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.12it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.76it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.51it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 171.26it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.50it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.88it/s]
-------------------------------------
| approxkl           | 0.0060947253 |
| clipfrac           | 0.2769896    |
| eplenmean          | 400          |
| eprewmean          | 86.8         |
| explained_variance | 0.621        |
| fps                | 1341         |
| nupdates           | 691          |
| policy_entropy     | 0.5674732    |
| policy_loss        | 0.0021668493 |
| serial_timesteps   | 276400       |
| time_elapsed       | 6.21e+03     |
| time_remaining     | 8.84         |
| total_timesteps    | 8292000      |
| true_eprew         | 86.8         |
| value_loss         | 18.839272    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 5.000515460968018 seconds
Total simulation time for 400 steps: 8.470455646514893 	 Other agent action time: 0 	 47.222961395775336 steps/s
Curr learning rate 0.000809 	 Curr reward per step 0.20833333333333331

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.33it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.48it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  80%|████████  | 12/15 [00:00<00:00, 118.91it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 124.68it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.39it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.31it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.24it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 165.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 160.38it/s]
--------------------------------------
| approxkl           | 0.0027449853  |
| clipfrac           | 0.22925       |
| eplenmean          | 400           |
| eprewmean          | 85.8          |
| explained_variance | 0.654         |
| fps                | 1299          |
| nupdates           | 692           |
| policy_entropy     | 0.5934331     |
| policy_loss        | -0.0017770885 |
| serial_timesteps   | 276800        |
| time_elapsed       | 6.22e+03      |
| time_remaining     | 8.69          |
| total_timesteps    | 8304000       |
| true_eprew         | 85.8          |
| value_loss         | 16.885447     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 19.060932159423828 seconds
Total simulation time for 400 steps: 37.05122137069702 	 Other agent action time: 0 	 10.79586543174933 steps/s
Curr learning rate 0.000808 	 Curr reward per step 0.22166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  20%|██        | 3/15 [00:00<00:00, 16.48it/s]
0/8:  40%|████      | 6/15 [00:00<00:00, 14.67it/s]
0/8:  67%|██████▋   | 10/15 [00:00<00:00, 21.16it/s]
0/8:  87%|████████▋ | 13/15 [00:00<00:00, 21.05it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 17.72it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8:  60%|██████    | 9/15 [00:00<00:00, 85.61it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 45.70it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  27%|██▋       | 4/15 [00:00<00:00, 35.82it/s]
2/8:  53%|█████▎    | 8/15 [00:00<00:00, 11.27it/s]
2/8:  73%|███████▎  | 11/15 [00:00<00:00, 14.63it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 18.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8:  20%|██        | 3/15 [00:00<00:00, 18.92it/s]
3/8:  33%|███▎      | 5/15 [00:00<00:00, 16.20it/s]
3/8:  53%|█████▎    | 8/15 [00:00<00:00, 17.94it/s]
3/8:  67%|██████▋   | 10/15 [00:00<00:00, 13.28it/s]
3/8:  87%|████████▋ | 13/15 [00:00<00:00, 16.05it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 16.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8:  33%|███▎      | 5/15 [00:00<00:00, 32.92it/s]
4/8:  67%|██████▋   | 10/15 [00:00<00:00, 39.82it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 23.38it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 25.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8:  33%|███▎      | 5/15 [00:00<00:00, 49.87it/s]
5/8:  67%|██████▋   | 10/15 [00:00<00:00, 31.27it/s]
5/8:  93%|█████████▎| 14/15 [00:00<00:00, 27.62it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 30.78it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8:  40%|████      | 6/15 [00:00<00:00, 58.71it/s]
6/8:  80%|████████  | 12/15 [00:00<00:00, 40.42it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 29.76it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8:  33%|███▎      | 5/15 [00:00<00:00, 39.40it/s]
7/8:  60%|██████    | 9/15 [00:00<00:00, 22.21it/s]
7/8:  80%|████████  | 12/15 [00:00<00:00, 20.04it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 25.35it/s]
-------------------------------------
| approxkl           | 0.0035251859 |
| clipfrac           | 0.24746874   |
| eplenmean          | 400          |
| eprewmean          | 86           |
| explained_variance | 0.585        |
| fps                | 283          |
| nupdates           | 693          |
| policy_entropy     | 0.5900203    |
| policy_loss        | 0.0005428946 |
| serial_timesteps   | 277200       |
| time_elapsed       | 6.26e+03     |
| time_remaining     | 8.58         |
| total_timesteps    | 8316000      |
| true_eprew         | 86           |
| value_loss         | 20.01316     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 39.26908850669861 seconds
Total simulation time for 400 steps: 72.60725140571594 	 Other agent action time: 0 	 5.509091616274987 steps/s
Curr learning rate 0.000807 	 Curr reward per step 0.205

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  20%|██        | 3/15 [00:00<00:00, 27.77it/s]
0/8:  47%|████▋     | 7/15 [00:00<00:00, 18.75it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 36.26it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 32.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8:  40%|████      | 6/15 [00:00<00:00, 59.93it/s]
1/8:  80%|████████  | 12/15 [00:00<00:00, 37.79it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 36.59it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  20%|██        | 3/15 [00:00<00:00, 25.98it/s]
2/8:  60%|██████    | 9/15 [00:00<00:00, 44.49it/s]
2/8:  93%|█████████▎| 14/15 [00:00<00:00, 22.53it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 26.21it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8:  13%|█▎        | 2/15 [00:00<00:01, 12.94it/s]
3/8:  27%|██▋       | 4/15 [00:00<00:00, 13.84it/s]
3/8:  73%|███████▎  | 11/15 [00:00<00:00, 28.15it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 29.86it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8:  13%|█▎        | 2/15 [00:00<00:00, 14.37it/s]
4/8:  80%|████████  | 12/15 [00:00<00:00, 56.54it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 30.82it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8:  33%|███▎      | 5/15 [00:00<00:00, 39.62it/s]
5/8:  60%|██████    | 9/15 [00:00<00:00, 28.22it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 34.69it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 33.92it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8:  33%|███▎      | 5/15 [00:00<00:00, 48.29it/s]
6/8:  87%|████████▋ | 13/15 [00:00<00:00, 62.99it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 60.63it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8:  20%|██        | 3/15 [00:00<00:00, 24.71it/s]
7/8:  40%|████      | 6/15 [00:00<00:00, 23.65it/s]
7/8:  73%|███████▎  | 11/15 [00:00<00:00, 30.80it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 32.47it/s]
--------------------------------------
| approxkl           | 0.00416043    |
| clipfrac           | 0.26932293    |
| eplenmean          | 400           |
| eprewmean          | 84            |
| explained_variance | 0.682         |
| fps                | 157           |
| nupdates           | 694           |
| policy_entropy     | 0.61775357    |
| policy_loss        | -0.0005727621 |
| serial_timesteps   | 277600        |
| time_elapsed       | 6.34e+03      |
| time_remaining     | 8.52          |
| total_timesteps    | 8328000       |
| true_eprew         | 84            |
| value_loss         | 15.339584     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 31.576510667800903 seconds
Total simulation time for 400 steps: 63.81757879257202 	 Other agent action time: 0 	 6.267865493614709 steps/s
Curr learning rate 0.000806 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  33%|███▎      | 5/15 [00:00<00:00, 19.23it/s]
0/8:  47%|████▋     | 7/15 [00:00<00:00, 16.92it/s]
0/8:  80%|████████  | 12/15 [00:00<00:00, 25.95it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 23.10it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 22.18it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8:  27%|██▋       | 4/15 [00:00<00:00, 26.95it/s]
1/8:  47%|████▋     | 7/15 [00:00<00:00, 17.81it/s]
1/8:  60%|██████    | 9/15 [00:00<00:00, 16.06it/s]
1/8:  73%|███████▎  | 11/15 [00:00<00:00, 15.97it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 21.12it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  33%|███▎      | 5/15 [00:00<00:00, 42.08it/s]
2/8:  67%|██████▋   | 10/15 [00:00<00:00, 42.13it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 31.78it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 34.01it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8:  27%|██▋       | 4/15 [00:00<00:00, 32.72it/s]
3/8:  53%|█████▎    | 8/15 [00:00<00:00, 22.90it/s]
3/8:  73%|███████▎  | 11/15 [00:00<00:00, 23.01it/s]
3/8:  93%|█████████▎| 14/15 [00:00<00:00, 23.89it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 24.92it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8:  33%|███▎      | 5/15 [00:00<00:00, 49.13it/s]
4/8:  67%|██████▋   | 10/15 [00:00<00:00, 38.54it/s]
4/8:  93%|█████████▎| 14/15 [00:00<00:00, 34.00it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 36.85it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8:  40%|████      | 6/15 [00:00<00:00, 36.07it/s]
5/8:  67%|██████▋   | 10/15 [00:00<00:00, 31.27it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 39.38it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8:  20%|██        | 3/15 [00:00<00:00, 22.68it/s]
6/8:  40%|████      | 6/15 [00:00<00:00, 20.16it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 31.98it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 29.47it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8:  27%|██▋       | 4/15 [00:00<00:00, 34.73it/s]
7/8:  80%|████████  | 12/15 [00:00<00:00, 58.95it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 61.17it/s]
--------------------------------------
| approxkl           | 0.0045893034  |
| clipfrac           | 0.2660104     |
| eplenmean          | 400           |
| eprewmean          | 82.2          |
| explained_variance | 0.631         |
| fps                | 174           |
| nupdates           | 695           |
| policy_entropy     | 0.56442726    |
| policy_loss        | 0.00081793923 |
| serial_timesteps   | 278000        |
| time_elapsed       | 6.41e+03      |
| time_remaining     | 8.45          |
| total_timesteps    | 8340000       |
| true_eprew         | 82.2          |
| value_loss         | 19.457611     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 60.216166973114014 seconds
Total simulation time for 400 steps: 104.07606768608093 	 Other agent action time: 0 	 3.8433427481762528 steps/s
Curr learning rate 0.000805 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  33%|███▎      | 5/15 [00:00<00:00, 35.41it/s]
0/8:  60%|██████    | 9/15 [00:00<00:00, 11.25it/s]
0/8:  80%|████████  | 12/15 [00:00<00:00, 14.30it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 15.35it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 15.19it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8:  27%|██▋       | 4/15 [00:00<00:00, 27.96it/s]
1/8:  80%|████████  | 12/15 [00:00<00:00, 38.79it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 41.64it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  47%|████▋     | 7/15 [00:00<00:00, 69.79it/s]
2/8:  93%|█████████▎| 14/15 [00:00<00:00, 69.27it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 68.97it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8:  53%|█████▎    | 8/15 [00:00<00:00, 75.89it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 58.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8:  13%|█▎        | 2/15 [00:00<00:00, 19.19it/s]
4/8:  53%|█████▎    | 8/15 [00:00<00:00, 40.87it/s]
4/8:  93%|█████████▎| 14/15 [00:00<00:00, 44.81it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 41.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8:  20%|██        | 3/15 [00:00<00:00, 29.62it/s]
5/8:  40%|████      | 6/15 [00:00<00:00, 26.95it/s]
5/8:  80%|████████  | 12/15 [00:00<00:00, 38.47it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 30.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8:  20%|██        | 3/15 [00:00<00:00, 24.08it/s]
6/8:  60%|██████    | 9/15 [00:00<00:00, 39.67it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 46.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8:  33%|███▎      | 5/15 [00:00<00:00, 49.72it/s]
7/8:  67%|██████▋   | 10/15 [00:00<00:00, 40.46it/s]--------------------------------------
| approxkl           | 0.0034702392  |
| clipfrac           | 0.23820832    |
| eplenmean          | 400           |
| eprewmean          | 84            |
| explained_variance | 0.632         |
| fps                | 111           |
| nupdates           | 696           |
| policy_entropy     | 0.5892258     |
| policy_loss        | -0.0002530504 |
| serial_timesteps   | 278400        |
| time_elapsed       | 6.51e+03      |
| time_remaining     | 8.42          |
| total_timesteps    | 8352000       |
| true_eprew         | 84            |
| value_loss         | 16.725004     |
--------------------------------------

7/8: 100%|██████████| 15/15 [00:00<00:00, 49.12it/s]
Current reward shaping 0
SP envs: 0/30
Other agent actions took 51.369457721710205 seconds
Total simulation time for 400 steps: 86.91184091567993 	 Other agent action time: 0 	 4.602364830680226 steps/s
Curr learning rate 0.000804 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  20%|██        | 3/15 [00:00<00:00, 20.35it/s]
0/8:  40%|████      | 6/15 [00:00<00:00, 13.04it/s]
0/8:  53%|█████▎    | 8/15 [00:00<00:00, 11.05it/s]
0/8:  87%|████████▋ | 13/15 [00:00<00:00, 19.52it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 18.42it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8:  33%|███▎      | 5/15 [00:00<00:00, 44.16it/s]
1/8:  67%|██████▋   | 10/15 [00:00<00:00, 30.24it/s]
1/8:  93%|█████████▎| 14/15 [00:00<00:00, 15.61it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 19.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  27%|██▋       | 4/15 [00:00<00:00, 27.07it/s]
2/8:  47%|████▋     | 7/15 [00:00<00:00, 19.32it/s]
2/8:  67%|██████▋   | 10/15 [00:00<00:00, 13.96it/s]
2/8:  87%|████████▋ | 13/15 [00:00<00:00, 17.46it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 17.20it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8:   7%|▋         | 1/15 [00:00<00:02,  5.07it/s]
3/8:  13%|█▎        | 2/15 [00:00<00:02,  5.94it/s]
3/8:  20%|██        | 3/15 [00:00<00:01,  6.53it/s]
3/8:  33%|███▎      | 5/15 [00:00<00:00, 10.27it/s]
3/8:  73%|███████▎  | 11/15 [00:00<00:00, 20.29it/s]
3/8:  87%|████████▋ | 13/15 [00:00<00:00, 16.28it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 15.04it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8:  20%|██        | 3/15 [00:00<00:00, 27.12it/s]
4/8:  40%|████      | 6/15 [00:00<00:00, 10.91it/s]
4/8:  67%|██████▋   | 10/15 [00:00<00:00, 17.43it/s]
4/8:  87%|████████▋ | 13/15 [00:00<00:00, 17.29it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 17.11it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8:  53%|█████▎    | 8/15 [00:00<00:00, 74.64it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 27.81it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8:  27%|██▋       | 4/15 [00:00<00:00, 26.77it/s]
6/8:  60%|██████    | 9/15 [00:00<00:00, 37.74it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 45.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8:   7%|▋         | 1/15 [00:00<00:03,  4.09it/s]
7/8:  53%|█████▎    | 8/15 [00:00<00:00, 19.96it/s]
7/8:  73%|███████▎  | 11/15 [00:00<00:00, 22.14it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 24.16it/s]
--------------------------------------
| approxkl           | 0.0045249993  |
| clipfrac           | 0.2672187     |
| eplenmean          | 400           |
| eprewmean          | 84.2          |
| explained_variance | 0.588         |
| fps                | 128           |
| nupdates           | 697           |
| policy_entropy     | 0.59477985    |
| policy_loss        | 0.00029311868 |
| serial_timesteps   | 278800        |
| time_elapsed       | 6.61e+03      |
| time_remaining     | 8.37          |
| total_timesteps    | 8364000       |
| true_eprew         | 84.2          |
| value_loss         | 19.223656     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 46.33700132369995 seconds
Total simulation time for 400 steps: 85.30991435050964 	 Other agent action time: 0 	 4.6887867962982 steps/s
Curr learning rate 0.000803 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  33%|███▎      | 5/15 [00:00<00:00, 47.15it/s]
0/8:  67%|██████▋   | 10/15 [00:00<00:00, 37.76it/s]
0/8:  93%|█████████▎| 14/15 [00:00<00:00, 37.31it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 39.51it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8:  40%|████      | 6/15 [00:00<00:00, 44.68it/s]
1/8:  73%|███████▎  | 11/15 [00:00<00:00, 30.44it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 29.08it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 30.60it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  20%|██        | 3/15 [00:00<00:00, 22.14it/s]
2/8:  47%|████▋     | 7/15 [00:00<00:00, 28.01it/s]
2/8:  87%|████████▋ | 13/15 [00:00<00:00, 36.49it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 36.56it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8:  33%|███▎      | 5/15 [00:00<00:00, 30.46it/s]
3/8:  60%|██████    | 9/15 [00:00<00:00, 29.63it/s]
3/8:  93%|█████████▎| 14/15 [00:00<00:00, 35.69it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 32.89it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8:  33%|███▎      | 5/15 [00:00<00:00, 43.57it/s]
4/8:  87%|████████▋ | 13/15 [00:00<00:00, 54.84it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 57.65it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8:  33%|███▎      | 5/15 [00:00<00:00, 41.52it/s]
5/8:  80%|████████  | 12/15 [00:00<00:00, 48.75it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 47.44it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8:  27%|██▋       | 4/15 [00:00<00:00, 33.23it/s]
6/8:  53%|█████▎    | 8/15 [00:00<00:00, 35.67it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 51.08it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8:  27%|██▋       | 4/15 [00:00<00:00, 39.12it/s]
7/8:  67%|██████▋   | 10/15 [00:00<00:00, 48.40it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 50.53it/s]
--------------------------------------
| approxkl           | 0.0035050937  |
| clipfrac           | 0.25539586    |
| eplenmean          | 400           |
| eprewmean          | 89.4          |
| explained_variance | 0.626         |
| fps                | 135           |
| nupdates           | 698           |
| policy_entropy     | 0.6066901     |
| policy_loss        | -0.0008678643 |
| serial_timesteps   | 279200        |
| time_elapsed       | 6.7e+03       |
| time_remaining     | 8.31          |
| total_timesteps    | 8376000       |
| true_eprew         | 89.4          |
| value_loss         | 17.833286     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 6.623605728149414 seconds
Total simulation time for 400 steps: 12.986809253692627 	 Other agent action time: 0 	 30.80048318152246 steps/s
Curr learning rate 0.000802 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.31it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.26it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.71it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.79it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.19it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.38it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.33it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.51it/s]
--------------------------------------
| approxkl           | 0.0033601162  |
| clipfrac           | 0.2561563     |
| eplenmean          | 400           |
| eprewmean          | 89.8          |
| explained_variance | 0.608         |
| fps                | 875           |
| nupdates           | 699           |
| policy_entropy     | 0.63408786    |
| policy_loss        | -0.0005634363 |
| serial_timesteps   | 279600        |
| time_elapsed       | 6.71e+03      |
| time_remaining     | 8.16          |
| total_timesteps    | 8388000       |
| true_eprew         | 89.8          |
| value_loss         | 18.002583     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.9254233837127686 seconds
Total simulation time for 400 steps: 8.535396814346313 	 Other agent action time: 0 	 46.86366770056655 steps/s
Curr learning rate 0.000801 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.76it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.22it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.09it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.39it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.93it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.89it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 184.62it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.76it/s]
--------------------------------------
| approxkl           | 0.00299132    |
| clipfrac           | 0.24408337    |
| eplenmean          | 400           |
| eprewmean          | 87.8          |
| explained_variance | 0.554         |
| fps                | 1298          |
| nupdates           | 700           |
| policy_entropy     | 0.6186349     |
| policy_loss        | 0.00024257884 |
| serial_timesteps   | 280000        |
| time_elapsed       | 6.72e+03      |
| time_remaining     | 8             |
| total_timesteps    | 8400000       |
| true_eprew         | 87.8          |
| value_loss         | 20.6609       |
--------------------------------------
Current reward shaping 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1Xo  X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1Xo  X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1Xo↓0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1Xo←0X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←oX 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑oP 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   X ↑0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑1X   P 
O   Xo↓0X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X   P 
O   Xo←0X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X   P 
O   X ←oX 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←1X ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø2X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø3X 
O →oX ↑0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø4X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø6X 
O →oX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø7X 
O →1Xo←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←1X ←oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X ø9X 
O ←oX →oP 
O   X   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø10X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø11X 
O ←oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø13X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø14X 
O →oX →0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø15X 
O →1Xo→0ø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø16X 
O   Xo←0ø-
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø17X 
O   X ←oø-
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø18X 
O   Xo←0ø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 52
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø19X 
O   X ←oø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 53
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 54
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←oø-
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø-
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑1X ←oø-
O   X   X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo←0ø-
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X ←oø-
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →oø-
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 60
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X →0ø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 61
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 62
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 63
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø20X 
O   X →0ø=
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 64
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 65
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   X →0ø=
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dX →0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xd←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1Xd←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →1X ←dø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ←1X ↑dø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 5 
X X X P X 
O ←oX ↑sø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX   ø=
O   X ↓sX 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX   ø=
O   X   X 
D   X ↓sX 
X X X S X 


Timestep: 78
Joint action taken: ('interact', '→') 	 Reward: 20 + shape * 0 
X X X P X 
O →oX   ø=
O   X   X 
D   X ↓0X 
X X X S X 


Timestep: 79
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX   ø=
O   X ↑0X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ↑0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ←oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O →1Xo←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O →1X ←oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O ←1X ↑oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø-X 
O ←1X ↑0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1X ←oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ↑oø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←oX ↑0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('↑', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ↑0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ↑0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ←0ø=
O   X   X 
D   X   X 
X X X S X 


tot rew 140 tot rew shaped 119
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 28
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 29
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 30
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 31
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 52
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 59
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 60
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 61
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 62
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 85
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 90
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
SP envs: 0/30
Other agent actions took 4.757536172866821 seconds
Total simulation time for 400 steps: 8.024268865585327 	 Other agent action time: 0 	 49.84877833736721 steps/s
Curr learning rate 0.0008 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 174.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 175.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.26it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.21it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.65it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]
---------------------------------------
| approxkl           | 0.0036077106   |
| clipfrac           | 0.25454164     |
| eplenmean          | 400            |
| eprewmean          | 85.6           |
| explained_variance | 0.616          |
| fps                | 1373           |
| nupdates           | 701            |
| policy_entropy     | 0.61774385     |
| policy_loss        | -0.00038261226 |
| serial_timesteps   | 280400         |
| time_elapsed       | 6.73e+03       |
| time_remaining     | 7.84           |
| total_timesteps    | 8412000        |
| true_eprew         | 85.6           |
| value_loss         | 17.801647      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.842419862747192 seconds
Total simulation time for 400 steps: 8.150869131088257 	 Other agent action time: 0 	 49.07452120343322 steps/s
Curr learning rate 0.000799 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.68it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 188.81it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 184.90it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 189.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 194.40it/s]
-------------------------------------
| approxkl           | 0.00363034   |
| clipfrac           | 0.23364583   |
| eplenmean          | 400          |
| eprewmean          | 84.8         |
| explained_variance | 0.637        |
| fps                | 1358         |
| nupdates           | 702          |
| policy_entropy     | 0.578925     |
| policy_loss        | -0.001128827 |
| serial_timesteps   | 280800       |
| time_elapsed       | 6.74e+03     |
| time_remaining     | 7.68         |
| total_timesteps    | 8424000      |
| true_eprew         | 84.8         |
| value_loss         | 16.593061    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.841071605682373 seconds
Total simulation time for 400 steps: 8.134210348129272 	 Other agent action time: 0 	 49.17502534121128 steps/s
Curr learning rate 0.000798 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.78it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.54it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.07it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.28it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.46it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.88it/s]
---------------------------------------
| approxkl           | 0.004358977    |
| clipfrac           | 0.26265624     |
| eplenmean          | 400            |
| eprewmean          | 84.2           |
| explained_variance | 0.609          |
| fps                | 1354           |
| nupdates           | 703            |
| policy_entropy     | 0.59418017     |
| policy_loss        | -0.00038843844 |
| serial_timesteps   | 281200         |
| time_elapsed       | 6.75e+03       |
| time_remaining     | 7.52           |
| total_timesteps    | 8436000        |
| true_eprew         | 84.2           |
| value_loss         | 16.979292      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8440937995910645 seconds
Total simulation time for 400 steps: 8.29199767112732 	 Other agent action time: 0 	 48.239280311522194 steps/s
Curr learning rate 0.000797 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 151.72it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.26it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 157.72it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 172.16it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 199.83it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 199.74it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 191.01it/s]
-------------------------------------
| approxkl           | 0.0036720159 |
| clipfrac           | 0.25013542   |
| eplenmean          | 400          |
| eprewmean          | 87.6         |
| explained_variance | 0.585        |
| fps                | 1331         |
| nupdates           | 704          |
| policy_entropy     | 0.59408      |
| policy_loss        | -0.001404803 |
| serial_timesteps   | 281600       |
| time_elapsed       | 6.76e+03     |
| time_remaining     | 7.36         |
| total_timesteps    | 8448000      |
| true_eprew         | 87.6         |
| value_loss         | 19.140265    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.81231427192688 seconds
Total simulation time for 400 steps: 8.07500696182251 	 Other agent action time: 0 	 49.535561008324 steps/s
Curr learning rate 0.000796 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.66it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 180.24it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.89it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 184.89it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 187.54it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.77it/s]
-------------------------------------
| approxkl           | 0.0025958265 |
| clipfrac           | 0.21439582   |
| eplenmean          | 400          |
| eprewmean          | 88.4         |
| explained_variance | 0.584        |
| fps                | 1371         |
| nupdates           | 705          |
| policy_entropy     | 0.5930927    |
| policy_loss        | -0.000467361 |
| serial_timesteps   | 282000       |
| time_elapsed       | 6.77e+03     |
| time_remaining     | 7.2          |
| total_timesteps    | 8460000      |
| true_eprew         | 88.4         |
| value_loss         | 18.975899    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.791785955429077 seconds
Total simulation time for 400 steps: 8.128921270370483 	 Other agent action time: 0 	 49.207021042014546 steps/s
Curr learning rate 0.000795 	 Curr reward per step 0.21166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.96it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 177.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 176.49it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 179.08it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 148.20it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 147.62it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.63it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.33it/s]
--------------------------------------
| approxkl           | 0.0034965505  |
| clipfrac           | 0.24853127    |
| eplenmean          | 400           |
| eprewmean          | 85.8          |
| explained_variance | 0.622         |
| fps                | 1354          |
| nupdates           | 706           |
| policy_entropy     | 0.6146507     |
| policy_loss        | -0.0011218284 |
| serial_timesteps   | 282400        |
| time_elapsed       | 6.77e+03      |
| time_remaining     | 7.04          |
| total_timesteps    | 8472000       |
| true_eprew         | 85.8          |
| value_loss         | 16.924372     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 5.1367902755737305 seconds
Total simulation time for 400 steps: 9.39115285873413 	 Other agent action time: 0 	 42.59327965554141 steps/s
Curr learning rate 0.000794 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.47it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.47it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.24it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 186.36it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.67it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 188.00it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.14it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.93it/s]
--------------------------------------
| approxkl           | 0.0044677877  |
| clipfrac           | 0.26004165    |
| eplenmean          | 400           |
| eprewmean          | 86.8          |
| explained_variance | 0.648         |
| fps                | 1188          |
| nupdates           | 707           |
| policy_entropy     | 0.5816447     |
| policy_loss        | -0.0005404803 |
| serial_timesteps   | 282800        |
| time_elapsed       | 6.78e+03      |
| time_remaining     | 6.88          |
| total_timesteps    | 8484000       |
| true_eprew         | 86.8          |
| value_loss         | 15.243465     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.928551435470581 seconds
Total simulation time for 400 steps: 8.38496708869934 	 Other agent action time: 0 	 47.70442099159714 steps/s
Curr learning rate 0.000793 	 Curr reward per step 0.2

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.11it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 190.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 194.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 189.76it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.96it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 204.11it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 207.89it/s]
-------------------------------------
| approxkl           | 0.0047920626 |
| clipfrac           | 0.2634063    |
| eplenmean          | 400          |
| eprewmean          | 84.8         |
| explained_variance | 0.587        |
| fps                | 1326         |
| nupdates           | 708          |
| policy_entropy     | 0.57234687   |
| policy_loss        | 0.0010739953 |
| serial_timesteps   | 283200       |
| time_elapsed       | 6.79e+03     |
| time_remaining     | 6.72         |
| total_timesteps    | 8496000      |
| true_eprew         | 84.8         |
| value_loss         | 18.759823    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8102381229400635 seconds
Total simulation time for 400 steps: 8.169037580490112 	 Other agent action time: 0 	 48.96537640557671 steps/s
Curr learning rate 0.0007920000000000001 	 Curr reward per step 0.205

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 165.96it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.35it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 194.70it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 191.03it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 195.12it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 197.50it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 196.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 188.35it/s]
---------------------------------------
| approxkl           | 0.0040873378   |
| clipfrac           | 0.24709374     |
| eplenmean          | 400            |
| eprewmean          | 84.2           |
| explained_variance | 0.591          |
| fps                | 1357           |
| nupdates           | 709            |
| policy_entropy     | 0.5757296      |
| policy_loss        | -0.00028094178 |
| serial_timesteps   | 283600         |
| time_elapsed       | 6.8e+03        |
| time_remaining     | 6.56           |
| total_timesteps    | 8508000        |
| true_eprew         | 84.2           |
| value_loss         | 18.33793       |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.987493276596069 seconds
Total simulation time for 400 steps: 8.436763286590576 	 Other agent action time: 0 	 47.411547107853735 steps/s
Curr learning rate 0.000791 	 Curr reward per step 0.21

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.00it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.37it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.50it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 168.49it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 153.86it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 170.01it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.95it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.56it/s]
-------------------------------------
| approxkl           | 0.0036699225 |
| clipfrac           | 0.23609377   |
| eplenmean          | 400          |
| eprewmean          | 82.4         |
| explained_variance | 0.59         |
| fps                | 1307         |
| nupdates           | 710          |
| policy_entropy     | 0.52991      |
| policy_loss        | 0.0007406016 |
| serial_timesteps   | 284000       |
| time_elapsed       | 6.81e+03     |
| time_remaining     | 6.4          |
| total_timesteps    | 8520000      |
| true_eprew         | 82.4         |
| value_loss         | 18.155233    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 6.0125603675842285 seconds
Total simulation time for 400 steps: 12.238292932510376 	 Other agent action time: 0 	 32.68429691999128 steps/s
Curr learning rate 0.00079 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  40%|████      | 6/15 [00:00<00:00, 49.83it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 70.98it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 67.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8:  20%|██        | 3/15 [00:00<00:00, 27.55it/s]
1/8:  80%|████████  | 12/15 [00:00<00:00, 54.09it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 48.04it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  73%|███████▎  | 11/15 [00:00<00:00, 106.39it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 88.70it/s] 

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8:  73%|███████▎  | 11/15 [00:00<00:00, 103.38it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 93.71it/s] 

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8:  60%|██████    | 9/15 [00:00<00:00, 60.83it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 64.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8:  27%|██▋       | 4/15 [00:00<00:00, 38.66it/s]
5/8:  53%|█████▎    | 8/15 [00:00<00:00, 36.94it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 49.32it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 46.15it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8:  53%|█████▎    | 8/15 [00:00<00:00, 74.66it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 59.52it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8:  33%|███▎      | 5/15 [00:00<00:00, 45.96it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 68.58it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 65.22it/s]
--------------------------------------
| approxkl           | 0.002665318   |
| clipfrac           | 0.20799999    |
| eplenmean          | 400           |
| eprewmean          | 84.8          |
| explained_variance | 0.66          |
| fps                | 845           |
| nupdates           | 711           |
| policy_entropy     | 0.54836106    |
| policy_loss        | -0.0011085131 |
| serial_timesteps   | 284400        |
| time_elapsed       | 6.83e+03      |
| time_remaining     | 6.24          |
| total_timesteps    | 8532000       |
| true_eprew         | 84.8          |
| value_loss         | 15.766013     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 16.56426763534546 seconds
Total simulation time for 400 steps: 34.78549122810364 	 Other agent action time: 0 	 11.499047041682566 steps/s
Curr learning rate 0.0007890000000000001 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8:  27%|██▋       | 4/15 [00:00<00:00, 38.17it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 75.44it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8:  47%|████▋     | 7/15 [00:00<00:00, 67.92it/s]
1/8:  93%|█████████▎| 14/15 [00:00<00:00, 59.49it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 61.14it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8:  47%|████▋     | 7/15 [00:00<00:00, 68.20it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 81.98it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8:  67%|██████▋   | 10/15 [00:00<00:00, 90.93it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 94.11it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8:  53%|█████▎    | 8/15 [00:00<00:00, 76.59it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 81.94it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8:  73%|███████▎  | 11/15 [00:00<00:00, 108.51it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 111.74it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8:  27%|██▋       | 4/15 [00:00<00:00, 37.42it/s]
6/8:  67%|██████▋   | 10/15 [00:00<00:00, 47.37it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 51.28it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8:  47%|████▋     | 7/15 [00:00<00:00, 67.23it/s]
7/8:  93%|█████████▎| 14/15 [00:00<00:00, 65.16it/s]-------------------------------------
| approxkl           | 0.0029916752 |
| clipfrac           | 0.19731246   |
| eplenmean          | 400          |
| eprewmean          | 87.4         |
| explained_variance | 0.58         |
| fps                | 328          |
| nupdates           | 712          |
| policy_entropy     | 0.49785793   |
| policy_loss        | -0.001596658 |
| serial_timesteps   | 284800       |
| time_elapsed       | 6.86e+03     |
| time_remaining     | 6.1          |
| total_timesteps    | 8544000      |
| true_eprew         | 87.4         |
| value_loss         | 19.05055     |
-------------------------------------

7/8: 100%|██████████| 15/15 [00:00<00:00, 64.84it/s]
Current reward shaping 0
SP envs: 0/30
Other agent actions took 9.055562496185303 seconds
Total simulation time for 400 steps: 19.94010281562805 	 Other agent action time: 0 	 20.06007710684922 steps/s
Curr learning rate 0.000788 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.46it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 157.88it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 155.31it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.72it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.74it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.10it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.38it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.67it/s]
---------------------------------------
| approxkl           | 0.004235742    |
| clipfrac           | 0.23836456     |
| eplenmean          | 400            |
| eprewmean          | 90.4           |
| explained_variance | 0.609          |
| fps                | 580            |
| nupdates           | 713            |
| policy_entropy     | 0.5374787      |
| policy_loss        | -0.00016723646 |
| serial_timesteps   | 285200         |
| time_elapsed       | 6.88e+03       |
| time_remaining     | 5.95           |
| total_timesteps    | 8556000        |
| true_eprew         | 90.4           |
| value_loss         | 16.53758       |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.815508842468262 seconds
Total simulation time for 400 steps: 8.37408185005188 	 Other agent action time: 0 	 47.766430656218375 steps/s
Curr learning rate 0.000787 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 151.37it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 153.38it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.67it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.63it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 171.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 159.36it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 159.82it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 168.97it/s]
-------------------------------------
| approxkl           | 0.005168307  |
| clipfrac           | 0.25428125   |
| eplenmean          | 400          |
| eprewmean          | 91           |
| explained_variance | 0.605        |
| fps                | 1312         |
| nupdates           | 714          |
| policy_entropy     | 0.52885014   |
| policy_loss        | 0.0008162278 |
| serial_timesteps   | 285600       |
| time_elapsed       | 6.89e+03     |
| time_remaining     | 5.79         |
| total_timesteps    | 8568000      |
| true_eprew         | 91           |
| value_loss         | 16.710365    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.802660226821899 seconds
Total simulation time for 400 steps: 8.320963144302368 	 Other agent action time: 0 	 48.071358214570736 steps/s
Curr learning rate 0.000786 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.80it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.07it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 183.30it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.83it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.25it/s]
--------------------------------------
| approxkl           | 0.00541203    |
| clipfrac           | 0.24264579    |
| eplenmean          | 400           |
| eprewmean          | 91.4          |
| explained_variance | 0.643         |
| fps                | 1329          |
| nupdates           | 715           |
| policy_entropy     | 0.54059106    |
| policy_loss        | 0.00063115614 |
| serial_timesteps   | 286000        |
| time_elapsed       | 6.9e+03       |
| time_remaining     | 5.63          |
| total_timesteps    | 8580000       |
| true_eprew         | 91.4          |
| value_loss         | 15.140368     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.801939487457275 seconds
Total simulation time for 400 steps: 8.08012080192566 	 Other agent action time: 0 	 49.50421037079938 steps/s
Curr learning rate 0.000785 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.21it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 163.59it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.63it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.55it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.62it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.07it/s]
--------------------------------------
| approxkl           | 0.004166243   |
| clipfrac           | 0.24960423    |
| eplenmean          | 400           |
| eprewmean          | 90.4          |
| explained_variance | 0.59          |
| fps                | 1364          |
| nupdates           | 716           |
| policy_entropy     | 0.5405563     |
| policy_loss        | 0.00072731654 |
| serial_timesteps   | 286400        |
| time_elapsed       | 6.91e+03      |
| time_remaining     | 5.47          |
| total_timesteps    | 8592000       |
| true_eprew         | 90.4          |
| value_loss         | 18.736525     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.929094552993774 seconds
Total simulation time for 400 steps: 8.346766710281372 	 Other agent action time: 0 	 47.92274827895793 steps/s
Curr learning rate 0.000784 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.13it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.56it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 185.67it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.90it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.67it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.25it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.42it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]
--------------------------------------
| approxkl           | 0.004249027   |
| clipfrac           | 0.24918756    |
| eplenmean          | 400           |
| eprewmean          | 89.2          |
| explained_variance | 0.607         |
| fps                | 1325          |
| nupdates           | 717           |
| policy_entropy     | 0.5468248     |
| policy_loss        | -7.412421e-05 |
| serial_timesteps   | 286800        |
| time_elapsed       | 6.92e+03      |
| time_remaining     | 5.31          |
| total_timesteps    | 8604000       |
| true_eprew         | 89.2          |
| value_loss         | 18.125828     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.818069219589233 seconds
Total simulation time for 400 steps: 8.151989459991455 	 Other agent action time: 0 	 49.06777688601419 steps/s
Curr learning rate 0.0007830000000000001 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.27it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.70it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 169.42it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.24it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 182.80it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 186.05it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 191.13it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 186.79it/s]
--------------------------------------
| approxkl           | 0.005126087   |
| clipfrac           | 0.25996876    |
| eplenmean          | 400           |
| eprewmean          | 87.6          |
| explained_variance | 0.636         |
| fps                | 1355          |
| nupdates           | 718           |
| policy_entropy     | 0.5449229     |
| policy_loss        | 0.00047945447 |
| serial_timesteps   | 287200        |
| time_elapsed       | 6.93e+03      |
| time_remaining     | 5.15          |
| total_timesteps    | 8616000       |
| true_eprew         | 87.6          |
| value_loss         | 16.818975     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.854996681213379 seconds
Total simulation time for 400 steps: 8.18668246269226 	 Other agent action time: 0 	 48.85984057923954 steps/s
Curr learning rate 0.000782 	 Curr reward per step 0.19833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 168.70it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.75it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 189.39it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.38it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.35it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.34it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 182.78it/s]
-------------------------------------
| approxkl           | 0.004787369  |
| clipfrac           | 0.27102086   |
| eplenmean          | 400          |
| eprewmean          | 85.6         |
| explained_variance | 0.542        |
| fps                | 1351         |
| nupdates           | 719          |
| policy_entropy     | 0.5739761    |
| policy_loss        | 0.0011783611 |
| serial_timesteps   | 287600       |
| time_elapsed       | 6.94e+03     |
| time_remaining     | 4.98         |
| total_timesteps    | 8628000      |
| true_eprew         | 85.6         |
| value_loss         | 19.795147    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.953974008560181 seconds
Total simulation time for 400 steps: 8.303073406219482 	 Other agent action time: 0 	 48.17493239315178 steps/s
Curr learning rate 0.000781 	 Curr reward per step 0.2333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.64it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.72it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.94it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.81it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 182.34it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 170.84it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 170.67it/s]
---------------------------------------
| approxkl           | 0.0037687335   |
| clipfrac           | 0.23402084     |
| eplenmean          | 400            |
| eprewmean          | 87.4           |
| explained_variance | 0.66           |
| fps                | 1329           |
| nupdates           | 720            |
| policy_entropy     | 0.54981786     |
| policy_loss        | -0.00033773374 |
| serial_timesteps   | 288000         |
| time_elapsed       | 6.95e+03       |
| time_remaining     | 4.82           |
| total_timesteps    | 8640000        |
| true_eprew         | 87.4           |
| value_loss         | 15.022509      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.894059419631958 seconds
Total simulation time for 400 steps: 8.23059368133545 	 Other agent action time: 0 	 48.599167385346895 steps/s
Curr learning rate 0.0007800000000000001 	 Curr reward per step 0.22166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.89it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 173.13it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 184.34it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 183.85it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.35it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 185.00it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.44it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.79it/s]
--------------------------------------
| approxkl           | 0.0034565434  |
| clipfrac           | 0.21331249    |
| eplenmean          | 400           |
| eprewmean          | 87            |
| explained_variance | 0.628         |
| fps                | 1344          |
| nupdates           | 721           |
| policy_entropy     | 0.5198742     |
| policy_loss        | -0.0004086535 |
| serial_timesteps   | 288400        |
| time_elapsed       | 6.95e+03      |
| time_remaining     | 4.66          |
| total_timesteps    | 8652000       |
| true_eprew         | 87            |
| value_loss         | 16.643974     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.842464208602905 seconds
Total simulation time for 400 steps: 8.126728296279907 	 Other agent action time: 0 	 49.2202994141079 steps/s
Curr learning rate 0.000779 	 Curr reward per step 0.2333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.07it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.57it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.17it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.48it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 190.09it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 190.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 192.16it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.56it/s]
--------------------------------------
| approxkl           | 0.0021937573  |
| clipfrac           | 0.1932604     |
| eplenmean          | 400           |
| eprewmean          | 89.6          |
| explained_variance | 0.627         |
| fps                | 1361          |
| nupdates           | 722           |
| policy_entropy     | 0.5196994     |
| policy_loss        | -0.0012951711 |
| serial_timesteps   | 288800        |
| time_elapsed       | 6.96e+03      |
| time_remaining     | 4.5           |
| total_timesteps    | 8664000       |
| true_eprew         | 89.6          |
| value_loss         | 17.993425     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.744709014892578 seconds
Total simulation time for 400 steps: 7.927639722824097 	 Other agent action time: 0 	 50.45637970257133 steps/s
Curr learning rate 0.000778 	 Curr reward per step 0.19666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.16it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.77it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 181.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.60it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.60it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.39it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 189.96it/s]
--------------------------------------
| approxkl           | 0.0032721558  |
| clipfrac           | 0.22402088    |
| eplenmean          | 400           |
| eprewmean          | 86            |
| explained_variance | 0.595         |
| fps                | 1390          |
| nupdates           | 723           |
| policy_entropy     | 0.55611956    |
| policy_loss        | 0.00060162944 |
| serial_timesteps   | 289200        |
| time_elapsed       | 6.97e+03      |
| time_remaining     | 4.34          |
| total_timesteps    | 8676000       |
| true_eprew         | 86            |
| value_loss         | 19.099077     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.960924863815308 seconds
Total simulation time for 400 steps: 8.350250482559204 	 Other agent action time: 0 	 47.90275463418279 steps/s
Curr learning rate 0.000777 	 Curr reward per step 0.225

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.80it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 178.18it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.10it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 178.97it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 183.59it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.91it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.53it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.49it/s]
--------------------------------------
| approxkl           | 0.00401258    |
| clipfrac           | 0.24482292    |
| eplenmean          | 400           |
| eprewmean          | 88.2          |
| explained_variance | 0.574         |
| fps                | 1327          |
| nupdates           | 724           |
| policy_entropy     | 0.5411163     |
| policy_loss        | 0.00014717298 |
| serial_timesteps   | 289600        |
| time_elapsed       | 6.98e+03      |
| time_remaining     | 4.18          |
| total_timesteps    | 8688000       |
| true_eprew         | 88.2          |
| value_loss         | 18.610327     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.823319673538208 seconds
Total simulation time for 400 steps: 8.036425590515137 	 Other agent action time: 0 	 49.773371941885905 steps/s
Curr learning rate 0.000776 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.91it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.60it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.10it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.05it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 178.97it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.07it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 183.06it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 180.65it/s]
--------------------------------------
| approxkl           | 0.004218346   |
| clipfrac           | 0.24369788    |
| eplenmean          | 400           |
| eprewmean          | 86.4          |
| explained_variance | 0.606         |
| fps                | 1371          |
| nupdates           | 725           |
| policy_entropy     | 0.51793027    |
| policy_loss        | 0.00029187856 |
| serial_timesteps   | 290000        |
| time_elapsed       | 6.99e+03      |
| time_remaining     | 4.02          |
| total_timesteps    | 8700000       |
| true_eprew         | 86.4          |
| value_loss         | 16.763702     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.833614110946655 seconds
Total simulation time for 400 steps: 8.209422588348389 	 Other agent action time: 0 	 48.72449867152885 steps/s
Curr learning rate 0.000775 	 Curr reward per step 0.21666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.23it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.05it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 175.10it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.08it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.04it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 176.58it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 175.61it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.12it/s]
--------------------------------------
| approxkl           | 0.003774242   |
| clipfrac           | 0.2410209     |
| eplenmean          | 400           |
| eprewmean          | 89            |
| explained_variance | 0.578         |
| fps                | 1344          |
| nupdates           | 726           |
| policy_entropy     | 0.56055653    |
| policy_loss        | -9.484963e-05 |
| serial_timesteps   | 290400        |
| time_elapsed       | 7e+03         |
| time_remaining     | 3.86          |
| total_timesteps    | 8712000       |
| true_eprew         | 89            |
| value_loss         | 19.510965     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.902201890945435 seconds
Total simulation time for 400 steps: 8.178472757339478 	 Other agent action time: 0 	 48.90888700962344 steps/s
Curr learning rate 0.0007740000000000001 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.81it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 170.89it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 172.21it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.63it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.34it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.42it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.29it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 179.45it/s]
-------------------------------------
| approxkl           | 0.0034720155 |
| clipfrac           | 0.23079172   |
| eplenmean          | 400          |
| eprewmean          | 91.2         |
| explained_variance | 0.642        |
| fps                | 1351         |
| nupdates           | 727          |
| policy_entropy     | 0.5498698    |
| policy_loss        | -0.000645798 |
| serial_timesteps   | 290800       |
| time_elapsed       | 7.01e+03     |
| time_remaining     | 3.69         |
| total_timesteps    | 8724000      |
| true_eprew         | 91.2         |
| value_loss         | 15.13888     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.774015426635742 seconds
Total simulation time for 400 steps: 8.116753101348877 	 Other agent action time: 0 	 49.28078937543712 steps/s
Curr learning rate 0.000773 	 Curr reward per step 0.22166666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.01it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.81it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.51it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 177.55it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.57it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.20it/s]
---------------------------------------
| approxkl           | 0.0041896347   |
| clipfrac           | 0.24610415     |
| eplenmean          | 400            |
| eprewmean          | 89.4           |
| explained_variance | 0.546          |
| fps                | 1358           |
| nupdates           | 728            |
| policy_entropy     | 0.5521791      |
| policy_loss        | -0.00041108252 |
| serial_timesteps   | 291200         |
| time_elapsed       | 7.02e+03       |
| time_remaining     | 3.53           |
| total_timesteps    | 8736000        |
| true_eprew         | 89.4           |
| value_loss         | 19.499672      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.839731216430664 seconds
Total simulation time for 400 steps: 8.24099063873291 	 Other agent action time: 0 	 48.53785394682863 steps/s
Curr learning rate 0.000772 	 Curr reward per step 0.225

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.59it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.95it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 178.16it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.78it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 163.97it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.82it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.15it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 174.75it/s]
---------------------------------------
| approxkl           | 0.0041967896   |
| clipfrac           | 0.25606254     |
| eplenmean          | 400            |
| eprewmean          | 91             |
| explained_variance | 0.627          |
| fps                | 1339           |
| nupdates           | 729            |
| policy_entropy     | 0.55207276     |
| policy_loss        | -0.00028852883 |
| serial_timesteps   | 291600         |
| time_elapsed       | 7.03e+03       |
| time_remaining     | 3.37           |
| total_timesteps    | 8748000        |
| true_eprew         | 91             |
| value_loss         | 15.137773      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.703217029571533 seconds
Total simulation time for 400 steps: 8.020568370819092 	 Other agent action time: 0 	 49.87177734876044 steps/s
Curr learning rate 0.000771 	 Curr reward per step 0.245

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.62it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 164.40it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 171.95it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.07it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.91it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 181.11it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 181.35it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.44it/s]
--------------------------------------
| approxkl           | 0.003827325   |
| clipfrac           | 0.22267713    |
| eplenmean          | 400           |
| eprewmean          | 92            |
| explained_variance | 0.607         |
| fps                | 1374          |
| nupdates           | 730           |
| policy_entropy     | 0.51158965    |
| policy_loss        | -0.0006955795 |
| serial_timesteps   | 292000        |
| time_elapsed       | 7.03e+03      |
| time_remaining     | 3.21          |
| total_timesteps    | 8760000       |
| true_eprew         | 92            |
| value_loss         | 17.975378     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.852262496948242 seconds
Total simulation time for 400 steps: 8.129154443740845 	 Other agent action time: 0 	 49.205609607772374 steps/s
Curr learning rate 0.00077 	 Curr reward per step 0.24

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 161.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.46it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 186.51it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 174.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 173.72it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 189.38it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 188.45it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 176.81it/s]
---------------------------------------
| approxkl           | 0.0035242536   |
| clipfrac           | 0.23143752     |
| eplenmean          | 400            |
| eprewmean          | 94.2           |
| explained_variance | 0.63           |
| fps                | 1357           |
| nupdates           | 731            |
| policy_entropy     | 0.52506506     |
| policy_loss        | -0.00022246814 |
| serial_timesteps   | 292400         |
| time_elapsed       | 7.04e+03       |
| time_remaining     | 3.05           |
| total_timesteps    | 8772000        |
| true_eprew         | 94.2           |
| value_loss         | 16.271837      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.852319717407227 seconds
Total simulation time for 400 steps: 8.304091691970825 	 Other agent action time: 0 	 48.16902496232761 steps/s
Curr learning rate 0.000769 	 Curr reward per step 0.2333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.83it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 162.64it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 176.52it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.37it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 186.97it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 184.39it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 173.61it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 181.18it/s]
-------------------------------------
| approxkl           | 0.003722176  |
| clipfrac           | 0.23521875   |
| eplenmean          | 400          |
| eprewmean          | 96.6         |
| explained_variance | 0.535        |
| fps                | 1331         |
| nupdates           | 732          |
| policy_entropy     | 0.553906     |
| policy_loss        | 8.359602e-05 |
| serial_timesteps   | 292800       |
| time_elapsed       | 7.05e+03     |
| time_remaining     | 2.89         |
| total_timesteps    | 8784000      |
| true_eprew         | 96.6         |
| value_loss         | 19.213858    |
-------------------------------------
Current reward shaping 0
BEST REW 96.6 overwriting previous model with 94.2
Deleting old dir data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/best/saved_model.pb
SP envs: 0/30
Other agent actions took 4.862734794616699 seconds
Total simulation time for 400 steps: 8.194336891174316 	 Other agent action time: 0 	 48.814200015478825 steps/s
Curr learning rate 0.000768 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 167.55it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 165.69it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 162.48it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 179.41it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 185.10it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.70it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.71it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.52it/s]
--------------------------------------
| approxkl           | 0.0039267903  |
| clipfrac           | 0.24253125    |
| eplenmean          | 400           |
| eprewmean          | 92.6          |
| explained_variance | 0.611         |
| fps                | 1346          |
| nupdates           | 733           |
| policy_entropy     | 0.55833626    |
| policy_loss        | -0.0010438841 |
| serial_timesteps   | 293200        |
| time_elapsed       | 7.07e+03      |
| time_remaining     | 2.73          |
| total_timesteps    | 8796000       |
| true_eprew         | 92.6          |
| value_loss         | 18.130232     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.796933889389038 seconds
Total simulation time for 400 steps: 8.117085218429565 	 Other agent action time: 0 	 49.27877301224011 steps/s
Curr learning rate 0.000767 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.78it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 146.54it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 146.10it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 158.36it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 169.38it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 161.18it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 161.73it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 160.66it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 160.93it/s]
--------------------------------------
| approxkl           | 0.0041197785  |
| clipfrac           | 0.22580211    |
| eplenmean          | 400           |
| eprewmean          | 88.8          |
| explained_variance | 0.545         |
| fps                | 1348          |
| nupdates           | 734           |
| policy_entropy     | 0.520341      |
| policy_loss        | 0.00018166871 |
| serial_timesteps   | 293600        |
| time_elapsed       | 7.07e+03      |
| time_remaining     | 2.57          |
| total_timesteps    | 8808000       |
| true_eprew         | 88.8          |
| value_loss         | 20.144718     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.908780813217163 seconds
Total simulation time for 400 steps: 8.283079147338867 	 Other agent action time: 0 	 48.291220316119926 steps/s
Curr learning rate 0.000766 	 Curr reward per step 0.22666666666666668

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 159.29it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 165.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 182.07it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.15it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.84it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.06it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.44it/s]
-------------------------------------
| approxkl           | 0.0037999286 |
| clipfrac           | 0.23747918   |
| eplenmean          | 400          |
| eprewmean          | 88           |
| explained_variance | 0.593        |
| fps                | 1332         |
| nupdates           | 735          |
| policy_entropy     | 0.5455845    |
| policy_loss        | 0.0008603821 |
| serial_timesteps   | 294000       |
| time_elapsed       | 7.08e+03     |
| time_remaining     | 2.41         |
| total_timesteps    | 8820000      |
| true_eprew         | 88           |
| value_loss         | 19.197285    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.836208343505859 seconds
Total simulation time for 400 steps: 8.1461021900177 	 Other agent action time: 0 	 49.10323866181832 steps/s
Curr learning rate 0.0007650000000000001 	 Curr reward per step 0.2316666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 169.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 176.21it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 187.88it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.98it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.67it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.54it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 196.85it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 192.89it/s]
--------------------------------------
| approxkl           | 0.0040096855  |
| clipfrac           | 0.24040629    |
| eplenmean          | 400           |
| eprewmean          | 90.4          |
| explained_variance | 0.608         |
| fps                | 1362          |
| nupdates           | 736           |
| policy_entropy     | 0.53261733    |
| policy_loss        | 0.00050991075 |
| serial_timesteps   | 294400        |
| time_elapsed       | 7.09e+03      |
| time_remaining     | 2.25          |
| total_timesteps    | 8832000       |
| true_eprew         | 90.4          |
| value_loss         | 18.405476     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.7804906368255615 seconds
Total simulation time for 400 steps: 8.032647609710693 	 Other agent action time: 0 	 49.79678176301905 steps/s
Curr learning rate 0.000764 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 171.82it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 187.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 197.30it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 200.54it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 201.50it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 203.02it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 194.99it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 193.21it/s]
-------------------------------------
| approxkl           | 0.005511501  |
| clipfrac           | 0.2650521    |
| eplenmean          | 400          |
| eprewmean          | 90.2         |
| explained_variance | 0.617        |
| fps                | 1382         |
| nupdates           | 737          |
| policy_entropy     | 0.5414869    |
| policy_loss        | 0.0015822058 |
| serial_timesteps   | 294800       |
| time_elapsed       | 7.1e+03      |
| time_remaining     | 2.09         |
| total_timesteps    | 8844000      |
| true_eprew         | 90.2         |
| value_loss         | 17.439556    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.729322195053101 seconds
Total simulation time for 400 steps: 8.03431510925293 	 Other agent action time: 0 	 49.786446580783156 steps/s
Curr learning rate 0.000763 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.73it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 169.08it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.45it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 181.68it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.65it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 177.32it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 182.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.20it/s]
-------------------------------------
| approxkl           | 0.004638272  |
| clipfrac           | 0.26992708   |
| eplenmean          | 400          |
| eprewmean          | 91           |
| explained_variance | 0.612        |
| fps                | 1369         |
| nupdates           | 738          |
| policy_entropy     | 0.5684475    |
| policy_loss        | 0.0008186318 |
| serial_timesteps   | 295200       |
| time_elapsed       | 7.11e+03     |
| time_remaining     | 1.93         |
| total_timesteps    | 8856000      |
| true_eprew         | 91           |
| value_loss         | 17.75827     |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8666832447052 seconds
Total simulation time for 400 steps: 8.236282110214233 	 Other agent action time: 0 	 48.565602130594776 steps/s
Curr learning rate 0.000762 	 Curr reward per step 0.24166666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 164.34it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 179.63it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 193.85it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 193.65it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 197.69it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 196.56it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 195.55it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.18it/s]
--------------------------------------
| approxkl           | 0.002859451   |
| clipfrac           | 0.2089688     |
| eplenmean          | 400           |
| eprewmean          | 92            |
| explained_variance | 0.648         |
| fps                | 1348          |
| nupdates           | 739           |
| policy_entropy     | 0.5400791     |
| policy_loss        | -0.0013272315 |
| serial_timesteps   | 295600        |
| time_elapsed       | 7.12e+03      |
| time_remaining     | 1.77          |
| total_timesteps    | 8868000       |
| true_eprew         | 92            |
| value_loss         | 15.486644     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.825459718704224 seconds
Total simulation time for 400 steps: 7.965244293212891 	 Other agent action time: 0 	 50.21817100334716 steps/s
Curr learning rate 0.0007610000000000001 	 Curr reward per step 0.22333333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 162.23it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 171.92it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 183.03it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 180.16it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 187.58it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 178.51it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.84it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 185.59it/s]
--------------------------------------
| approxkl           | 0.003988845   |
| clipfrac           | 0.2406875     |
| eplenmean          | 400           |
| eprewmean          | 90.4          |
| explained_variance | 0.583         |
| fps                | 1383          |
| nupdates           | 740           |
| policy_entropy     | 0.5553608     |
| policy_loss        | -0.0001525458 |
| serial_timesteps   | 296000        |
| time_elapsed       | 7.13e+03      |
| time_remaining     | 1.61          |
| total_timesteps    | 8880000       |
| true_eprew         | 90.4          |
| value_loss         | 18.096064     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.762662649154663 seconds
Total simulation time for 400 steps: 8.117897272109985 	 Other agent action time: 0 	 49.273843532640925 steps/s
Curr learning rate 0.00076 	 Curr reward per step 0.2366666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 175.90it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 184.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 189.46it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 177.54it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 199.40it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 193.19it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 196.28it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 195.21it/s]
---------------------------------------
| approxkl           | 0.0030279697   |
| clipfrac           | 0.20767708     |
| eplenmean          | 400            |
| eprewmean          | 92.8           |
| explained_variance | 0.595          |
| fps                | 1366           |
| nupdates           | 741            |
| policy_entropy     | 0.5093283      |
| policy_loss        | -0.00044575552 |
| serial_timesteps   | 296400         |
| time_elapsed       | 7.14e+03       |
| time_remaining     | 1.44           |
| total_timesteps    | 8892000        |
| true_eprew         | 92.8           |
| value_loss         | 17.544065      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.8894736766815186 seconds
Total simulation time for 400 steps: 8.183716297149658 	 Other agent action time: 0 	 48.8775496945462 steps/s
Curr learning rate 0.000759 	 Curr reward per step 0.20666666666666667

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 163.30it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 168.12it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 170.55it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.01it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 164.79it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.24it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 180.80it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 172.19it/s]
--------------------------------------
| approxkl           | 0.0038507725  |
| clipfrac           | 0.23919788    |
| eplenmean          | 400           |
| eprewmean          | 90            |
| explained_variance | 0.575         |
| fps                | 1345          |
| nupdates           | 742           |
| policy_entropy     | 0.56928927    |
| policy_loss        | 0.00010797487 |
| serial_timesteps   | 296800        |
| time_elapsed       | 7.14e+03      |
| time_remaining     | 1.28          |
| total_timesteps    | 8904000       |
| true_eprew         | 90            |
| value_loss         | 18.073544     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.915504455566406 seconds
Total simulation time for 400 steps: 8.296211242675781 	 Other agent action time: 0 	 48.214780012157426 steps/s
Curr learning rate 0.0007580000000000001 	 Curr reward per step 0.24

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.50it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 166.94it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 164.95it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 170.87it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 180.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 179.03it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 178.73it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 177.13it/s]
--------------------------------------
| approxkl           | 0.0031935351  |
| clipfrac           | 0.20658332    |
| eplenmean          | 400           |
| eprewmean          | 90.4          |
| explained_variance | 0.541         |
| fps                | 1331          |
| nupdates           | 743           |
| policy_entropy     | 0.5039905     |
| policy_loss        | 8.3776955e-05 |
| serial_timesteps   | 297200        |
| time_elapsed       | 7.15e+03      |
| time_remaining     | 1.12          |
| total_timesteps    | 8916000       |
| true_eprew         | 90.4          |
| value_loss         | 19.24113      |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.767624855041504 seconds
Total simulation time for 400 steps: 8.066318988800049 	 Other agent action time: 0 	 49.58891416957269 steps/s
Curr learning rate 0.000757 	 Curr reward per step 0.21333333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 159.15it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 160.26it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.08it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 166.95it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.95it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.27it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 174.09it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.99it/s]
--------------------------------------
| approxkl           | 0.002170542   |
| clipfrac           | 0.17863542    |
| eplenmean          | 400           |
| eprewmean          | 88.2          |
| explained_variance | 0.536         |
| fps                | 1362          |
| nupdates           | 744           |
| policy_entropy     | 0.51916283    |
| policy_loss        | -0.0011544129 |
| serial_timesteps   | 297600        |
| time_elapsed       | 7.16e+03      |
| time_remaining     | 0.963         |
| total_timesteps    | 8928000       |
| true_eprew         | 88.2          |
| value_loss         | 20.708666     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.811673879623413 seconds
Total simulation time for 400 steps: 8.182190895080566 	 Other agent action time: 0 	 48.88666191355847 steps/s
Curr learning rate 0.000756 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 149.87it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 149.40it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 158.73it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 173.81it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 173.99it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 181.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 180.20it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 177.08it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 168.48it/s]
--------------------------------------
| approxkl           | 0.0044428185  |
| clipfrac           | 0.24256243    |
| eplenmean          | 400           |
| eprewmean          | 91            |
| explained_variance | 0.564         |
| fps                | 1344          |
| nupdates           | 745           |
| policy_entropy     | 0.53391826    |
| policy_loss        | -9.247017e-05 |
| serial_timesteps   | 298000        |
| time_elapsed       | 7.17e+03      |
| time_remaining     | 0.802         |
| total_timesteps    | 8940000       |
| true_eprew         | 91            |
| value_loss         | 17.8664       |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.824797868728638 seconds
Total simulation time for 400 steps: 8.117252111434937 	 Other agent action time: 0 	 49.27775982669208 steps/s
Curr learning rate 0.000755 	 Curr reward per step 0.23

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 154.78it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 154.15it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 166.58it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.95it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.20it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 173.67it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.92it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 171.09it/s]
---------------------------------------
| approxkl           | 0.003522705    |
| clipfrac           | 0.2206771      |
| eplenmean          | 400            |
| eprewmean          | 90.6           |
| explained_variance | 0.591          |
| fps                | 1353           |
| nupdates           | 746            |
| policy_entropy     | 0.5333517      |
| policy_loss        | -0.00013987046 |
| serial_timesteps   | 298400         |
| time_elapsed       | 7.18e+03       |
| time_remaining     | 0.642          |
| total_timesteps    | 8952000        |
| true_eprew         | 90.6           |
| value_loss         | 18.915888      |
---------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.739740610122681 seconds
Total simulation time for 400 steps: 8.027204275131226 	 Other agent action time: 0 	 49.83054950267364 steps/s
Curr learning rate 0.000754 	 Curr reward per step 0.215

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 166.28it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 167.36it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 157.04it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 171.57it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 170.71it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 171.28it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 172.25it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.16it/s]
--------------------------------------
| approxkl           | 0.004091543   |
| clipfrac           | 0.24421868    |
| eplenmean          | 400           |
| eprewmean          | 89.2          |
| explained_variance | 0.589         |
| fps                | 1368          |
| nupdates           | 747           |
| policy_entropy     | 0.5360478     |
| policy_loss        | -4.143046e-05 |
| serial_timesteps   | 298800        |
| time_elapsed       | 7.19e+03      |
| time_remaining     | 0.481         |
| total_timesteps    | 8964000       |
| true_eprew         | 89.2          |
| value_loss         | 17.703966     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.861318826675415 seconds
Total simulation time for 400 steps: 8.198494911193848 	 Other agent action time: 0 	 48.789442981035265 steps/s
Curr learning rate 0.000753 	 Curr reward per step 0.22833333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 170.14it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 177.35it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 203.65it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 199.47it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 175.73it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 172.94it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 168.05it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 175.58it/s]
-------------------------------------
| approxkl           | 0.0039854036 |
| clipfrac           | 0.22820832   |
| eplenmean          | 400          |
| eprewmean          | 89.8         |
| explained_variance | 0.671        |
| fps                | 1349         |
| nupdates           | 748          |
| policy_entropy     | 0.51831466   |
| policy_loss        | 0.0009044208 |
| serial_timesteps   | 299200       |
| time_elapsed       | 7.2e+03      |
| time_remaining     | 0.321        |
| total_timesteps    | 8976000      |
| true_eprew         | 89.8         |
| value_loss         | 15.468626    |
-------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.939167499542236 seconds
Total simulation time for 400 steps: 8.39114236831665 	 Other agent action time: 0 	 47.669313955430376 steps/s
Curr learning rate 0.0007520000000000001 	 Curr reward per step 0.21833333333333332

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 157.53it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 155.04it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 148.13it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 147.72it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.50it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 162.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 175.96it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 179.38it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 173.73it/s]
--------------------------------------
| approxkl           | 0.004087762   |
| clipfrac           | 0.2370729     |
| eplenmean          | 400           |
| eprewmean          | 88.4          |
| explained_variance | 0.667         |
| fps                | 1312          |
| nupdates           | 749           |
| policy_entropy     | 0.5289074     |
| policy_loss        | 0.00019424382 |
| serial_timesteps   | 299600        |
| time_elapsed       | 7.21e+03      |
| time_remaining     | 0.16          |
| total_timesteps    | 8988000       |
| true_eprew         | 88.4          |
| value_loss         | 15.660558     |
--------------------------------------
Current reward shaping 0
SP envs: 0/30
Other agent actions took 4.803655385971069 seconds
Total simulation time for 400 steps: 8.066347599029541 	 Other agent action time: 0 	 49.58873828448998 steps/s
Curr learning rate 0.000751 	 Curr reward per step 0.2033333333333333

0/8:   0%|          | 0/15 [00:00<?, ?it/s]
0/8: 100%|██████████| 15/15 [00:00<00:00, 160.86it/s]

1/8:   0%|          | 0/15 [00:00<?, ?it/s]
1/8: 100%|██████████| 15/15 [00:00<00:00, 175.74it/s]

2/8:   0%|          | 0/15 [00:00<?, ?it/s]
2/8: 100%|██████████| 15/15 [00:00<00:00, 168.41it/s]

3/8:   0%|          | 0/15 [00:00<?, ?it/s]
3/8: 100%|██████████| 15/15 [00:00<00:00, 172.69it/s]

4/8:   0%|          | 0/15 [00:00<?, ?it/s]
4/8: 100%|██████████| 15/15 [00:00<00:00, 171.77it/s]

5/8:   0%|          | 0/15 [00:00<?, ?it/s]
5/8: 100%|██████████| 15/15 [00:00<00:00, 174.15it/s]

6/8:   0%|          | 0/15 [00:00<?, ?it/s]
6/8: 100%|██████████| 15/15 [00:00<00:00, 176.61it/s]

7/8:   0%|          | 0/15 [00:00<?, ?it/s]
7/8: 100%|██████████| 15/15 [00:00<00:00, 178.87it/s]
-------------------------------------
| approxkl           | 0.005397672  |
| clipfrac           | 0.2657812    |
| eplenmean          | 400          |
| eprewmean          | 86.4         |
| explained_variance | 0.544        |
| fps                | 1365         |
| nupdates           | 750          |
| policy_entropy     | 0.5370731    |
| policy_loss        | 0.0015078962 |
| serial_timesteps   | 300000       |
| time_elapsed       | 7.22e+03     |
| time_remaining     | 0            |
| total_timesteps    | 9000000      |
| true_eprew         | 86.4         |
| value_loss         | 19.782585    |
-------------------------------------
Current reward shaping 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
PPO agent on index 0:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←1X   X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 10
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →oX   X 
D   X   X 
X X X S X 


Timestep: 11
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O →1Xo  X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X ←0P 
O   Xo  X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   Xo↓0X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   Xo←0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O ↑1X   P 
O   X ←oX 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('↑', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑oP 
O ↓1X   X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 18
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 19
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ↓1X   X 
X X X S X 


Timestep: 20
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 21
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 22
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←1X   X 
X X X S X 


Timestep: 23
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø-X 
O   X ↑0P 
O   X   X 
D ←dX   X 
X X X S X 


Timestep: 24
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ↑0P 
O ↑dX   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑dX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑dX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑dX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑dX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑dX ←0P 
O   X   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O ↓dX   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ↓dX   X 
X X X S X 


Timestep: 32
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ↓dX   X 
X X X S X 


Timestep: 33
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ↓dX   X 
X X X S X 


Timestep: 34
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ↓dX   X 
X X X S X 


Timestep: 35
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X XdX S X 


Timestep: 36
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X ←0P 
O   X   X 
D ↓1X   X 
X XdX S X 


Timestep: 37
Joint action taken: ('→', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X →0P 
O   X   X 
D ←1X   X 
X XdX S X 


Timestep: 38
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O   X →0P 
O ↑1X   X 
D   X   X 
X XdX S X 


Timestep: 39
Joint action taken: ('interact', '↑') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑1X →0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 40
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑1X →0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 41
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ↑1X →0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 42
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X →0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 43
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX →0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 44
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →oX →0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 45
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo→0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 46
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø-X 
O →1Xo←0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 47
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←1X ←oP 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 48
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø-X 
O ←oX ↑oP 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 49
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 3 
X X X ø=X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 50
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 51
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →oX ↑0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 52
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo↑0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 53
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1Xo←0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 54
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø=X 
O →1X ←oP 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 55
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X ø=X 
O ←1X ↑oP 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 56
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø1X 
O ←oX ↑0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 57
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø2X 
O →oX ↑0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 58
Joint action taken: ('←', '←') 	 Reward: 0 + shape * 0 
X X X ø3X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 59
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø4X 
O ←oX ←0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 60
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø5X 
O →oX ←0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 61
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø6X 
O →1Xo←0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 62
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø7X 
O ←1X ←oP 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 63
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø8X 
O ←1Xo←0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 64
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø9X 
O ←1X ←oP 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 65
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø10X 
O ←1Xo←0P 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 66
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø11X 
O ←oX ←oP 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 67
Joint action taken: ('→', '→') 	 Reward: 0 + shape * 0 
X X X ø12X 
O →oX →oP 
O   X   X 
D   X   X 
X XdX S X 


Timestep: 68
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 3 
X X X ø13X 
O →1Xo→0ø-
O   X   X 
D   X   X 
X XdX S X 


Timestep: 69
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø14X 
O →1Xo  ø-
O   X ↓0X 
D   X   X 
X XdX S X 


Timestep: 70
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X ø15X 
O →1Xo  ø-
O   X ↓0X 
D   X   X 
X XdX S X 


Timestep: 71
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X ø16X 
O ←1Xo  ø-
O   X ↓0X 
D   X   X 
X XdX S X 


Timestep: 72
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø17X 
O ←1Xo  ø-
O   X ←0X 
D   X   X 
X XdX S X 


Timestep: 73
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø18X 
O ←oXo  ø-
O   X ←0X 
D   X   X 
X XdX S X 


Timestep: 74
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø19X 
O →oXo  ø-
O   X ←0X 
D   X   X 
X XdX S X 


Timestep: 75
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oXo  ø-
O   X   X 
D   X ↓0X 
X XdX S X 


Timestep: 76
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oXo  ø-
O   X ↑0X 
D   X   X 
X XdX S X 


Timestep: 77
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →oXo  ø-
O   X ↑0X 
D   X   X 
X XdX S X 


Timestep: 78
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓oX →0X 
D   X   X 
X XdX S X 


Timestep: 79
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓oX   X 
D   X ↓0X 
X XdX S X 


Timestep: 80
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓oX   X 
D   X ↓0X 
X XdX S X 


Timestep: 81
Joint action taken: ('↓', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓oX   X 
D   X ↓0X 
X XdX S X 


Timestep: 82
Joint action taken: ('↓', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O →oX   X 
D   X ↓0X 
X XdX S X 


Timestep: 83
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O →1Xo  X 
D   X ↓0X 
X XdX S X 


Timestep: 84
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   Xo  X 
D ↓1X ←0X 
X XdX S X 


Timestep: 85
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   Xo  X 
D ↓1X ←0X 
X XdX S X 


Timestep: 86
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   Xo↑0X 
D ↓1X   X 
X XdX S X 


Timestep: 87
Joint action taken: ('→', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   Xo→0X 
D ↓1X   X 
X XdX S X 


Timestep: 88
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   Xo→0X 
D ←1X   X 
X XdX S X 


Timestep: 89
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O   Xo←0X 
D ←dX   X 
X XdX S X 


Timestep: 90
Joint action taken: ('↓', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↑dXo  X 
D   X ↓0X 
X XdX S X 


Timestep: 91
Joint action taken: ('←', '↑') 	 Reward: 0 + shape * 0 
X X X ø20X 
O ↑dXo  ø-
O   Xo  X 
D   X ←0X 
X XdX S X 


Timestep: 92
Joint action taken: ('interact', '→') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dXo  ø-
O   Xo  X 
D   X ←0X 
X XdX S X 


Timestep: 93
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dXo  ø-
O   Xo  X 
D   X ←0X 
X XdX S X 


Timestep: 94
Joint action taken: ('interact', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dXo  ø-
O   Xo  X 
D   X ←0X 
X XdX S X 


Timestep: 95
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X ø20X 
O →dXo  ø-
O   Xo  X 
D   X ←0X 
X XdX S X 


Timestep: 96
Joint action taken: ('←', '↓') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓dXo  X 
D   X ←0X 
X XdX S X 


Timestep: 97
Joint action taken: ('↑', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓dXo↑0X 
D   X   X 
X XdX S X 


Timestep: 98
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓dXo←0X 
D   X   X 
X XdX S X 


Timestep: 99
Joint action taken: ('←', 'stay') 	 Reward: 0 + shape * 0 
X X X ø20X 
O   Xo  ø-
O ↓dXo←0X 
D   X   X 
X XdX S X 


tot rew 80 tot rew shaped 74
PPO agent on index 1:
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 

Timestep: 1
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 2
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 3
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 4
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ↑1X   X 
D   X   X 
X X X S X 


Timestep: 5
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 6
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑1X ↓0X 
D   X   X 
X X X S X 


Timestep: 7
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←1X ↓0X 
D   X   X 
X X X S X 


Timestep: 8
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 9
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 10
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 11
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 12
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 13
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 14
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 15
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 16
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 17
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 18
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 19
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 20
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 21
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 22
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 23
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 24
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 25
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 26
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 27
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 28
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 29
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 30
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 31
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 32
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 33
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 34
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 35
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 36
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 37
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 38
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 39
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 40
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 41
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 42
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 43
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 44
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 45
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 46
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 47
Joint action taken: ('stay', 'stay') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 48
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 49
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 50
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 51
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 52
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 53
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↓0X 
D   X   X 
X X X S X 


Timestep: 54
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 55
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 56
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 57
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 58
Joint action taken: ('↓', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 59
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 60
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 61
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX   X 
D   X ↓0X 
X X X S X 


Timestep: 62
Joint action taken: ('↑', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 63
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 64
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 65
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 66
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 67
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 68
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 69
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 70
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 71
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 72
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 73
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 74
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 75
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 76
Joint action taken: ('interact', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 77
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 78
Joint action taken: ('→', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 79
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 80
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 81
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X →0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 82
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 83
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 84
Joint action taken: ('interact', '↓') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O   X   X 
D ↓oX   X 
X X X S X 


Timestep: 85
Joint action taken: ('stay', '↑') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ←0P 
O ↑oX   X 
D   X   X 
X X X S X 


Timestep: 86
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX ↓0X 
D   X   X 
X X X S X 


Timestep: 87
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX ↓0X 
D   X   X 
X X X S X 


Timestep: 88
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX ↓0X 
D   X   X 
X X X S X 


Timestep: 89
Joint action taken: ('↓', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ↑oX   X 
D   X ↓0X 
X X X S X 


Timestep: 90
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 91
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 92
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 93
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ↑0X 
D   X   X 
X X X S X 


Timestep: 94
Joint action taken: ('←', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 95
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 96
Joint action taken: ('interact', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 97
Joint action taken: ('stay', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X   P 
O ←oX ←0X 
D   X   X 
X X X S X 


Timestep: 98
Joint action taken: ('↑', '←') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


Timestep: 99
Joint action taken: ('stay', 'interact') 	 Reward: 0 + shape * 0 
X X X P X 
O   X ↑0P 
O ←oX   X 
D   X   X 
X X X S X 


tot rew 0 tot rew shaped 0
data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/
INFO:tensorflow:Assets added to graph.
INFO - tensorflow - Assets added to graph.
INFO:tensorflow:No assets to write.
INFO - tensorflow - No assets to write.
INFO:tensorflow:SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/ppo_agent/saved_model.pb
INFO - tensorflow - SavedModel written to: data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/ppo_agent/saved_model.pb
Saved training info at data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/seed9456/training_info
Creating env with params {'RUN_TYPE': 'ppo', 'SEEDS': [9456, 1887, 5578, 5987, 516], 'LOCAL_TESTING': False, 'EX_NAME': 'dispenser_side_specific_ppo_bc_train_random0_test2', 'SAVE_DIR': 'data/ppo_runs/2021_08_16-19_09_59_dispenser_side_specific_ppo_bc_train_random0_test2/', 'GPU_ID': 0, 'PPO_RUN_TOT_TIMESTEPS': 9000000.0, 'mdp_params': {'layout_name': 'random0', 'start_order_list': None, 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}}, 'env_params': {'horizon': 400}, 'mdp_generation_params': {'padded_mdp_shape': [11, 7], 'mdp_shape_fn': [[5, 11], [5, 7]], 'prop_empty_fn': [0.6, 1], 'prop_feats_fn': [0, 0.6]}, 'ENTROPY': 0.1, 'GAMMA': 0.99, 'sim_threads': 30, 'TOTAL_BATCH_SIZE': 12000, 'BATCH_SIZE': 400, 'MAX_GRAD_NORM': 0.1, 'LR': 0.0015, 'LR_ANNEALING': 2, 'VF_COEF': 0.1, 'STEPS_PER_UPDATE': 8, 'MINIBATCHES': 15, 'CLIPPING': 0.05, 'LAM': 0.98, 'SELF_PLAY_HORIZON': None, 'REW_SHAPING_HORIZON': 4000000.0, 'OTHER_AGENT_TYPE': 'bc_train', 'HM_PARAMS': [True, 0.3], 'NUM_HIDDEN_LAYERS': 3, 'SIZE_HIDDEN_LAYERS': 64, 'NUM_FILTERS': 25, 'NUM_CONV_LAYERS': 3, 'NETWORK_TYPE': 'conv_and_mlp', 'SAVE_BEST_THRESH': 50, 'TRAJECTORY_SELF_PLAY': True, 'VIZ_FREQUENCY': 50, 'grad_updates_per_agent': 90000.0, 'CURR_SEED': 9456}
Computing MediumLevelPlanner to be saved in /home/mzhao2/overcooked-teaming/overcooked_ai/overcooked_ai_py/data/planners/random0_am.pkl
It took 0.033049583435058594 seconds to create mlp
