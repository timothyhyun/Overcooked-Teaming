{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel():\n",
    "    def __init__(self, A, O):\n",
    "        '''Initialize an HMM. Assumes the following:\n",
    "        - States and observations are integers starting from 0.\n",
    "        - There is a start state. There is no integer associated with the \n",
    "        start state, only probabilities in the vector A_start.\n",
    "        - There is no end state.\n",
    "        \n",
    "        Arguments:\n",
    "        A: Transition matrix with dimensions (L x L) where L is the\n",
    "        number of states. The (i,j)th element is the probability of \n",
    "        transitioning from state i to state j. Note that this does not \n",
    "        include the starting probabilities.\n",
    "        O: Observation matrix with dimensions (L x D) where D is the \n",
    "        number of observation types. The (i, j)th element is the probability\n",
    "        of emitting observation j given state i.\n",
    "        \n",
    "        Parameters: \n",
    "        L: Number of states\n",
    "        D: Number of observations\n",
    "        A: State transition matrix\n",
    "        O: Observation emission matrix\n",
    "        A_start: Starting transition probabilities. The ith element is the\n",
    "        probability of transitioning from the start state to state i. For\n",
    "        simplicity, we assume that this distribution is uniform.\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        self.L = len(A)\n",
    "        self.D = len(O[0])\n",
    "        self.A = A\n",
    "        self.O = O\n",
    "        self.A_start = [1./self.L for _ in range(self.L)]\n",
    "        \n",
    "    def viterbi(self, x):\n",
    "        '''\n",
    "        Use the Viterbi algorithm to find the maximum probability\n",
    "        state sequence corresponding to a given input sequence.\n",
    "        \n",
    "        Arguments:\n",
    "        x: Input sequence of observerations in the form of a list of length M, \n",
    "        consisting of integers ranging from 0 to D-1.\n",
    "        \n",
    "        Returns: \n",
    "        max_seq: State sequence corresponding to x with the highest\n",
    "        probability.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        M = len(x) # length of observation sequence\n",
    "        # The (i,j)th elements of probs and seqs are the max probability\n",
    "        # of the prefix of length i ending in state j and the prefix that\n",
    "        # gives this probability, respectively.\n",
    "        \n",
    "        # For instance, probs[1][0] is the probability of the prefix of length 1\n",
    "        # ending in state 0.\n",
    "        probs = [[0. for _ in range(self.L)] for _ in range(M+1)]\n",
    "        seq = [['' for _ in range(self.L)] for _ in range(M+1)]\n",
    "        \n",
    "        num_states = self.L\n",
    "        num_obs = self.D\n",
    "        \n",
    "        # y = OBSERVATIONS (D) BY x = STATES (L)\n",
    "        \n",
    "        # Set start state transitions to be A_start.\n",
    "        probs[0] = self.A_start\n",
    "        for t in range(1, M+1):\n",
    "            for o_curr in range(num_states):\n",
    "                # For first state after the start state, only multiply\n",
    "                # the probability by emission probability.\n",
    "                if t == 1:\n",
    "                    checkVal = np.array(probs[t-1]) * self.O[o_curr][x[t-1]]\n",
    "                    # Set the maximum probability to be the value at the next\n",
    "                    # probs[i,j] and add the max probability sequence to seqs.\n",
    "                    probs[t][o_curr] = max(checkVal)\n",
    "                    add = []\n",
    "                    for j in range(num_states):\n",
    "                        add.append(str(j))\n",
    "                    seqs[t] = add\n",
    "                else:\n",
    "                    # For other states, multiply the previous max probability\n",
    "                    # by the emission and transition probability.\n",
    "                    checkVal = np.multiply(probs[t-1], np.transpose(self.A)[o_curr])\n",
    "                    max_index = np.argmax(checkVal)\n",
    "                    \n",
    "                    # Set the maximum probability to be the value at the next probs[i,j] and \n",
    "                    # add the max probability sequence to seqs.\n",
    "                    probs[t][o_curr] = max(checkVal)\n",
    "                    add = seqs[t-1][max_index] + str(o_curr)\n",
    "                    seqs[t][o_curr] = add\n",
    "                    \n",
    "        # Get the maximum probability and max probability sequence\n",
    "        max_prob_i = np.argmax(probs[M]) # max probability final state\n",
    "        max_seq = seqs[M][max_prob_i] # max probability seq ending at final state\n",
    "                \n",
    "        return max_seq\n",
    "                    \n",
    "    \n",
    "    def forward(self, x, normalize=False):\n",
    "        '''\n",
    "        Use the forward algorithm to calculate the alpha probability vectors\n",
    "        corresponding to a given input sequence.\n",
    "        \n",
    "        Arguments:\n",
    "        x: Input sequence of observations in the form of a list of length M,\n",
    "        consisting of integers ranging from 0 to D-1.\n",
    "        normalize: Whether to normalize each set of alpha_j(i) vectors at each \n",
    "        i. This is useful to avoid underflow in unsupervised learning. \n",
    "        \n",
    "        Returns:\n",
    "        alphas: Vector of alphas. The (i,j)th element of alphas is alpha_j(i),\n",
    "        = the probability of observing (observation seq) prefix x_1:i and \n",
    "        state y_i = j.\n",
    "        e.g. alphas[1][0] corresponds to the probability of observing x_1:1, the\n",
    "        probability of observing x_1:1 (first observation) given (joint) that the \n",
    "        first state is 0. \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        M = len(x) # length of observation sequence\n",
    "        alphas = [[0. for n_states in range(self.L)] for len_obs_seq in range(M+1)]\n",
    "        num_states = self.L\n",
    "        num_obs = self.D\n",
    "        alphas[0] = self.A_start # probability of being in each state, without observations yet\n",
    "        \n",
    "        # for each timestep in observation sequence length\n",
    "        for t in range(1, M+1):\n",
    "            # for each state\n",
    "            for o_curr in range(num_states):\n",
    "                # for each state, multiply the previous max probability by the \n",
    "                # emission and transition probability, set alphas to be the sum of \n",
    "                # probabilities.\n",
    "                if t==1:\n",
    "                    checkVal = np.array(alphas[t-1]) * self.O[o_curr][x[t-1]]\n",
    "                    alphas[t][o_curr] = sum(checkVal)\n",
    "                    \n",
    "                else:\n",
    "                    checkVal = np.multiply(alphas[t-1], np.transpose(self.A)[o_curr]) * self.O[o_curr][x[t-1]]\n",
    "                    max_index = np.argmax(checkVal) # most likely state k at time t\n",
    "                    alphas[t][o_curr] = sum(checkVal)\n",
    "        \n",
    "        return alphas\n",
    "    \n",
    "    def backward(self, x, normalize=False):\n",
    "        '''\n",
    "        Use the backward algorithm to calculate the beta probability\n",
    "        vectors corresponding to a given input sequence.\n",
    "        \n",
    "        Arguments:\n",
    "        x: Input sequence in the form of a list of length M,\n",
    "        consisting of integers ranging from 0 to D-1. \n",
    "        normalize: Whether to normalize each set of alpha_j(i) \n",
    "        vectors at each i. This is useful to avoid underflow in supervised \n",
    "        learning. \n",
    "        \n",
    "        Returns:\n",
    "        betas: Vector of betas.\n",
    "        The (i,j)th element of betas is beta_j(i), ie. the probability \n",
    "        of observing obs seq prefix x_i+1:M and state y_i = j.\n",
    "        e.g. betas[M][0] corresponds to the probability of observing \n",
    "        x_M+1:M = no observations, given that y_M = state 0 (the last state\n",
    "        is 0).        \n",
    "        '''\n",
    "        \n",
    "        M = len(x) # length of obs seq\n",
    "        betas = [[0. for state_i in range(self.L)] for obs_seq_timestep in range(M+1)]\n",
    "        num_states = self.L\n",
    "        num_obs = self.D\n",
    "        \n",
    "        # initialize end probabilities to be 1.\n",
    "        for i in range(num_states):\n",
    "            betas[M][i] = 1\n",
    "            # The probability of the last timestep observation given\n",
    "            # each state is 1.\n",
    "            \n",
    "            \n",
    "        t = M-1\n",
    "        while t >= 0:\n",
    "            # For each state\n",
    "            for o_curr in range(num_states):\n",
    "                # Take the sum of the previous probability times\n",
    "                # the transition and emission probabilities.\n",
    "                checkVal = 0\n",
    "                for i in range(len(self.A)):\n",
    "                    checkVal += (betas[t+1][i] * self.A[o_curr][i] * self.O[i][x[t]])\n",
    "                betas[t][o_curr] = checkVal\n",
    "                \n",
    "            t -= 1\n",
    "            \n",
    "        return betas\n",
    "    \n",
    "    \n",
    "    \n",
    "    def supervised_learning(self, X, Y):\n",
    "        '''\n",
    "        Trains the HMM using the Maximum Likelihood closed form solutions\n",
    "        for the transition and observation matrices on a labeled dataset (X,Y).\n",
    "        Note that this method does not return anything, but instead updates the\n",
    "        attributes of the HMM object.\n",
    "        \n",
    "        Arguments:\n",
    "        X: A dataset of input observation sequences in the form of lists of variable length, \n",
    "        consisting of integers ranging from 0 to D-1. In other words a list of lists.\n",
    "        Y: A dataset of state sequences in the form of lists of variable lenght,\n",
    "        consisting of integers ranging from 0 to L-1. In other words, a list of lists.\n",
    "        Note that the elements in X line up with those in Y. \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        # Calculate each element of A using the M-step formulas.\n",
    "        \n",
    "        N = len(X)\n",
    "        for a in range(len(self.A)): # for all states i\n",
    "            for b in range(len(self.A[0])): # for all states j (transitioning from i)\n",
    "                sum2_num = 0\n",
    "                sum2_denom = 0\n",
    "                for i in range(N):\n",
    "                    sum1_num = 0\n",
    "                    sum1_denom = 0\n",
    "                    # Compute each marginal probability\n",
    "                    for j in range(1, len(Y[i])):\n",
    "                        if Y[i][j-1]==a: # If the state is a\n",
    "                            sum1_denom += 1\n",
    "                        if Y[i][j-1] == a and Y[i][j] == b: # If the state transitions from a to b\n",
    "                            sum1_num += 1\n",
    "                            \n",
    "                    sum2_num += sum1_num\n",
    "                    sum2_denom += sum1_denom\n",
    "                if sum2_denom == 0: # if the state is never a\n",
    "                    self.A[a][b] = 0  # State a never transitions to b\n",
    "                    \n",
    "                else:\n",
    "                    self.A[a][b] = sum2_num/sum2_denom\n",
    "                    \n",
    "        # Calculate each element of O using the M-step formulas\n",
    "        for w in range(len(self.O[0])): # For all observations w\n",
    "            for a in range(len(self.O)): # For all states a\n",
    "                sum2_numerator = 0\n",
    "                sum2_denom = 0\n",
    "                for i in range(0, N):\n",
    "                    sum1_numerator = 0\n",
    "                    sum1_denom = 0\n",
    "                    # Compute each marginal probability\n",
    "                    for j in range(len(Y[i])):\n",
    "                        if Y[i][j] == a: # If state is a\n",
    "                            sum1_denom += 1\n",
    "                            if X[i][j] == w:\n",
    "                                sum1_numerator += 1\n",
    "                    sum2_numerator += sum1_numerator\n",
    "                    sum2_denom += sum1_denom\n",
    "                if sum2_denom == 0: #Never in state a\n",
    "                    self.O[a][w] = 0\n",
    "                else:\n",
    "                    self.O[a][w] = sum2_numerator/sum2_denom\n",
    "                \n",
    "    # Compute the marginal probabilities for the numerator of O,\n",
    "    # and denominators of O and A.\n",
    "    def P_with_1Y(self, j, a, b, alphas, betas):\n",
    "        numerator = alphas[j][a] * betas[j][a]\n",
    "        summation = 0\n",
    "        for p in range(self.L):\n",
    "            summation += alphas[j][p] * betas[j][p]\n",
    "        if summation == 0:\n",
    "            return 0 \n",
    "        return numerator/summation\n",
    "    \n",
    "    # Compute the marginal probability for the numerator of A\n",
    "    def P_with_2Y(self, x, j, a, b, alphas, betas):\n",
    "        intermediate = 0\n",
    "        for x_idx in range(len(x)):\n",
    "            intermediate += self.O[b][x[x_idx]]\n",
    "            \n",
    "        numerator = alphas[j][a] * self.O[b][x[j]] * self.A[a][b] * betas[j+1][b]\n",
    "        \n",
    "        summation = 0\n",
    "        for a_idx in range(self.L):\n",
    "            for b_idx in range(self.L):\n",
    "                summation += alphas[j][a_idx] * self.O[b_idx][x[j]] * self.A[a_idx][b_idx] * betas[j+1][b_idx]\n",
    "                \n",
    "        if summation == 0:\n",
    "            return 0\n",
    "        return numerator/summation\n",
    "                \n",
    "    def unsupervised_learning(self, X, N_iters=1000):\n",
    "        '''\n",
    "        Trains the HMM using the Baum-Welch algorithm on an unlabeled \n",
    "        dataset of observations, X. This method does not return anything, but\n",
    "        instead updates the attributes of the HMM object.\n",
    "        \n",
    "        Arguments:\n",
    "        X: A dataset consisting of input sequences (observations) in the \n",
    "        form of lists of length M, consisting of integers ranging from 0 \n",
    "        to D-1. In other words, a list of lists.\n",
    "        N_iters: The number of iterations of EM to train on.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # N = len(X)\n",
    "        for n_iter in range(N_iters):\n",
    "            # Make temporary arrays to hold A and O values\n",
    "            A_num = np.zeros((len(self.A), len(self.A[0])))\n",
    "            A_den = np.zeros((len(self.A), len(self.A[0])))\n",
    "            O_num = np.zeros((len(self.O), len(self.O[0])))\n",
    "            O_den = np.zeros((len(self.O), len(self.O[0])))\n",
    "                \n",
    "            for x in X:\n",
    "                # Compute alphas and betas. \n",
    "                alphas = self.forward(x)\n",
    "                betas = self.backward(x)\n",
    "                \n",
    "                M = len(x) # length of obs sequence (N timesteps)\n",
    "\n",
    "                # Compute A denominator values first\n",
    "                for j in range(1, M+1):\n",
    "                    for a in range(len(self.A)): # for state a\n",
    "                        for b in range(len(self.A[0])): # for transitioning to state b\n",
    "                            A_den[a][b] += self.P_with_1Y(j, a, b, alphas, betas)\n",
    "\n",
    "                # Compute O numerator and denominator values next.\n",
    "                for j in range(1, M): # for obs timestep j\n",
    "                    for w in range(len(self.O[0])): # for obs type w\n",
    "                        for a in range(len(self.O)): # for state a\n",
    "                            O_den[a][w] += self.P_with_1Y(j, a, b, alphas, betas)\n",
    "                            if x[j-1] == w:\n",
    "                                O_num[a][w] += self.P_with_1Y(j, a, b, alphas, betas)\n",
    "\n",
    "                # Compute A numerator values next\n",
    "                for j in range(1, M-1):\n",
    "                    for a in range(len(self.A)): # for state a \n",
    "                        for b in range(len(self.A[0])): # for transitioning to state b\n",
    "                            A_num[a][b] += self.P_with_2Y(x, j, a, b, alphas, betas)\n",
    "\n",
    "            # Set new A and O matrix values by dividing numerator over denominator\n",
    "            for a in range(len(self.A)):\n",
    "                for b in range(len(self.A[0])):\n",
    "                    if A_den[a][b] == 0:\n",
    "                        self.A[a][b] = 0\n",
    "                    else:\n",
    "                        self.A[a][b] = A_num[a][b]/A_den[a][b]\n",
    "\n",
    "            for w in range(len(self.O[0])):\n",
    "                for a in range(len(self.O)):\n",
    "                    if O_den[a][w] == 0:\n",
    "                        self.O[a][w] = 0\n",
    "                    else:\n",
    "                        self.O[a][w] = O_num[a][w]/O_den[a][w]\n",
    "\n",
    "                        \n",
    "                        \n",
    "    def generate_emission(self, M):\n",
    "        '''\n",
    "        Generates an emission of length M, assuming that the starting\n",
    "        state is chosen uniformly at random.\n",
    "        \n",
    "        Arguments:\n",
    "        M: length of emission to generate\n",
    "        \n",
    "        Returns:\n",
    "        emission: Randomly generated emission (observations) as a list\n",
    "        states: randomly generates hidden states as a list\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        emission = []\n",
    "        states = []\n",
    "        # randomly select a start state.\n",
    "        current_state = np.random.randint(len(self.A))\n",
    "        \n",
    "        # for an emission of length M\n",
    "        for m in range(M):\n",
    "            current_A = self.A[current_state]\n",
    "            rand_prob_A = np.random.uniform(0,1)\n",
    "            \n",
    "            next_state = 0\n",
    "            # Find next state by randomly picking a probability\n",
    "            # between 0 and 1. If this probability falls in the\n",
    "            # range for a particular state, assign that state\n",
    "            # to be the next state. \n",
    "            for a1 in range(len(current_A)): # for all next states\n",
    "                sum_A = 0\n",
    "                for a2 in range(a1):\n",
    "                    sum_A += current_A[a2] # sum up the probabilities\n",
    "                if sum_A > rand_prob_A:\n",
    "                    break\n",
    "                next_state = a1\n",
    "            current_state = next_state\n",
    "            \n",
    "            # Find the next observation emission by randomly picking a\n",
    "            # probability between 0 and 1. If this probability falls in the\n",
    "            # range for a particular emission for the current state, \n",
    "            # assign that emission to be the emission.\n",
    "            next_emission = 0\n",
    "            current_O = self.O[current_state]\n",
    "            rand_prob_O = np.random.uniform(0,1)\n",
    "            for o1 in range(len(current_O)):\n",
    "                sum_O = 0\n",
    "                for o2 in range(o1):\n",
    "                    sum_O += current_O[o2]\n",
    "                if sum_O > rand_prob_O:\n",
    "                    break\n",
    "                next_emission = o1\n",
    "                \n",
    "            # Add the new state and new emission to the lists.\n",
    "            states.append(current_state)\n",
    "            emission.append(next_emission)\n",
    "            \n",
    "        return emission, states\n",
    "    \n",
    "    def probability_alphas(self, x):\n",
    "        '''\n",
    "        Finds the maximum probability of a given input sequence using the forward algorithm.\n",
    "        \n",
    "        Arguments:\n",
    "        x: Input sequence in the form of a list of length M, \n",
    "        consisting of integers ranging from 0 to D-1.\n",
    "        \n",
    "        Returns: \n",
    "        prob: Total probability that x can occur \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # Calculate alphas vectors. Runs the forward algorithm\n",
    "        alphas = self.forward(x)\n",
    "        \n",
    "        \n",
    "        # alpha_j(M) gives the probability that the state sequence ends\n",
    "        # in state j. Summing this value over all possible states\n",
    "        # j gives the total probability of x paired with any state\n",
    "        # sequence (ie. the probability of x observation sequence)\n",
    "        \n",
    "        prob = sum(alphas[-1])\n",
    "        return prob\n",
    "    \n",
    "    \n",
    "    def probability_betas(self, x):\n",
    "        '''\n",
    "        Finds the maximum probability of a given input sequence using the \n",
    "        backward algorithm.\n",
    "        \n",
    "        Arguments:\n",
    "        x: Input sequence in the form of a list of length M, consisting of\n",
    "        integers ranging from 0 to D-1.\n",
    "        \n",
    "        Returns:\n",
    "        prob: Total probability that x can occur.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        betas = self.backward(x)\n",
    "        \n",
    "        # beta_j(1) gives the probability that the state sequence starts\n",
    "        # with j. Summing this, multiplied by the starting transition probability \n",
    "        # and the observation probability, over all states gives the total\n",
    "        # probability of x paired with any state sequence (ie. prob of x)\n",
    "        prob = sum([beta[1][j] * self.A_start[j] * self.O[j][x[0]] for j in range(self.L)])\n",
    "        \n",
    "        return prob\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_HMM(X, Y):\n",
    "    '''\n",
    "    Helper function to train a supervised HMM. The function determines \n",
    "    the number of unique states and observations in the given data, \n",
    "    initializes the transition and observation matrices, creates the HMM,\n",
    "    and then runs the training function for supervised learning. \n",
    "    \n",
    "    Arguments: \n",
    "    X: A dataset consisting of input observation sequences in the form of \n",
    "    lists of variable length, consisting of integers ranging from 0 to D-1.\n",
    "    In other words, a list of lists. \n",
    "    \n",
    "    Y: A dataset consisting of state sequences in the form of lists of \n",
    "    variable length, consisting of integers ranging from 0 to L-1. In other words, \n",
    "    a list of lists. Note that the elements in X line up with those in Y.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Make a set of observations\n",
    "    observations = set()\n",
    "    for x in X:\n",
    "        observations |= set(x) # Concatenate sets\n",
    "        \n",
    "    # Make a set of states\n",
    "    states = set()\n",
    "    for y in Y:\n",
    "        states |= set(y)\n",
    "        \n",
    "    # compute L and D\n",
    "    L = len(states)\n",
    "    D = len(observations)\n",
    "    \n",
    "    # Randomly initialize and normalize matrix A.\n",
    "    A = [[random.random() for i in range(L)] for j in range(L)]\n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        norm = sum(A[i])\n",
    "        for j in range(len(A[i])):\n",
    "            A[i][j]/=norm\n",
    "    \n",
    "    # Randomly initialize and normalize matrix O.\n",
    "    O = [[random.random() for i in range(D)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(O)):\n",
    "        norm = sum(O[i])\n",
    "        for j in range(len(O[i])):\n",
    "            O[i][j] /= norm\n",
    "\n",
    "    # Train an HMM with labeled data.\n",
    "    HMM = HiddenMarkovModel(A, O)\n",
    "    HMM.supervised_learning(X, Y)\n",
    "\n",
    "    return HMM\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_HMM(X, n_states, N_iters):\n",
    "    '''\n",
    "    Helper function to train an unsupervised HMM. The function \n",
    "    determines the number of unique observations in the given data, \n",
    "    initializes the transition and observation matrices, creates\n",
    "    the HMM, and then runs the training function for unsupervised learning.\n",
    "    \n",
    "    Arguments:\n",
    "    X: A dataset consisting of input sequences in the form of lists of variable length, \n",
    "    consisting of integers ranging from 0 to D-1. In other words, a list of lists.\n",
    "    \n",
    "    n_states: Number of hidden states to use in training. \n",
    "    \n",
    "    N_iters: The number of iterations to train EM on. \n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Make a set of observations.\n",
    "    observations = set()\n",
    "    for x in X:\n",
    "        observations |= set(x)\n",
    "    \n",
    "    # Compute L and D.\n",
    "    L = n_states\n",
    "    D = len(observations)\n",
    "\n",
    "    # Randomly initialize and normalize matrix A.\n",
    "    A = [[random.random() for i in range(L)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        norm = sum(A[i])\n",
    "        for j in range(len(A[i])):\n",
    "            A[i][j] /= norm\n",
    "    \n",
    "    # Randomly initialize and normalize matrix O.\n",
    "    O = [[random.random() for i in range(D)] for j in range(L)]\n",
    "\n",
    "    for i in range(len(O)):\n",
    "        norm = sum(O[i])\n",
    "        for j in range(len(O[i])):\n",
    "            O[i][j] /= norm\n",
    "\n",
    "    # Train an HMM with unlabeled data.\n",
    "    HMM = HiddenMarkovModel(A, O)\n",
    "    HMM.unsupervised_learning(X, N_iters)\n",
    "\n",
    "    return HMM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sparsities(hmm, O_max_cols=50, O_vmax=0.1):\n",
    "    plt.close('all')\n",
    "    plt.set_cmap('viridis')\n",
    "\n",
    "    # Visualize sparsity of A.\n",
    "    plt.imshow(hmm.A, vmax=1.0)\n",
    "    plt.colorbar()\n",
    "    plt.title('Sparsity of A matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize parsity of O.\n",
    "    plt.imshow(np.array(hmm.O)[:, :O_max_cols], vmax=O_vmax, aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title('Sparsity of O matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,1,0], [1,1,1], [0,0,1]])\n",
    "n_states = 2\n",
    "N_iters = 100\n",
    "\n",
    "test_unsuper_hmm = unsupervised_HMM(X, n_states, N_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A matrix [[0.12283960871914909, 0.21055284195613141], [0.2103763529352866, 0.12289788484148952]]\n",
      "O matrix [[0.49999936527955746, 0.5000006347204425], [0.5000006345232726, 0.49999936547672746]]\n",
      "random emission ([0, 0, 0, 1, 0, 1, 0, 1, 1, 1], [1, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print('A matrix', test_unsuper_hmm.A)\n",
    "print('O matrix', test_unsuper_hmm.O)\n",
    "\n",
    "print('random emission', test_unsuper_hmm.generate_emission(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
